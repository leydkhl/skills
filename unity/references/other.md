# Unity - Other

**Pages:** 992

---

## Get available leaderboard versions

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-available-leaderboard-version

**Contents:**
- Get available leaderboard versions#

If the leaderboard resets and existing scores are archived, this call returns the current leaderboard versionId, and a list of archived versions in reverse chronological order. For example, the first entry is the archived version containing the most recent scores.

If you have a scheduled reset configured on your leaderboard, this method also returns the next time that the leaderboard resets based on your schedule as the nextReset property.

Use the GetVersionsAsync method below to get a list of available leaderboard versions:

Retrieving a set of the most recent versions only is available with the GetVersionsOptions object with the optional Limit pagination argument.

Limit is the number of leaderboard scores to return, starting with the most recent. Defaults to null and returns all versions.

**Examples:**

Example 1 (unknown):
```unknown
GetVersionsAsync
```

Example 2 (unknown):
```unknown
public async void GetLeaderboardVersions(string leaderboardId)
{
    var versionsResponse = await LeaderboardsService.Instance
        .GetVersionsAsync(leaderboardId);

    // Get the ID of the most recently archived Leaderboard version
    var versionId = versionsResponse.Results[0].Id;

    Debug.Log(JsonConvert.SerializeObject(versionsResponse.Results));
}
```

Example 3 (unknown):
```unknown
public async void GetLeaderboardVersions(string leaderboardId)
{
    var versionsResponse = await LeaderboardsService.Instance
        .GetVersionsAsync(leaderboardId);

    // Get the ID of the most recently archived Leaderboard version
    var versionId = versionsResponse.Results[0].Id;

    Debug.Log(JsonConvert.SerializeObject(versionsResponse.Results));
}
```

Example 4 (unknown):
```unknown
GetVersionsOptions
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/desktop-app

---

## ATTRIBUTE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/attribute

**Contents:**
- ATTRIBUTE#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to manage attributes.

cm attribute | att <command> [options]

cm attribute <command> --usage

cm attribute <command> --help

cm attribute create status

cm attribute set att:status br:/main/SCM105 open

cm attribute unset att:status br:/main/SCM105

cm attribute delete att:status

cm attribute rename att:status "buildStatus"

cm attribute edit att:status "Status of the task in the CI pipeline"

**Examples:**

Example 1 (unknown):
```unknown
cm attribute | att <command> [options]
```

Example 2 (unknown):
```unknown
cm attribute <command> --usage
```

Example 3 (unknown):
```unknown
cm attribute <command> --help
```

Example 4 (unknown):
```unknown
cm attribute create status
```

---

## Use case sample: Tune game difficulty level for individual player

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/use-cases/tune-game-difficulty

**Contents:**
- Use case sample: Tune game difficulty level for individual player#
- Prerequisites#
  - Authenticate using a Service Account#
  - Configure the UGS CLI#
  - Set up Leaderboards#
- Examine events#
  - Cloud Save: Key Saved#
  - Leaderboards: Score Submitted#
  - Authentication: Signed up#
- Initialize Cloud Save data for new players on sign-up#

This sample shows how you can use Triggers to tune your game difficulty level based on player data in Cloud Save and scores in Leaderboards.

WARNING: To follow this sample, you need to use 1.7.1 or above of the UGS CLI, so that you have the required features for Triggers. Otherwise, the configurations don't deploy with filters.

Note: This sample uses a Cloud Code module due to the complexity of the use case.

The sample uses the key-saved event emitted by the Cloud Save service, the score-submitted event emitted by the Leaderboards service, and the signed-up event emitted by the Authentication service.

The sample uses the player data in Cloud Save to track the player's progress, and uses the scores in Leaderboards to track the player's skill level. The sample uses the player's progress and skill level to tune the individual game difficulty level for the player.

This sample contains multiple triggers that affect the game difficulty level in different ways:

The trigger uses a filter to evaluate the event payload to only trigger the Cloud Code logic when certain Cloud Save keys update.

First, you need to create a service account with the required access roles.

Before you can call the Triggers service, you must authenticate using a Service Account.

Add Product roles and create a key:

For more information, refer to Authentication.

Follow the steps below to get started with the UGS CLI:

Configure your Project ID and Environment as such:

ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Authenticate using the Service account you created earlier. Refer to Get Authenticated.

To follow this sample, you need to create a leaderboard. If you haven't used Leaderboards before, refer to Get started with Leaderboards.

You can use the UGS CLI to deploy the following leaderboard.lb file. The file defines a leaderboard with ascending sort order and keeps the best score. The file name corresponds to the leaderboard ID.

Use the UGS CLI tool to deploy the file:

Now that you have created a leaderboard, you can add scores to it. Note down the Leaderboard ID.

The use case uses the following events:

The events pass the event payload to Cloud Code as parameters.

The Cloud Save service emits the key-saved event when a key updates in Cloud Save.

The event payload contains the following information:

For more information, refer to Cloud Save: Key Saved.

Leaderboards emits the score-submitted event when a score is submitted to a Leaderboard.

The event payload contains the following information:

For more information, refer to Leaderboards: Score Submitted.

The Authentication service emits the signed-up event when a player signs up.

The event payload contains the following information:

For more information, refer to Authentication: Signed up.

To track player progress, you need to initialize the Cloud Save data for new players. To initialize the data, you can use the Authentication: Signed up event and trigger a Cloud Code module endpoint.

Create a Cloud Code module containing the function that initializes the Cloud Save data for new players:

Create a Config class to store the player's data in Cloud Save.

The class contains a PlayerConfig class that defines the player's data structure in Cloud Save.

Create a TuneGameDifficulty class to initialize the Cloud Save data for new players. The class contains a function InitializeNewPlayer that is triggers when a player signs up. The class relies on the Config class to initialize the player's data in Cloud Save.

Now you have a module that can trigger when a player signs up.

Now that you have a module to initialize the Cloud Save data for new players, you can configure the triggers.

WARNING: To follow this sample, you need to use 1.7.1 or above of the UGS CLI, so that you have the required features for Triggers. Otherwise, the configurations don't deploy with filters.

Run the new-file command to create a trigger configuration locally:

The triggers-config.tr file stores the trigger configurations for deployment using the UGS CLI.

Add a trigger configuration to the triggers-config.tr file to trigger the InitializeNewPlayer function when a player signs up:

This configuration consumes the Authentication: Signed up event emitted by the Authentication service.

Refer to Use case sample: Initialize Cloud Save data for new players on sign-up for more information.

To tune the game difficulty level, you need to create multiple triggers that are triggered by different events. The triggers use filters to evaluate the event payload to only trigger the Cloud Code logic when the defined filter criteria are met.

You can customize the filter criteria based on your game design. For instance, you can trigger Cloud Save events only on certain value ranges.

Add the following trigger configurations to the triggers-config.tr file:

Use the UGS CLI tool to deploy the configuration:

You should get a response similar to the following:

Create a Cloud Code module containing all the functions that increase the game difficulty level for every trigger.

Add a MultplierConfig class to the module. The class defines the default values for the difficulty modifiers. The sample uses the multipliers to calculate the new values for each difficulty level on triggers. You can use this class to customize the difficulty modifiers based on your game design.

Add a class DifficultyTriggerHandler to the module to define the logic for each trigger. The class contains a function for each trigger.

Now the module contains all the functions that increase the game difficulty level for every trigger.

Define a class PlayerConfigManagement to add helper methods.

You can use the helper methods to manipulate the player's data in Cloud Save and fire events. You can also use the helper method to submit a score to the leaderboard.

You can use the ChangeDifficulty method to reset the player's data in Cloud Save to default values when the player requests a manual difficulty change. Note that this method is not associated with a trigger. You can call this method from your game client.

Note: You can use Access Control to restrict access to the ChangeDifficulty and ensure that only authorized users can call the method.

Deploy the Cloud Code module containing the functions that increase the game difficulty level for every trigger. Refer to Deploying Hello World to learn how to deploy a module.

Note: If you want to deploy the module with the same Service Account, don't forget to add the additional Service Account role of Cloud Code Editor.

To test the use case you can trigger the events that are associated with the triggers.

For API requests, you need to use the Bearer token as the value for the Authorization header. Refer to Authentication to authenticate as a player or a trusted client using a service-account or a stateless token. Use the received token as a bearer token for HTTP authentication in the request header.

For instance, you can use the cURL command below to submit a score to the leaderboard to trigger the TriggerOnHighSkill function:

You can also update the player's data in Cloud Save to trigger other functions. For instance, to trigger the TriggerOnSessionsPlayed function, call the UpdatePlayerStats function with the SessionsPlayed key:

Note: If you are testing the Cloud Save events through a Cloud Code script, you must define the parameter type as number. With no specific type defined, the parameter is passed as a string and the filter evaluation fails.

Note: In a real game scenario, to trigger the functions, you call the endpoints from your game client based on the player's actions. For more information on how to run the functions, refer to Run modules.

To validate the changes to Cloud Save data, you can inspect the player's Cloud Save data in the Unity Dashboard.

**Examples:**

Example 1 (unknown):
```unknown
score-submitted
```

Example 2 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 3 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 4 (unknown):
```unknown
leaderboard.lb
```

---

## Google Play data safety section for Economy

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/GoogleDataSafety

**Contents:**
- Google Play data safety section for Economy#
- Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Unity Ads. For your convenience, Unity Ads provides information on its data collection practices in the following sections.

Important: The data disclosures below are for this service only. You are also responsible for providing any additional disclosures for your app, including other third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

---

## Delete accounts

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/delete-accounts

**Contents:**
- Delete accounts#

To give your players more control over their personal data, you can provide a way to delete their own account by using the DeleteAccountAsync() API. This permanently deletes the player’s account. You should inform and prompt the player before calling this API.

Offering this option is a requirement for iOS applications as part of the App Store Review Guideline 5.1.1.

Note: DeleteAccountAsync() only deletes the player’s Unity Authentication account. Upon such a deletion request, you must delete all associated player data connected to the player’s Unity Authentication account and other UGS services you use.

**Examples:**

Example 1 (unknown):
```unknown
DeleteAccountAsync()
```

Example 2 (unknown):
```unknown
DeleteAccountAsync()
```

---

## LOCK

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/lock

**Contents:**
- LOCK#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

This command allows the user to manage locks.

cm lock <command> [options]

cm lock <command> --usage

cm lock <command> --help

(The 'list' subcommand is the default.)

cm lock list --anystatus

cm lock unlock itemid:56@myrep@localhost:8084

cm lock create /main/task@myrep itemid:56@myrep

**Examples:**

Example 1 (unknown):
```unknown
cm lock <command> [options]
```

Example 2 (unknown):
```unknown
cm lock <command> --usage
```

Example 3 (unknown):
```unknown
cm lock <command> --help
```

Example 4 (unknown):
```unknown
cm lock list --anystatus
```

---

## Cloud Save Queries

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/concepts/queries

**Contents:**
- Cloud Save Queries#
- Index creation#
- Query types#
- Random sampling#
- Limits#
  - Limits on queries#
  - Limits on indexes#
- Additional resources#

You can use Cloud Save to query both numerical and text data stored in Player Data and Game Data.

You can use queries for many purposes, such as to create a guild or clan system, add matchmaking, implement an economy system or auction house, or return data for NPCs or items in a multiplayer environment.

You need to index data in Cloud Save before you can query it. You can create and manage indexes in the Unity Dashboard, the Unity CLI or the Admin REST API.

You can form indexes of individual Cloud Save keys, or combine multiple keys in a specific order to form a compound index. Cloud Save marks each key with a boolean to specify if the index is sorted in ascending or descending order. There is no additional charge for you to use indexes.

The following types of queries are supported in Cloud Save:

Cloud save compares values to the indexed value, lexicographically for string data, numerically for numerical data.

Cloud Save allows you to return a random sample of results for a query, if you don't want to return the full sorted result set which you can paginate over (the default behavior).

To use this feature, pass the sampleSize option when you perform a query and specify the maximum number of results you want Cloud Save to return.

You can use sampling for use cases such as to display a selection of possible guilds for a player to join, or to randomly match two players with similar statistics.

The data that you can query from a client or server is defined by the Access Class of the key that is indexed:

Using the Cloud Save SDK for Unity, a game client can query Player Data in the Public Access Class or query Game Data stored in the Default Access Class.

Using the Cloud Save SDK for Cloud Code, or by using the CLI or Admin REST API, you can query for an indexed key in any Access Class (for example, Default, Public, Private or Protected).

The maximum size of a value that you can index is 128 bytes:

Values greater than 128 bytes don't index; if you attempt to write values greater than 128 bytes to an indexed key,the index fails (the data still saves to Cloud Save but the data isn't indexed).

You can define up to 20 keys that you can index across all indexes and across all access classes and across Player State and Game State.

This means that you can have up to 20 indexes with a single indexed key, or a single index with 20 keys, or any combination in between so long as the total number of indexed keys does not exceed the limit.

Important: You can only query data that you save after you create the index. Query resposes don't include any data you save before you create the index.

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/get-started-toc

**Contents:**
- Get started#

Follow the listed guides to set up the Vivox Core SDK.

The quick start guide is recommended for those who are already familiar with Vivox or have planned out their communication implementation already. Or if you want to jump into the process and figure it out as you go.

If you’re new to Vivox, or haven’t begun thinking about how communications will work in your game, it’s recommended that you review the full Integration guide. This will provide guidance on what’s most important for an efficient Vivox integration as well as details you may not have considered yet.

---

## Gluon workspaces

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/gluon-workspaces

**Contents:**
- Gluon workspaces#

Learn how Gluon displays your workspace and how to manage your workspace.

A workspace is your working directory that contains the project files you create, modify, and delete.

---

## Use Gitserver with partial replicas

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gitserver/gitserver-partial

**Contents:**
- Use Gitserver with partial replicas#
- Partial replicas aren’t visible to GitHub#
- Unlinked branches aren’t visible to GitHub#
  - Force map unlinked branches#
- Xlinks with Gitserver#
  - Force GitServer to ignore missing xlinks#

Unity Version Control (UVCS) supports partial replicas, which don’t map to GitHub. Avoid or work around issues in mixed GitHub and UVCS scenarios.

Ensure that GitHub mappings only calculate when the correct branches are in the UVCS repository.

When GitServer indexes new changesets, it creates GitHub mappings. GitServer ignores any pushes that can alter the SHA of a changeset and potentially break synchronization with GitHub repositories that have already pulled a changeset.

For example, the following screenshot shows that you can push changeset 10, even if changeset 9 on branch 001 hasn't been pushed. GitServer recalculates the GitHub mappings without including branch 001. If you later push the branch 001, GitHub will ignore it because it's not part of the GitHub mappings:

Because GitHub doesn’t allow partial replicas, any branches that don’t have a parent branch that links them to the main branch aren’t visible to GitHub:

Similarly, any merges to main from unlinked branches are ignored.

To make a branch available to GitHub even if it doesn’t have a parent branch or the changesets don’t meet the required conditions, add add branch.toForceMap entries in your gitserver.conf file as follows:

Gitserver ignores changesets with unresolved Xlinks so they aren’t visible to GitHub clients. For example, if you have a branch main@root that contains an Xlink to main@xlink, but in changeset 15 on the root branch, the Xlink points at a changeset that isn’t replicated yet:

This means that GitServer ignores changeset 15 until the changeset you replicate the changeset it Xlinks to.

To configure GitServer to skip missing Xlinks and allow synchronization with GitHub even if you lose some content, add unresolvedxlink.skip=true to your gitserver.conf file as follows:

**Examples:**

Example 1 (unknown):
```unknown
add branch.toForceMap
```

Example 2 (unknown):
```unknown
gitserver.conf
```

Example 3 (unknown):
```unknown
# branches which changesets are made visible
# although they have unlinked merge sources
branch.toForceMap=/main
```

Example 4 (unknown):
```unknown
# branches which changesets are made visible
# although they have unlinked merge sources
branch.toForceMap=/main
```

---

## Invite team members

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/invite-members

**Contents:**
- Invite team members#
- Assign a seat#
- Additional resources#

The free plan of Unity Version Control allows three team members to join a Unity Version Control Organization and work together on the same project. To add more seats, you need to upgrade your plan.

Note: You count as one of the three seats on the free trial. For more information about seats, refer to seat management.

To invite someone to join a project:

---

## Get joined lobbies

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/get-joined-lobbies

**Contents:**
- Get joined lobbies#

If players need to determine their current lobby membership, they can use the GetJoinedLobbies API. This API returns a list of lobby IDs for the lobbies that the active player is currently a member of.

One common use for GetJoinLobbies is handling unexpected disconnects. If a game crashes or the user disconnects from a lobby for any reason, you can use this API to get a list of all lobbies a player is a member of and then use the GetLobby API to retrieve the full lobby details or Reconnect to lobby.

Note: You can't get a private lobby unless you're a member of the lobby.

The following code sample shows how to get a player’s joined lobbies:

**Examples:**

Example 1 (unknown):
```unknown
try
{
        var lobbyIds = await LobbyService.Instance.GetJoinedLobbiesAsync();
}
catch (LobbyServiceException e)
{
        Debug.Log(e);
}
```

Example 2 (unknown):
```unknown
try
{
        var lobbyIds = await LobbyService.Instance.GetJoinedLobbiesAsync();
}
catch (LobbyServiceException e)
{
        Debug.Log(e);
}
```

---

## Integrate using C++

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/unreal-engine-sdk/integrate-using-cpp

**Contents:**
- Integrate using C++#
  - Add the Matchmaker SDK as a dependency#
  - Matchmaker Client Subsystem#
    - CreateTicket#
    - GetTicketStatus#
    - DeleteTicket#
  - Matchmaker Server Subsystem#
    - CreateBackfillTicket#
    - ApproveBackfillTicket#
    - DeleteBackfillTicket#

The following section shows how to integrate with the Matchmaker SDK using the Unreal Engine Subsystems.

The Unity Gaming Services SDK offers two matchmaker interfaces:

Matchmaker Client Subsystem

Matchmaker Server Subsystem

Before continuing, add the MatchmakerSDK as a public dependency of your module, then include the plugin header files in your classes as shown below.

Add MatchmakerServer and MatchmakerClient to your module's dependencies to your Unreal project build file (YourProjectName.Build.cs):

Include the plugin header files you want to access in your classes:

Note: Before accessing the Matchmaking Client Subsystem, ensure that you set up Authentication.

The Matchmaker Client Subsystem controls the client portion of matchmaking and finding matches. This includes creating, deleting, and polling matchmaking tickets.

You can access the Matchmaker Client Subsystem by getting a reference to the UMatchmakerClientSubsystem subsystem. UMatchmakerClientSubsystem is a UGameInstanceSubsystem you can retrieve from UGameInstance.

Use the CreateTicket() method to start the matchmaking process by creating a matchmaking ticket for the clients.

Calling this method adds all valid players in the Players array to the matchmaking queue as a group and joins a match as part of the same team.

There are multiple parameters you can pass in, but the only required parameter is the Players list (with a minimum of one player using a valid ID). Other optional parameters include Queue Name, Qos Results, and custom data for players.

You can handle the response from the SDK using THandler which accepts a FCreateTicketResponse.

Poll for a client's ticket status against the matchmaker service by using the GetTicketStatus() method.

You should poll continuously in a loop until you retrieve a response indicating either a success or failure of the matchmaking process.

To achieve this, use FTimerDelegate to start a timer as in the following example:

Then your poll match function would look similar to the following example:

You can handle the response from the SDK using a THandler which accepts a FGetTicketStatusResponse.

Use the DeleteTicket() method to delete a matchmaking ticket and cancel matchmaking. This is typically done after a match is found (successfully or not) or when a client no longer wants to be considered for the matchmaking process.

You can handle the response from the SDK in a response handler which accepts a FDeleteTicketResponse.

You can handle the response from the SDK using a THandler which accepts a FDeleteTicketResponse.

The Matchmaker Server Subsystem controls the server portion of matchmaking. This includes creating, approving, deleting, and updating backfill tickets.

Before you can use the UMatchmakerServerSubsystem, you must retrieve it as shown in the following code snippet:

Note: Matchmaker is at the time of writing expected to be used solely with Multiplay Servers and as such it is important to note that the following server functions are expected to be used with some of the Multiplay SDK functionality.

See Allocation Payload for more details (access with GetPayloadAllocation() with Multiplay’s Subsystem). This is used to initially fill MatchProperties.

You need to create a new backfill ticket when a player or players leave a full match, and the server needs to fill in the empty slots. To create a new backfill ticket for the server, use the CreateBackfillTicket() method.

The following code snippet shows how to create a new backfill ticket:

You can handle the response from the SDK using a THandler which accepts a FCreateBackfillTicketResponse.

To approve a backfill ticket after creation, use the ApproveBackfillTicket() method. Approving a backfill ticket allows new players into the server.

It's recommended to approve backfill tickets no faster than once a second. The Unity Matchmaker deletes tickets if they haven’t been approved in 20 seconds.

The following code snippet shows how to approve a backfill ticket:

You can handle the response from the SDK using a THandler which accepts a FApproveBackfillTicketResponse.

Delete a backfill ticket when a match becomes full, and you no longer need the server to accept new players. You should also do this after a match concludes and you no longer want the server to receive new players. To stop backfilling on a server, use the DeleteBackfillTicket() method.

The following code snippet shows how to delete a backfill ticket:

You can handle the response from the SDK using a THandler which accepts a FDeleteBackfillTicketResponse.

To update a server's current backfill ticket, use the UpdateBackfillTicket() method.

Update a backfill ticket anytime a player leaves the server or anytime a player joins the server from outside of matchmaking logic. This can include (but isn't limited to) party invites, direct connections, and friend invites.

You should update backfill tickets no more than once every three seconds or after an approved backfill ticket sees a change in the backfill ticket to ensure that a matchmaking cycle has passed. Updating a backfill ticket too often can cause players to never backfill into the match. See Matchmaking Logic Sample to learn more.

**Examples:**

Example 1 (unknown):
```unknown
MatchmakerSDK
```

Example 2 (unknown):
```unknown
MatchmakerServer
```

Example 3 (unknown):
```unknown
MatchmakerClient
```

Example 4 (unknown):
```unknown
YourProjectName.Build.cs
```

---

## SHOWACL

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/showacl

**Contents:**
- SHOWACL#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Shows the ACL of an object.

cm showacl | sa <object_spec> [--extended] [--xml[=<output_file>]] [--encoding=<name>]

cm showacl repserver:PlasticServer:8084

(Shows the ACL of the selected server.)

cm sa br:/main --extended

(Shows the ACL hierarchy tree of the selected branch specification.)

**Examples:**

Example 1 (unknown):
```unknown
cm showacl | sa <object_spec> [--extended] [--xml[=<output_file>]] [--encoding=<name>]
```

Example 2 (unknown):
```unknown
cm showacl repserver:PlasticServer:8084
```

Example 3 (unknown):
```unknown
cm sa br:/main --extended
```

---

## Synchronization of player names in a session

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/player-name-integration-session

**Contents:**
- Synchronization of player names in a session#
- Enable player name sync in session options#
- Read player names from the session#
- Additional resources#

Expose and read player display names as session player properties in order to allow all players to view each other’s names.

When a player is authenticated through the Authentication service, you can write the player's name into the session as a player property, and update it during the session lifecycle.

You can achieve this functionality using the following two extension methods:

Use WithPlayerName to synchronize the player's authenticated name into the session with a chosen visibility. The following example demonstrates how to enable player-name synchronization on session creation:

Note: Use VisibilityPropertyOptions.Member or VisibilityPropertyOptions.Public so other players can read the name. Use VisibilityPropertyOptions.Private if you don't want names to be visible to others. In that case, other players’ GetPlayerName() calls return null.

Use GetPlayerName to retrieve the synchronized name from any player’s properties.

If a name isn’t available for any reason, GetPlayerName() returns null. For example, a name might be unavailable because the player hasn’t set a name, or the property isn't visible.

The player must be signed in and have a player name available via the Authentication service. Synchronization occurs while the session is connected. Updates made while disconnected won’t propagate until reconnected.

**Examples:**

Example 1 (unknown):
```unknown
WithPlayerName(VisibilityPropertyOptions visibility)
```

Example 2 (unknown):
```unknown
GetPlayerName()
```

Example 3 (unknown):
```unknown
WithPlayerName
```

Example 4 (unknown):
```unknown
var myPlayerName = "CustomName";
await UnityServices.InitializeAsync();
await AuthenticationService.Instance.SignInAnonymouslyAsync();
await AuthenticationService.Instance.UpdatePlayerNameAsync(myPlayerName);

// Configure your session and enable name sync (member visibility makes it readable by other members)
var sessionOptions = new SessionOptions
{
    MaxPlayers = 4,
    Type = "Session"
}.WithPlayerName(VisibilityPropertyOptions.Member);
```

---

## Join a lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/join-a-lobby

**Contents:**
- Join a lobby#
- Join by specifying a lobby ID#
- Join by providing a lobby code#
- Join a password-protected lobby#

Players can specify a lobby ID or provide a lobby code to join a lobby. Lobby codes are short, auto-generated codes that map to specific lobbies and are intended for players to share with each other. The lobby code for a lobby is available as a members-only lobby property.

The Lobby service provides the best experience when requests are minimized. The Join API supports passing in player data as part of the Join call, so it's best to do that rather than making a Join call followed by a separate Update Player call after you've joined the lobby.

The following code sample shows how to join a lobby by specifying a lobby ID:

The following code sample shows how to join a lobby with a code:

Some text input packages may append invisible characters to strings from text fields that may result in an invalid join code being passed to the service. You will receive an InvalidJoinCode error with a detailed explanation as to why the code is invalid to help with this sort of error. You should also handle this error to notify users if they've entered an invalid character for a join.

The following code sample shows how to join a password-protected lobby with an ID or code:

Some text input packages may append invisible characters to strings from text fields that may result in an invalid password being passed to the service. The service is unable to determine whether these invisible characters are intentional or not so it may be impossible to differentiate this from a valid IncorrectPassword error. Be sure to verify that the password being sent in the request is the exact string you expect. The Join Lobby by Code API is able to provide more detailed information for errors like this so you may be able to verify the behavior of your UI using that API first.

**Examples:**

Example 1 (unknown):
```unknown
try
{
    Lobby joinedLobby = await LobbyService.Instance.JoinLobbyByIdAsync("lobbyId");
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

Example 2 (unknown):
```unknown
try
{
    Lobby joinedLobby = await LobbyService.Instance.JoinLobbyByIdAsync("lobbyId");
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

Example 3 (unknown):
```unknown
try
{
    Lobby joinedLobby = await LobbyService.Instance.JoinLobbyByCodeAsync("lobbyCode");
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

Example 4 (unknown):
```unknown
try
{
    Lobby joinedLobby = await LobbyService.Instance.JoinLobbyByCodeAsync("lobbyCode");
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

---

## Standard Events

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/standard-events

**Contents:**
- Standard Events#

Standard Events are events that are ready to use without the need for instrumentation or developer configuration. Unity Analytics SDK sends some of these events automatically, but you need to populate and record others manually at an appropriate point in your game's lifecycle. These are used by out-of-the-box dashboards and in the Data Explorer.

Standard events are triggered when players perform key actions. You can find out things like: How engaged are your players? What are your best performing countries? Which audiences are underperforming?

The available standard events are:

**Examples:**

Example 1 (unknown):
```unknown
aquisitionSource
```

Example 2 (unknown):
```unknown
gameStarted
```

Example 3 (unknown):
```unknown
clientDevice
```

Example 4 (unknown):
```unknown
gameRunning
```

---

## REPOSITORY LIST

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/repository-list

**Contents:**
- REPOSITORY LIST#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Output format parameters (--format option)#
    - The output parameters of this command are the following#
  - Examples#

Lists the repositories on a server.

cm repository | repo [list | ls] [<repserverspec>] [--format=<str_format>]

This command accepts a format string to show the output.

If the format parameter value is 'TABLE', the output will be printed using a table format with the {repid}, {repname} and {repserver} fields.

(Lists all repositories.)

cm repository list localhost:8084 --format="{1, -20} {3}"

(Writes the repository name in 20 spaces, aligned to left, then a blank, and then the repository owner.)

cm repository ls localhost:8084 --format="{repname, -20} {repowner}"

(Writes the same as the previous example.)

cm repo ls localhost:8084 --format=TABLE

(Writes the list of repositories using a table format with the following fields: repository id, repository name, and repository server name.)

**Examples:**

Example 1 (unknown):
```unknown
cm repository | repo [list | ls] [<repserverspec>] [--format=<str_format>]
```

Example 2 (unknown):
```unknown
cm repository
```

Example 3 (unknown):
```unknown
cm repository list localhost:8084 --format="{1, -20} {3}"
```

Example 4 (unknown):
```unknown
cm repository ls localhost:8084 --format="{repname, -20} {repowner}"
```

---

## 

**URL:** https://docs.unity.com/ugs/manual/leaderboards/manual/leaderboards

---

## Funnels

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/introducing-funnels

**Contents:**
- Funnels#
- What are funnels?#
- When to use funnels?#
- What are some popular funnels?#
  - Tutorial completion#
  - Level progression#
  - Feature discoverability#
  - First and further purchases#
  - Audience conversion#
  - Offer impression#

Designing a new game with new features combines assumptions about your players. Using previous knowledge and best practices is good, but it's recommended you check those assumptions with data and that's where funnels come in. This type of report can highlight pain points in your experience that can be improved to increase retention and revenue.

Use funnels to visualize the user flow and journey through your game. Define ordered steps to analyze how many users go from beginning to end, and also how long it takes for users to go from one step to another. The Funnels tool includes:

We recommend using funnels to verify all assumptions based on user journey and time spent in-game to reach a specific point. The assumptions can range from:

Funnels can also be used quickly answer questions about player behavior:

Funnels can be used to validate a large number of assumptions. You need to track the right events and parameters to challenge your assumptions. Refer to Events for more information on tracking, and then you can follow Create a funnel to get started.

Tutorial completion is one of the most common funnels. As the tutorial is one of the first things players see in the game, your players will decide if the core gameplay is what they want out of your game. Measuring tutorial completion through a funnel will help you identify if some steps in your tutorial are unclear, too difficult, or take longer to achieve than expected. This is usually a sequence of "step completed" events.

The level progression funnel is a basic visualization to see how players flow through your main progression mechanic. This can be a player level (RPG), a level completion (puzzle), or whatever suits your game design. This funnel will help you understand if a particular level is too difficult or takes long to complete and is where you lose most of your players. This is usually a sequence of "level up" or "level completed" events.

The feature discoverability funnel challenges UX assumptions, from character ability usage, gear equipping, and page visits. Though some features might be presented in tutorials, some players might forget about them or find them unhelpful to progress. Funnels can check if players go on to use a feature regularly after learning about it.

The first and further purchases funnel helps you understand how many players convert from non-paying to paying users, and how many players got enough value from the first purchase to buy again. This is usually a sequence of the transaction events where the realCurrency parameter is greater than 0. This funnel can also be applied to ads consumption with a sequence of adImpression events.

Use the audience conversion funnel to target audiences with specific offers to understand how sequences of offers are converting. Tune your offer campaigns and adjust the price and rewards of each offer to get the conversion you're targeting. This funnel is a sequence of your offer names that you expect your audience to buy.

The offer impression funnel is used for in-app purchasing on your shop page and also on popup offers. Choose the time for these offers using rules to ensure you're displaying the right offer at the right time to the right audience. Use the offer impression funnel to verify that offers are shown enough and are converting correctly.

**Examples:**

Example 1 (unknown):
```unknown
transaction
```

Example 2 (unknown):
```unknown
realCurrency
```

Example 3 (unknown):
```unknown
adImpression
```

---

## Unreservation flow

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/beta/unreservation-flow

**Contents:**
- Unreservation flow#

Warning: This feature is in closed beta and accessible by permission only.

Similarly to deallocations, Multiplay Hosting must know when a game server that's using the reservation model is no longer in use to return that server back to the available pool.

The following steps outline the unreservation process.

---

## Input

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/input

**Contents:**
- Input#

UVCS sends information related to the executing operation to the trigger script. UVCS uses the following two approaches:

---

## SHELVESET

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/shelveset

**Contents:**
- SHELVESET#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to manage shelvesets.

cm shelveset <command> [options]

cm shelveset <command> --usage

cm shelveset <command> --help

cm shelveset create -c="my comment"

cm shelveset delete sh:3

cm shelveset apply sh:3

**Examples:**

Example 1 (unknown):
```unknown
cm shelveset <command> [options]
```

Example 2 (unknown):
```unknown
cm shelveset <command> --usage
```

Example 3 (unknown):
```unknown
cm shelveset <command> --help
```

Example 4 (unknown):
```unknown
cm shelveset create -c="my comment"
```

---

## Command batching

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/CommandBatching

**Contents:**
- Command batching#
- Prerequisites#
- Overview#
  - Initialization#
  - Functionality#
    - Player turns#
    - Gave over#
- Setup#
  - Requirements#
  - Unity Cloud services configuration#

Command batching is the concept where each game action is a Command which can be collected into a queue to be sent to the server in batches for processing. Command batching optimizes your game’s bandwidth to be as energy efficient as possible, and prevent poor performance due to frequent server calls or rate limiting. This provides a smoother game experience with less downtime.

In this sample, the player has a fixed number of turns. Each simulated action generates a command that is cached, then executed by the server as part of a batch at the end of the game, thereby reducing the number of calls to the server.

For example, consider a game that distributes rewards after every action by calling Cloud Save to distribute player XP and Economy to distribute Coins. The player completes the following three actions:

These three actions would result in a minimum of six calls to various Unity Services (in this case, Cloud Save and Economy). However, if all three of these actions are stored as batch commands and processed a single time, the game would only make two Unity Services calls: one to Cloud Save to increase XP by 350, and one to Economy to add 45 Coins.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

To see this use case in action, open the samples menu and navigate to Command Batching. To open this scene directly and interact with the use case:

The CommandBatchingSceneManager.cs script performs the following initialization tasks in its Start function:

In this sample, a single "game" involves making a fixed number of turns, where a single turn is completed by clicking on one of four buttons. Each button represents a simulated action with corresponding rewards. When you click on one of the action buttons, the following occurs:

The button’s OnClick method calls the CommandBatchingSceneManager.cs script, which consumes a turn.

The script then generates a command associated with the action you clicked and sends it to the batch queue for future server processing. Each command uses Remote Config values to map rewards for the corresponding action.

It also calls that action’s associated CommandSystem script to distribute rewards to the client.

Note: Local reward distribution allows players to immediately see the results of the turn, but is not server-authoritative. The server overwrites any local distributions after it validates and processes all commands at the end of the game.

Finally, the calling script checks to see if the player is out of turns, in which case it triggers the game-over condition.

When the player has zero turns remaining, the game is over. The following occurs:

Mapping the rewards in Remote Config allows you to tune them remotely in a single place, affecting both the client-side and server-side distributions simultaneously. The rewards for all commands in the batch are grouped by type, so if multiple commands increase XP, the total XP gains are added up and updated with a single server call to Cloud Save.

Whether or not the Cloud Code script returns success or failure, the client code calls the Unity Services to retrieve their latest data. If the batch was processed successfully by the server, this should result in no visible change to the player's Currency, GoalsAchieved, or XP HUDs, because from their perspective the rewards were distributed immediately during game play. However, if the Cloud Code script failed to process an invalid batch, the client updates the player's status back to what it was before the game was played, overwriting the local state.

Note: This creates a mixed-authoritative game. At certain times, the game relies on the local (client) authority to know the player's stats and currency balances. However, the server ultimately has final authority on the player's state. While this mixed-authority setup is not appropriate for all game styles, it can be very useful for others, such as turn-based, single-player, infinite runner, and puzzle games. Command batching can also be a good starting point when developing a solution for offline support or bad connection tolerance in games that choose to provide such features.

To replicate this use case, you'll need the following Unity packages in your project:

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys all the necessary items.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Publish the following script in the Unity Dashboard:

An array of command keys. For example:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resources in the Unity Dashboard:

Set up the following config values in the Unity Dashboard:

**Examples:**

Example 1 (unknown):
```unknown
CommandBatchingSample.unity
```

Example 2 (unknown):
```unknown
CommandBatchingSceneManager.cs
```

Example 3 (unknown):
```unknown
CommandBatchingSceneManager.cs
```

Example 4 (unknown):
```unknown
CommandSystem
```

---

## Matchmaker A/B testing

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/ab-testing

**Contents:**
- Matchmaker A/B testing#
- Requirements#
- To set up A/B testing:#
- Troubleshooting#
  - Why aren't my tickets showing up in the variant pool?#
- Limitations#

Finding the right matchmaking rule that provides the best game experience is important for player engagement. A/B testing is a feature that allows you to test, evaluate and optimize matchmaking rules without tampering with game operations or revenue. You can experiment with different matchmaking rule configurations and compare match outcomes.

The A/B testing dashboard displays real-time metrics about how the different matchmaking rules are performing. This data helps you evaluate and decide which ones align with your goals. The dashboard displays retention, engagement and monetization data to give a full picture of each of the matchmaking rule variants. You can also use the dashboard real-time data to tweak the matchmaking rules to best fit your needs.

Note: If the Analytics SDK isn't installed, tickets are silently sent to your pool's primary variant.

To use A/B testing, install the latest SDK package for the following services:

First, check the A/B test result using the following code:

The A/B test result should return an object similar to the following example:

The A/B test result might return null, if the:

In any of these cases, tickets will be sent to your pool's primary variant.

To fix, review the initial steps on this page to validate your configuration.

The current version of Matchmaker A/B Testing does not currently support the following Game Overrides features:

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.multiplayer
```

Example 2 (unknown):
```unknown
com.unity.services.matchmaker
```

Example 3 (unknown):
```unknown
com.unity.services.analytics
```

Example 4 (unknown):
```unknown
var ticketResponse = await MatchmakerService.Instance.CreateTicketAsync(players, options);

object abTestingSerialize = (object)ticketResponse.AbTestingResult;
string abTestingJsonOutput = JsonConvert.SerializeObject(abTestingSerialize, Formatting.Indented);
Debug.Log(abTestingJsonOutput);
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/core-vivox-setup

---

## Get scores

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-score

**Contents:**
- Get scores#

Players can get the scores from a specified leaderboard with the GetScoresAsync method. You should create your leaderboard first and then substitute the leaderboardId for your own ID. By default the method will fetch the top 10 scores:

Paginated access to all scores is available by specifying the optional GetScoresOptions object with the optional Offset and Limit pagination arguments. Offsetis the number of entries to skip when retrieving the leaderboard scores and defaults to 0. Limit is the number of leaderboard scores to return and defaults to 10.

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetScoresOptions configuration object:

For details on how to get available leaderboard version IDs, visit Get available leaderboard version.

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
GetScoresAsync
```

Example 2 (unknown):
```unknown
leaderboardId
```

Example 3 (unknown):
```unknown
public async void GetScores(string leaderboardId)
{
    var scoresResponse = await LeaderboardsService.Instance
        .GetScoresAsync(leaderboardId);
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 4 (unknown):
```unknown
public async void GetScores(string leaderboardId)
{
    var scoresResponse = await LeaderboardsService.Instance
        .GetScoresAsync(leaderboardId);
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

---

## Create a mergebot

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/create-mergebot

**Contents:**
- Create a mergebot#
- Apply the mergebot to a branch#
  - Set attribute through the Cloud dashboard#
  - Set attribute through the desktop client#
  - Set attribute through the CLI#
- Additional resources#

Mergebots automate tasks and merges in your repository. To understand mergebots and what you can use them for, refer to Mergebots.

You can create a mergebot in your Unity Dashboard:

Note: For more information on the mergebot configuration options, refer to the Mergebot configuration section of the Mergebots page.

Your mergebot processes branches that have the resolved status attribute. You can add the status attribute through either the desktop client or the Cloud dashboard.

You can also set an attribute through the CLI:

cm attribute set att:status br:/main/example-branch resolved

For more information, refer to the attribute set reference documentation.

For a full tutorial on how to create a Trunk bot, refer to the Create a mergebot Unity Learn tutorial.

**Examples:**

Example 1 (unknown):
```unknown
cm attribute set att:status br:/main/example-branch resolved
```

Example 2 (unknown):
```unknown
attribute set
```

---

## About Crash and Exception Reporting

**URL:** https://docs.unity.com/cloud-diagnostics/en/manual/CrashandExceptionReporting/AboutCrashandExceptionReporting

**Contents:**
- About Crash and Exception Reporting#
  - What’s next?#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Crashes and exceptions can have many different causes and effects. Some are noticeable to players while others are not. For example, one issue may cause your game to briefly freeze when trying to load a level. A more noticeable issue may prevent a multiplayer game from connecting to the server or cause the game to crash altogether. An issue might be caused by a bug in your code, such as a missing asset or an updated API for an online service. The more you know about an issue, the quicker it can be fixed.

When Cloud Diagnostics is enabled with your made-with-Unity project, use the Unity Dashboard to view real-time data about any crashes and exceptions your players may experience. View information about possible issues in your app, such as how many users are affected or what platforms and devices an issue occurs on. Investigate log messages, stack traces and view metadata about individual crashes or exceptions. This detailed information about the cause and effect of issues in your app helps you to identify, prioritize, and fix any problems which may arise.

---

## Authentication configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/authentication-config

**Contents:**
- Authentication configuration#
- Local name#
- Name and ID#
- LDAP#
  - Override for LDAP user filter#
- Active directory#
  - Time to reload users and groups#
- Username and password#
  - Configure the UP mode#
    - Use the Authentication configuration section from the UVCS Server Administration console#

Use the authentication section of the server administration console to configure the authentication mode that your Unity Version Control (UVCS) clients use.

A UVCS client communicates security information to the server for validation. The basic token sent from client to server is called SEID, short for SEcurity IDentifier. The following connectors are based on different ways to build the SEID and obtain users.

UVCS can use the following connectors to retrieve its user information:

You can also change the authentication mode when you need to.

In the Local name mode, the UVCS server reads the local users' names from the machine it runs on. On startup, the UVCS server creates a list of known users and recalculates the list periodically.

For the system to work correctly, you need to configure the UVCS clients to also use the Local Users mechanism. The client takes the name of its logged-on user and sends it to the server. This is the name that the server uses to check whether it is a known user, and then make security calculations.

This system relies on the correct network configuration. You can use this mode on secured networks to configure a mixed Unix /Windows environment, depending, for example, on a NIS+ system. You can also use this mode to configure access from the Internet, provided that the server only allows trusted clients to connect.

Name and ID mode is identical to the Local name mode except it also uses the user ID.

This authentication mode works on non cross-platform systems such as Unix-Unix or Windows-Windows, but breaks under Windows-Unix platforms without a specific authentication mechanism.

You can use this authentication method to work under NIS+ systems on Unix or under any other configuration as long as both systems share the same user name and ID.

The LDAP security configuration mechanism allows interoperability with an LDAP environment.

You can use the LDAP authentication mode to authenticate users against any kind of LDAP server. For example, you can use a Sun One or iPlanet LDAP server to authenticate Plastic SCM users.

The LDAP mode works for mixed Windows and Unix environments. For example, you can connect UVCS to an Active Directory server when you connect from a Unix box where the integrated Active Directory mode is not available.

You can configure the following settings in the server.conf file:

[!IMPORTANT]: Warning: This is considered an advanced level feature to be used ideally after consultation with our Support team. To support LDAP setups that are not compatible with our default LDAP user search filters, you can use the limited ability to override the filter with a user-specified filter. Use the MemberNameFilterOverride setting.

Enter the following to specify the filter override:

For example, LDAP setups without the UID attribute can use the following filter: (|(sAMAccountName={user})(cn={user})).

With the Active Directory configuration mechanism, UVCS retrieves the user list from the current Active Directory main server and buils the SEID with a Windows SID. This authentication methods requires the server to run on Windows based operating systems.

You can use Active Directory authentication in single domain or multi-domain environments. If you use UVCS in an Active Directory forest with multiple domains, you need to group usernames and groups that you enter in the DOMAIN\username and DOMAIN\group syntax.

By default, the Plastic server reloads the users and groups information from the authentication provider every five minutes.

In the server.conf file, you can configure the ReloadUsersRefreshTimeSpan setting. To configure the time, use the format: [d.]hh:mm:ss.

In this example, the user and group information refreshes every hour: <ReloadUsersRefreshTimeSpan>01:00:00</ReloadUsersRefreshTimeSpan>.

Username and password (UP) is the traditional authentication method, which allows you to define your own users and groups on the UVCS server. This method allows UVCS to work with an autonomous security mechanism. The UP mode can be the best option for many organizations that don't rely on systems like LDAP or Active Directory. The UVCS server obtains the list of users’ names from the users.conf and the groups.conf files in the server folder, and the authentication contains the username and encoded password.

The UP authentication mode is appropriate for mixed Linux/Windows environments where LDAP or Active Directory integration isn’t an option. You can also use this authentication mode to manage access to your UVCS server on heterogeneous environments with no common user login among operating systems.

In the UP mode, UVCS keeps a list of the users, and each user defines their password. UVCS also keeps groups as well as the relation between users and groups.

The main difference between UP and the other authentication methods is, instead of relying on an external user and group provider, the UP authentication mode stores all its data into the following files:

To configure the UP mode, use one of the following tools:

The User and password configuration section is a tool that you can use to configure the users.conf and groups.conf files. Administrators can use this tool to create users and groups, assign users to a specific group, change a user's password, and rename or delete users and groups.

To configure the login and password, use the client configuration wizard.

If the credentials don't match, a login screen pops up when the GUI client starts for you to enter the correct credentials.

umtool is the server application command used to configure the users, groups, and their relationships and passwords from the operating system's console.

For more information on each command, use%serverinstalldir%/plasticd umtool help <command_name>. Replace %serverinstalldir% with your directory path.

The umtool implements several subcommands:

The following are some examples:

The UVCS server obtains the list of users’ names from the users.conf and the groups.conf files in the server folder, and the authentication contains the username and encoded password.

**Examples:**

Example 1 (unknown):
```unknown
LdapTimeoutSeconds
```

Example 2 (unknown):
```unknown
<LdapTimeoutSeconds>10</LdapTimeoutSeconds>
```

Example 3 (unknown):
```unknown
LdapTokenExpirationTimeSpan
```

Example 4 (unknown):
```unknown
[d.]hh:mm:ss: \ <LdapTokenExpirationTimeSpan>05:00:00</LdapTokenExpirationTimeSpan>
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/allocation-lifecycle

---

## WORKSPACE RENAME

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/workspace-rename

**Contents:**
- WORKSPACE RENAME#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

cm workspace | wk rename [<wk_name>] <new_name>

This command renames a workspace. If no workspace name is supplied, the current workspace will be used.

cm workspace rename mywk1 wk2

(Renames the workspace 'mywk1' to 'wk2'.)

(Renames the current workspace to 'newname'.)

**Examples:**

Example 1 (unknown):
```unknown
cm workspace | wk rename [<wk_name>] <new_name>
```

Example 2 (unknown):
```unknown
cm workspace rename mywk1 wk2
```

Example 3 (unknown):
```unknown
cm wk rename newname
```

---

## TRIGGER DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/trigger-delete

**Contents:**
- TRIGGER DELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

cm trigger | tr delete | rm <subtype-type> <position_number> [--server=<repserverspec>]

cm trigger delete after-setselector 4

cm tr rm after-setselector 4

**Examples:**

Example 1 (unknown):
```unknown
cm trigger | tr delete | rm <subtype-type> <position_number> [--server=<repserverspec>]
```

Example 2 (unknown):
```unknown
cm trigger delete after-setselector 4
```

Example 3 (unknown):
```unknown
cm tr rm after-setselector 4
```

---

## Configure Atlassian JIRA integration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/issue-tracking/jira/configure-jira

**Contents:**
- Configure Atlassian JIRA integration#
- JIRA configuration#
  - Create a custom field#
  - Accept remote API calls#
- Configure the client for Atlassian JIRA#
  - Configure the client on Windows#
  - Configure the client on Linux and macOS#
  - JIRA parameters#
- Configure JIRA for multiple projects#
  - Add the project key#

Configure Atlassian JIRA and your Unity Version Control (UVCS) client so that you can use the JIRA integration. You can set up the following configurations:

Configure Atlassian JIRA so that JIRA can connect with Unity Version Control (UVCS).

Create a custom field so that UVCS can link changesets or branches to a JIRA issue.

Refer to the Atlassion documentation on how to create a custom field.

Make sure to configure the following options:

You can use any name, because UVCS uses the field ID to identify the field. You can find the ID in the URL on the screens page. For example, fieldID=customfield_1000.

Ensure that UVCS can access JIRA’s remote API:

Note: In JIRA Cloud, the Accept remote API calls option is enabled by default.

To test that the connection works in the UVCS application, select the Test Connection button in the Issue trackers section of the Preferences window.

Configure your Unity Version Control (UVCS) client to work with the JIRA integration. You can configure the client in Windows or Linux and macOS.

Configure the JIRA integration in the UVCS desktop application:

Set a local JIRA configuration on a Linux or macOS machine:

Note: You can also set a global extension configuration on the server.

Configure the Unity Version Control (UVCS) client to work with a multi-project configuration. A multi-project configuration allows each branch to explicitly contain the project key of the related task so you don’t define a global project key for all branches.

When you configure the client for JIRA, add the value MULTIPLE_PROJECTS to the Project Key parameter.

Note: If you use Linux or macOS, remember to update the required values in your jira.conf file.

If you work with multi-project configuration, you need to distinguish which branch links to which project.

Use the following format to name your UVCS branches:

<BranchPrefix>_<ProjectShortName>-<IssueID>

For example, to link a branch with the prefix task to JIRA issue VCS-1, use the branch name task_VCS-1.

Map fields from a JIRA issue to display them on the task information panel in the Branches or Changeset tabs in the Unity Version Control (UVCS) desktop application.

Configure the Fields mapping parameter on Windows:

Note: If you work on a Linux or macOS system, remember to update the required field in the jira.conf file.

Use the following syntax for the field mapping parameter:

The to attribute in the name pair describes the UVCS field that the vcs_property_name refers to. You can use the following attributes:

The from attribute in the name pair describes the filed in the JIRA issue that the jira_field_issue refers to. You can use the following attributes:

To map a custom field, use the customFieldValues modifier with the custom field ID number.

For example, customFieldValues[10000]->Description.

For example, the following is a valid example for the following configuration:

**Examples:**

Example 1 (unknown):
```unknown
fieldID=customfield_1000
```

Example 2 (unknown):
```unknown
issuetrackers/<server_port>/<repository>
```

Example 3 (unknown):
```unknown
<plasticscm_install_path>/client/extensions/config_samples
```

Example 4 (unknown):
```unknown
/Applications/PlasticSCM.app/Contents/IssueTrackerConfigSamples
```

---

## Matchmaker integration

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/matchmaker-integration

**Contents:**
- Matchmaker integration#
- Matchmaker lifecycles#
  - Session-based games#
  - Long-lived games#
- Matchmaker integration options#
  - Exit after each session#
  - Manually deallocate after each session#

This section briefly introduces matchmakers and provides loose guidelines around how matchmakers integrate with the Multiplay Hosting service.

A matchmaker controls finding players, grouping them together, and placing them on a game server for a game session. Matchmakers and often used in unison with Multiplay Hosting to create a multiplayer experience. Multiplay Hosting comes into play in the last stage: placing players on a game server.

At its core, matchmakers must be able to:

Matchmakers might also be able to backfill, which involves sending players to a game server after a game session begins to replace (backfill) players that left the game session.

The lifecycle of a matchmaker varies drastically depending on the type of game, implementation of the game, and requirements of the game. That said, the most common lifecycle patterns of a matchmaker fall into two categories:

Session-based games are games in which the game session is short-lived (an hour or less). Multiplay Hosting works best for these types of games because it prioritizes effectively finding game servers for matches in a way that saves money and optimizes the player experience.

Game types that often use short-lived sessions include:

Long-lived games are games in which the session lasts an hour or more (possibly in the range of days or weeks).

Game types that often use long-lived sessions include:

The integration point between Multiplay Hosting and a matchmaker is flexible, but the integration patterns fall into two categories based on how you manage game session allocations:

In this pattern, the matchmaker allocates a server for a match and sends the players to the server. After the match completes, the build executable exits cleanly, Multiplay Hosting detects the clean exit and automatically deallocates the server, freeing it up for the next match.

The advantages of exiting after each session include:

In this pattern, the matchmaker allocates a server for a match, sends the players to the server, waits for the match to complete, then deallocates the server (without restarting the process).

The advantage of this pattern is that you get much faster start-up times, and the server is ready to accept players immediately after each match because you don’t need to restart the build executable process.

---

## Configure lock rules

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/exclusive-checkouts

**Contents:**
- Configure lock rules#
- Configure lock rules in the server administration console#
  - Add global rules#
  - Add repository specific rules#
- Configure lock rules in the lock.conffile#
- Example lock.conf file#
- Example lock rules for specific cases#

Use one of the following methods to add or edit your Unity Version Control (UVCS) lock rules to configure your file locks:

Note: If you leave the global rules field empty, no global rules apply.

Note: Repository specific rules apply to a single repository and overwrite any global lock rules for that repository.

Create or edit the lock.conf file on the server directory in the following format:

To configure the paths that lock on checkout, specify complete paths or patterns, with each rule in a new line:

In the following example, you ensure that all *.png pictures and all files under the /assets/textures folder that begin with model lock on checkout in the battlegame repository.

You can use lock rules to lock files or a directory in a specific folder. For examples for how to use these types of lock, refer to the following:

**Examples:**

Example 1 (unknown):
```unknown
rep:<repname> [br:[<destination_branch>]] [excluded_branches:<exclusion_pattern>…]
```

Example 2 (unknown):
```unknown
rep:<repname> [br:[<destination_branch>]] [excluded_branches:<exclusion_pattern>…]
```

Example 3 (unknown):
```unknown
destination_branch
```

Example 4 (unknown):
```unknown
exclusion_pattern
```

---

## Enable DTLS encryption

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/enable-dtls-encryption

**Contents:**
- Enable DTLS encryption#

Note: Enabling DTLS encryption only enables encryption of message. Other Relay behavior, such as timeouts, remains the same.

Relay supports DTLS encryption of all UDP communication to and from the Relay servers. Set the Relay server connectionType to dtls when creating an allocation as a host player to enable DTLS encryption.

Warning: Secure connections using DTLS are only available with Unity Editor versions 2020.3 (starting at 2020.3.34), 2022.1, and above.

Note: Players joining the host player can use a different connection type than the host player. However, most gaming platforms required encrypted connections.

The following code snippet has a function, AllocateRelayServerAndGetJoinCode, that shows how to use the Relay SDK to create an allocation, request a join code, and configure the connection type as DTLS.

**Examples:**

Example 1 (unknown):
```unknown
connectionType
```

Example 2 (unknown):
```unknown
AllocateRelayServerAndGetJoinCode
```

Example 3 (javascript):
```javascript
public static async Task<(string ipv4address, ushort port, byte[] allocationIdBytes, byte[] connectionData, byte[] key, string joinCode)> AllocateRelayServerAndGetJoinCode(int maxConnections, string region = null)
{
    Allocation allocation;
    string createJoinCode;
    try
    {
        allocation = await RelayService.Instance.CreateAllocationAsync(maxConnections, region);
    }
    catch (Exception e)
    {
        Debug.LogError($"Relay create allocation request failed {e.Message}");
        throw;
    }

    Debug.Log($"server connection data: {allocation.ConnectionData[0]} {allocation.ConnectionData[1]}");
    Debug.Log($"server allocation ID: {allocation.AllocationId}");

    try
    {
        createJoinCode = await RelayService.Instance.GetJoinCodeAsync(allocation.AllocationId);
    }
    catch
    {
        Debug.LogError("Relay create join code request failed");
        throw;
    }

    var dtlsEndpoint = allocation.ServerEndpoints.First(e => e.ConnectionType == "dtls");
    return (dtlsEndpoint.Host, (ushort)dtlsEndpoint.Port, allocation.AllocationIdBytes, allocation.ConnectionData, allocation.Key, createJoinCode);
}
```

Example 4 (javascript):
```javascript
public static async Task<(string ipv4address, ushort port, byte[] allocationIdBytes, byte[] connectionData, byte[] key, string joinCode)> AllocateRelayServerAndGetJoinCode(int maxConnections, string region = null)
{
    Allocation allocation;
    string createJoinCode;
    try
    {
        allocation = await RelayService.Instance.CreateAllocationAsync(maxConnections, region);
    }
    catch (Exception e)
    {
        Debug.LogError($"Relay create allocation request failed {e.Message}");
        throw;
    }

    Debug.Log($"server connection data: {allocation.ConnectionData[0]} {allocation.ConnectionData[1]}");
    Debug.Log($"server allocation ID: {allocation.AllocationId}");

    try
    {
        createJoinCode = await RelayService.Instance.GetJoinCodeAsync(allocation.AllocationId);
    }
    catch
    {
        Debug.LogError("Relay create join code request failed");
        throw;
    }

    var dtlsEndpoint = allocation.ServerEndpoints.First(e => e.ConnectionType == "dtls");
    return (dtlsEndpoint.Host, (ushort)dtlsEndpoint.Port, allocation.AllocationIdBytes, allocation.ConnectionData, allocation.Key, createJoinCode);
}
```

---

## Frequently asked questions

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/faq

**Contents:**
- Frequently asked questions#
    - Are there any costs associated with Unity Authentication?#
    - Which third party/external logins are currently supported by Unity Authentication?#
    - Are there any samples available to showcase what Unity Authentication offers?#
    - Which Facebook app types are currently supported?#
    - What is the supported SteamWorks SDK version?#
    - How can I manage player accounts locally for multiplayer testing?#
    - Do we support console platforms?#
    - Do we support cross-platform use cases?#

There are currently no costs for Unity Authentication.

Refer to the section on external identity providers for more information.

We have samples that demonstrate how to use Anonymous login and some third party logins. The samples also include linking, unlinking accounts and session management.

We currently support the Consumer and Business app types.

SteamWorks SDK version 20.0.0 and above are supported.

You can isolate and preserve sessions by using AuthenticationService.Instance.SwitchProfile(string profile)API. This allows managing multiple accounts locally by switching the current player profile and isolating the session token in PlayerPrefs. Refer to the Profile management page for more information.

We support console-specific logins with cross-platform code-linking for console ID providers. Learn more about code-link.

UGS offers robust cross-platform account and authentication solutions that support cross-play and progression across all major devices and platforms.

**Examples:**

Example 1 (unknown):
```unknown
AuthenticationService.Instance.SwitchProfile(string profile)
```

Example 2 (unknown):
```unknown
PlayerPrefs
```

---

## Speech-to-text

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/speech-to-text/stt-overview

**Contents:**
- Speech-to-text#

Speech-to-text audio transcription is an optional paid Vivox service that allows per-user enablement of speech transcription in one or more connected non-positional or positional voice channels. For pricing information and to discuss enabling this service for your organization, contact your sales representative.

This service supports developers pursuing Communications and Video Accessibility Act (CVAA) compliance.

Customers with speech-to-text transcription enabled can provide transcribed audio to any user who has opted into receiving it on a per-channel basis. Transcribed audio is returned in text message format with an indication that the message was transcribed from voice. These messages can also indicate if the transcribed text is from the user who requested transcription.

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/unreal-engine-sdk/get-started

**Contents:**
- Get started#
  - Understand the requirements#
- Download the Authentication SDK#
  - From the Unreal Engine Marketplace website#
  - From the Epic Games Launcher#
  - Configure the Authentication SDK#
  - Sign up for UGS#
  - Link your project#
- What's next?#

The Authentication SDK for Unreal Engine is a part of the Unity Gaming Services SDK plugin for Unreal Engine. To use Unity Authentication inside the Unreal Engine, you’ll first need to install the Unity Gaming Services SDK.

The Authentication SDK plug-in for Unreal Engine supports the Unreal Engine versions 4.27 to 5.3.

Sign in to the Unreal Engine Marketplace.

Access the Unity Gaming Services SDK for Unreal Engine Marketplace page.

Select Open in Launcher.

Skip to Step 4 in From the Epic Games Launcher.

>Note: If you use a version of the engine built from sources then you can access your Marketplace folder by doing the following:

Before you begin using the Authentication SDK, you need to sign up for Unity Gaming Services and register a project.

>Note: If you already signed up for Unity Gaming Services and have a registered project, skip this step.

If you don't have a Unity account, create one and create a new project to sign up for Unity Gaming Services:

>Note: We’re copying the name of the environment, not the Environment ID. In the example above, the name is “testenv”. Using any other value causes Authentication requests to fail.

After you copy both fields, the project settings in the Unreal Editor should look like the following:

The Default Player Profile Name field grants a different name to be given to the default Authentication player profile. This can be left alone, or customized according to your needs.

>Note: A valid player profile name is between 1-30 characters, and consists of characters a-z, A-Z, 0-9, -, and _, with no spaces.

See Player Profiles to read more about Player Profiles inside the Authentication SDK.

Proceed with either integrations:

**Examples:**

Example 1 (unknown):
```unknown
C:\Program Files\Epic Games\UE_5.3\Engine\Plugins\Marketplace
```

Example 2 (unknown):
```unknown
UnityGamingServicesSDK
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/attribute-edit

---

## Run a query with SQL Data Explorer

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/run-sql-data-explorer-query

**Contents:**
- Run a query with SQL Data Explorer#

SQL is a programming language used to communicate with databases. A basic understanding of writing SQL queries is required to use SQL Data Explorer. See our collection of "recipes" in the SQL cookbook Data Explorer Queries. Queries are run against Snowflake, so use the Snowflake SQL dialect. Note that non-SELECT statements and $SYSTEM commands are limited in functionality.

When you first open SQL Data Explorer, a query that counts the number of distinct users who have played your game in the last seven days is shown. You can try this query out or delete it and build your own.

The Glossary panel provides a list of parameters you can use in your query. Use the copy button to copy parameters to the clipboard. The glossary terms are pulled from two sources: the database column names (such as EVENT_DATE) and custom parameters parsed from the event json (see Snowflake documentation on how to query JSON data). You can define custom parameters depending on the events you send. Some parameters are fields specific to Snowflake, which can change the syntax in the SQL. A list of available tables and their columns can also be found on the SQL Data Explorer queryable tables page.

Database column names are more performant for querying than the parameters parsed from JSON and should be preferred when possible.

If a parameter is represented by a column (such as USER_COUNTRY), the query uses it as:

If a parameter comes from the event itself, named missionName in this example, it's accessed via:

For more information about building custom events, see the create a custom event tutorial.

After running a query, you need to set up the chart. You can toggle between a bar chart, line graph, area graph, pie chart, and stacked bar chart. Currently, two Y axes and one X axis are supported.

To rename an axis label, use the as expression in your SQL query.

If you run a query without any data ordering, it's possible that your charts won't be an accurate representation of your data as it's not sorted. A warning will be displayed in this instance and it's recommended to order your query through the use of an order by keyword.

Under your chart is a table of results, showing the columns and result of your query.

Use reports to save your queries. The Reports selector provides a list of all saved queries so you can reload and use them later.

Use the Environments selector to switch between Unity Environments.

For information on all the tables and columns available, see the SQL Data Explorer queryable tables page.

**Examples:**

Example 1 (unknown):
```unknown
USER_COUNTRY
```

Example 2 (unknown):
```unknown
`USER_COUNTRY`
```

Example 3 (unknown):
```unknown
`USER_COUNTRY`
```

Example 4 (unknown):
```unknown
missionName
```

---

## Configure the client

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/overview

**Contents:**
- Configure the client#

Use configuration files to set up your Unity DevOps Version Control desktop client.

**Examples:**

Example 1 (unknown):
```unknown
externaltools.conf
```

---

## Command-line interface (CLI)

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/gsh-cli

**Contents:**
- Command-line interface (CLI)#
- Get started with Multiplay Hosting CLI#

The Multiplay Hosting command-line interface (CLI) is a sub-module of the UGS CLI and offers a way to build automated workflows that interact with the Multiplay Hosting service.

The Multiplay Hosting CLI sub-module supports the same functionality as the user interface on the Unity Dashboard. Refer to the CLI documentation for a full list of available commands.

You can access the Multiplay Hosting CLI sub-module through the Unity UGS CLI. The UGS CLI also provides common functionality for all UGS services, such as authentication, managing organizations, managing environments, and managing projects.

To get started, download the UGS CLI and follow the instructions in the UGS CLI documentation to authenticate and set your organization, project, and environment.

---

## Disable and re-enable Analytics

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/disable-and-reenable-analytics

**Contents:**
- Disable and re-enable Analytics#
- Additional resources#

Learn what happens after you disable Analytics and how to re-enable it.

When data collection is disabled on your project, data is not collected from players and your dashboards won't be updated with any new data. You can still access previously collected data in the dashboard but this might impact features or services that rely on real-time Analytics to provide segmentation or reporting.

The following features and services might be impacted when Analytics is disabled:

Note that games will continue to record and upload events even if Analytics is disabled. The logic in your game still runs as before, but the events won't be injested by the Analytics service.

Re-enable Analytics to resume data collection for a project. It may take approximately one hour for data to appear in the dashboard again.

---

## Provide feedback

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/safety-moderator/provide-feedback

**Contents:**
- Provide feedback#
- Player details#
- Moments#

The Player details table allows the moderators to provide feedback on the demographics data and the scores attributed to each player.

Based on the selected option, an icon will appear confirming the provided feedback.

In the case of unknown values, it’s possible to suggest one:

For scores, you can suggest a value if one is not attributed:

For languages, you can confirm the predicted language, or suggest a value if one is not attributed:

You can remove feedback by deselecting the previous option or by clicking the X icon if it was a suggestion.

The Moment tooltip allows moderators to suggest moment tags and to validate the accuracy of the existing ones. You can remove feedback by deselecting the previously selected option.

For suggested toxicity tags, remove them by clicking on the X icon displayed on the right side of the chip.

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal data collected about app users/game-players#
    - Developer defines#
- Relationship under privacy laws#
- Legal basis for processing#
- Consent (opt in) vs opt out#
- Data subject requests#
  - Access#
  - Deletion#
- Dependencies#

Unity Matchmaker is part of Unity's growing suite of multiplayer services that are designed to help game developers create and operate multiplayer games no matter what engine they’re using.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default personal data collected (always collected in order for product to work)

Optional Personal Data Collected (personal data which may be collected at choice/action of the end user/Developer)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they should do so within their application.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Unity Gaming Services support team with the Player ID of the end user that requested access.

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Unity Gaming Services support team with the Player ID of the end user that requested data deletion

Please note: This functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests. To delete the Player ID created by the Unity Authentication SDK (if enabled), please use the Authentication API.

This product is dependent on the Unity Authentication product. By enabling this product, you will also be enabling the Authentication product and you should refer to Unity Authentication SDK for more information.

Matchmaker does not store IP Addresses or Player ID. However, the Player ID in Matchmaker logs has a retention period of up to 30 days.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## Navigate the Mergetool window

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/mergetool-window

**Contents:**
- Navigate the Mergetool window#
- Contributor panels#
- Result file#
- Toolbar#
  - Conflict navigation#
  - Save options#
    - Exit with unresolved conflicts#
  - Merge options#
- Additional resources#

The three top panels in the window show three different versions of the file that has conflicts. These versions are the following:

The conflicted lines are color coded so that you can identify them in the Result file. Above each panel, there is a Deselect/Select bar that you can select to toggle whether or not the Result file panel includes that contributor's version of the conflicted line. For more information, refer to Resolve merge conflicts.

The Result file initially displays each contributor's version of the conflicted lines, color coded to help you distinguish between them. As you resolve the merge conflicts, the Result file updates to display only the selected lines. You can also manually edit lines in the Result file panel.

There are two types of arrow navigation in the top toolbar:

You can also select the colored conflict bars in the scroll bar to skip to a specific conflict.

---

## Unity Dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/write-configuration/unity-dashboard

**Contents:**
- Unity Dashboard#
- Set up Remote Config keys#
- Preview keys#
- Create a key#
- Publishing your keys#
- Delete a key#

Unity Dashboard is a simple way to get started as it allows you to take full control of your keys through a graphical interface. This section covers how you can preview, create, edit, and delete your keys.

If this is the first time you are creating Remote Config keys:

You can access all your Remote Config keys for an environment from the Unity Dashboard. To access it:

A list of all Remote Config keys in the selected environment for the project appears. The table contains the name, type, value, tags, and overrides. You can sort the table by key name or use the pagination to see the full range of keys.

You can create a key by clicking the Add Key button. A window will appear prompting you to include a name, type, value for this entry.

To make keys available to the game client, press the Publish button. A window will slide in from the side to show you the changes since the last time the remote config keys were published. Click Publish in the bottom right to confirm.

To delete keys from the Unity Dashboard:

Navigate to the Configuration page.

Select the bin icon. The state change column will mark this key as Remove.

Deleting a key that is in use by a live game causes errors in the game client.

To finalize your changes and remove this key from game clients, make sure to Publish your keys.

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal data collected about app users/game-players#
  - Developer defines#
- Relationship under privacy laws#
- Legal basis for processing#
- Consent (opt in) vs opt out#
- Data subject requests#
  - Access#
  - Deletion#
- Dependencies#

Remote Config is a cloud service that lets you tune and customize your app over the air without requiring an update to your game. You can use rules to enable or disable features, change the difficulty of your game or run special events to target specific audiences

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default personal data collected (always collected in order for product to work)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are an Independent Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine the legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they should do so within their application.

Please note: this functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests. To delete the Player ID created by the Unity Authentication SDK, please use the Authentication API.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by using the documented REST API:

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. You can action them by using the documented REST API:

Please note: this functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests.

This product is dependent on the Authentication product. By enabling this product, you will also be enabling the Authentication product and you should refer to Unity Authentication SDK for more information.

This product does not retain personal data.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

Unity DPA applies to the transfer of data for this product.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/HowDoesRemoteConfigWork

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/player-history

---

## Leaderboards

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/leaderboards

**Contents:**
- Leaderboards#
- Interfaces#
- Outcomes#

Leaderboards is a feature of Unity Gaming Services that supports the storage, sorting, and ranking of player scores.

You can interact with Leaderboards and implement them in your application using the following interfaces:

---

## Publication

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/publication

**Contents:**
- Publication#

You must publish any changes you make in Economy to make them public and accessible to your players. Use the Publish button to make your current Economy configuration available to the game client.

When a player loads your game, they access the most recently published resources of your configuration. Any new, unpublished items remain in the Unity Dashboard, unavailable to your players. If you haven’t published your configuration and try to access it using any of the SDK methods, the system returns an error.

To publish a configuration update:

Make sure that your items and their details are as you want them before you publish. Any mistakes at this stage could imbalance or break your in-game economy system.

---

## DEACTIVATEUSER

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/deactivateuser

**Contents:**
- DEACTIVATEUSER#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Deactivates a licensed user.

cm deactivateuser | du <usr_name>[ ...] [--server=<name:port>] [--nosolveuser]

This command sets a user to inactive, disabling the usage of UVCS for that user.

See the 'cm activateuser' command for more information about activating UVCS users.

This command checks whether the user exists on the underlying authentication system (e.g. ActiveDirectory, LDAP, User/Password...). To force the deactivation of a user that no longer exists on the authentication system, you can use the '--nosolveuser' option.

cm deactivateuser john

cm du peter "mary collins"

cm deactivateuser john --server=myserver:8084

cm deactivateuser S-1-5-21-3631250224-3045023395-1892523819-1107 --nosolveuser

**Examples:**

Example 1 (unknown):
```unknown
cm deactivateuser | du <usr_name>[ ...] [--server=<name:port>] [--nosolveuser]
```

Example 2 (unknown):
```unknown
cm deactivateuser john
```

Example 3 (unknown):
```unknown
cm du peter "mary collins"
```

Example 4 (unknown):
```unknown
cm deactivateuser john --server=myserver:8084
```

---

## Before you begin

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/before-you-begin-toc

**Contents:**
- Before you begin#

The following guides will help you understand what's needed to start working with the Vivox Core SDK as well as understand the main principles behind how the SDK works.

---

## Player profiles

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/unreal-engine-sdk/player-profiles

**Contents:**
- Player profiles#

To authorize multiple players sequentially inside a single game session, player profiles can be used. This feature grants the ability to switch, validate, and sign out of different authorization profiles.

By default, a single player profile is created under the name configured in the ‘Unity Authentication’ Project Settings. If the configured name is invalid, it’ll revert to “default”.

Note: Switching profiles is only a valid action when a player is signed out. If you try to switch profiles while signed-in, a warning is logged and results in the Player Profile staying the same.

---

## Allocation time to live (TTL)

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/allocation-ttl

**Contents:**
- Allocation time to live (TTL)#
- Session length considerations#
- Fleet overrides#

The allocation time to live (TTL) is a fleet-level setting that defines the maximum lifetime of an allocation. It primarily works as a safeguard for allocated game servers that are left idle. As players join and leave a game session, the game server must stay active to allow new connections. After a game server has been allocated for a certain amount of time without any player connections (the allocation TTL), it’s considered safe to shut down.

Different allocation TTL values can dramatically increase or decrease the resources your fleet uses and, by extension, the costs associated with the fleet. Games without persistent experiences have little need for extending the maximum lifetime of an allocation well past the default, so you can reduce the resources the fleet uses without much (if any) downside. On the other hand, games that offer persistent experiences benefit from extending the maximum lifetime of an allocation because it means that players can join and leave the game server over an extended time without worrying about losing their data.

Warning: Setting long allocation TTLs to your game server could lead to higher hosting costs for your game. Please consider deallocating any game server not running an active session to prevent cost overruns.

The ideal allocation TTL balances flexibility and cost; the longer an inactive allocation remains alive, the higher the hosting cost. Games without persistent data that use short-lived sessions do well with allocation TTLs that range from minutes to hours. However, games (and other applications) with a persistent virtual experience benefit from longer allocation TTLs that range from days to months (and possibly longer). Because long-lived sessions have different characteristics than typical short-lived game sessions, scaling and game server placement can quickly become suboptimal when mixing short-lived and long-lived sessions. As a result, the recommended best practice is to have a separate fleet dedicated to long-lived game servers.

The allocation TTL can also impact the performance of the game servers in a fleet. For example, a long-lived session might surface memory leaks that were difficult to find without long-running tests. Consider the following points when adjusting the allocation TTL:

You can set and manage the allocation TTL for each of your fleets through the API.

---

## Game Overrides

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/SDK-game-overrides

**Contents:**
- Game Overrides#
- Game Overrides in the Economy SDK#
  - Accessing the configuration assignment hash#

Game Overrides in Economy allow you to make changes to your Economy configuration for groups of players, schedule changes, and A/B test them, without releasing new versions of your game.

See Game Overrides for more general information about this feature. See Create an Override for information on how to set up Game Overrides for Economy.

This documentation covers how to interact with Game Overrides using the Economy SDK.

Game Overrides uses a configuration assignment hash to tell Economy which configuration to show a player, depending on which audience they fall into. The SDK predominately handles this for you: when you fetch your Economy configuration (for example, using GetCurrenciesAsync()), the Economy SDK automatically stores the most recent configuration assignment hash for that player.

On initialization, you must call one of the fetch configuration methods (for example, GetCurrenciesAsync()) before using the methods in the PlayerBalances, PlayerInventory, or Purchases namespaces to populate the configuration assignment hash in the SDK.

Future calls to Economy use this hash to get the correct Economy configuration for the player.

To fetch an updated configuration assignment hash, fetch your configuration again.

Please refer to Config Caching

**Examples:**

Example 1 (unknown):
```unknown
GetCurrenciesAsync()
```

Example 2 (unknown):
```unknown
GetCurrenciesAsync()
```

Example 3 (unknown):
```unknown
PlayerBalances
```

Example 4 (unknown):
```unknown
PlayerInventory
```

---

## Unity Gaming Services CLI

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/write-configuration/cli

**Contents:**
- Unity Gaming Services CLI#
- Prerequisites#
- Using the CLI#
  - Deploy resources#
  - Retrieve resources#
  - Environment synchronization#
  - Delete resource#

You can use the Unity Gaming Services CLI to interact with Economy resources. The CLI allows you to create, deploy, and manage Economy resources from the command line.

For a deep dive into the CLI, follow the steps in the Unity Gaming Services CLI Get Started guide.

To follow this guide, you must first complete the following actions:

Refer to the Economy Command Line documentation for a full reference of all commands and options.

Note: The ugs economy command is also available as ugs ec.

Run the new-file command to create a resource locally:

You can use the Deploy command to promote your local resources to the remote environment and publish them at once. The local resources must be deployed to become available to the game client.

To retrieve information about the deployed resource, run the following command:

You can use the Fetch command to retrieve multiple Economy resources from the remote at once. The provided path is a directory where the resources will be fetched to:

You can move all your resources from one environment and deploy them to another environment.

Run the following command to produce an archive of all the resources in your current environment:

You can then deploy the resources to another environment by running the following command:

The resources are published as part of the deploy command.

To delete an existing resource, run the following command:

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
ugs economy
```

Example 4 (unknown):
```unknown
ugs economy new-file <file-name>
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/diff

---

## Implementation

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/implementation

**Contents:**
- Implementation#
- Link project#
- SDK installation#
- Unity Dashboard#
- Authentication#
  - Deploy an Economy configuration#
    - Configure the UGS CLI#
    - Deploy the resource#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

To get Economy working with your project, you need to link your project to the Unity Dashboard to access Unity services, enable your project in the Dashboard, then install the SDK in Unity Editor. For the full SDK, see Economy SDK guide.

There is a rate limit of 60 requests per player per minute to the Economy service.

You must link your project with the Unity Dashboard to use the Economy service. See Link your project in the Unity Editor in the Introduction to Unity Gaming Services documentation to learn how.

To install the latest Economy package for Unity:

See the Package Manager documentation for more information.

See Economy SDK guide for the detailed SDK documentation.

You can set up and manage Economy in the Unity Dashboard:

When you launch Economy for the first time, this adds Economy to the Shortcuts section on the sidebar and opens the Setup Guide page.

The Economy API uses JSON Web Token (JWT) authentication. The Authentication SDK supports Anonymous authentication and Platform-specific authentication.

To make your configuration accessible to the game client, you must deploy the configuration to the Economy service.

Refer to write configuration to learn more about configuration deployment.

Follow the steps below to get stated with the UGS CLI:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Configure a Service Account with the required roles for Economy and environments management. Refer to Get Authenticated.

Run the following command:

ugs deploy <path-to-economy-file>

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.economy
```

Example 2 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 3 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 4 (unknown):
```unknown
ugs deploy <path-to-economy-file>
```

---

## PURGE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/purge

**Contents:**
- PURGE#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to inspect, register and execute repository purges. Purged revisions are no longer accessible for that repository, thus helping to free space.

Warning: Purge actions are irreversible. Once they are executed, you will not be able to load purged revisions anymore—either by switching a workspace or when showing branch or changeset differences. Use this under your own responsibility.

cm purge <command> [options]

cm purge <command> --usage

cm purge <command> --help

cm purge register ".mkv" "1955-Nov-05 6:00 AM" --repository=timemachine

(registers a purge action for the 'timemachine' repository)

(lists the ID and status of all the purge actions ever registerd in the server)

cm purge show 545ec81b-23ea-462c-91f4-d7c62a6e8817 --verbose

(shows in detail the purge action metadata for a given ID, including items and revisions affected by the purge)

cm purge execute 545ec81b-23ea-462c-91f4-d7c62a6e8817

(starts a previously registered purge action)

cm purge unregister 545ec81b-23ea-462c-91f4-d7c62a6e8817

(purges that were not executed can be deleted from the registry)

**Examples:**

Example 1 (unknown):
```unknown
cm purge <command> [options]
```

Example 2 (unknown):
```unknown
cm purge <command> --usage
```

Example 3 (unknown):
```unknown
cm purge <command> --help
```

Example 4 (unknown):
```unknown
cm purge register ".mkv" "1955-Nov-05 6:00 AM" --repository=timemachine
```

---

## Glossary

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/Glossary

**Contents:**
- Glossary#
- UGS#
- Analytics-specific#

Players that are grouped by criteria such as player behavior or location. Audiences can be targeted to personalize their game journey.

The California Consumer Privacy Act protects residents of California by enhancing privacy rights. Consumers have more control over what happens to their personal information.

Children's Online Privacy Protection Rule defines requirements for websites targeted to children under 13, and protects the collection of personal information.

Logical partitions for Unity Game Services that contain data associated with your project.

General Data Protection Regulation protects EU residents by enhancing privacy rights. Consumers have more control over what happens to their personal information.

In-app purchases are items in-game that are bought with real money, such as gems, lives, or weapons.

JEXL (Java EXpression Language) conditions are evaluated against a variety of factors in each request. This method uses contextual data attributes to define the audience for which you want a rule to apply.

JavaScript Object Notation is a text format for storing and moving data.

China Personal Information Protection Law protects China residents by enhancing privacy rights. Consumers have more control over what happens to their personal information.

A game in the Unity Editor, that is linked to UGS.

A REpresentational State Transfer Application Programming Interface that follows the REST architectural style, allowing communication between RESTful web services.

Software Development Kit, which can be installed into your Unity project to add functionality, such as the sending of events for analysis.

Unity Gaming Services is a suite of products designed to enhance and develop your games, providing a better experience for players.

A real-time 3D development platform and editor to make creative projects.

Software that connects the developers to the advertisers. Used for transactions between advertisers and game publishers.

Attribution support is where you can manage the ad networks that display ads in your game; you can track where users come from which ad (this is attribution), and spend your budget accordingly.

An event that was created and customized for specific usage for your game. You can define your own custom events in Event Manager and instrument them using the SDK.

Up-to-date charts and visualizations that show you how well your game performs at a glance.

Data Access provides access to your Analytics data through Snowflake (a data warehouse). You can leverage the power of Snowflake to view your Analytics data through a third-party visualization tool such as Tableau.

Charts that show your data based on metrics of events, grouped by platform, country, or version. Query your data based on predefined metrics or events, apply dimension filters, and group by section.

Daily active users: number of unique players per day.

An event is an action that occurs in your game, such as when the game starts, or when the player does something like finding a treasure or buying an item. Events contain contextual information around that event such as: the item that was obtained, how much currency the player had, and how the item was acquired.

The Event Browser debugs events coming in from your game. You can see up to the last 100 events sent by your game in the last 48 hours. You can view the event payload as flattened JSON.

Event Manager lets you view your configured events, and create custom events.

Choosing a smaller part of your data by criteria such as country, platform, version, audience, and acquisition.

A sequence of steps a player goes through in-game during a time period (for example, the last 24 hours or the last 7 days). A funnel analysis is a method of understanding the steps required to reach an outcome and how many users get through each of those steps.

Identifying information about user behavior that you can use in charts and analysis, such as WAU (weekly active users), new users, session length, and total revenue.

Found in the Unity Editor, the package manager adds a software package in-game in Analytics, which contains code that lets you track events.

Additional details of an event, for example, an event could be dungeonCompleted with the parameters of dungeonName and playerHealth.

Write and execute SQL queries on your data, plot the results into different types of visualizations, and add those to a dashboard. You can gain insights that might not be surfaced from other Analytics products.

Structured Query Language is a computer language used to communicate with databases from a client (e.g. a computer). SQL is used for structured data, such as databases and spreadsheets.

Standard events are events that are ready to use without the need for instrumentation or developer configuration. These events are used to calculate the metrics and KPIs available through Unity Analytics.

Use the transaction event to track successful in-app purchases. This event contains arrays and some special product objects that can be used to capture multiple items and currencies bought in a single transaction.

A unique identifier that you to connect events sent through the Analytics SDK.

**Examples:**

Example 1 (unknown):
```unknown
dungeonCompleted
```

Example 2 (unknown):
```unknown
dungeonName
```

Example 3 (unknown):
```unknown
playerHealth
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/repository-add

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/privacy-overview

**Contents:**
- Privacy overview#
- Product overview#
- Personal Data Collected about App Users/ Game Players#
  - Developer Defined#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent (Opt-in) vs Opt-out#
  - Data Subject Requests#
  - Access#
  - Deletion#

Unity Push Notifications adds support for Push Notifications to your game. It allows sending rich push notifications with images, and provides analytics on the number of received push notifications.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected (always collected in order for the product to work)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are an Independent Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are Business.

As we are a Processor, we do not determine the legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

Personal data collection for the Push Notifications product happens through the Unity Analytics product. To implement consent opt-in and opt-out mechanism refer to the Unity Analytics documentation.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by submitting the request here.

This service has native functionality to support data deletion requests. This is achieved using the RequestDataDeletion method of the SDK.

Call AnalyticsService.Instance.RequestDataDeletion() to request personal data deletion, which triggers a purge of user data from the server.

If there is no internet connection when this request is made, the SDK will reattempt to send the request at regular intervals until it is successful. It will remember this across app restarts using Unity’s PlayerPrefs system

Please note: this functionality only applies to Unity Analytics & Push Notifications If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests.

This product is dependent on the Unity Analytics product and Mobile Notifications package. By enabling this product, you will also be enabling Unity Analytics and Mobile Notifications. You should refer to Unity Analytics Documentation and the Mobile Notifications documentation for more information.

By default, personal data is retained for 13 months. If you wish to implement a shorter retention period, you can do so by contacting support.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

Unity DPA applies to the transfer of data for this product.

**Examples:**

Example 1 (unknown):
```unknown
AnalyticsService.Instance.RequestDataDeletion()
```

Example 2 (unknown):
```unknown
public void RequestDataDeletion()
{
	AnalyticsService.Instance.RequestDataDeletion();
}
```

Example 3 (unknown):
```unknown
public void RequestDataDeletion()
{
	AnalyticsService.Instance.RequestDataDeletion();
}
```

Example 4 (unknown):
```unknown
PlayerPrefs
```

---

## Server-side recording

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/server-side-recording/ssr-overview

**Contents:**
- Server-side recording#

Server-side recording is in limited early release and must be enabled by Vivox. Contact your sales representative for pricing and enablement.

Server-side recording (SSR) is an optional paid Vivox service that can help manage the health and safety of the voice communications in your player community.

SSR provides customer service representatives with a workflow for capturing and reviewing conversations that occur on the Vivox platform where potentially unwanted behavior is reported or detected.

---

## Use filter pattern files

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/filter-pattern

**Contents:**
- Use filter pattern files#
- Filter pattern files in UVCS#
- Rule types#
  - Absolute path rules#
  - Rules with wildcards#
    - Catch all rules#
  - Item name rules#
  - Extension rules#
  - Regular expression patterns#
- Exclusion rules#

Use filter pattern rules to set up specific client configuration files.

Pattern files are plain text files that contain one rule per line to match files according to their paths. Unity Version Control (UVCS) checks the path of each item to check if it’s affected by the set of rules. To comment lines, place the # character at the beginning of any line.

Note: If you filter a directory, you filter the complete sub tree. This means that if you filter /src/lib, for example, you also filter /src/lib/core.h and /src/lib/module/main.c.

The following filter pattern files apply to the workspace or pending changes to specify how Unity Version Control (UVCS) filters items:

UVCS has multiple types of rules that you can use in configuration files.

For more information on which rule types take precedence when you use multiple, refer to pattern hierarchy.

Absolute path rules allow you to match a single file or directory.

Use wildcards to customize absolute path rules:

Catch all rules are a subset of the wildcard rules. These rules are equivalent and match the complete workspace tree:

Match files or directories according to their names:

Match files according to the file extension:

Use regular expressions to match files. Ensure that the pattern starts with the ^ character and ends with the $ character:

To use a rule to exclude an item from the filter, use the same rules but start the pattern with the ! character. For example, the following rules match the entire directory, but exclude the specified paths:

Note: Exclusion rules take precedence over regular (inclusion) rules.

UVCS uses the patterns in a file to match the path of an item. Some pattern formats take precedence over others. The following shows the hierarchy of pattern formats:

Exclusion rules take precedence over other rules, so UVCS matches those first. There are two exceptions to this rule:

UVCS applies absolute path rules that match exactly before exclusion rules. For example, if you use the following rules, UVCS filters the item /src/test/testdata.zip even though the exclusion rule prevents the entire directory from being filtered:

UVCS applies absolute path rules applied to the item directory structure before exclusion rules. In this case, the most precise rule takes precedence.

For example, you can use the following rules:

In this example, UVCS filters files such as /src/build.sh or /src/client/bin/output.so, but not a /src/client/socket.c file.

**Examples:**

Example 1 (unknown):
```unknown
/src/lib/core.h
```

Example 2 (unknown):
```unknown
/src/lib/module/main.c
```

Example 3 (unknown):
```unknown
ignore.conf
```

Example 4 (unknown):
```unknown
cloaked.conf
```

---

## Gluon

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/gluon

**Contents:**
- Gluon#

Gluon is a tool designed for users who typically work on a single branch with files that can't be merged (typically, binary files such as images, animations, or documents). These users usually lock file access to coordinate teamwork collaboration. Repositories are normally huge and include very large binary files. A typical Gluon user is an artist involved with game development teams. However, the tool is not restricted to only game teams.

Gluon might be helpful in the following scenarios:

---

## Unity Environments

**URL:** https://docs.unity.com/ugs-overview/en/manual/ServiceEnvironments

**Contents:**
- Unity Environments#
- Supported Services#
- Managing environments#
- Switching environments for a service#
- Accessing environments within Unity projects#
- Environments Recommended Practices#
  - Configuration as Code#
  - Recommended environment strategy#
  - Environment management tooling#
    - Editor Deployment window#

Environments are logical partitions for Unity Game Services that contain data associated with your project. Examples can include game code using Cloud Code, or game configurations using Remote Config.

The following services currently support Environments:

Unity Gaming Services will continue to release Environments support for additional services.

To access a project’s Environments from the Unity Dashboard:

All projects start with a production environment. You can create up to 25 environments. To create a new environment, click Add Environment, give the new environment a name, and select Add.

Refer to Environments best practices for other tooling and recommendations.

To switch the environment for a service in the Unity Dashboard:

Use the Services Core initialization options to initialize your Unity Gaming Services in the development environment you want the player to experience. If unspecified, Unity Gaming Services will initialize in the default “production” environment.

Note: The Services Core SDK is included as a dependency for each service that supports Environments. For more information, see documentation on Services Core API.

To do this, include the Unity.Services.Core and Unity.Services.Core.Environments namespaces, then invoke the UnityServices.InitializeAsync() method with an options parameter configured to pass in the environment name. For example:

Initializing Unity Gaming Services with the "dev" environment.

If no option is specified, the Environment Selector value is used. If no Environment Selector option is present, 'production' is used as the default.

For more information, refer to Environment Selector.

Important: You must include the Unity.Services.Core.Environments namespace to access the SetEnvironmentName method.

Most UGS services support implementing Configuration-as-Code practices. Configuration as Code is the practice of treating configurations the same as code. This approach enables versioning, code review, automated deployment, and eliminates manual environment setup across your development pipeline.

It also lets you reuse configurations across projects and organizations.

The recommended best practice is to use environments as follows:

The Deployment Window is accessible through Services > Deployment in Unity Editor 2022 and later, once the package is installed. It allows you to deploy local service content to the services. It is the preferred way of iterating and working on service-enabled features.

The following services are supported:

The respective service package must be installed to enable the integration, refer to the Deployment window for details.

Any content that can be deployed via the Deployment window can be deployed to any environment.

Actions available through the Deployment window can also be used in automations using the Deployment API, such as build scripts. You can also use the Deployment API to build custom tooling to work with environments.

Use the UGS CLI to call services' admin APIs, and to deploy and fetch configurations for the following services:

The CLI also provides access to other services without config-as-code needs. For more information, refer to the CLI documentation.

You can use the deploy and fetch commands in automations to achieve common needs, such as diffing an environment and rolling back an environment with the supported services.

Use the deploy command to move content from one environment to another, with rollback:

Without source control:

Source control makes it easier to track what's being deployed, and automate deployments.

Use fetch to compare the configuration between two environments. This fetches the relevant configuration and compares it, using your preferred diff tool.

Fetch configurations from both environments and use git diff:

The Services APIs package provides simple access to most public UGS API packages. This lets you build any amount of custom tooling using the admin APIs or game APIs directly from within Unity.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.Core
```

Example 2 (unknown):
```unknown
Unity.Services.Core.Environments
```

Example 3 (unknown):
```unknown
UnityServices.InitializeAsync()
```

Example 4 (unknown):
```unknown
using Unity.Services.Authentication;
using Unity.Services.Core;
using Unity.Services.Core.Environments;
using UnityEngine;

class InitWithEnvironment : MonoBehaviour {
   async void Awake()
   {
       var options = new InitializationOptions();

       options.SetEnvironmentName("dev");
       await UnityServices.InitializeAsync(options);
       await AuthenticationService.Instance.SignInAnonymouslyAsync();
   }
}
```

---

## Frequently asked questions

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/frequently-asked-questions

**Contents:**
- Frequently asked questions#

Below is a list of frequently asked questions. If you have any questions that aren’t answered, please get in touch with our support team.

How much does Push Notifications cost? How is it priced?

Push Notifications is included as part of Unity Analytics. To learn more about Unity Analytics pricing, refer to UGS pricing.

Is there a limit to how many notifications I can send?

There is no limit to how many notifications you can send but there are fair usage policies in place which you can learn more about here. There is no limit to how many notifications you can have scheduled concurrently.

Can I implement Push Notifications without Unity Analytics?

Unity Analytics is required for Push Notifications today; you need to first implement Unity Analytics. Unity Analytics provides device token collection, targeting, and reporting for Push Notifications.

I’m already using Mobile Notifications, what should I do?

The Push Notifications SDK depends on the Mobile Notifications SDK, so you can use them together. Mobile notifications handles the presentation of the notification and the Push Notifications SDK handles device tokens and sending events.

I want to send notifications when a player does something in my game? Does Push Notifications support that?

The recommended best practise is to use local notifications through the Unity Remote Notifications package for this use case and anything that can be triggered from the game client. Push Notifications are best for anything that needs to be scheduled in advance or sent remotely.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/CrashandExceptionReporting/UnderstandingCrashandExceptionReporting

---

## SDK Event class

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/event-class

**Contents:**
- SDK Event class#
- Validate#
- Reset#

The Unity Analytics SDK is designed to help you match your game code with your event schemas as defined in the dashboard. While Analytics provides helper classes for all of the standard events that you might encounter, you must make your own helper classes to support the custom events that are unique to your game. This is done through making sub-classes of the abstract Event class, giving you type safety when working with the same event across multiple locations, and can help you to prevent validation errors when the events are uploaded.

While the Event class is primarily a container for passing data into the Analytics SDK, it also offers some advanced functions. You may also provide additional functionality through extending the Validate() and Reset() methods.

The Validate() method is called just before event serialization and can be used during development to check locally whether an event matches its schema or not. For example, many of the standard events offered by the SDK display warnings if they are missing required fields using this method. You can also prevent an invalid event from being recorded at all by throwing an exception inside Validate().

Note that events that are recorded and uploaded are validated more thoroughly by the back-end, so take care in allowing invalid events to get through so that they are visible outside the application itself. This mechanism is primarily intended to provide fast feedback to assist initial implementation and debugging, where a loud failure may be useful.

The Event class is designed to be pooled, so you can create a single instance and re-use it for the entire application lifecycle. Once an Event has been serialized to the Analytics buffer, the Reset method is invoked to clear the Event of all its parameters, returning it to a blank state for re-use.

If you added any extra logic or fields of your own to your sub-class and want to make use of object pooling, you must extend the Reset method to clear up any additional state you might have accumulated.

**Examples:**

Example 1 (unknown):
```unknown
protected override void Validate()
{
    base.Validate();

    if (!ParameterHasBeenSet("requiredParameter"))
    {
        Debug.LogWarning("A value for requiredParameter must be set!");
		// Event will be recorded but a warning will be displayed in the log.
    }
	
	if (!ParameterHasBeenSet("doubleRequiredParameter"))
	{
		throw new Exception("A value for doubleRequiredParameter REALLY must be set!");
		// Event will not be recorded at all.
	}
}
```

Example 2 (unknown):
```unknown
protected override void Validate()
{
    base.Validate();

    if (!ParameterHasBeenSet("requiredParameter"))
    {
        Debug.LogWarning("A value for requiredParameter must be set!");
		// Event will be recorded but a warning will be displayed in the log.
    }
	
	if (!ParameterHasBeenSet("doubleRequiredParameter"))
	{
		throw new Exception("A value for doubleRequiredParameter REALLY must be set!");
		// Event will not be recorded at all.
	}
}
```

Example 3 (unknown):
```unknown
public override void Reset()
{
    base.Reset();

    m_MyExtraSystemValue = null;
}
```

Example 4 (unknown):
```unknown
public override void Reset()
{
    base.Reset();

    m_MyExtraSystemValue = null;
}
```

---

## Monitor your MAU and fair usage limits

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/monitor-your-mau-and-fair-usage-limits

**Contents:**
- Monitor your MAU and fair usage limits#
- Additional resources#

The Service usage page displays the MAU usage tracker and two fair usage trackers for custom events and query seconds. If you exceed any of the free tiers, banners appear on the dashboard to notify you.

To monitor your MAU and fair usage limits, from the Unity Dashboard, select Usage > Service usage.

Note: The data in the Cost and Usage Reporting dashboard is delayed by about 12 hours.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/navigate-repositories

---

## Use cases

**URL:** https://docs.unity.com/ugs/en-us/manual/game-overrides/manual/use-cases

**Contents:**
- Use cases#
- Change your game without store releases#
- Roll out new features to your players#
- Run a seasonal event#
- Fine-tune and balance your game economy#
- Test a change to your level design#
- Fine-tune and optimize your ad strategy#
- Provide the best assets to your players#

Game Overrides are flexible and can be used to solve many of your use cases. The following examples provide suggestions for using Game Overrides in your game:

If you have any questions about any of the use cases below, open a support ticket.

Quickly change your game design for groups of players without code changes or store releases. Adjust level difficulty, game speed, or store layouts directly from the Unity Dashboard with changes reflected in real-time.

Answer questions like:

Use Game Overrides with JEXL or Audiences targeting to apply changes to player groups and set changes to occur over a specified time period.

New game mechanics, features, and events can drastically impact your game design and player experience. Build confidence in your changes by progressively rolling out new changes to your game, and monitoring your KPIs and community feedback.

You might be wondering…

Use Game Overrides and progressive rollout to control the percentage of your players that receive a change. Increase the percentage as you build confidence in your changes. Use Analytics to learn how changes impact your KPIs.

Players expect fresh and engaging experiences after launch, meaning you need to provide new experiences and content regularly. Seasonal events are a great way to achieve this. You might, for example, run a Halloween event that:

Use Game Overrides to set up time-based changes to your game. Enable and disable game modes with Remote Config keys. Enable new content using Cloud Content Delivery. Adjust rewards and IAPs using Economy.

Your game economy is integral to the success of your game. Creating a sustainable economy in your game is a process, and it might require adjustments and frequent changes before getting it right.

You might be wondering…

Use Game Overrides and Economy to target players with changes to your economy configuration, and learn how they react to those changes. Use Analytics to monitor your KPIs and ensure positive player experiences are at the core of everything you do.

The difficulty and general level design are naturally key areas for your game. The ability to change, test, and iterate these on the go is vital.

You might be wondering…

Use Game Overrides and A/B testing to test different versions of your game. Use Analytics to monitor how these changes impact key metrics like your retention and revenue.

Your ad strategy could be pivotal in your game's success. You should ensure that your ads don't negatively impact your player experience while also still providing revenue. Use Game Overrides to adjust ad frequency, cooldown times, and rewards. Changes can be granularly targeted at different player groups and A/B tested.

You might be wondering…

Use Game Overrides and Unity LevelPlay to remotely configure and test new ad strategies. Use Analytics to monitor how these changes impact retention and revenue.

For more information, refer to Reducing ad frequency for engaged players.

Target specific content to specific player groups with Cloud Content Delivery. Distribute content to players using CCD’s badge system and make sure you’re providing the best assets to your players.

You might be wondering…

Use Game Overrides and Cloud Content Delivery to remotely target and schedule changes to your game assets. Target different player groups and use Analytics to monitor the impact on your KPIs.

---

## Player incidents

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/player-incidents

**Contents:**
- Player incidents#
- View player incident history#

Player incidents are incidents in which a player is involved as the reporter or the reported.

When you view an incident, you can view the other incident reports the player is involved in (as a reporter or an offender) in the bottom half of the panel. These incidents are grouped into two categories:

Select an incident report to access more detailed information on the incident.

---

## Optimize SQL Data Explorer queries

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/optimize-sql-data-explorer-queries

**Contents:**
- Optimize SQL Data Explorer queries#
- Trade query accuracy for speed by using (mod)hash#
- Trade query accuracy for speed by rounding#
- Use smaller objects#

As your game becomes increasingly successful and your player base grows, you might find that even simple SQL Data Explorer queries can take significant time to run.

See the following basic query:

With a large dataset, this might take a while to run. However, since user_ids are stored as a hash, you can rewrite your code as follows:

Here, we’re splitting our users into 100 pseudo-randomly assigned and numbered buckets, looking at bucket number 63. As we increase computational complexity, filtering data in this way becomes more useful, saving time.

A simple way to improve query speed without 100% accuracy is to use approximate_count_distinct. Our previous query would become:

We can improve many queries by using smaller objects.

Look at the SQL Data Explorer tables page to see what tables are available to query. These are available out-of-the-box with UGS:

Between FACT_EVENT_TYPE_USERS_DAY and FACT_USER_SESSIONS_DAY, you can probably answer 80%+ of most queries on smaller objects.

For example, to track mission fail rates, we could use the FACT_EVENT_TYPE_USERS_DAY to calculate overall failure rates each day, with the NUMBER_OF_EVENTS count stored in this table.

**Examples:**

Example 1 (unknown):
```unknown
SELECT count(distinct event_name, user_id)/count(distinct user_id) as "avg number of event types per user"
FROM EVENTS
WHERE event_date>current_date-7
```

Example 2 (unknown):
```unknown
SELECT count(distinct event_name, user_id)/count(distinct user_id) as "avg number of event types per user"
FROM EVENTS
WHERE event_date>current_date-7
```

Example 3 (unknown):
```unknown
SELECT count(distinct event_name, user_id)/count(distinct user_id) as "avg number of event types per user"
FROM EVENTS
WHERE event_date>current_date-7
AND mod(hash(user_id),100) = 63
```

Example 4 (unknown):
```unknown
SELECT count(distinct event_name, user_id)/count(distinct user_id) as "avg number of event types per user"
FROM EVENTS
WHERE event_date>current_date-7
AND mod(hash(user_id),100) = 63
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/init-UGS

---

## Unity Gaming Services CLI

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/define-triggers/cli

**Contents:**
- Unity Gaming Services CLI#
- Prerequisites#
- Using the CLI#
  - Deploy triggers#
  - Retrieve triggers#
  - Delete triggers#

You can use the Unity Gaming Services CLI to interact with triggers. The CLI allows you to manage trigger configurations from the command line.

For a more comprehensive information on the CLI, follow the steps in the Unity Gaming Services CLI Get Started guide.

To follow this guide, you first need to complete the following actions:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Configure a Service Account with the required roles for Triggers and environments management. Refer to Get Authenticated.

For a full reference of all commands and options, refer to the Triggers Command Line documentation.

Note: The ugs triggers command is also available as ugs tr.

Run the new-file command to create a trigger configuration locally:

The configuration file contents can look like the following:

You can also modify a configuration file to include multiple triggers:

You can use the Deploy command to promote your local trigger configuration files to the remote environment.

You need to deploy the configuration files for them to become active triggers:

If you associate the trigger with an existing Cloud Code script or module, then emitting the event with the specified eventType fires the trigger and executes the associated Cloud Code script or module.

You can use the Fetch command to retrieve multiple triggers from remote at once.

The provided path is a directory where the triggers are saved to:

To delete a trigger, you can run the deploy command with a --reconcile flag.

Warning: Reconcile is a destructive operation. It deletes all triggers that are not present in the provided path. You can check the output of the command with the --dry-run flag before running the command without it.

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
ugs triggers
```

Example 4 (unknown):
```unknown
ugs triggers new-file <file-name>
```

---

## Unity Version Control plugin for Intellij IDEs

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/intellij-plugin

**Contents:**
- Unity Version Control plugin for Intellij IDEs#
- Requirements#
- Install the plugin#
- Use the plugin#
  - Version Control tab#
  - Diff files#
  - Annotate files#

The installation process below is a summary of the required steps to install a custom plugin in your IDE manually.

More info: JetBrains documentation

To view the version control features, right-click the project hierarchy and select Plastic SCM:

There is a dedicated Version Control tab that covers version control related details, such as local changes pending to check in, history and revisions, and un-versioned and ignored files.

One of Unity Version Control's main features, semantic diffing (understanding code structure to reduce integration conflicts), is embedded in the IDE interface.

Annotate lines and history of the local files to better understand the evolution of the project.

**Examples:**

Example 1 (unknown):
```unknown
${INSTALL_DIR}/client/plugins/intellij/plastic4intellij-X.Y.Z.zip
```

---

## Key concepts

**URL:** https://docs.unity.com/ugs/en-us/manual/overview/manual/key-concepts

**Contents:**
- Key concepts#
- Server-side game systems#
- Asynchronous code#
- SDK APIs versus REST APIs#
  - Client APIs#
  - Web APIs#
  - Onboarding impact#

Before you start, take a few minutes to understand some of the key concepts that underpin Unity Gaming Services.

For live games, especially multiplayer ones, it’s important to have a single place to manage player data. Rather than each player’s device managing that player’s data, a central server communicating with all player devices handles important game decisions. This can help mitigate cheating tactics that may allow players to gain an unfair advantage, or acquire resources that they would otherwise need to purchase or earn. Similarly, to ensure that live events and competitive features are fair to all players, your game should manage data and decisions in the cloud.

Unity Gaming Services lets you:

Like any online service, Unity Gaming Services are all based on asynchronous operations. This means that client requests to a service don’t stop the game to wait for the response. Gameplay, UI, and animations can continue while service requests occur in the background.

For this, Unity Gaming Services rely on the Task-based Asynchronous Pattern (TAP), which makes writing asynchronous code in C# relatively easy. If you’re already familiar with writing code in Unity, you probably understand Coroutines, which you can use for asynchronous logic. While Coroutines are still useful for controlling what’s going on in the foreground, async Tasks are better for managing things happening in the background, such as web requests.

Throughout the UGS documentation, you will encounter the async and await keywords. An async method returns a Task that represents an ongoing process. The await keyword tells the caller to wait until the called async method has finished before continuing.

For example, to update a player’s currency data, you might have something like the following code:

For more information, see Microsoft’s conceptual guide on asynchronous programming.

There are two ways to access Unity Gaming Services programmatically:

If you intend to use Unity Gaming Services with the Unity game engine, Unity recommends using client APIs for your project.

Client APIs make it easier to access Unity Gaming Services APIs from a supported language (C#) within the context of the Unity Editor. Unity developers can access all of the services’ functionality with Unity packages. These SDKs install directly to your Unity project and provide all the C# API libraries you need. Client APIs simplify your workflow and significantly reduce the amount of code you need to write.

Non-made with Unity developers can access Unity Gaming Services APIs via web endpoints, or REST APIs. REST APIs provide more flexibility and allow you to automate your workflows by using your favorite language and gaming engine.

Whether you’re using the SDK or REST APIs, you need to create a project on the Unity Dashboard. However, if you’re using the REST APIs, the subsequent steps in the getting started guide may differ slightly. Unity recommends that these customers visit the services API documentation website for onboarding.

**Examples:**

Example 1 (unknown):
```unknown
async Task RefreshPlayerWallet()
{
	// Use an animation to show the player something is happening.
	waitIndicator.gameObject.SetActive(true);

	// Download this player's currency statuses from UGS;
	// this asynchronous task won't interrupt the animation.
	var newWalletData = await EconomyManager.RefreshWalletData();

	// Once you have the downloaded data, update your UI.
	walletView.Refresh(newWalletData);

	waitIndicator.gameObject.SetActive(false);
}
```

Example 2 (unknown):
```unknown
async Task RefreshPlayerWallet()
{
	// Use an animation to show the player something is happening.
	waitIndicator.gameObject.SetActive(true);

	// Download this player's currency statuses from UGS;
	// this asynchronous task won't interrupt the animation.
	var newWalletData = await EconomyManager.RefreshWalletData();

	// Once you have the downloaded data, update your UI.
	walletView.Refresh(newWalletData);

	waitIndicator.gameObject.SetActive(false);
}
```

---

## Use case sample: Send a push message to the player whose score was beaten

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/use-cases/higher-score-message

**Contents:**
- Use case sample: Send a push message to the player whose score was beaten#
- Prerequisites#
  - Authenticate using a Service Account#
  - Configure the UGS CLI#
- Set up Leaderboards#
  - Optional: Add scores to the leaderboard#
- Examine the score-submitted event#
- Set up Cloud Code#
- Configure a trigger#
- Validate the result#

The use case sample demonstrates how to use Triggers to send a push message to a player whose score was beaten in a leaderboard. The sample uses the score-submitted event from the Leaderboards service.

Note: You can only use push messages with Cloud Code modules.

You must first create a service account with required access roles and configure the UGS CLI.

Before you can call the Triggers service, you must authenticate using a Service Account.

Add Product roles and create a key:

For more information, refer to Authentication.

Follow the steps below to get stated with the UGS CLI:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Authenticate using the Service account you created earlier. Refer to Get Authenticated.

To follow this sample, you should create a leaderboard.

You can use the UGS CLI to deploy the following leaderboard.lb file. It defines a leaderboard with ascending sort order and keeps the best score.

Run the new-file command to create a leaderboard configuration locally:

The file name corresponds to the leaderboard ID. Update the leaderboard.lb file with the following configuration:

Deploy the file using the UGS CLI tool:

Now that you have created a leaderboard, you can add scores to it.

You can run the following Cloud Code script to add scores to the leaderboard from the Unity Dashboard. Make sure to select the Generate icon to regenerate the Player ID token on every test run to generate a score for a new player.

The Leaderboards service emits a score-submitted event when a new score is submitted to a leaderboard. The event payload looks like this:

The event passes the event payload to Cloud Code as parameters.

Refer to Leaderboards: Score Submitted for more information.

Define a module endpoint that sends a push message to the player whose score was beaten.

Create a SendPushNotification module function with contents as below:

Refer to Deploying Hello World to learn how to deploy a module.

Note: If you are deploying the module using the UGS CLI, don't forget to add additional Service Account role of Cloud Code Editor.

To connect your Cloud Code resource to the Leaderboards score-submitted event, create a trigger. The trigger executes the Cloud Code module when the event is fired, for example, every time a new score is submitted.

Run the new-file command to create a trigger configuration locally:

Update the triggers-config.tr file with the following configuration:

Deploy the configuration using the UGS CLI tool:

A successful response is similar to the following:

The sample trigger executes your Cloud Code module function when a player signs up.

To validate the result, you can set up a Unity project that subscribes to push messages and use the Cloud Code script you created earlier to submit a new score to the leaderboard.

To subscribe to push messages, you need to install the Cloud Code SDK and link your Unity Gaming Services project to the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

In Unity Editor, select Edit > Project Settings > Services.

Link your project.If your project doesn't have a Unity project ID:

If you have an existing Unity project ID:

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

To install the latest Cloud Code package for Unity Editor:

Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

You can subscribe to messages with Cloud Code SDK versions 2.4.0+.

To subscribe to player-level messages, set up a Monobehaviour script. Refer to Send push messages for more information.

You can use the sample code below for your MonoBehaviour script:

The first time you run the Monobehaviour script, it logs a player ID. You can modify your Cloud Code script to submit a score for the specified ID to add the player to the leaderboard.

Run the script again to generate scores for the leaderboard.

You should encounter a push message sent when your player score is beaten in the Unity Editor:

**Examples:**

Example 1 (unknown):
```unknown
score-submitted
```

Example 2 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 3 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 4 (unknown):
```unknown
leaderboard.lb
```

---

## View file history

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/history

**Contents:**
- View file history#
- View file history in the Unity Dashboard#
  - View file diffs#
- View file history in the GUI#
  - View diffs for pending changes#
  - Diff a changeset#
- View file history in the CLI#
  - View logs#
  - View diffs#

You can view file history in the DevOps section of the Unity Dashboard:

You can also compare changes on a branch or changeset:

You can view file histories in the Unity DevOps Version Control desktop application:

The Pending Changes tab shows the changes that you have made in your workspace. To view the changes for a file before checkin, select the file. The window displays the diff. To go from one change to another, use the scroll arrows.

You can also view the diff for a specific changeset in the Branch explorer tab. To view the diff, right-click the changeset and select one of the following options:

To show changes made on a specific changeset or range of changesets, you can use the cm log command. In the example below, the file FileSystem.cs has been both changed and moved:

The cm diff command can only show changes for a specific changeset:

**Examples:**

Example 1 (unknown):
```unknown
FileSystem.cs
```

Example 2 (unknown):
```unknown
>cm log cs:575
Changeset number: 575
Branch: /main/fix-1342
Owner: pablo
Date: 7/18/2015 19:41:29
Comment:
Changes:
 C code\lib\FileSystem.cs
 M code\lib\FileSystem.cs
```

Example 3 (unknown):
```unknown
>cm log cs:575
Changeset number: 575
Branch: /main/fix-1342
Owner: pablo
Date: 7/18/2015 19:41:29
Comment:
Changes:
 C code\lib\FileSystem.cs
 M code\lib\FileSystem.cs
```

Example 4 (unknown):
```unknown
>cm diff cs:575
C "code\lib\FileSystem.cs"
M "code\FileSystem-renamed.cs" "code\lib\FileSystem.cs"
```

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal data collected about app users/game-players#
- Developer defines#
- Relationship under privacy laws#
- Legal basis for processing#
- Consent (opt in) vs opt out#
- Data subject requests#
  - Access#
  - Deletion#
- Data retention#

The Friends service allows you to add a new social experience to your games by helping players connect with others across any platform.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default personal data collected (always collected in order for product to work)

While this product allows for the collection of developer-defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are an Independent Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they should do so within their application.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by using a service account to fetch all relationships for a given user from the service.

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. You can action them by using a service account to delete all relationships from the service.

If you have questions about this section please contact us on the Unity Dashboard.

By default, Unity Authentication Service ID (UAS ID) is retained indefinitely. If you wish to implement a shorter retention period, you can do so by doing one of the following:

IP Address is collected and logged by UGG (Unity Game Gateway). These logs have a retention period of 30 days.

This service is not intended to be used in applications with child users, unless you, the developer, have obtained Verified Parental Consent where required as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your own privacy policy.

Additionally, you will need to link out to our Privacy Policy from within your own, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## CHANGESET EDITCOMMENT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/changeset-editcomment

**Contents:**
- CHANGESET EDITCOMMENT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Modifies the comment of a changeset.

cm changeset editcomment | edit <csetspec> <new_comment>

cm changeset editcomment cs:15@myrepo "I forgot to add the checkin details"

cm changeset edit cs:cb11ecdb-1aa9-4f11-8698-dcab14e5885a "This comment text will replace the previous one."

cm changeset edit "89095131-895d-4173-9440-ff9ef9b2538d@project@cloud" "Changing my comment"

**Examples:**

Example 1 (unknown):
```unknown
cm changeset editcomment | edit <csetspec> <new_comment>
```

Example 2 (unknown):
```unknown
cm changeset editcomment cs:15@myrepo "I forgot to add the checkin details"
```

Example 3 (unknown):
```unknown
cm changeset edit cs:cb11ecdb-1aa9-4f11-8698-dcab14e5885a "This comment text will replace the previous one."
```

Example 4 (unknown):
```unknown
cm changeset edit "89095131-895d-4173-9440-ff9ef9b2538d@project@cloud" "Changing my comment"
```

---

## Starter Packs

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/StarterPacks

**Contents:**
- Starter Packs#
- Prerequisites#
- Overview#
  - Initialization#
  - Functionality#
    - Give 10 Gems#
    - Purchase starter pack#
    - Reset Starter Pack#
- Setup#
  - Requirements#

Starter packs are one-time deals that grant new players additional resources at a discount. Starter packs improve the onboarding process and boost engagement early, and can also help convert new players to paying users.This sample demonstrates how to create a one-time starter pack deal in your game that a player can purchase with in-game currency.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

To see this use case in action, open the samples menu and navigate to Starter Packs. To open this scene directly and interact with the use case:

The StarterPackSceneManager.cs script performs the following initialization tasks in its Start function:

In this example, the starter pack costs 10 Gems. For demonstration purposes, this scene provides a button that grants the player 10 Gems each time it is clicked, which ensures enough currency to test the purchase. When you click the Give 10 Gems button, the following occurs:

Note that the purchase button is temporarily disabled while the currency balance updates.

When you click the button to buy the starter pack having 10 or more Gems, the player consumes 10 Gems in exchange for the resources offered in the pack. The following occurs:

The purchase button also updates to indicate that the offer has already been claimed. At this point, you cannot purchase additional starter packs unless you click the Reset Starter Pack button, no matter how many Gems you have.

After purchasing a starter pack, the player cannot purchase another one unless they reset their game save. To illustrate this, this scene provides a button to reset the flag so the player can purchase it again. When you click the Reset Starter Pack button, the following occurs:

To replicate this use case, you'll need the following Unity packages in your project:

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys all the necessary items.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Publish the following scripts in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resources in the Unity Dashboard:

**Examples:**

Example 1 (unknown):
```unknown
StarterPackSample.unity
```

Example 2 (unknown):
```unknown
StarterPackSceneManager.cs
```

Example 3 (unknown):
```unknown
StarterPackSceneManager.cs
```

Example 4 (unknown):
```unknown
OnGiveTenGemsButtonPressed
```

---

## Integrations

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/integrations

**Contents:**
- Integrations#

Explore the following links to learn how to integrate Lobby with other services.

---

## Get scores from a leaderboard version

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-score-version

**Contents:**
- Get scores from a leaderboard version#

Players can get scores from a specified leaderboard version with the GetVersionScoresAsync method. By default the method fetches the top 10 scores:

Paginated access to all scores in the leaderboard is available by specifying the optional GetVersionScoresOptions object with the optional Offset and Limit pagination arguments.

Offsetis the number of entries to skip when retrieving the leaderboard scores and defaults to 0.

Limit is the number of leaderboard scores to return and defaults to 10.

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option in the GetVersionScoresOptions configuration object:

For details on how to get available leaderboard version IDs, see Get available leaderboard version.

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
GetVersionScoresAsync
```

Example 2 (unknown):
```unknown
public async void GetVersionScores(string leaderboardId, string versionId)
{
    var scoresResponse = await LeaderboardsService.Instance
        .GetVersionScoresAsync(leaderboardId, versionId);
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 3 (unknown):
```unknown
public async void GetVersionScores(string leaderboardId, string versionId)
{
    var scoresResponse = await LeaderboardsService.Instance
        .GetVersionScoresAsync(leaderboardId, versionId);
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 4 (unknown):
```unknown
GetVersionScoresOptions
```

---

## Revert to a specific revision

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/revert-to-revision

**Contents:**
- Revert to a specific revision#

Revert a file to a specific revision. For example, if you don’t like a series of changes, you can restore the file to the revision you do want.

This reversion loads the selected revision into your workspace and checks out the file. Gluon updates the file status to Checked-out (unchanged)|Replaced.

Note: To revert to a specific revision with the command line, run the cm revert command.

---

## Google Play data safety section for Lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/google-data-safety-section-for-lobby

**Contents:**
- Google Play data safety section for Lobby#
- Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Lobby. For your convenience, Friends provides information on its data collection practices in the following sections.

Important: The data disclosures below are for this service only. You are also responsible for providing any additional disclosures for your app, including other third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

---

## Pricing

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/pricing

**Contents:**
- Pricing#

Familiarize yourself with the pricing details for Multiplay Hosting. Multiplay Hosting dynamically and automatically scales based on player demand. You pay only for the resources you use.

---

## Failure handling

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/concepts/failure-handling

**Contents:**
- Failure handling#

If the invoked Cloud Code script or module returned an error response, the action is not retried.

However, in case of an internal problem with the execution of a Cloud Code script or module, the Triggers service retries the execution.

To monitor and debug the execution of your triggers, use Logging.

---

## CHECKOUT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/checkout

**Contents:**
- CHECKOUT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - To checkout an item#
  - Reading input from stdin#
  - Examples#

Marks files as ready to modify.

cm checkout | co [<item_path>[ ...]] [-R | -r | --recursive] [--format=<str_format>] [--errorformat=<str_format>] [--resultformat=<str_format>] [--silent] [--symlink] [--ignorefailed] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

If locks are configured on the server (lock.conf exists), then each time a checkout on a path happens, UVCS checks if it meets any of the rules and if so, the path will be in exclusive checkout (locked) so that none can simultaneously checkout. You can get all the locks in the server by using 'cm lock list'. See the Administrator Guide for more information:

https://www.plasticscm.com/download/help/adminguide

The format string replaces the placeholder '{0}' with the path of the item being checked out. Check the examples to see how to use it.

The 'checkout' command can read paths from stdin. To do this, pass a single dash "-". Example: cm checkout -

Paths will be read until an empty line is entered. This allows you to use pipe to specify which files to checkout. Example:

dir /S /B *.c | cm checkout -

(In Windows, checkouts all .c files in the workspace.)

cm checkout file1.txt file2.txt

(Checkouts 'file1.txt' and 'file2.txt' files.)

(Checkouts all txt files.)

(Checkouts current directory.)

cm checkout -R c:\workspace\src

(Recursively checkouts 'src' folder.)

cm co file.txt --format="Checking out item {0}" --resultformat="Item {0} checked out"

(Checkouts 'file.txt' using the specified formatting strings to show the progress and the result of the operation.)

cm checkout link --symlink

(Checkouts the symlink file and not the target.)

cm checkout . -R --ignorefailed

(Recursively checkouts the current folder, ignoring those files that can not be checked out.)

cm co . --machinereadable --startlineseparator=">"

(Checkouts the current directory, and prints the result in a simplified, easier-to-parse format, starting the lines with the specified strings.)

**Examples:**

Example 1 (unknown):
```unknown
cm checkout | co [<item_path>[ ...]] [-R | -r | --recursive] [--format=<str_format>] [--errorformat=<str_format>] [--resultformat=<str_format>] [--silent] [--symlink] [--ignorefailed] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
dir /S /B *.c | cm checkout -
```

Example 3 (unknown):
```unknown
cm checkout file1.txt file2.txt
```

Example 4 (unknown):
```unknown
cm co *.txt
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/gluon

---

## Purchases

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/purchases

**Contents:**
- Purchases#
- Retrieve purchases#
- Determine purchase status#
  - Purchase attributes#
  - Purchase states#
- Process purchases#
- Purchase acknowledgement and reliability#
- Save purchases to the cloud#

Unity IAP fetches purchase information from the store so your application can recognize and fulfil what players have bought. This ensures that your game can deliver content or entitlements to users based on their purchase history, even if they bought items outside your app or on another device.

A purchase is represented as an Order object. The Order contains all relevant details about the purchase and provides information needed to track and manage it with the store.

Purchases made by the user can be retrieved from the store. However, consumable products must be tracked by your application after they are consumed, because stores don't return consumables that have already been fulfilled. For non-consumable products and subscriptions, the store accurately returns these purchases when you call FetchPurchases or CheckEntitlement.

You can determine the status of a purchase in two ways:

The OnPurchasePending callback is invoked when a purchase is made and is awaiting fulfillment. Your application should fulfill the purchase at this point, for example by unlocking local content or sending the purchase receipt to a server to update a server-side game model.

Note that OnPurchasePending may be called at any point following a successful initialization. If your application crashes during execution of the OnPurchasePending handler, then it is invoked again the next time Unity IAP initializes. Consider implementing your own de-duplication logic.

Note: If you don't confirm purchases, the store sends back the purchases, and some stores may even refund it automatically to protect the users.

Unity IAP requires you to explicitly acknowledge purchases to ensure that purchases are reliably fulfilled, even during network outages or application crashes. If a purchase is paid for but not fulfilled, Unity IAP delivers the purchase to your application the next time it initializes. This process prevents purchases from being lost when the purchase flow is interrupted or when purchases are completed while the application is offline.

After successfully fulfilling a purchase, call ConfirmPurchase with the relevant PendingOrder to acknowledge the purchase to the store.

Note: For consumables, once you acknowledge the purchase, the store does not return it again. Always persist consumable rewards remotely. If you store consumable rewards locally, you risk losing data with no way to restore it.

If you are saving consumable purchases to the cloud, you must call ConfirmPurchase when you have successfully persisted the purchase.

When returning Pending, Unity IAP keeps transactions open on the underlying store until confirmed as processed. This ensures consumable purchases are not lost even if a user reinstalls your application while a consumable is pending.

**Examples:**

Example 1 (unknown):
```unknown
FetchPurchases
```

Example 2 (unknown):
```unknown
CheckEntitlement
```

Example 3 (unknown):
```unknown
PendingOrder
```

Example 4 (unknown):
```unknown
ConfirmedOrder
```

---

## Configure the Open with menu

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/openwith-conf

**Contents:**
- Configure the Open with menu#
- Example openwith.conf file#

Customize the tools that display in the Open with menu in the Unity DevOps Version Control application. To access the menu, right-click on a file or revision and select Open > Open with.

To customize the Open with menu, create an openwith.conf file in the following location:

To define the shortcuts in the openwith.conf file, use the following format:

Note: The shortcut that you define can override predefined shortcuts.

For a list of valid shortcuts for Windows, refer to the Microsoft shortcut reference.

**Examples:**

Example 1 (unknown):
```unknown
openwith.conf
```

Example 2 (unknown):
```unknown
C:\Users\user\AppData\Local\plastic4
```

Example 3 (unknown):
```unknown
$HOME/.plastic4
```

Example 4 (unknown):
```unknown
openwith.conf
```

---

## VERSION

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/version

**Contents:**
- VERSION#
- Description#
  - Usage#
- Help#

Shows the current client version number.

Shows the current client version number.

---

## Economy

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual

**Contents:**
- Economy#
- Set up Economy in Unity Cloud#
- Sample projects#

Unity’s Economy service provides you with an easy way to create, manage and publish an economy system to be used in your game.

Economy includes the following for your game:

You can set up and manage Economy through the Unity Dashboard:

When you launch Economy for the first time, this adds Economy to the Shortcuts section on the sidebar and opens the Setup Guide page.

Download the Unity Gaming Services Samples project to see how to implement Economy to solve common game development challenges:

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/ApplePrivacySurvey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

Note the following dependencies:

Cloud Code is dependent on Unity Authentication. Refer to its privacy manifest for applicable data practices.

Cloud Code has an optional dependency on Runtime. Refer to the privacy manifest file for applicable data practices. If you implement the Cloud Code Unity SDK, this becomes a hard dependency on Runtime.

The privacy manifest for Cloud Code is available from version 2.5.2.

The following code sample contains the PrivacyInfo.xcprivacy manifest for Cloud Code. This file is also available in the SDK.

To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTrackingDomains</key>
	<array>
	</array>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
	</array>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeDeviceID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTrackingDomains</key>
	<array>
	</array>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
	</array>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeDeviceID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/purge-register

---

## Filter logs

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/logging/concepts/filter-logs

**Contents:**
- Filter logs#
- Basic syntax and operators#
- Boolean expressions and grouping#
- Examples of filter queries#
  - Notes#

The Logging service supports a custom query language that allows you to easily filter your structured logs. This section walks you through the syntax and usage of the query language, and provides some examples to help you get started.

A filter query consists of one or more conditions. The basic syntax of a condition consists of the following components:

Refer to the table below for a list of supported operators.

You can create complex filter queries using boolean expressions and grouping with parentheses. This allows you to combine multiple conditions to create precise filters.

Line feeds are also interpreted as boolean ANDs to simplify query writing. This means that you can write one condition per line when you want them all to be matched.

Select all logs with a certain severity level:

Select all logs from Cloud Code that are above a certain severity level (newlines are treated as AND):

Exclude logs with a particular word in the message:

Combine multiple conditions and groupings (using severity alias):

The following notes apply to the filter query language:

**Examples:**

Example 1 (unknown):
```unknown
severityText
```

Example 2 (unknown):
```unknown
logAttributes
```

Example 3 (unknown):
```unknown
severityText = "ERROR"
```

Example 4 (unknown):
```unknown
severityText = "ERROR"
```

---

## PURGE EXECUTE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/purge-execute

**Contents:**
- PURGE EXECUTE#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Executes a purge action previously registered.

Warning: Purge actions are irreversible. Once they are executed, you will not be able to load purged revisions anymore—either by switching a workspace or when showing branch or changeset differences. Use this under your own responsibility.

Please ensure you check the file history to confirm which revisions/changesets are not relevant. Do not hesitate to use the cm purge show command prior to the purge execution in order to verify no unexpected revision is selected for its removal.

cm purge execute <purge_guid> [--server=<server>]

cm purge execute be5b9145-1bd9-4c43-bd90-f2ff727bbf13

(Executes a purge given its ID).

cm purge execute be5b9145-1bd9-4c43-bd90-f2ff727bbf13 --server=myorg@cloud

(You can specify a precise server if you need it).

**Examples:**

Example 1 (unknown):
```unknown
cm purge show
```

Example 2 (unknown):
```unknown
cm purge execute <purge_guid> [--server=<server>]
```

Example 3 (unknown):
```unknown
cm purge register
```

Example 4 (unknown):
```unknown
cm purge execute be5b9145-1bd9-4c43-bd90-f2ff727bbf13
```

---

## Search incidents

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/incident-search

**Contents:**
- Search incidents#
- Filter incidents#

You can search through incident reports by incident ID or player ID using the search bar on the Incident reports dashboard. The player IDs are IDs found in the Reporter and Offender fields.

Search results appear automatically.

You can filter incident reports from the Incident reports dashboard. The available filters include:

In-use filters are highlighted in blue.

---

## UNDELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/undelete

**Contents:**
- UNDELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Example#

Undeletes an item using a specific revision.

cm undelete <revspec> <path>

The item to undelete should not be already loaded in the workspace.

The 'undelete' operation is not supported for xlinks.

cm undelete revid:756 C:\mywks\src\foo.c

cm undelete itemid:68#cs:2 C:\mywks\dir\myfile.pdf

cm undelete serverpath:/src#br:/main C:\mywks\Dir

**Examples:**

Example 1 (unknown):
```unknown
cm undelete <revspec> <path>
```

Example 2 (unknown):
```unknown
cm undelete revid:756 C:\mywks\src\foo.c
```

Example 3 (unknown):
```unknown
cm undelete itemid:68#cs:2 C:\mywks\dir\myfile.pdf
```

Example 4 (unknown):
```unknown
cm undelete serverpath:/src#br:/main C:\mywks\Dir
```

---

## Use anonymous sign-in

**URL:** https://docs.unity.com/authentication/en/manual/use-anon-sign-in

**Contents:**
- Use anonymous sign-in#

Anonymous sign-in creates a new player for the game session without any input from the player. It's a quick way for a player to get started with your game.

You cannot recover anonymous accounts that are not linked to a platform-specific account and if the session token is lost. For example, the player will not be able to log in to their anonymous account if they uninstall and then reinstall the game.

If a session token is cached on the SDK, then the SignInAnonymouslyAsync() method recovers the existing credentials of the cached player, regardless of whether they signed in anonymously or through a platform account. If there is no player sign-in information, this method creates a new anonymous player.

For more information about signing in returning players, refer to Sign In a Cached Player.

The following code sample shows how sign in to your game anonymously.

After implementing anonymous sign-in, it is recommended to integrate with at least one supported external identity provider to allow your players to continue their progress from another device or recover their account, if needed.

**Examples:**

Example 1 (unknown):
```unknown
SignInAnonymouslyAsync()
```

Example 2 (unknown):
```unknown
async Task SignUpAnonymouslyAsync()
{
    try
    {
        await AuthenticationService.Instance.SignInAnonymouslyAsync();
        Debug.Log("Sign in anonymously succeeded!");

        // Shows how to get the playerID
        Debug.Log($"PlayerID: {AuthenticationService.Instance.PlayerId}");

    }
    catch (AuthenticationException ex)
    {
        // Compare error code to AuthenticationErrorCodes
        // Notify the player with the proper error message
        Debug.LogException(ex);
    }
    catch (RequestFailedException ex)
    {
        // Compare error code to CommonErrorCodes
        // Notify the player with the proper error message
        Debug.LogException(ex);
     }
}
```

Example 3 (unknown):
```unknown
async Task SignUpAnonymouslyAsync()
{
    try
    {
        await AuthenticationService.Instance.SignInAnonymouslyAsync();
        Debug.Log("Sign in anonymously succeeded!");

        // Shows how to get the playerID
        Debug.Log($"PlayerID: {AuthenticationService.Instance.PlayerId}");

    }
    catch (AuthenticationException ex)
    {
        // Compare error code to AuthenticationErrorCodes
        // Notify the player with the proper error message
        Debug.LogException(ex);
    }
    catch (RequestFailedException ex)
    {
        // Compare error code to CommonErrorCodes
        // Notify the player with the proper error message
        Debug.LogException(ex);
     }
}
```

---

## Server hold

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/beta/server-hold

**Contents:**
- Server hold#
- Problem context#
- Solution#
- Executing a server hold#
- Server hold expiration#

Warning: This feature is in closed beta and accessible by permission only.

Server hold is a management pattern which allows a server to remain capable of receiving an allocation or executing a reservation for a specified period of time.

In most cases, initiating a server hold is only functionally applicable for reservation-based fleets, however, the feature is also available to fleets which handle allocations.

With a reservation-based fleet, Multiplay Hosting cannot select the best server for an incoming match. It cannot scale as efficiently as an allocation-based fleet and as such reserved servers can be left fragmented across many machines. Machines that contain no reserved servers are considered for shutdown and deletion based upon pre-configured TTLs.

Due to the potential fragmented nature of reserved servers, it can be difficult for Multiplay Hosting to effectively cost-optimise reservation-based fleets. Shorter TTLs allow for unused machines to be deprovisioned more quickly (saving cost), but without careful management of the server lifecycle, machines which have short TTLs are more likely receive reservation requests during shutdown, causing interrupted game sessions. For example, a player could join a server as it is about to be turned off. This can be resolved without the server hold solution by having a longer machine shutdown TTL, but this comes at a financial cost.

Holding a server allows the machine the server is running on to be kept alive past its pre-configured TTLs. The hold timeout can be configured on a per-server basis, however, from a Multiplay Hosting perspective, the timeout furthest in the future will be taken into account when making the decision as to whether a machine should be deprovisioned. Note that holding a server does not negatively influence the number of available servers - the server hold only influences deprovisioning, not provisioning of new machines.

Multiplay Hosting recommends the following behaviour:

Holding a server has the following benefits:

A server hold can be created, viewed and removed by executing the relevant endpoint on the Local Proxy. API documentation can be found here.

By creating a server hold, the server in question transitions into the HELD state. A server cannot transition into this state if it is in any of the ALLOCATED or RESERVED states.

A server hold can be expired manually by calling the DELETE endpoint specified in the documentation above.

Aside from this, a server hold is expired automatically under all of the following conditions:

A server hold does not expire automatically under the following conditions

It is important to note that if a server hold is required after an allocation or reservation has been removed, the server must create a new hold; the platform does not move the server back into the HELD state even if the previous timeout would not yet have been exceeded.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/show-find-objects

---

## Back up withrdiff

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/backups/rdiff-backups

**Contents:**
- Back up withrdiff#
- Commands#
  - Create backups#
  - List backups#
  - Restore an incremental backup#
- Cold copy example#
- Hot copy example#

Use rdiff on a Linux machine to perform both cold copy backups and hot copy backups.

rdiff uses a dst tmp aux folder to store the full backup. At the beginning of each week, rdiff resets the folder and creates a new backup. Each following day of the week, rdiff uses rdiff-backup to add incremental backups. Every day, the contents of the dst tmp aux folder is compressed into a tar.gz file and stored in a week_xx folder, which replaces any older tar.gz files in that folder.

Create a backup. If you reuse the target path, you create an incremental backup.

List the incremental backups stored that you can restore them later:

The following command restores the last backup prior to 8 hours and 30 minutes ago. The example uses the --tempdir path to avoid using the system temp path and running out of space on the disk.

This example shows the setup for a weekly and incremental backup using rdiff-backup on a Linux machine:

As this is a hot copy, you need to switch the server between normal and read-only modes ( cm admin readonly ).

**Examples:**

Example 1 (unknown):
```unknown
dst tmp aux
```

Example 2 (unknown):
```unknown
rdiff-backup
```

Example 3 (unknown):
```unknown
dst tmp aux
```

Example 4 (unknown):
```unknown
sudo rdiff-backup "/media/codice/New Volume/jet_ubuntu" "/media/codice/New Volume/rdiff_backups/"
```

---

## Get started with UGS

**URL:** https://docs.unity.com/ugs-overview/manual/getting-started

**Contents:**
- Get started with UGS#
  - Prerequisites#
  - Games using the Unity Engine#
  - Games using REST API#
- Create a project in the Unity Hub#
- Create a project in the Unity Dashboard#
- Link your project in the Unity Editor#
- Install UGS packages#
- Import SDK namespace#
- Initialize Unity Services in your game code#

This topic describes how to set up your project to use Unity Gaming Services.

If you haven’t done so already, complete the following before starting the onboarding process:

To get started using UGS with your Unity project:

If you use a different gaming engine, you can implement UGS in your game using REST APIs. To start using UGS:

If you use the Unreal Engine, you can also implement some UGS features in your game, using:

The fastest way to create a new Unity Cloud connected project is via the Unity Hub.

Your new Unity project is automatically created in the Unity Dashboard and you don't need to connect them manually.

You can already begin browsing services in the Unity Dashboard. To integrate the services, proceed to Install UGS packages.

Manage your projects and services from the Unity Dashboard. To create a new project:

You can now configure your project in the Unity Dashboard and start to configure some services prior to integration with a Unity Editor project. For example, configure Economy items or create Game Overrides. Next, link your Unity Cloud project to a Unity Editor project.

Learn more about managing Unity projects.

To use Unity Gaming Services, you must link your project in the Unity Editor to a Unity Cloud project.

To link your project in the Editor:

Learn more about linking projects to the Unity Dashboard.

Install the corresponding packages for the services you want to implement in your project. To view and install packages applicable to UGS:

You can also type services in the search bar, which returns results for all the services except Remote Config.

In Editor versions 2022.1 or higher, the Package Manager’s Services tab displays all packages available for UGS.

To access the API for an SDK, you must import the SDK's namespace in your script. For example, for Analytics:

You must initialize the Services Core SDK before calling any of the services’ functionality. The recommended best practice is to initialize services early in your game’s runtime, preferably at launch.

Note: You don't need to install the com.unity.services.core package or include it in your package manifest. This is pulled automatically when you install a UGS package that depends on it.

To initialize Unity Services in your game code, create a script that imports the Services Core namespace (Unity.Services.Core), then call the InitializeAsync method. For example:

This method initializes all Unity Gaming Services that are installed in your project. You can use the State method to check the initialization status of your game at runtime. For more information, refer to the Services Core API documentation.

Custom server-authoritative economy logic or game logic is one of the most common uses for Unity Gaming Services. This Cloud Code walkthrough includes everything you’ll need to get started, including installation, initialization, dashboard configuration, and remotely executing a simple Cloud Code script from your game client.

**Examples:**

Example 1 (unknown):
```unknown
using Unity.Services.Analytics;
```

Example 2 (unknown):
```unknown
using Unity.Services.Analytics;
```

Example 3 (unknown):
```unknown
com.unity.services.core
```

Example 4 (unknown):
```unknown
Unity.Services.Core
```

---

## SHOWOWNER

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/showowner

**Contents:**
- SHOWOWNER#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Shows the owner of an object.

cm showowner | so <object_spec>

This command displays the owner of an object. The owner can be a user or a group. The owner can be modified with 'cm setowner' command.

cm showowner repserver:PlasticServer:8084

(Shows the owner of the selected server.)

(Shows the owner of the selected item specification.)

**Examples:**

Example 1 (unknown):
```unknown
cm showowner | so <object_spec>
```

Example 2 (unknown):
```unknown
cm showowner repserver:PlasticServer:8084
```

Example 3 (unknown):
```unknown
cm so item:samples\
```

---

## Cloud AI mini game

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/CloudMiniGame

**Contents:**
- Cloud AI mini game#
- Prerequisites#
- Overview#
  - Initialization#
  - Functionality#
    - Example Cloud Save game states#
- Setup#
  - Requirements#
  - Unity Cloud services configuration#
    - Using the Deployment package#

Mini-games introduce fun ways to earn additional rewards or advance gameplay. This sample demonstrates how to use Cloud Code with other UGS packages to validate game play by implementing a simple artificial opponent against the player in a tic-tac-toe mini-game.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

In this sample, each mini-game begins with a random player (50% human, 50% AI) and progresses until a player successfully places 3 pieces in a row (win) or the board is full (tie). The player receives 100 Coins for a win, 25 Coins for a tie, and nothing for a loss.

To see this use case in action, open the samples menu and navigate to Cloud AI Mini Game. To open this scene directly and interact with the use case:

The CloudAIMiniGameSceneManager.cs script performs the following initialization tasks in its Start function:

When you click the New Game button (or the Forfeit button when a game is in progress), the following occurs:

When a game is in progress you can click on a game tile to attempt to place a piece. The following occurs:

The client calls the CloudAi_ValidatePlayerMoveAndRespond.js Cloud Code script, passing your click coordinates to the script.

The move is validated based on the coordinate inputs. If the game is over or the tile is occupied, the move is invalid.

If the move is valid, the script updates the game state to reflect the new piece placement, then places the piece on the client-side game board.

The script checks to see if the new move triggers a game-over condition (either three in a row, or the board is full).

If the game is not over, the script places an AI piece according to the following logic:

If the game is over, the script calls the Economy service to distribute rewards directly, according to the win condition detected. If the player won, they receive 100 Coins. If the board is full, they receive 25 Coins.

The Cloud Save service keeps a JSON record of the full game state, using the CLOUD_AI_GAME_STATE key string. The associated value stores sequential moves made by each player, the overall state, flags for game-over, player turn, whether this is a new game or move, and a persistent counter for wins, losses, and ties.

The Reset Game button exists to demonstrate the full game cycle. At the start of the first game (or when manually resetting the game), Cloud Code removes the CLOUD_AI_GAME_STATE key from Cloud Save and calls the CloudAi_GetState.js Cloud Code script to reset the Coin balance to 0, create a new save state with all counters set to 0, generate a new game board, and choose a random starting player.

CLOUD_AI_GAME_STATE for a new game with the AI going first

CLOUD_AI_GAME_STATE when the player wins the game

To replicate this use case, you'll need the following Unity packages in your project:

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configuration using the Deployment package:

This deploys all the necessary items.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Publish the following scripts in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resource in the Unity Dashboard:

**Examples:**

Example 1 (unknown):
```unknown
CloudAIMiniGameSample.unity
```

Example 2 (unknown):
```unknown
CloudAIMiniGameSceneManager.cs
```

Example 3 (unknown):
```unknown
CloudAi_GetState.js
```

Example 4 (unknown):
```unknown
CloudAi_StartNewGame.js
```

---

## MS Visual Studio integration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/vs-plugin

**Contents:**
- MS Visual Studio integration#
- Select Plastic SCM as the source control provider#
- Adding the solution to UVCS#
- Adding a solution for the first time#
    - Workspace name#
    - Path on disk#
    - Default repository#
- Open an Existing Solution#
- Binding a Solution already in UVCS#
- Basic operations#

Note: This plugin is now deprecated. There is a new Unity Version Control Extension for Visual Studio that is supported. For more information, refer to the new Visual Studio extension documentation.

Unity Version Control System (UVCS) provides a comprehensive integration with Visual Studio 2010 and later versions. In the form of a Visual Studio Extensibility Package, this integration offers the user most of the functionality found in the UVCS GUI right inside Visual Studio.

This section will describe the functionality and commands of the Unity Version Control Package for Visual Studio. Basic knowledge of UVCS concepts and terminology is needed. Things like a workspace, checkout / checkin, branch or merge should be familiar to the reader. For more details, please refer to the Unity Version Control page.

Once Plastic SCM has been installed and configured, the next step is to configure Visual Studio to use Plastic SCM as the source control provider. To do this, you need to go to:

Tools > Options > Source Control

There, select "Plastic SCM Source Control Package" as shown in the next figure, and click OK. The plug-in is ready to be used.

Note: If you selected "Plastic SCM SCC plug-in" during the installation, you will see this plug-in as well in the dropdown list. The SCC plug-in was designed for the old SCC version control interface that was standard in versions of Visual Studio prior to 2005. The "Plastic SCM Source Control Package" is a far more complete solution and is the recommended integration for Visual Studio 2005 and newer versions.

Before using UVCS inside Visual Studio, the solution has to be added to UVCS. Adding the solution to UVCS binds them together and this binding is stored inside the solution and project files.

Note: the solution should be contained in a single UVCS workspace. If the projects inside the solution are located in more than one UVCS workspace, many operations of the plug-in will choose to act only on the workspace of the first project (for instance, displaying any view from the UVCS menu, or checking in pending changes right clicking on the solution will be applied only to the workspace of the first project).

If no other developer has added the solution to UVCS already, it has to be added for the first time. This is done by right clicking on the solution in the Visual Studio's Solution Explorer and selecting Add to source control.

If the solution directory tree is not contained inside a workspace, the UVCS plug-in will show a dialog to create a new workspace. This dialog is the same used to create a new workspace in the UVCS GUI client. For more details, refer to the Unity Version Control GUI guide.

The new workspace configuration can be customized using the following commands:

This is a name chosen by the user to identify the workspace. This name will appear in the UVCS GUI workspaces tab.

This is the directory where the workspace will be created. By default, the plug-in will fill in this field with the top directory of the solution.

This is the repository where the solution will be added. The dropdown list contains all the repositories in the Plastic SCM server. When adding a new solution to Unity Version Control, you will normally want to create a new repository for it. This is done using the New button.

The New button will open a new dialog that lets you create a new repository to contain all the data of the solution you are adding to UVCS. This dialog is the same used to create a new repository in the UVCS GUI. Refer to the UVCS GUI guide for more details.

If the solution was already contained in a workspace, although it had not been added to UVCS yet, the new workspace dialog will not appear and the solution will be added automatically.

Once the workspace and optionally the repository have been created, the solution is added to the source control. All the items inside it are added to the repository and checked in. Being controlled items (as UVCS defines it) they are decorated with a lock icon.

When the solution has already been added to UVCS by another user, you can directly open it from within Visual Studio. To do so, go to:

File > Open > Open from Plastic SCM...

This command lets you open a solution from one of the UVCS repositories. The sequence is this:

If the files that make the solution are already in UVCS, but the solution and projects are not bound to UVCS, binding them is just a matter of adding the solution to source control. The solution and project files will be modified to include the binding information, so they are automatically checked out.

To complete the binding, you will need to checkin the changes. To do so, right click on the solution and select Checkin. The Pending changes view will appear, letting you enter a comment to checkin. This is the same Checkin dialog that appears when you select the Checkin command in the items in the UVCS GUI.

Once the solution is bound to UVCS, most of the changes in the solution are handled transparently by the integration. When a file is modified, it is automatically checked out. When a file is moved (even between projects), the change is detected as a moved item.

You can review all the pending changes by right clicking in the solution in the Solution Explorer and selecting Checkin. This will open the Pending changes window and let you check in the changes or undo some of them. The Pending changes view details the items whose content has changed as well as moved, added and deleted items. For more details on the Pending changes view, refer to the UVCS GUI guide.

UVCS provides several commands when right clicking a file or folder in the Visual Studio Solution Explorer.

The following commands are added to the context menu by the Plastic SCM Source Control Package.

Explicitly checkout the item so that UVCS knows that it is going to be edited. By default, the plug-in will automatically checkout the files that are modified inside Visual Studio. If an item is modified outside the IDE, however, you may want to check it out explicitly.

Update the selected item to the latest changes in the repository.

Open a Side-by-side Diff tool that compares the selected file with its previous version. If the item is checked out, the diff view shows the changes made.

Display a dialog in which you choose two revisions of the selected item and then open a Side-by-side Diff tool to compare those revisions. By default, one of the revisions is the item as it exists in your workspace.

Open an Annotate view for the selected item. The annotate view displays the contents of the file with annotations for each line detailing its author as well as the branch and changeset where the change was made.

Open a History view of the selected item. This view details all the revisions created for the item, as well as any namespace change (i.e. if the file has been moved, renamed or deleted).

Open a Branch Explorer for the selected item showing the revisions and their types as described in the 2D revision tree.

Change the revision type of each selected item, to binary or text. The type of an item controls how it is handled by the Diff and Merge tools.

Reload the status (checked out / checked in / controlled / added) of the selected item and its children, updating the decorators. This command is useful when some items have been modified outside Visual Studio, to set the status up to date again in the IDE.

Open a new window to view or edit the permissions of the selected item.

Any open document in the code editor has an associated context menu. The UVCS plug-in adds some options to that menu, detailed below.

Open a new window with a browser for the history of the specific method where the right click was made. This option works on C#, Java and Vb.net projects. Many times a developer looks at a piece of code and wonders how it ended up written like it is. In such cases, she can use the history and annotate view to find out how the method evolved. But in this process, she has to go find the method inside the file each time a new revision is compared.

With method history, the developer can focus on a specific method and browse the changes specific to it. The method history view can filter the revisions in which the analyzed method had changes, so the answer to the question "What happened to this method?" is quickly answered.

The method history view will download the different revisions of the item from the repository, and parse the code to find the requested method, so it is found even if it has been moved.

The view contains a top panel with a table displaying all the revisions of the file that contains the selected method. When a revision is selected in the top panel, the changes made to the method in that revision are shown in the bottom panel. This panel contains a Side-by-side diff tool as described in the UVCS GUI guide.

The revisions table on the top panel has one row for each revision of the file. It has the following columns:

The top panel has several controls to filter the list of revisions upon the following criteria:

The UVCS Toolbar shows the most common views available.

To enable this toolbar click on

View > Toolbars or Tools > Customize

and select "Plastic SCM".

By clicking on these buttons the corresponding view will appear the same way as clicking on the View > Plastic SCM menu (see picture below).

Most of the work in Plastic SCM happens inside a "view". The most relevant views can be open right inside Visual Studio, through the View > Plastic SCM menu.

The views available under that menu behave in the same way as their counterparts in the UVCS GUI. Since they are fully described in the Plastic SCM GUI guide, that information will not be duplicated here. Please refer to the pointers given below for more details on each specific section.

Open a Pending changes view with all the changes of the solution. This is mostly as the Checkin command available on the solution explorer. Both commands differ only in their extent: while this includes changes for the whole solution, the one in the solution explorer only affects the selected item and its children. If you want to see all the pending changes in the workspace instead of only those of items in the Visual Studio solution, check the Pending changes on workspace command described below.

Open a Branches view with the branches of the repository loaded in the workspace. The view is fully functional and lets the user perform all the operations available to branches such as creating new child branches or switching the workspace to a specific branch.

Open a Branch Explorer view for the repository loaded in the workspace. The view is fully functional letting the user perform all the operations available to branches, changesets and labels, like comparing changes or opening new filtered Branch Explorer views.

Open a Labels view for the repository loaded in the workspace. Again, all the operations normally available for labels on the UVCS GUI are available here as well.

Open a Changesets view for the repository loaded in the workspace. This lists all the changeset of the last month by default. It operates as the same view in the UVCS GUI.

Open a Repositories view that contains the list of repositories in the default UVCS server and possibly repositories in other servers as defined by the server connection profiles (in Preferences, see below). This view behaves as the Repositories view in the UVCS GUI client.

Open a Sync replication view.

The Workspace explorer view is the same as the Workspace Explorer in the UVCS GUI. Normally items are handled in Visual Studio through the Solution Explorer, but this view can be better suited for files in the workspace that are not contained in the Visual Studio solution.

Open a Pending changes view displaying with the changes of the whole workspace. Like the Workspace explorer view, this one makes more sense when the user needs to look at changes on items not contained in the Visual Studio solution. To open a view that only contains the changes in the solution, see the Pending changes under solution view above.

Open a workspace status view. It contains details about the workspace, such as the location on disk of the workspace as well as the repository and branch loaded in the workspace. This view is slightly different to the UVCS GUI counterpart (the workspace status bar) and is meant to be docked in a visible place inside Visual Studio. But the information shown is essentially the same.

For more details, refer to chapter Introduction to the Graphical User Interface in the UVCS GUI guide.

Open a Preferences dialog to change UVCS settings. This window is the same as the Preferences window available in the UVCS GUI.

All the views opened from the View > Plastic SCM menu can be arranged with the usual docking controls found in Visual Studio.

To dock any UVCS view, drag the window or tab title and drag it. Visual Studio will display the docking guides that let you dock the window in the desired location.

When a solution has been bound to UVCS, the plug-in will try to connect to the UVCS server to perform each operation (checkout, checkin, diff, annotate, etc). If the server is not available for some reason, most of the operations will fail, after some time spent waiting for the network timeout.

It is possible to set the UVCS plug-in into "offline mode", so that the operations that require the server are not available (like annotate or diff), but still it is possible to make changes in the code. Later, when the connection with the server is back, those changes can be sent to it by setting the plug-in online again.

To set the solution offline, go to:

File > Plastic SCM Source Control > Change Source Control

The bindings dialog appears and displays the status of the solution and the different projects inside it.

To work offline, select all the items in the table and click the Disconnect button. The green status line "The Plastic SCM plug-in is Connected" changes to a red "The Plastic SCM plug-in is disconnected (Working offline)".

If you right click on an item in the Solution Explorer, the only UVCS command available is Checkout for edit. When an item is modified, it is indeed checked out in the workspace.

To go online again, open the bindings dialog and select all the items in the table and click the Connect button. The red status line changes back to green and the items that were checked out locally while offline are now checked out in the source control.

This same dialog also lets you remove the bindings from the solution so it is no longer connected to UVCS, as well as bind it back if needed.

To unbind the solution, select all the items in the table and click the Unbind button. The status column for all the selected items should change from "Bound" to "Not bound".

To bind the solution with the UVCS plug-in, select all the items in the list and click the Bind button. The status column changes from "Not bound" to "Bound".

Additional options can be configured inside Visual Studio once the "Plastic SCM Source Control Package" has been selected as the source control plug-in. Go to:

Tools > Options > Source Control > Plastic SCM settings

This button opens the Preferences dialog from the UVCS GUI. It is the same as the menu command View > Plastic SCM > Plastic SCM Preferences.

Visual Studio provides hooks to notify the UVCS plug-in when certain operations happen. For instance, when a file is moved, Visual Studio notifies the UVCS plug-in of this fact. However if you move a file between different projects inside the solution, Visual Studio notifies this as a deleted item in the source project and a new added file in the destination project. This is normally not desirable from the source control perspective because the history if that item is "lost" (it is there, but you will have two items, the old and the new, instead of the one single item that has been moved).

UVCS is capable of detecting when a file has been moved on its own, so when this option is not set (the default), the moved items detection is handled by UVCS. The only thing to consider is that, in the pending changes view, the option to "Show deleted items" has to be checked and everything will work smoothly.

If Delete files in UVCS when they are delete in Visual Studio is set, then moving a file between projects will appear in UVCS as if the file has been deleted from the source and added new in the destination.

**Examples:**

Example 1 (unknown):
```unknown
Tools > Options > Source Control
```

Example 2 (unknown):
```unknown
Add to source control
```

Example 3 (unknown):
```unknown
File > Open > Open from Plastic SCM...
```

Example 4 (unknown):
```unknown
View > Toolbars or Tools > Customize
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/overview/manual/apple-privacy-manifest

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy. For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Services Core is available from version 1.12.5.

The following code sample contains the PrivacyInfo.xcprivacy manifest for Services Core. This file is also available in the SDK.

To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
   <array/>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
		<dict>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>CA92.1</string>
			</array>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategoryUserDefaults</string>
		</dict>
	</array>
</dict>
</plist>
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
   <array/>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
		<dict>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>CA92.1</string>
			</array>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategoryUserDefaults</string>
		</dict>
	</array>
</dict>
</plist>
```

---

## PARTIAL CONFIGURE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-configure

**Contents:**
- PARTIAL CONFIGURE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Allows you to configure your workspace by loading or unloading items from it.

cm partial configure <+|-path>[ ...] [--silent] [--ignorefailed] [--ignorecase] [--restorefulldirs] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

The command assumes recursive operation.

cm partial configure +/landscape_grey.png

(Loads 'landscape_grey.png' item.)

cm partial configure -/landscape_black.png

(Unloads 'landscape_black.png' item.)

cm partial configure +/soft -/soft/soft-black.png

(Loads all 'soft' directory children items except 'soft-black.png'.)

cm partial configure -/

(Unloads the whole workspace.)

cm partial configure -/ +/

(Loads the whole workspace.)

cm partial configure -/figure-64.png --ignorefailed

(Unloads 'figure-64.png' item even if it was already unloaded.)

cm partial configure +/ --restorefulldirs

(Sets all directories to automatically download the new content.)

cm partial configure +/src/lib --restorefulldirs

(Sets only '/src/lib' and its subdirectories to automatically download the new content.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial configure <+|-path>[ ...] [--silent] [--ignorefailed] [--ignorecase] [--restorefulldirs] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
cm partial configure +/landscape_grey.png
```

Example 3 (unknown):
```unknown
cm partial configure -/landscape_black.png
```

Example 4 (unknown):
```unknown
cm partial configure +/soft -/soft/soft-black.png
```

---

## Multiplay Hosting SDK for Unity

**URL:** https://docs.unity.com/game-server-hosting/en-us/manual/sdk/game-server-sdk-for-unity

**Contents:**
- Multiplay Hosting SDK for Unity#
- Requirements and limitations#
- Initialize the SDK#
- Configure the game server#
- Ready the game server#
- Unready the game server#
- Start server query handler#
- Subscribe to server events#
- Handle Multiplay Hosting events#
  - Allocate#

The Multiplay Hosting SDK for Unity has all the functionality necessary to use Multiplay Hosting scaling and game server services in your game. Unity.Services.Multiplay is the primary namespace for interacting with the Multiplay service.

Note: Refer to Get started with Multiplay Hosting and the integration requirements before continuing.

The Multiplay Hosting SDK for Unity works with Unity Editor version 2020.3 and later.

Warning: There's a known issue with Unity Editor version 2022 that prevents the SDK from working. If you use version 2022, ensure you use version 2022.2.3f1 or later.

Use the Instance method to create a singleton of the IMultiplayService. You can use the singleton to interact with the Multiplay Hosting API.

The ServerConfig class represents a game server configuration, and allows you to create a ServerConfig instance for the current game session.

Use the ServerConfig method (within the ServerConfig class) to create a ServerConfig instance for the current game session.

The following code example shows how to use the ServerConfig method to log information about a game server, such as the server ID, allocation ID, port number, query port number, and server log directory.

Use the ReadyServerForPlayersAsync method to let Multiplay Hosting know a game server is ready to receive players. Refer to Game server readiness.

Use the UnreadyServerAsync method to let Multiplay Hosting know that a game server is no longer ready to receive players. Refer to Game server readiness.

Use the StartServerQueryHandlerAsync method to connect to the game server’s SQP implementation with the provided parameters.

Multiplay Hosting uses the StartServerQueryHandlerAsyncparameters to initialize the server query handler.

After you initialize the server query handler, you can use the IServerCheckManager instance provided by this call to update the values at any time. You must call UpdateServerCheck() for the changes to take effect. Call UpdateServerCheck() when game server variables change. Refer to SQP for more information.

You should call UpdateServerCheck() often enough to ensure you send up-to-date data back to Multiplay Hosting when the query request happens every 60 seconds.

One of the best ways to do so is to call it in the Update loop. But you can also call it when specific game events occur, such as a player joining, a player leaving, or a game match starting.

Note: The currentPlayers field always starts at 0. You must update this value each time a player connects to (or disconnects from) the game server.

The following example shows how to start the server query handler.

Use the SubscribeToServerEventsAsync method to subscribe to server event callbacks for a game server.

The following example shows how to subscribe to and handle game server event callbacks, including OnAllocate, OnDeallocate, and OnError.

The MultiplayEventCallbacks class provides callbacks for responding to Multiplay Hosting events, such as allocations, deallocations, errors, and game server state changes.

The following code example shows how to respond to event callbacks, such as OnAllocate, OnDeallocate, and OnError.

Use the Allocate callback to respond to a MultiplayAllocation event.

Use the Deallocate callback to respond to a MultiplayDeallocation event.

Use the Error callback to respond to a MultiplayError event.

Use the SubscriptionStateChanged callback to respond to a MultiplayServerSubscriptionState event.

The Multiplay Authoring module (installed with the Multiplay package) allows you to optionally author and modify resources directly within the Unity Editor. You can then upload resources from the Unity Editor to the Dashboard by using the Deployment package.

Multiplay configurations existing in the Unity Editor allow users to treat their source control as the single source of truth (instead of the version in the cloud), simplifying actions such as rollbacks, bisection, and other common operations.

To use Multiplay in the Unity Editor:

To create Multiplay configurations within the Editor, install the following packages:

To install these packages:

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

In Unity Editor, select Edit > Project Settings > Services.

If your project doesn't have a Unity project ID:

If you have an existing Unity project ID:

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

The Multiplay Authoring module allows you to create, edit, and deploy Multiplay configurations directly within the Unity Editor.

Follow these steps to create an Multiplay configuration using the Multiplay Authoring module:

The new configuration is now visible in the Project window, and in the Deployment window, accessible by selecting Services > Deployment.

There is currently one method to edit an existing configuration:

The deployment window finds resources and assigns their type according to their file extension.

The configuration uses the yaml format to describe its contents and the .gsh file extension.

Example for new_multiplay_config.gsh:

The configuration describes 3 components within the file:

You can deploy a Multiplay configuration through the Deployment window. Refer to the Deployment package manual for more information.

Some configurations have dependencies on other resources,such as build configurations being dependent on the build itself.

When deploying, Builds will deploy first, then the Build Configurations, then the Fleets. A failure at one point in the chain will halt deployment for the configurations that depend on it.

The Deployment window is a core feature of the Deployment package. It allows all services to have a single cohesive interface for deployment needs, and allows you to upload cloud assets to their respective cloud services.

Refer to the Deployment package manual for more information.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.Multiplay
```

Example 2 (unknown):
```unknown
IMultiplayService
```

Example 3 (unknown):
```unknown
async void Example_InitSDK()
{
	try
	{
		await UnityServices.InitializeAsync();
	}
	catch (Exception e)
	{
		Debug.Log(e);
	}
}
```

Example 4 (unknown):
```unknown
async void Example_InitSDK()
{
	try
	{
		await UnityServices.InitializeAsync();
	}
	catch (Exception e)
	{
		Debug.Log(e);
	}
}
```

---

## CCD and Addressables walkthrough

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDWalkthrough

**Contents:**
- CCD and Addressables walkthrough#
- Prerequisites#
  - Download and test the project#
  - Install the Addressable Assets package#
- Configure Addressables in the Editor#
  - Configure game assets as addressable#
  - Configure an Addressables profile#
- Connect your project to CCD#
  - The Command-line interface (optional)#
- Create buckets#

You can use the Addressable Asset system in Unity with CCD to effectively serve content to your users. This page demonstrates how to set up an actual Unity game project with Cloud Content Delivery (CCD) and Addressables, which allows you to easily integrate a pipeline of assets from Unity Editor into CCD.

Note: The Addressables Asset System isn’t required for using CCD.

This workflow gives you instructions on how to do the following tasks with the Loady Dungeons sample project in Unity:

Note: This walkthrough uses Unity 2023.18f.

For this workflow, you need to install the Loady Dungeon sample project. This project comes with the Addressables Assets package pre-installed, but you can also install the package from the Asset Manager.

The first thing you need to do to follow along with this walkthrough is to download the latest version of our sample game from GitHub, Loady Dungeons.

You can then test the project in the Unity Editor:

Note: When you play the game in its initial state, you can't load the first level. As you progress through this workflow, you associate the required assets to use CCD with Addressables to fix this limitation.

In order to mark assets as addressable, you need to install the Addressables package directly in Unity Editor.

This project already has an Addressables package pre-installed, but if you are following along with a custom project or want to upgrade to a newer verified version, install the Addressables package through the Package Manager:

Addressable assets provide an easy way to handle asset management overload by loading assets by address. To load game assets by address, you need to mark them as Addressable:

Open the Scenes folder in the Project window.

Select the following assets:

In the Inspector window, select Addressable for each asset.

Select Window > Asset Management > Addressables > Groups to open the Addressables Groups window.

Select Create > Group > Packed Assets and create the following new groups:

Drag the Scenes assets from the default group into their corresponding groups. For example, drag the Level_01 scene from the default group into the new Level 01 group you created.

In the Project window (Prefabs > Hats), drag the entire contents from the Hats folder (not the folder itself) into the Hats group.

Select each of the assets from the Addressables Groups window, and rename their lengthy Addressable field to something simpler in the Inspector window.

Note: To automatically rename them, select all the assets, right-click, and select Simplify Addressable Names.

To save all of the associated settings related to development of the game, you can create a new Addressables profile:

After you set up your Addressables in the Unity Editor, you can connect the game project to the Cloud Content Delivery (CCD) service, ultimately leveraging the Addressables and AssetBundles. CCD is managed cloud service that hosts and delivers content to your application’s users worldwide without the need to reinstall a new version of the application.

To get started with CCD:

Sign in to the Unity Dashboard with your Unity ID.

From the projects page, select New button.

Open your new Loady Dungeons Workshop project and take note of the Project ID.

Select the Environments tab. If you don't already have a development environment, create one.

From the Products page in the dashboard, locate and open Cloud Content Delivery.

Note: If you haven't used CCD before, you can refer to CCD in the Unity Dashboard for more information about how to set it up.

You can also use the optional command-line interface (CLI) to manage your project:

For more information, refer to CCD Command-line interface (CLI).

You can create buckets to assist in the different stages of creation for this project.

From the CCD landing page, select Buckets on the left.

Select Loady Dungeons Workshop from the projects dropdown (if not already selected).

Select Create Bucket to create a new bucket.

Name the bucket Loady Dungeons Sample and give the bucket an optional description.

Select the permissions for this bucket from the following:

To restrict read access to this bucket, select Enable Bucket Privacy. Private buckets only allow users with an access token to read the content.

Note: You cannot change the bucket privacy settings after you create the bucket.

Select Next and make sure both production and development environments are selected.

When you create the Loady Dungeons Sample bucket. it appears on the Cloud Content Delivery Buckets page in the Unity Dashboard, for both development and production environments. You can use the environments dropdown to switch between environments at the top of the page. Take note of the Bucket IDs of the buckets in both environments because you need to use them later in your remote load path.

If you want to read the data from private buckets, you need to have a valid Bucket Access Token.

As of Addressables 1.19.4, you can use the WebRequestOverride feature to add a Bucket Access Token as a header to the request, which the following example demonstrates:

In this example, token is the base64 encoded Bucket Access Token value.

Note: If you want to use the CCD Management package instead, skip to the Generate AssetBundles and upload content with CCD Management package section.

An AssetBundle is an archive file that contains platform-specific non-code assets that Unity can load at run time.

To generate AssetBundles:

In your Unity Editor project, select Window > Asset Management > Addressables > Groups.

In the Profile dropdown, make sure that Development Profile is selected. If it isn’t, select it now.

In the Profile dropdown, select Manage Profiles.

With Development Profile selected, set the following:

RemoteBuildPath: AssetBundles/[BuildTarget], where [BuildTarget] is the default subfolder.

RemoteLoadPath: https://PROJECT_ID.client-api.unity3dusercontent.com/client_api/v1/buckets/BUCKET_ID/release_by_badge/latest/entry_by_path/content/?path=

Return to the Addressables Groups window and select Hats.

In the Inspector panel, set the build path and load paths for these four sets of assets to the paths we specified for the Development Profile:

In the Groups window, select the Build dropdown, then select New Build > Default Build Script. This saves the AssetBundles at the RemoteBuildPath location.

To use the build you made as the basis for a play test, select Play Mode Script > Use Existing Build.

Select the Play button in Unity Editor to test the game. Press Start in the game. Notice how the game is now stuck.

At this point, you can upload this content into the Development bucket you set up in CCD earlier.

CCD automatically applies the automatically created latest badge to this release, which marks it as the newest release created in this bucket.

Note: You can also use the CLI to upload content.

The CCD Management package with Addressables 1.19.15+ allows you to build, upload and release Addressable content.

Note: You need to upgrade the Addressables versions and install the CCD Management package through the Package Manager.

Note: At this point if you don't already have the CCD Management package installed, Unity Editor prompts you to add it. Select the Install CCD Management SDK Package button to install it.

When you select Start in the game, the game is now stuck.

To generate, upload, and release this content into the Loady Dungeons Sample bucket we set up in CCD earlier:

The CCD Management package uses the default build script behavior to generate the Addressable bundles. Then, the management package uploads all groups associated with the path pair that is connected to the Loady Dungeons Sample bucket and latest badge that we set up earlier to those remote targets. Finally, the management package creates a release for those remote targets and updates their badge to latest.

After you upload your assets to the Loady Dungeons Sample bucket in your development environment and you tie those assets into a release, you can put these latest changes out for public consumption. That’s why we also created the bucket in your production environment. The buckets in your production environment contain releases ready for your players. This means moving the release from the bucket in your development environment to the one in your production environment by a process called promotion.

To promote the release from the bucket in your development environment to the one in your production environment:

Again, CCD automatically applies the automatically created latest badge to this release, which marks it as the newest release created in this bucket.

Before you test the game, you need to modify the profile variables to point to the correct bucket. There are two ways to do this:

In this workflow, you successfully move the release and all its assets from Development to Production, ready to deploy to your users as a functional game.

**Examples:**

Example 1 (unknown):
```unknown
Development Profile
```

Example 2 (unknown):
```unknown
Loady Dungeons Workshop
```

Example 3 (unknown):
```unknown
Loady Dungeons Sample
```

Example 4 (javascript):
```javascript
void Start()
{
	textComponent = GetComponent<Text>();
	Addressables.WebRequestOverride = webRequest =>
	{
		webRequest.SetRequestHeader("Authorization", "Basic "+token);
		//  Debug.Log($"Fetching: {webRequest.url}");
	};
	Addressables.LoadAssetAsync<TextAsset>("Assets/one.txt").Completed += handle =>
	{
		textComponent.text = handle.Result.text;
		// Debug.Log($"Text is now: {handle.Result.text}");
	};
}
```

---

## Leaderboard features

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/features

**Contents:**
- Leaderboard features#

Leaderboards can enhance your project with the following features:

---

## Resets

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/concepts/resets

**Contents:**
- Resets#
- Manual resets#
- Scheduled resets#

You can configure leaderboards to reset automatically on a predefined schedule or you can reset them manually. Resetting a leaderboard clears out all of the current scores.

When resetting a leaderboard you can optionally create a read-only archive copy of the current leaderboard scores, which game clients can access by fetching scores for that archived version. Refer to the Leaderboards archives page for details on archives.

To reset leaderboards in the Unity Dashboard, select the leaderboard and select Reset Leaderboard. You can also reset leaderboards using the CLI and by using the Admin API.

When resetting a leaderboard from the Unity Dashboard, you can optionally create an archive of the scores before you reset the leaderboard.

You can configure a scheduled reset to be a recurring reset or a one time reset.

If you configure a scheduled recurring reset, scores contained in the leaderboard will expire based on this schedule and users will be able to submit new scores for each reset cycle.

For advanced configuration options for scheduled resets - e.g. using @every 72h to reset a leaderboard every 3 days - check the documentation for resetConfig option in the Admin API.

As with manual resets you can configure leaderboards to automatically create an archive on reset.

---

## Player profiles

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/unreal-engine-sdk/player-profiles

**Contents:**
- Player profiles#

To authorize multiple players sequentially inside a single game session, player profiles can be used. This feature grants the ability to switch, validate, and sign out of different authorization profiles.

By default, a single player profile is created under the name configured in the ‘Unity Authentication’ Project Settings. If the configured name is invalid, it’ll revert to “default”.

Note: Switching profiles is only a valid action when a player is signed out. If you try to switch profiles while signed-in, a warning is logged and results in the Player Profile staying the same.

---

## Use branches

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/use-branches

**Contents:**
- Use branches#
- Switch branch#
- Create a new branch#

Use branches in Gluon.

To switch the branch you're on, select your current branch in the top bar and select the branch you want to switch to from the dropdown menu.

Create a new branch to work on:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/lock-unlock

---

## Get started with Unity Version Control via the Unity Hub

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/get-started-vcs-hub

**Contents:**
- Get started with Unity Version Control via the Unity Hub#
- View your projects in the Unity Hub#
- Enable UVCS for your projects#
  - Create a project with UVCS#
  - Add UVCS to an existing project#
- Add projects from UVCS to your Hub#
  - Add encrypted repositories to your Hub#
  - Add repositories that don't contain Unity projects to your local machine#
  - Use different workspaces for different projects in the same repository#
- Open your UVCS connected projects#

You can add Unity Version Control (UVCS) to your Unity Editor projects through the Unity Hub.

If you don't already have DevOps set up, then you get a free trial of the DevOps services when you enable Version Control through the Hub. You can also set up DevOps through your Unity Dashboard. For more information, refer to Get started with Unity DevOps.

Note: If you’ve been added to a Unity organization or Unity Cloud project that uses DevOps, all you need to get started is a Unity ID. For detailed instructions, refer to Add projects from UVCS to your Hub.

The second column on the Projects page of the Unity Hub shows whether each project has UVCS enabled:

Important: We are in the process of updating the Version Control experience. If you are not on the New experience, step 4 also prompts you to enter a UVCS organization name.

To create a new Unity Editor project in the Unity Hub and connect the repository to UVCS:

To enable UVCS for existing Unity Editor projects in the Hub:

If you've been added to a Unity organization or Unity Cloud project that contains Unity Editor projects, you can add those projects to the Hub:

Important: We are in the process of updating the Version Control experience. If you are not on the New experience, you can add repositories from all of the UVCS organizations you belong to.

Important: We are in the process of updating the Version Control experience. If you are not on the New experience, you can add repositories from all encrypted UVCS organizations you belong to.

If you have been invited to an encrypted UVCS repository, you can add its contained projects to the Hub by following these steps:

A repository must contain the file ProjectSettings/ProjectVersion.txt to be recognized as a Unity project. If you have been invited to a UVCS repository that doesn't contain a Unity project in the root directory, you can still add it to your local machine by following these steps:

If the repository contains Unity projects within subdirectories, you can add them to the Hub after following the previous steps by doing the following:

If you want to use different workspaces for different projects in the same repository, allowing you to work on different branches for each project, follow these steps:

When you open an Editor project that you enabled UVCS on, the Editor opens the project with the Unity Version Control tab open.

Note: If the Unity Version Control tab isn’t displayed, select Window > Unity Version Control to open the tab.

For information on how to use UVCS through the Unity Editor, refer to the Tutorials section.

**Examples:**

Example 1 (unknown):
```unknown
ProjectSettings/ProjectVersion.txt
```

---

## Vivox integration

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/vivox-integration

**Contents:**
- Vivox integration#
- Join a voice channel#
- Other interactions with Lobby#
  - Important notes:​#

Note: You must be using a Vivox package version of at least 16.0.0 for the integration to work.

The Vivox service offers a way for game developers to enable voice and text communications between users without investing in a self-hosted solution. Vivox protects users by requiring you to securely authenticate and authorize users before they can perform authoritative actions such as joining a channel, muting, or kicking another player.

In the past, Vivox required clients to implement a server token that securely generates a Vivox Access Token (VAT) similar to a JSON Web Token (JWT) for each authoritative action. Generating a VAT for each authoritative action is cumbersome, and often presents a significant hurdle for securely implementing voice communication in games. Lobby simplifies implementing secure voice communication with Vivox by acting as a token provider for users connected to a lobby.

Note: You must have both the Vivox and the Lobby packages installed to use the two services together. You can install these packages from the Unity Dashboard. See the Vivox SDK documentation to learn how to set up Vivox.

Keep reading for a quick guide on using Vivox and Lobby together.

Once you enable Vivox in your project:

Create a new lobby, or join an existing lobby. The Lobby SDK automatically registers itself as a token provider for Vivox using the Lobby ID.

Join the voice channel for a lobby. When you attempt to join a Vivox channel, it calls the token provider. If the channel ID matches the lobby ID, then it generates a token.

The following code sample shows you how to create a Lobby and then join the voice channel associated with it.

Use Vivox events to be notified of the channel change. For example, VivoxService.Instance.ChannelJoined += channelName => { ... }.

Apart from creating or joining a lobby, you can interact with Vivox channels using the Vivox SDK. However, certain actions should be performed using the Lobby SDK instead to keep the Lobby and Voice channels synchronized. The following list contains example actions that you must perform through the Lobby SDK:

**Examples:**

Example 1 (unknown):
```unknown
using System;
using UnityEngine;
using Unity.Services.Authentication;
using Unity.Services.Core;
using Unity.Services.Vivox;
using VivoxUnity;

async void Start()
{
    // Authenticate with Unity services
    await UnityServices.InitializeAsync();
    await AuthenticationService.Instance.SignInAnonymouslyAsync();

    await VivoxService.Instance.InitializeAsync();

    // Log in to Vivox services
    await VivoxService.Instance.LoginAsync();
}
```

Example 2 (unknown):
```unknown
using System;
using UnityEngine;
using Unity.Services.Authentication;
using Unity.Services.Core;
using Unity.Services.Vivox;
using VivoxUnity;

async void Start()
{
    // Authenticate with Unity services
    await UnityServices.InitializeAsync();
    await AuthenticationService.Instance.SignInAnonymouslyAsync();

    await VivoxService.Instance.InitializeAsync();

    // Log in to Vivox services
    await VivoxService.Instance.LoginAsync();
}
```

Example 3 (unknown):
```unknown
using System;
   using UnityEngine;
   using Unity.Services.Core;
   using Unity.Services.Lobbies;
   using Unity.Services.Lobbies.Models;
   using Unity.Services.Vivox;
   using VivoxUnity;
​
   async void CreateLobbyAndJoinVoice()
   {
             // Create a new lobby (or join an existing one)
       Lobby myLobby = await LobbyService.Instance.CreateLobbyAsync(
           lobbyName: "myLobby",
           maxPlayers: 5,
           options: new CreateLobbyOptions()
           {
               IsPrivate = false,

           });
​
       // Join the voice channel
       await VivoxService.Instance.JoinGroupChannelAsync(myLobby.Id, ChatCapability.AudioOnly);
   }
```

Example 4 (unknown):
```unknown
using System;
   using UnityEngine;
   using Unity.Services.Core;
   using Unity.Services.Lobbies;
   using Unity.Services.Lobbies.Models;
   using Unity.Services.Vivox;
   using VivoxUnity;
​
   async void CreateLobbyAndJoinVoice()
   {
             // Create a new lobby (or join an existing one)
       Lobby myLobby = await LobbyService.Instance.CreateLobbyAsync(
           lobbyName: "myLobby",
           maxPlayers: 5,
           options: new CreateLobbyOptions()
           {
               IsPrivate = false,

           });
​
       // Join the voice channel
       await VivoxService.Instance.JoinGroupChannelAsync(myLobby.Id, ChatCapability.AudioOnly);
   }
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/apple-privacy-survey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Relay is available from version 1.1.1.

The following code sample displays the contents of the PrivacyInfo.xcprivacy manifest file for Relay. This file is also available in the Relay SDK version 1.1.1.

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

Example 2 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## Advance a community goal

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/modules/use-cases/community-goal

**Contents:**
- Advance a community goal#
- Prerequisites#
  - Aggregate player contributions#
  - Set up the ScoreAggregator as a singleton#
  - Use the ScoreAggregator in your Cloud Code module#
- Test the Cloud Code module#
- Verify the Cloud Save data#

Use Cloud Code to enable players to contribute to a community goal. A community goal is a goal that players can contribute to collectively. The goal can be anything that contributes to a score or a count, such as to collect items, defeat enemies, or complete quests. It's up to you to define the goal and how players can contribute to it.

Cloud Save stores the state of the goal in game data. To contribute to the goal, players call a Cloud Code function.

In many instances, this might be a heavy operation, because you need to update the goal progress in real-time as players contribute to the goal. To reduce the number of calls to Cloud Save, you can aggregate the player contributions and update the goal progress in Cloud Save at regular intervals.

To enable players to contribute to a community goal, complete the following tasks:

The get started page provides a workflow of how to set up the Cloud Code module so that you can implement the community goal use case.

If you call out to Cloud Save for every individual player contribution, it can increase costs. To reduce the number of calls to Cloud Save, aggregate the player contributions and update the goal progress in Cloud Save at regular intervals. The ScoreAggregator class in the following sample demonstrates how to aggregate player contributions and update the goal progress in Cloud Save.

In the following sample, the ScoreAggregator class has a RunningCount field that stores the total number of items contributed by players. The Increment method increments the RunningCount field by the number of items that the player contributes. The method also updates the goal progress in Cloud Save at regular intervals.

The increments are locked to ensure that each request successfully updates the count and isn't overwritten. The method also locks the LastUpdate field so that multiple simultaneous calls don't all hit Cloud Save at the same time.

Create a new file ScoreAggregator.cs in your Cloud Code module and add the following code:

To ensure that ScoreAggregator holds state between requests, use dependency injection to set up the ScoreAggregator as a singleton.

Modules use an in-memory cache to store the state between invocations. Refer to Module persistence between invocations for more information on the limitations of in-memory caches.

Define a Configuration class that implements the ICloudCodeSetup interface:

Use the ScoreAggregator in your Cloud Code module to increment the player contributions. You can also define a helper method to initialize the Cloud Save data. Call the helper method once to set up the Cloud Save data.

Define a Main class that uses the ScoreAggregator:

Generate bindings and deploy the module.

Next, define a MonoBehaviour script that calls the AddScore function to increment the player contributions. The following test script is a simple example that increments the score by 10:

Note: In a live version, replace the score with your own logic to generate the score.

Attach the MonoBehaviour script to a GameObject in your scene and run the scene.

After you verify that the Cloud Code module works as you expect, you can remove the InitializeCloudSave function from the Cloud Code module.

You can further customize the Cloud Code module to suit your game's requirements for score generation.

Track the goal progress update in Cloud Save as players contribute to the goal.

The value of the item should increase as players contribute to the goal.

**Examples:**

Example 1 (unknown):
```unknown
ScoreAggregator
```

Example 2 (unknown):
```unknown
ScoreAggregator
```

Example 3 (unknown):
```unknown
ScoreAggregator
```

Example 4 (unknown):
```unknown
ScoreAggregator
```

---

## UNDO

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/undo

**Contents:**
- UNDO#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - These commands are equivalent when executed from the /src directory#
    - These commands are also equivalent when executed from the /src directory#
  - Filters#
  - Deleted items#

Undoes changes in a workspace.

cm undo [<path>[ ...]] [--symlink] [-r | --recursive] [<filter>[ ...]] [--silent | --machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

If dirpath is a workspace path, every change in the workspace will be undone.

cm undo file.txt code.cs /test

cm undo /src file.txt code.cs

The paths can be filtered using one or more of the filters below. Each of those filters refers to a type of change:

If the path matches one or more of the specified kinds of changes, those types of changes will be undone on that said path. For example, if you specify both '--checkedout' and '--moved', if a file is both checkedout and moved, both changes will be undone.

If no filter is specified, all kinds of changes are undone.

To undo file and directory deletions, you must either specify the full path of the item, or specify the containing directory and use the recursive ('-r') flag.

(Does NOT undo deletions (but other changes) in the current directory.)

(Undoes all deletions (and other changes) in the current directory recursively.)

(Undoes deletion (or other change) of src/file.txt.)

(Undoes all changes in the current directory recursively. If executed from the workspace's root, undoes all changes in the entire workspace.)

(Undoes the checkout on 'file.txt'.)

cm undo c:\otherworkspace\file.txt

(Undoes changes in file 'file.txt' located in a workspace other than the current one.)

echo content >> file.txt

(Undoes the local change to 'file.txt'.)

(Undoes changes to the src directory and its files.)

(Undoes changes in every file and directory contained in src, without affecting src.)

(Undoes changes to every file or directory that matches *.cs in the current directory.)

(Undoes changes on every file or directory that matches *.cs in the current directory and every directory below it.)

cm co file1.txt file2.txt

echo content >> file1.txt

(Undoes the checkout of unchanged 'file2.txt', ignoring locally changed 'file1.txt'.)

echo content >> file1.txt echo content >> file2.txt

(Undoes the changes in checked-out file 'file1.txt', ignoring 'file2.txt' as it is not checked-out.)

(Undo the add of 'file.txt' making it once again a private file.)

rm file1.txt echo content >> file2.txt

cm undo --deleted --added *

(Undoes the 'file1.txt' delete and 'file3.txt' add, ignoring the 'file2.txt' change.)

**Examples:**

Example 1 (unknown):
```unknown
cm undo [<path>[ ...]] [--symlink] [-r | --recursive] [<filter>[ ...]] [--silent | --machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
cm undo dirpath -r
```

Example 3 (unknown):
```unknown
cm undo file.txt code.cs /test
```

Example 4 (unknown):
```unknown
cm undo /src file.txt code.cs
```

---

## SDKs for Multiplay Hosting

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/sdk/sdk-overview

**Contents:**
- SDKs for Multiplay Hosting#

Find the right Multiplay Hosting SDK for your game engine.

The following SDKs have all the functionality necessary to use Multiplay Hosting scaling and game server services in your game.

Note: For most users, the unified Multiplayer Services package replaces the Multiplay Hosting standalone package, which is deprecated in Unity 6. Consider migrating to the unified package to facilitate a smooth transition. Visit the migration guide for a step-by-step transition process.

---

## Server readiness

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/concepts/server-readiness

**Contents:**
- Server readiness#

Game servers aren't always ready to start hosting a match or have players connect when the processes start up. They likely have an initialization process to run through for loading assets or connecting to external services.

Game server readiness is a feature that allows game servers to let Multiplay Hosting know, and by extension, the matchmaker or service that controls player connections, when they're prepared to accept players and when they're no longer ready to accept players through the Game Server SDK. The exact process for this is dependent on whether you are using the Multiplay Hosting SDK for Unity or the Multiplay Hosting SDK for Unreal Engine.

The feature enables a game server to complete its start-up logic before players try to connect. Without this feature, a game server with a long start-up time can reject players trying to connect, resulting in a bad experience.

The Multiplay Hosting allocations system only considers a game server to fulfill an allocation when it’s online and has announced itself as ready.

Game server readiness is an attribute associated with a build configuration. To establish the readiness, it must be configured during the creation of a build configuration.

Tip: Game server readiness can also function as an indication of server health. You can implement health checks at start-up and only flag a server as ready if it passes all health checks. This way, you ensure that Multiplay Hosting doesn’t use a potentially unhealthy server to fulfill an allocation.

The following flow chart illustrates where server readiness comes into the allocation flow.

---

## Understand User Reporting

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/UserReporting/UnderstandingUserReporting

**Contents:**
- Understand User Reporting#
- View user reports#
  - Understand user report details#
  - Send user report from an unhandled exception#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

After you Set up User Reporting, user reports appear on the Unity Dashboard. If they don’t, verify that your report is not over 10MB in size.

The User Reporting page shows the reports you’ve received. Select a user report to open its details.

You can filter the reports using the Dimensions and Value drop-down menus. To apply filters, select Apply. To remove any report filters, select Clear. For more information on creating custom dimensions, see Configure User Reporting.

The top of the User Reporting page displays your current report limits and usage, depending on your Unity plan. To increase your report count limit and usage, upgrade to Advanced Cloud Diagnostics with Unity Pro or higher.

Select a user report card from the User Reporting page to open its details.

The subsequent page displays the detailed data for the selected report. The top of the page displays the date the report was received and a summary description.

To delete or download the report, use the Report actions drop-down menu.

The User report details page also includes data such as metrics, screenshots, fields, device metadata, and events:

Note: While this approach is possible, it's strongly recommended to use the Crash and Exception Reporting feature of Cloud Diagnostics to handle unhandled exceptions. This feature gives a full stack trace for the unhandled exception, the logs from the event, and track occurrences and discover patterns, visible from the Unity Dashboard. Crash and Exception Reporting aggregates crash and exception reports.

You can send a user report when there's an unhandled exception, to bring over log files and more useful data.

Add the following script to a sample scene of the User Reporting package:

This approach comes from the Application.logMessageReceived C# Event which triggers in many situations, including unhandled exceptions. By checking that the LogType of the message is Exception, the code only executes when an unhandled exception occurs. Be mindful to remove your callback from the event when/if the response is no longer necessary for performance considerations.

**Examples:**

Example 1 (unknown):
```unknown
void OnEnable()
{
    Application.logMessageReceived += UhandledExceptionCallback;
}
 
void OnDisable()
{
    Application.logMessageReceived -= UnhandledExceptionCallback;
}
 
void UnhandledExceptionCallback(string condition, string stackTrace, LogType type)
{
    if (type == LogType.Exception)
    {
         // Insert your desired behavior here, such as creating and sending a user report.
    }
}
```

Example 2 (unknown):
```unknown
void OnEnable()
{
    Application.logMessageReceived += UhandledExceptionCallback;
}
 
void OnDisable()
{
    Application.logMessageReceived -= UnhandledExceptionCallback;
}
 
void UnhandledExceptionCallback(string condition, string stackTrace, LogType type)
{
    if (type == LogType.Exception)
    {
         // Insert your desired behavior here, such as creating and sending a user report.
    }
}
```

Example 3 (unknown):
```unknown
Application.logMessageReceived
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/pricing-for-unity-devops

---

## Configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/SDK-configuration

**Contents:**
- Configuration#
  - SyncConfigurationAsync#
- Currencies#
  - GetCurrencies#
  - GetCurrency#
  - CurrencyDefinition#
    - GetPlayerBalance#
- Inventories#
  - GetInventoryItems#
  - GetInventoryItem#

The methods in the Configuration namespace allow you to retrieve items from the global economy configuration.

SyncConfigurationAsync() caches the latest version of your Economy configuration, after which you can call methods like GetCurrencies() to read your configuration from the cache. If you publish a new configuration, you must call SyncConfigurationAsync() again to update the cache.

Gets the currently published Economy configuration and caches it in the SDK. You must call this method before calling any other configuration methods (for example, GetCurrencies()), otherwise an exception is thrown.

Retrieves all currencies from your cached configuration. Returns a list of CurrencyDefinition objects.

Retrieves a specific CurrencyDefinition using a currency ID from your cached configuration. Returns null if the currency doesn't exist.

A CurrencyDefinition object represents a single currency configuration and contains the following data:

It also has the following convenience methods:

This method gets the balance for the currently signed in player of the currency specified in the CurrencyDefinition. It returns a PlayerBalance as specified in Player balances.

Retrieves all inventory items from your cached configuration. Returns a list of InventoryItemDefinition objects.

Retrieves a specific InventoryItemDefinition using an item ID from your cached configuration. Returns null if the item doesn't exist.

A InventoryItemDefinition object represents a single inventory item configuration, and contains the following data:

It also contains the following helper methods:

Gets all of the player's inventory items for the currently logged in player. Returns a GetInventoryResult as defined in Player inventories.

Retrieves all virtual purchases from your cached configuration. Returns a list of VirtualPurchaseDefinition objects.

Retrieves a single virtual purchase from your cached configuration. Returns a single VirtualPurchaseDefinition object.

A VirtualPurchaseDefinition object represents a virtual purchase definition from your configuration. It is made up of a number of component objects as listed below.

The VirtualPurchaseDefinition has the following fields:

Economy SDK 3.0.0 contains an issue that causes the GetRealMoneyPurchase()) / GetRealMoneyPurchases() methods to not return StoreIdentifiers. The recommended best practice is that developers revert to version 2.0.4 of the SDK to avoid this issue until it is resolved.

Retrieves all real money purchases from your cached configuration. Returns a list of RealMoneyPurchaseDefinition objects.

Retrieves a single real money purchase from your cached configuration. Returns a single RealMoneyPurchaseDefinition object.

A RealMoneyPurchaseDefinition object represents a real money purchase definition from your configuration. It is made up of a number of component objects as listed below.

The RealMoneyPurchaseDefinition has the following fields:

A StoreIdentifers object contains both the Google and Apple store identifiers. These are set when creating a purchase in the Unity Dashboard in the "Store connection" step. They can be edited by clicking on your purchase in the Unity Dashboard and scrolling down to "Store connection".

A PurchaseItemQuantity represents an amount of currency/inventory items associated with a purchase. Each one relates to a single currency/inventory item type (for example, 4 swords, 10 gold, etc.). It has the following fields:

An EconomyReference is a reference to another definition from within the purchase. It has a single method:

Getting the referenced item this way happens synchronously as it doesn't require a further network request, and will get the referenced item as it was when the purchase was retrieved (any changes to the definition between fetching the purchase and accessing the reference will not be reflected in the referenced item).

Custom data is set in the Unity Dashboard. Select a currency, inventory item, or purchase, navigate to Custom data, then add the data in a JSON format.

Custom data is stored in CustomDataDeserializable on fetched configuration items. It is of type IDeserializable. This allows you to deserialize your items’ custom data into your own custom classes.

For example, if your game has a color rarity system then the items could have the following JSON code in the Unity Dashboard:

You can deserialize the instance data with the following:

**Examples:**

Example 1 (unknown):
```unknown
Configuration
```

Example 2 (unknown):
```unknown
SyncConfigurationAsync()
```

Example 3 (unknown):
```unknown
GetCurrencies()
```

Example 4 (unknown):
```unknown
SyncConfigurationAsync()
```

---

## Player segmentation

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/advanced-topics-player-segmentation

**Contents:**
- Player segmentation#
- Segment player population#

Player segmentation is important in matchmaking as it impacts the number of players that can be matched with each other. This number impacts the time it takes to find another player.

The more players there are in a pool of tickets, the higher the chances of finding players to match with. At the same time, if there are too many players, then it'll take time to go through all the players and find a match for them.

However, if there aren't enough players in a pool of tickets, it takes Matchmaker time to find other players to match together.

The following diagram shows the relationship between time to match players and the number of players in a pool.

There are several ways to segment player population. The first type of segmentation is game driven segmentation. For example the different game modes that a game offers.

Players playing in these different modes should never be matched together.

In Matchmaker, this segmentation is represented by queues.

The second type of segmentation is a segmentation based on attributes that are provided by the player who wants to join a match.

This type of segmentation is dynamic and based on filters and represented by pools. Pools always belong to a queue. Players from different pools could potentially be matched together. Matchmaker will use the attributes of a ticket to determine if a ticket matches the filters defined in a pool.

Pools can be used to dynamically merge/split player population in case a population is too small or too large.

The following diagrams show how the dynamic partitioning works:

1 - Player A will fall in Ticket Pool 1.0 No Cheater.

2 - The different players are distributed in the different pools as followed using the attributes on their ticket and the pools filters.

3 - The number of tickets for the pools of the beta version is too small and the cheater pool is removed. Tickets targeting 1.1-beta, cheater or not, will now all end up in the same pool.

Note: The deletion of a pool only applies for new tickets. Tickets already in a pool aren't redistributed to other pools.

---

## Config options

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/config-options

**Contents:**
- Config options#

The following table describes all the properties that are available as config options and their default values. You can change the config options in the developer dashboard and set them for each environment.

---

## Reserved parameter names

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/reserved-parameter-names

**Contents:**
- Reserved parameter names#

Unity Analytics has a set of reserved parameter names that cannot be used in custom event definitions. These are listed below.

**Examples:**

Example 1 (unknown):
```unknown
NAME, ABORT, ABSOLUTE, ACCESS, ACCESSRANK, ACCOUNT, ACTION, ACTIVATE, ADD, ADMIN, AFTER, AGGREGATE, ALL, ALSO, ALTER, ANALYSE, ANALYTIC, ANALYZE, 
AND, ANTI, ANY, ARRAY, AS, ASC, ASSERTION, ASSIGNMENT, AT, AUTHENTICATION, AUTHORIZATION, AUTO, AUTO_INCREMENT, AVAILABLE, BACKWARD, BASENAME, BATCH, 
BEFORE, BEGIN, BEST, BETWEEN, BIGINT, BINARY, BIT, BLOCK, BLOCKDICT_COMP, BLOCK_DICT, BOOLEAN, BOTH, BROADCAST, BY, BYTEA, BYTES, BZIP, BZIP_COMP, 
CACHE, CALLED, CASCADE, CASE, CAST, CATALOGPATH, CHAIN, CHAR, CHARACTER, CHARACTERISTICS, CHARACTERS, CHARACTER_LENGTH, CHAR_LENGTH, CHECK, CHECKPOINT, 
CLASS, CLEAR, CLOSE, CLUSTER, COLLATE, COLSIZES, COLUMN, COLUMNS_COUNT, COMMENT, COMMIT, COMMITTED, COMMONDELTA_COMP, COMPLEX, CONNECT, CONSTRAINT, 
CONSTRAINTS, CONTROL, COPY, CORRELATION, CPUAFFINITYMODE, CPUAFFINITYSET, CREATE, CREATEDB, CREATEUSER, CROSS, CSV, CUBE, CURRENT, CURRENT_DATABASE, 
CURRENT_DATE, CURRENT_SCHEMA, CURRENT_TIME, CURRENT_TIMESTAMP, CURRENT_USER, CURSOR, CUSTOM, CYCLE, DATA, DATABASE, DATAPATH, DATEDIFF, DATETIME, DAY, 
DEACTIVATE, DEALLOCATE, DEC, DECIMAL, DECLARE, DECODE, DEFAULT, DEFAULTS, DEFERRABLE, DEFERRED, DEFINE, DEFINER, DELETE, DELIMITER, DELIMITERS, 
DELTARANGE_COMP, DELTARANGE_COMP_SP, DELTAVAL, DEPENDS, DESC, DETERMINES, DIRECT, DIRECTCOLS, DIRECTED, DIRECTGROUPED, DIRECTPROJ, DISABLE, DISABLED, 
DISCONNECT, DISTINCT, DISTVALINDEX, DO, DOMAIN, DOUBLE, DROP, DURABLE, EACH, ELSE, ENABLE, ENABLED, ENCLOSED, ENCODED, ENCODING, ENCRYPTED, END, 
ENFORCELENGTH, EPHEMERAL, EPOCH, ERROR, ESCAPE, EVENT, EVENTS, EXCEPT, EXCEPTION, EXCEPTIONS, EXCLUDE, EXCLUDING, EXCLUSIVE, EXECUTE, EXECUTIONPARALLELISM, 
EXISTS, EXPIRE, EXPLAIN, EXPORT, EXTERNAL, EXTRACT, FAILED_LOGIN_ATTEMPTS, FALSE, FAULT, FENCED, FETCH, FILESYSTEM, FILLER, FILTER, FIRST, FIXEDWIDTH, FLEX, 
FLEXIBLE, FLOAT, FOLLOWING, FOR, FORCE, FOREIGN, FORMAT, FORWARD, FREEZE, FROM, FULL, FUNCTION, FUNCTIONS, GCDDELTA, GET, GLOBAL, GRANT, GROUP, GROUPED, 
GROUPING, GZIP, GZIP_COMP, HANDLER, HAVING, HCATALOG, HCATALOG_CONNECTION_TIMEOUT, HCATALOG_DB, HCATALOG_SCHEMA,HCATALOG_SLOW_TRANSFER_LIMIT, 
HCATALOG_SLOW_TRANSFER_TIME, HCATALOG_USER, HIGH, HIVE_PARTITION_COLS, HOLD, HOST, HOSTNAME, HOUR, HOURS, IDENTIFIED, IDENTITY, IDLESESSIONTIMEOUT, IF, 
IGNORE, INOUT, INPUT, INSENSITIVE, INSERT, INSTEAD, INT, INTEGER, INTERFACE, INTERPOLATE, INTERSECT, INTERVAL, INTERVALYM, INTO, INVOKER, IS, ISNULL, 
ISOLATION, JOIN, JSON, KEY, KSAFE, LABEL, LANCOMPILER, LANGUAGE, LARGE, LAST, LATEST, LEADING, LEFT, LESS, LEVEL, LIBRARY, LIKE, LIKEB, LIMIT, LISTEN, LOAD, 
LOCAL, LOCALTIME, LOCALTIMESTAMP, LOCATION, LOCK, LONG, LOW, LZO, MANAGED, MASK, MATCH, MATCHED, MATERIALIZE, MAXCONCURRENCY, MAXCONCURRENCYGRACE, 
MAXCONNECTIONS, MAXMEMORYSIZE, MAXPAYLOAD, MAXVALUE, MEDIUM, MEMORYCAP, MEMORYSIZE, MERGE, MERGEOUT, METHOD, MICROSECONDS, MILLISECONDS, MINUS, MINUTE, 
MINUTES, MINVALUE, MODE, MODEL, MONEY, MONTH, MOVE, MOVEOUT, NAME, NATIONAL, NATIVE, NATURAL, NCHAR, NETWORK, NEW, NEXT, NO, NOCREATEDB, NOCREATEUSER, NODE, 
NODES, NONE, NOT, NOTHING, NOTIFIER, NOTIFY, NOTNULL, NOWAIT, NULL, NULLAWARE, NULLCOLS, NULLS, NULLSEQUAL, NUMBER, NUMERIC, OBJECT, OCTETS, OF, OFF, OFFSET, 
OIDS, OLD, ON, ONLY, OPERATOR, OPT, OPTIMIZER, OPTION, OPTVER, OR, ORC, ORDER, OTHERS, OUT, OUTER, OVER, OVERLAPS, OVERLAY, OWNER, PARAMETER, PARAMETERS, 
PARQUET, PARSER, PARTIAL, PARTITION, PARTITIONING, PASSWORD, PASSWORD_GRACE_TIME, PASSWORD_LIFE_TIME, PASSWORD_LOCK_TIME, PASSWORD_MAX_LENGTH, 
PASSWORD_MIN_DIGITS, PASSWORD_MIN_LENGTH, PASSWORD_MIN_LETTERS, PASSWORD_MIN_LOWERCASE_LETTERS, PASSWORD_MIN_SYMBOLS, PASSWORD_MIN_UPPERCASE_LETTERS, 
PASSWORD_REUSE_MAX, PASSWORD_REUSE_TIME, PATTERN, PERCENT, PERMANENT, PINNED, PLACING, PLANNEDCONCURRENCY, POLICY, POOL, PORT, POSITION, PRECEDING, 
PRECISION, PREPARE, PREPASS, PRESERVE, PREVIOUS, PRIMARY, PRIOR, PRIORITY, PRIVILEGES, PROCEDURAL, PROCEDURE, PROFILE, PROJECTION, PROJECTIONS, PSDATE, 
QUERY, QUEUETIMEOUT, QUOTE, RANGE, RAW, READ, REAL, RECHECK, RECORD, RECOVER, RECURSIVE, REFERENCES, REFRESH, REINDEX, REJECTED, REJECTMAX, RELATIVE, 
RELEASE, REMOVE, RENAME, REORGANIZE, REPEATABLE, REPLACE, RESET, RESOURCE, RESTART, RESTRICT, RESULTS, RETURN, RETURNREJECTED, REVOKE, RIGHT, RLE, 
ROLE, ROLES, ROLLBACK, ROLLUP, ROW, ROWS, RULE, RUNTIMECAP, RUNTIMEPRIORITY, RUNTIMEPRIORITYTHRESHOLD, SAVE, SAVEPOINT, SCHEMA, SCROLL, SEARCH_PATH, 
SECOND, SECONDS, SECURITY, SECURITY_ALGORITHM, SEGMENTED, SELECT, SEMI, SEMIALL, SEQUENCE, SEQUENCES, SERIALIZABLE, SESSION, SESSION_USER, SET, SETOF, 
SETS, SHARE, SHARED, SHOW, SIMILAR, SIMPLE, SINGLEINITIATOR, SITE, SITES, SKIP, SMALLDATETIME, SMALLINT, SOME, SOURCE, SPLIT, STABLE, STANDBY, START, 
STATEMENT, STATISTICS, STDIN, STDOUT, STEMMER, STORAGE, STREAM, STRENGTH, STRICT, SUBNET, SUBSTRING, SYSDATE, SYSID, SYSTEM, TABLE, TABLES, TABLESAMPLE, 
TABLESPACE, TEMP, TEMPLATE, TEMPORARY, TEMPSPACECAP, TERMINATOR, TEXT, THAN, THEN, TIES, TIME, TIMESERIES, TIMESTAMP, TIMESTAMPADD, TIMESTAMPDIFF, 
TIMESTAMPTZ, TIMETZ, TIMEZONE, TINYINT, TLS, TO, TOAST, TOKENIZER, TOLERANCE, TRAILING, TRANSACTION, TRANSFORM, TREAT, TRICKLE, TRIGGER, TRIM, TRUE, 
TRUNCATE, TRUSTED, TUNING, TYPE, UDPARAMETER, UNBOUNDED, UNCOMMITTED, UNCOMPRESSED, UNI, UNINDEXED, UNION, UNIQUE, UNKNOWN, UNLIMITED, UNLISTEN, UNLOCK, 
UNPACKER, UNSEGMENTED, UPDATE, USAGE, USER, USING, VACUUM, VALIDATE, VALIDATOR, VALINDEX, VALUE, VALUES, VARBINARY, VARCHAR, VARCHAR2, VARYING, VERBOSE, 
VERTICA, VIEW, VOLATILE, WAIT, WEBHDFS_PORT, WEBSERVICE_HOSTNAME, WEBSERVICE_PORT, WHEN, WHERE, WINDOW, WITH, WITHIN, WITHOUT, WORK, WRITE, YEAR, 
ZONE, collectInsertedTimestamp, convertedProductAmount, eventDate, eventID, eventLevel, eventStoreInsertedTimestamp, gaUserAcquisitionChannel, 
gaUserCountry, gaUserGender, gaUserStartDate, id, mainEventID, msSinceLastEvent, parentEventID, timestamp, transactionVector
```

Example 2 (unknown):
```unknown
NAME, ABORT, ABSOLUTE, ACCESS, ACCESSRANK, ACCOUNT, ACTION, ACTIVATE, ADD, ADMIN, AFTER, AGGREGATE, ALL, ALSO, ALTER, ANALYSE, ANALYTIC, ANALYZE, 
AND, ANTI, ANY, ARRAY, AS, ASC, ASSERTION, ASSIGNMENT, AT, AUTHENTICATION, AUTHORIZATION, AUTO, AUTO_INCREMENT, AVAILABLE, BACKWARD, BASENAME, BATCH, 
BEFORE, BEGIN, BEST, BETWEEN, BIGINT, BINARY, BIT, BLOCK, BLOCKDICT_COMP, BLOCK_DICT, BOOLEAN, BOTH, BROADCAST, BY, BYTEA, BYTES, BZIP, BZIP_COMP, 
CACHE, CALLED, CASCADE, CASE, CAST, CATALOGPATH, CHAIN, CHAR, CHARACTER, CHARACTERISTICS, CHARACTERS, CHARACTER_LENGTH, CHAR_LENGTH, CHECK, CHECKPOINT, 
CLASS, CLEAR, CLOSE, CLUSTER, COLLATE, COLSIZES, COLUMN, COLUMNS_COUNT, COMMENT, COMMIT, COMMITTED, COMMONDELTA_COMP, COMPLEX, CONNECT, CONSTRAINT, 
CONSTRAINTS, CONTROL, COPY, CORRELATION, CPUAFFINITYMODE, CPUAFFINITYSET, CREATE, CREATEDB, CREATEUSER, CROSS, CSV, CUBE, CURRENT, CURRENT_DATABASE, 
CURRENT_DATE, CURRENT_SCHEMA, CURRENT_TIME, CURRENT_TIMESTAMP, CURRENT_USER, CURSOR, CUSTOM, CYCLE, DATA, DATABASE, DATAPATH, DATEDIFF, DATETIME, DAY, 
DEACTIVATE, DEALLOCATE, DEC, DECIMAL, DECLARE, DECODE, DEFAULT, DEFAULTS, DEFERRABLE, DEFERRED, DEFINE, DEFINER, DELETE, DELIMITER, DELIMITERS, 
DELTARANGE_COMP, DELTARANGE_COMP_SP, DELTAVAL, DEPENDS, DESC, DETERMINES, DIRECT, DIRECTCOLS, DIRECTED, DIRECTGROUPED, DIRECTPROJ, DISABLE, DISABLED, 
DISCONNECT, DISTINCT, DISTVALINDEX, DO, DOMAIN, DOUBLE, DROP, DURABLE, EACH, ELSE, ENABLE, ENABLED, ENCLOSED, ENCODED, ENCODING, ENCRYPTED, END, 
ENFORCELENGTH, EPHEMERAL, EPOCH, ERROR, ESCAPE, EVENT, EVENTS, EXCEPT, EXCEPTION, EXCEPTIONS, EXCLUDE, EXCLUDING, EXCLUSIVE, EXECUTE, EXECUTIONPARALLELISM, 
EXISTS, EXPIRE, EXPLAIN, EXPORT, EXTERNAL, EXTRACT, FAILED_LOGIN_ATTEMPTS, FALSE, FAULT, FENCED, FETCH, FILESYSTEM, FILLER, FILTER, FIRST, FIXEDWIDTH, FLEX, 
FLEXIBLE, FLOAT, FOLLOWING, FOR, FORCE, FOREIGN, FORMAT, FORWARD, FREEZE, FROM, FULL, FUNCTION, FUNCTIONS, GCDDELTA, GET, GLOBAL, GRANT, GROUP, GROUPED, 
GROUPING, GZIP, GZIP_COMP, HANDLER, HAVING, HCATALOG, HCATALOG_CONNECTION_TIMEOUT, HCATALOG_DB, HCATALOG_SCHEMA,HCATALOG_SLOW_TRANSFER_LIMIT, 
HCATALOG_SLOW_TRANSFER_TIME, HCATALOG_USER, HIGH, HIVE_PARTITION_COLS, HOLD, HOST, HOSTNAME, HOUR, HOURS, IDENTIFIED, IDENTITY, IDLESESSIONTIMEOUT, IF, 
IGNORE, INOUT, INPUT, INSENSITIVE, INSERT, INSTEAD, INT, INTEGER, INTERFACE, INTERPOLATE, INTERSECT, INTERVAL, INTERVALYM, INTO, INVOKER, IS, ISNULL, 
ISOLATION, JOIN, JSON, KEY, KSAFE, LABEL, LANCOMPILER, LANGUAGE, LARGE, LAST, LATEST, LEADING, LEFT, LESS, LEVEL, LIBRARY, LIKE, LIKEB, LIMIT, LISTEN, LOAD, 
LOCAL, LOCALTIME, LOCALTIMESTAMP, LOCATION, LOCK, LONG, LOW, LZO, MANAGED, MASK, MATCH, MATCHED, MATERIALIZE, MAXCONCURRENCY, MAXCONCURRENCYGRACE, 
MAXCONNECTIONS, MAXMEMORYSIZE, MAXPAYLOAD, MAXVALUE, MEDIUM, MEMORYCAP, MEMORYSIZE, MERGE, MERGEOUT, METHOD, MICROSECONDS, MILLISECONDS, MINUS, MINUTE, 
MINUTES, MINVALUE, MODE, MODEL, MONEY, MONTH, MOVE, MOVEOUT, NAME, NATIONAL, NATIVE, NATURAL, NCHAR, NETWORK, NEW, NEXT, NO, NOCREATEDB, NOCREATEUSER, NODE, 
NODES, NONE, NOT, NOTHING, NOTIFIER, NOTIFY, NOTNULL, NOWAIT, NULL, NULLAWARE, NULLCOLS, NULLS, NULLSEQUAL, NUMBER, NUMERIC, OBJECT, OCTETS, OF, OFF, OFFSET, 
OIDS, OLD, ON, ONLY, OPERATOR, OPT, OPTIMIZER, OPTION, OPTVER, OR, ORC, ORDER, OTHERS, OUT, OUTER, OVER, OVERLAPS, OVERLAY, OWNER, PARAMETER, PARAMETERS, 
PARQUET, PARSER, PARTIAL, PARTITION, PARTITIONING, PASSWORD, PASSWORD_GRACE_TIME, PASSWORD_LIFE_TIME, PASSWORD_LOCK_TIME, PASSWORD_MAX_LENGTH, 
PASSWORD_MIN_DIGITS, PASSWORD_MIN_LENGTH, PASSWORD_MIN_LETTERS, PASSWORD_MIN_LOWERCASE_LETTERS, PASSWORD_MIN_SYMBOLS, PASSWORD_MIN_UPPERCASE_LETTERS, 
PASSWORD_REUSE_MAX, PASSWORD_REUSE_TIME, PATTERN, PERCENT, PERMANENT, PINNED, PLACING, PLANNEDCONCURRENCY, POLICY, POOL, PORT, POSITION, PRECEDING, 
PRECISION, PREPARE, PREPASS, PRESERVE, PREVIOUS, PRIMARY, PRIOR, PRIORITY, PRIVILEGES, PROCEDURAL, PROCEDURE, PROFILE, PROJECTION, PROJECTIONS, PSDATE, 
QUERY, QUEUETIMEOUT, QUOTE, RANGE, RAW, READ, REAL, RECHECK, RECORD, RECOVER, RECURSIVE, REFERENCES, REFRESH, REINDEX, REJECTED, REJECTMAX, RELATIVE, 
RELEASE, REMOVE, RENAME, REORGANIZE, REPEATABLE, REPLACE, RESET, RESOURCE, RESTART, RESTRICT, RESULTS, RETURN, RETURNREJECTED, REVOKE, RIGHT, RLE, 
ROLE, ROLES, ROLLBACK, ROLLUP, ROW, ROWS, RULE, RUNTIMECAP, RUNTIMEPRIORITY, RUNTIMEPRIORITYTHRESHOLD, SAVE, SAVEPOINT, SCHEMA, SCROLL, SEARCH_PATH, 
SECOND, SECONDS, SECURITY, SECURITY_ALGORITHM, SEGMENTED, SELECT, SEMI, SEMIALL, SEQUENCE, SEQUENCES, SERIALIZABLE, SESSION, SESSION_USER, SET, SETOF, 
SETS, SHARE, SHARED, SHOW, SIMILAR, SIMPLE, SINGLEINITIATOR, SITE, SITES, SKIP, SMALLDATETIME, SMALLINT, SOME, SOURCE, SPLIT, STABLE, STANDBY, START, 
STATEMENT, STATISTICS, STDIN, STDOUT, STEMMER, STORAGE, STREAM, STRENGTH, STRICT, SUBNET, SUBSTRING, SYSDATE, SYSID, SYSTEM, TABLE, TABLES, TABLESAMPLE, 
TABLESPACE, TEMP, TEMPLATE, TEMPORARY, TEMPSPACECAP, TERMINATOR, TEXT, THAN, THEN, TIES, TIME, TIMESERIES, TIMESTAMP, TIMESTAMPADD, TIMESTAMPDIFF, 
TIMESTAMPTZ, TIMETZ, TIMEZONE, TINYINT, TLS, TO, TOAST, TOKENIZER, TOLERANCE, TRAILING, TRANSACTION, TRANSFORM, TREAT, TRICKLE, TRIGGER, TRIM, TRUE, 
TRUNCATE, TRUSTED, TUNING, TYPE, UDPARAMETER, UNBOUNDED, UNCOMMITTED, UNCOMPRESSED, UNI, UNINDEXED, UNION, UNIQUE, UNKNOWN, UNLIMITED, UNLISTEN, UNLOCK, 
UNPACKER, UNSEGMENTED, UPDATE, USAGE, USER, USING, VACUUM, VALIDATE, VALIDATOR, VALINDEX, VALUE, VALUES, VARBINARY, VARCHAR, VARCHAR2, VARYING, VERBOSE, 
VERTICA, VIEW, VOLATILE, WAIT, WEBHDFS_PORT, WEBSERVICE_HOSTNAME, WEBSERVICE_PORT, WHEN, WHERE, WINDOW, WITH, WITHIN, WITHOUT, WORK, WRITE, YEAR, 
ZONE, collectInsertedTimestamp, convertedProductAmount, eventDate, eventID, eventLevel, eventStoreInsertedTimestamp, gaUserAcquisitionChannel, 
gaUserCountry, gaUserGender, gaUserStartDate, id, mainEventID, msSinceLastEvent, parentEventID, timestamp, transactionVector
```

---

## Axosoft OnTime integration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/issue-tracking/axosoft

**Contents:**
- Axosoft OnTime integration#
- Configure the Axosoft server#
  - Obtain the Axosoft API key#
  - Create a custom field#
- Configure the client for Axosoft#
  - Configure the client on Windows#
  - Configure the client on Linux and macOS#
  - Axosoft parameters#
- Use the Axosoft integration#
  - Task on branch workflow#

Learn how to configure and use the Axosoft OnTime extension with Unity Version Control (UVCS). You can use the Axosoft integration for Axosoft v14 and higher.

Configure Axosoft so that Axosoft can connect with Unity Version Control (UVCS).

To work with Axosoft, the UVCS client needs the client-id and client-secret parameters:

Refer to the Axosoft documentation on how to obtain a private API key.

Create a custom field that UVCS can use to log changes in linked changesets:

Refer to the Axosoft documentation on how to add a custom field.

Configure your Unity Version Control (UVCS) client to work with your Axosoft integration.

There are different methods to configure the client depending on your operating system:

Regardless of your operating system, you need to configure the Axosoft parameters.

Set a local Axosoft configuration on a Linux or macOS machine:

Note: You can also set a global extension configuration on the server.

Use the following parameters to further configure your Axosoft integration:

Use one of the following working modes for your Axosoft integration:

Find issue information in the Axosoft extension panel. You can open the issue in the browser, add a new issue, or delete an issue. If you select the Open issue in browser icon, or double-click on the Axosoft task, UVCS opens the associated issue in a browser window. UVCS also uses the custom field in Axosoft to log every checkin for a linked branch or changeset.

Task on branch is the default working mode. Each Axosoft task links to a branch in Unity Version Control (UVCS).

The branch name connects the branch to a Axosoft issue:

The task on changeset working mode allows you to link multiple changesets to multiple branches:

Use the UVCS desktop application to link changesets to Axosoft work items:

To log the checkin information in the related Axosoft issue, enter a comment in the Checkin comments field, start the comment with the # character followed by the issue key. For example, #def4: Updates.

**Examples:**

Example 1 (unknown):
```unknown
client-secret
```

Example 2 (unknown):
```unknown
Plastic SCM
```

Example 3 (unknown):
```unknown
issuetrackers/<server_port>/<repository>
```

Example 4 (unknown):
```unknown
ontime.conf
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/apple-privacy-survey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Friends is available from version 1.0.1.

The following code sample displays the contents of the PrivacyInfo.xcprivacy manifest file for Friends. This file is also available in the Friends SDK version 1.0.1.

To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 3 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## Session operations as a client

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/session-op-client

**Contents:**
- Session operations as a client#
- Session property operations#
  - Read APIs#
  - Read a session property#
- Player property operations#
  - Read APIs#
  - Read a player property#
  - Write APIs#
  - Add a player property#
  - Update a player property#

Manage your sessions with the operations available to you as a session client.

Note: The Multiplayer Services SDK uses sessions to manage groups of players. Sessions relies internally on different combinations of Unity Gaming Services such as Relay, Distributed Authority, Lobby, Matchmaker and Multiplay Hosting, and thus contributes to the billing of those services.

As a session client, you have access to operations that let you interact with session and player properties. Note that some client operations differ from those available to the host.

A client can read properties from a session. Unlike a host, a client can't add, update, or delete session properties.

Note: If you are the host and have an ISession (client session), you can call ISession.AsHost() to get an IHostSession (host session) from your ISession. After you have an IHostSession, you can add, update, or delete session property. Refer to Session operations as a host.

The following APIs allow a client to read session properties:

The following code snippet demonstrates how to read the colour property:

A client can access any player properties set as visible to them. However, a client can only add, update, or remove the player properties they own.

The following APIs allow a client to read player properties:

Note: Use ISession.CurrentPlayer to read your own properties.

The following code snippet demonstrates how to read the colour player property:

The following APIs allow a client to modify its player properties:

To add a property, decide upon the visibility of the property:

The following code snippet demonstrates how to add a colour property with the value red on a client:

The following code snippet demonstrates how to set the colour property to null on a client:

The following code snippet demonstrates how to delete the colour property on a client:

**Examples:**

Example 1 (unknown):
```unknown
ISession.AsHost()
```

Example 2 (unknown):
```unknown
IHostSession
```

Example 3 (unknown):
```unknown
IHostSession
```

Example 4 (unknown):
```unknown
ISession.IReadOnlyDictionary<string, SessionProperty> Properties { get; }
```

---

## Unity Version Control integration with VS Code's SCM features

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/vscode-plugin

**Contents:**
- Unity Version Control integration with VS Code's SCM features#
- Intro#
- Requirements#
- Features#
- Install#
- Configure#
- Commands#
  - Checkin#
  - File Changes#
- Issues#

plastic-scm is a Visual Studio Code extension that integrates Unity Version Control System (UVCS). With this plugin, you can use UVCS as your SCM tool.

This plugin contains a subset of UVCS commands and features. Please stay tuned for upgrades.

You can type in the input field in the SCM view and hit Ctrl+Enter to checkin all your pending changes. We don't support selecting what items you want to check in at the moment.

You can also invoke the Checkin command using the Command Palette. You'll be prompted to enter a commit message in that case.

When editing a tracked text file, you'll see VS Code show inline gutter color indicators to show lines added, changed, or removed, similar to using Git or other source control extensions. You can also open the Source Control panel to and click on any modified text file to open a full-file diff from the latest changeset.

Have a look at the list of issues on Github.

**Examples:**

Example 1 (unknown):
```unknown
plastic-scm
```

Example 2 (unknown):
```unknown
Install Extensions
```

Example 3 (unknown):
```unknown
Plastic SCM
```

Example 4 (unknown):
```unknown
plastic-scm.autorefresh
```

---

## Overview of services

**URL:** https://docs.unity.com/ugs/en-us/manual/overview/manual/unity-gaming-services-home

**Contents:**
    - Unity Gaming Services is an end-to-end platform that is designed to help you build, engage, and grow your game.#
- Overview of services#
- Build your foundation#
  - Accounts#
  - Content management#
  - DevOps#
  - Multiplayer#
- Engage your players#
  - Analytics and player engagement#
  - Communications and Safety#

Take your game to the next level without having to worry about maintaining or scaling your back-end infrastructure. UGS simplifies many game development tasks and challenges. Examples include:

Unity Gaming Services supports your entire development lifecycle. Use them to build your foundation, engage your players, and grow your game.

---

## Free start-up credit

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/pricing-free-credit

**Contents:**
- Free start-up credit#
- Additional resources#

All new organizations receive an $800 sign-up credit. The credits are valid for six months from your sign-up date. The credits automatically apply on your first and following invoices until they're exhausted or expire.

Your credit starts rolling when you subscribe to Unity Gaming Services. It applies to your entire Organization. For example, if you have two projects using Multiplay Hosting, they are pulling from the same $800 credit.

Once your credit is consumed or expires, you are charged for your usage.

Note: To view a real-time preview of your consumption, in the Unity Dashboard, select Administration > Costs and usage reporting. You also receive emails and dashboard notifications when the credit is almost consumed or expired.

---

## PARTIAL SHELVESET DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-shelveset-delete

**Contents:**
- PARTIAL SHELVESET DELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

cm partial shelveset delete | rm <sh_spec>

The 'partial shelveset delete' command deletes a shelveset.

cm partial shelveset delete sh:3

(Removes a stored shelveset.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial shelveset delete | rm <sh_spec>
```

Example 2 (unknown):
```unknown
cm partial shelveset delete sh:3
```

---

## Unity Version Control (previously Plastic SCM)

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/unity-version-control

**Contents:**
- Unity Version Control (previously Plastic SCM)#
- Example workflow#
  - Task#
  - Task branch development#
  - Code review#
  - Automated testing and merge#
  - Deployment#
- Use Unity Version Control#
  - Use Unity Version Control via the Desktop Client#
  - Use Unity Version Control via the Hub#

Unity Version Control (UVCS), previously named Plastic SCM, is a version control and source code management tool you can use for game and real-time 3D development to improve team collaboration and scalability with any engine.

UVCS offers you workflows optimized for artists and programmers, and efficiency when you work with large files and binaries.

The UVCS web experience in the Unity Dashboard has new and deeply integrated role-based workflows, code reviews, and user and user group management. These capabilities not only connect teams, they help increase productivity for real-time content creators.

For more information on the tools available with UVCS, refer to the Concepts section.

You can customize your workflow to best support your needs.

A version control workflow starts with a task. This task can be in your issue tracker or project, so that each change in code has an associated task.

Next, you create a branch for the task. You can work on the task branch and make check-in changes with comments as you go to record your work.

Once you mark your task as completed, you can request a code review from one of your coworkers. They can then add comments, ask questions and request changes until they are happy and approve your changes. You can also get a coworker to manually test your code for validation if necessary.

Once the task is reviewed or validated, you can merge the changes. Before you check in the merge, the task changes are tested to check for merge conflicts to avoid breaking the build. To test for merge conflicts before the merge, or to automatically merge changes after a review, you can use a mergebot.

You can deploy changes in the way that best suits your projects. If you use a mergebot, you can enable automatic CI integration.

You can enable Unity Version Control through your Unity Dashboard.

You can use UVCS with multiple applications and repositories through the UVCS desktop client. For more information, refer to the documentation on how to Get started via the desktop client.

You can also add UVCS to your projects through the Unity Hub. For more information, refer to the documentation on how to Get started via the Hub.

---

## Use SSL certificates

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/ssl/use-ssl-certificates

**Contents:**
- Use SSL certificates#
- Use the SSL certificate for the UVCS secure channel#
  - Example configuration file#
- Accept and install SSL certificates#
  - Use the UVCS GUI#
  - Use the CLI#
  - Use manual installation#
    - Manually install on a Windows server#
    - Manually install on a macOS server#
- Additional resources#

Use SSL certificates to end to end encrypt your Unity Version Control (UVCS) network traffic. Refer to more information on how to create SSL certificates.

By default, the UVCS server SSL channel is configured to listen on port 8088 with the default SSL UVCS SSL certificate.

To use your own self-signed certificate, edit the network.conf file, located in the UVCS server directory. Modify the following values:

Save the network.conf file and restart the UVCS server to apply the changes.

The following example shows the server network.conf file that uses the new Tardis.pfx certificate and the ciphered password:

You can install the SSL certificates in the following ways:

The first time your UVCS GUI uses the SSL port to connect to the UVCS server, the GUI displays a dialog window that prompts you to accept and install the new UVCS server certificate.

Select Yes to add the key to your UVCS key store.

When you use the UVCS CLI tool, the CLI prompts you to accept and install the UVCS server certificate. Enter Y to select Yes and add the key to your UVCS key store.

In some situations, you need to accept and install the SSL certificate without your UVCS client. For example, for a replication operation, the UVCS server needs to connect with another UVCS server and since the server itself can't accept a certificate, you need to install the .cer file manually.

Note: The certificate that you install is only valid for the system user that accepts the certificate on the server. If you need to install a certificate for the UVCS server to use, then you need to run the UVCS server or daemon as an Administrator or root user.

To confirm that the certificate is installed correctly, expand the Plastic Client store to display the installed certificates.

To install the certificate on a macOS server, copy the .cer file to a directory. Use the following directory path: /Users/<Your_User>/.config/.mono/certs/Plastic Client.

Note: This only installs the certificate for the system user <Your_User>. If you need to install certificates for other users, repeat the process for each of those users.

**Examples:**

Example 1 (unknown):
```unknown
network.conf
```

Example 2 (unknown):
```unknown
sslPfxFilePassword
```

Example 3 (unknown):
```unknown
network.conf
```

Example 4 (unknown):
```unknown
network.conf
```

---

## Log schema

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/logging/concepts/schema

**Contents:**
- Log schema#

The Logging schema is built upon the OpenTelemetry standard.

You can expect the following fields in all log entries:

**Examples:**

Example 1 (unknown):
```unknown
severityText
```

Example 2 (unknown):
```unknown
severityNumber
```

Example 3 (unknown):
```unknown
resourceAttributes
```

Example 4 (unknown):
```unknown
service.name
```

---

## CLONE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/clone

**Contents:**
- CLONE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Clones a remote repository.

cm clone <src_rep_spec> [<dst_rep_spec> | <dst_repserver_spec>] [--user=<usr_name> [--password=<pwd>] | [--authmode=<mode> --authdata=<data>] | [--authfile=<authentication_file>]] [--trmode=(copy|name|table --trtable=<translation_table_file>]

(Direct repository-to-repository clone.)

cm clone <src_rep_spec> --package=<pack_file> [--user=<usr_name> [--password=<pwd>] | [--authmode=<mode> --authdata=<data>] | [--authfile=<authentication_file>]] [--trmode=(copy|name|table --trtable=<translation_table_file>]

(Clones to an intermediate package, that can be imported later using a pull into the destination repository.)

The clone command can replicate branches (along with their changesets, labels, attributes, reviews, and so on) from a source repository to a destination repository. The repositories can be located at different servers.

The destination repository can be created beforehand, but if it contains previous data, the clone operation will fail.

The clone operation does NOT clone repository submodules, nor repositories under a Xlink.

cm clone awesomeProject@tardis@cloud

(Clones 'awesomeProject' repository from 'tardis@cloud' organization into a local repository with the same name.)

cm clone repo@server.home:9095 repo-local

(Clones 'repo' from 'server.home:9095' into 'repo-local' at user's default repository server.)

cm clone project@192.168.111.130:8084 repserver:192.168.111.200:9095

(Clones 'project' repository from '192.168.111.130:8084' into 'project@192.168.111.200:9095'.)

cm clone project@ldapserver:8084 --authmode=LDAPWorkingMode --authdata=::0:dave:fPBea2rPsQaagEW3pKNveA

(Clones 'project' repository from 'ldapserver:8084' using LDAP authentication against the remote repository.)

cm clone project@upserver:8084 --authmode=UPWorkingMode --authdata=dave:fPBea2rPsQaagEW3pKNveA==

(Clones 'project' repository from 'upserver:8084' using UPWorkingMode authentication against the remote repository.)

cm clone project@upserver:8084 --authmode=UPWorkingMode --user=<user> --password=<pwd>

(Clones 'project' repository from 'upserver:8084' using UPWorkingMode authentication against the remote repository but specifying the user and password instead of the authdata.)

cm clone project@ldapserver:8084 --authfile=credentials.txt --trmode=table --trtable=table.txt

(Clones 'project' repository from 'ldapserver:8084' using an authentication file against the remote repository, and translating users following the specified translation table.)

cm clone project@server.home:9095 --package=project.plasticpkg

cm repository create project@mordor.home:8084

cm pull --package=project.plasticpkg project@mordor.home:8084

(Clones 'project' repository from 'server.home:9095' into the package 'project.plasticpkg', which is later imported through a pull into the 'project' repository at 'mordor.home:8084'.)

**Examples:**

Example 1 (unknown):
```unknown
cm clone <src_rep_spec> [<dst_rep_spec> | <dst_repserver_spec>] [--user=<usr_name> [--password=<pwd>] | [--authmode=<mode> --authdata=<data>] | [--authfile=<authentication_file>]] [--trmode=(copy|name|table --trtable=<translation_table_file>]
```

Example 2 (unknown):
```unknown
cm clone <src_rep_spec> --package=<pack_file> [--user=<usr_name> [--password=<pwd>] | [--authmode=<mode> --authdata=<data>] | [--authfile=<authentication_file>]] [--trmode=(copy|name|table --trtable=<translation_table_file>]
```

Example 3 (unknown):
```unknown
cm clone awesomeProject@tardis@cloud
```

Example 4 (unknown):
```unknown
cm clone repo@server.home:9095 repo-local
```

---

## Unity Gaming Services CLI

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/write-configuration/cli

**Contents:**
- Unity Gaming Services CLI#
- Prerequisites#
- Using the CLI#
  - Deploy resources#
  - Retrieve resources#
  - Environment synchronization#

You can use the Unity Gaming Services CLI to interact with Remote Config files. The CLI allows you to create, deploy, and manage Remote Config files from the command line.

For a deep dive into the CLI, follow the steps in the Unity Gaming Services CLI Get Started guide.

To follow this guide, you must first complete the following actions:

Refer to the Remote Config Command Line documentation for a full reference of all commands and options.

Note: The ugs remote-config command is also available as ugs rc.

Run the new-file command to create a resource locally:

You can use the Deploy command to promote your local resources to the remote environment and publish them at once. The local resources must be deployed to become available to the game client.

You can use the Fetch command to retrieve all the Remote Config keys from the remote into a single file. The provided path is a directory where the keys will be fetched to:

You can move all your modules from one environment and deploy them to another environment.

Run the following command to produce an archive of all the modules in your current environment:

You can then import the modules and deploy them to another environment by running the following command:

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
ugs remote-config
```

Example 4 (unknown):
```unknown
ugs remote-config new-file <file-name>
```

---

## Glossary

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/glossary

**Contents:**
- Glossary#
    - Heartbeat#
    - Host#
    - Inactive lobby#
    - Lobby code#
    - Lobby data#
    - Lobby ID#
    - Member data#
    - Player#
    - Player data#

A request to keep a lobby from becoming inactive by updating the LastUpdated time.

A player who creates the lobby or assumes the role of host from another host.

Lobbies are marked as inactive if they haven’t been updated or sent a heartbeat request in the last 30 seconds. An inactive lobby can be reactivated by being updated or sending a heartbeat request. Inactive public lobbies do not appear in query results. A public or private lobby that has been inactive for more than one hour may be deleted at any time.

A randomly generated alphanumeric code that players can share with other players to join a private lobby.

Data specific to the lobby.

A randomly generated ID assigned to a lobby when it is created to uniquely identify it. When joining a public lobby, the lobby ID is used to identify the lobby to join.

Data that is only visible to players who have joined the lobby.

A player within the lobby.

Data specific to the player in this lobby.

Data that is only visible to an individual player who is in the lobby.

A lobby that does not appear in query results and is generally only accessible using a lobby code.

Data that is visible to anyone, including players who are not in the lobby.

A type of lobby that is accessible to all players and appears in the query list.

A filter that can be provided as part of a query request to limit the results returned to lobbies that match specific properties.

A list of available public lobbies returned by a search query.

Players can use this to quickly find and join a lobby without having to manually select a specific lobby from a query list.

Unity Relay offers a way for game developers to securely provide increased connectivity between players by using a join code style workflow.

---

## Record an event

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/record-event

**Contents:**
- Record an event#
- Automatic events#
  - Unity 6.2 and later with Analytics SDK 6.1 and later#
  - Unity 6.1 and earlier, or Analytics SDK 6.0 and earlier#

Whether you are recording a standard event provided by Unity Analytics or a custom event that you have created especially for your game, the way to send data to Analytics is the same. Events must conform to a schema that exists on the dashboard or else they are rejected as invalid. You can view your configured events, and create new custom events, in the Event Manager.

To make it easy to record events that are correctly structured, the SDK provides helper classes for standard events and a base class you can extend for custom events.

Events are recorded by building an instance of an Event class and passing it into the AnalyticsService.Instance.RecordEvent(...) method as in this example:

You can also record a custom event that has no parameters by using its name alone:

Note: these API methods changed in version 5.1.0 of the SDK. Please ensure you have the latest version of the SDK installed!

Events recorded by the Analytics SDK are batched and uploaded automatically every 60 seconds.

Once your events have been uploaded, you can view them in the Event Browser.

Note: The Analytics backend rejects events as invalid under the following scenarios:

Note: If you are using the REST API instead of the SDK, you are responsible for populating, recording and uploading events. For more information, see the REST API page.

The SDK automatically populates every event with common parameters, such as userID, sessionID, eventTimestamp, eventUUID and platform, so you don't need to worry about these.

The SDK also automatically records a number of standard events for you.

To learn about the standard event classes, including ones that you must record manually, refer to the list of standard events page.

For more information about the standard event classes, including ones that you must record manually, see the list of standard events page.

**Examples:**

Example 1 (unknown):
```unknown
AnalyticsService.Instance.RecordEvent(...)
```

Example 2 (unknown):
```unknown
MyEvent myEvent = new MyEvent
{
	FabulousString = "hello there",
	SparklingInt = 1337,
	SpectacularFloat = 0.451f,
	PeculiarBool = true
};

AnalyticsService.Instance.RecordEvent(myEvent);
```

Example 3 (unknown):
```unknown
MyEvent myEvent = new MyEvent
{
	FabulousString = "hello there",
	SparklingInt = 1337,
	SpectacularFloat = 0.451f,
	PeculiarBool = true
};

AnalyticsService.Instance.RecordEvent(myEvent);
```

Example 4 (unknown):
```unknown
AnalyticsService.Instance.RecordEvent("myEvent");
```

---

## Google Play Data Safety Section

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/google-data-unity-player-accounts

**Contents:**
- Google Play Data Safety Section#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Unity Player Accounts. For your convenience, Unity Player Accounts provides information on its data collection practices in the following sections.

Important: The data disclosures below are for this service only. You are also responsible for providing any additional disclosures for your app, including other third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, see the Google documentation.

Data collection survey

---

## Google Play data safety section for Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/google-data-safety

**Contents:**
- Google Play data safety section for Authentication#
  - Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Authentication. For your convenience, Authentication provides information on its data collection practices below.

Important: The data disclosures below are for this service only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

---

## CHANGESET MOVE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/changeset-move

**Contents:**
- CHANGESET MOVE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Moves a changeset and all its descendants to a different branch.

cm changeset move | mv <csetspec> <branchspec>

cm changeset move cs:15@myrepo br:/main/scm005@myrepo

cm changeset move cs:cb11ecdb-1aa9-4f11-8698-dcab14e5885a br:/hotfix/TL-352

**Examples:**

Example 1 (unknown):
```unknown
cm changeset move | mv <csetspec> <branchspec>
```

Example 2 (unknown):
```unknown
cm changeset move cs:15@myrepo br:/main/scm005@myrepo
```

Example 3 (unknown):
```unknown
cm changeset move cs:cb11ecdb-1aa9-4f11-8698-dcab14e5885a br:/hotfix/TL-352
```

---

## Economy Game Overrides

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/game-overrides-economy

**Contents:**
- Economy Game Overrides#

Game Overrides allow you to target content to specific audiences, for example, by running A/B tests, and customizing content to geographical location and specific periods of time. You can access the main functionality of Game Overrides in the Player engagement section, allowing you to create Overrides for multiple configuration types. This section describes how to interact with this new functionality from within the Economy service.

To create an Override in Economy:

The Game Overrides documentation has further details about creating an override with Economy for the different types of resources.

To view existing Overrides in Economy:

From the Unity Dashboard, open Economy and select Configuration. The Configuration page displays a list of resources that exist in your project.

Select the name of the resource you want to view.

Select the OVERRIDES tab. The Dashboard displays a table of Overrides that exist for that resource. This table shows the following information:

Select Inspect to see more information about an Override. The subsequent screen displays a table comparing the resource’s original parameters compared to those of the Override.

---

## Find code reviews

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-reviews

**Contents:**
- Find code reviews#
- Filtering options#
- Output options#
- cm find reviews example#

Find information about the status of a code review.

The following list displays the different filtering options (where) that are available to use with the cm find review command:

Note: The condition date and targetid correspond to the Creation date and Reviewed object columns in the Code reviews view of the UVCS desktop application.

The following list displays the different output options (--format) available to use with the cm find review command:

Filter reviews by the following conditions:

**Examples:**

Example 1 (unknown):
```unknown
cm find review
```

Example 2 (unknown):
```unknown
cm find review
```

Example 3 (unknown):
```unknown
cm find reviews
```

Example 4 (unknown):
```unknown
cm find "review where assignee = 'me' and date > '2013/06/14' and date < '2013/06/15' and status = 1"
8424078   29/05/2013 14:50:35 borja    Status1    pablo   "Review scm12816" Branch id:424073
426717   14/06/2013 14:01:14 roberto  Status1   pablo   "Code review 1" Branch id: 426648
```

---

## Loot boxes with cooldown

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/LootBoxesWithCooldown

**Contents:**
- Loot boxes with cooldown#
- Prerequisites#
- Overview#
  - Initialization#
  - Functionality#
- Setup#
  - Requirements#
  - Unity Cloud services configuration#
    - Using the Deployment package#
    - Using the Unity Dashboard#

Whether they're receiving items, currencies, extra lives, or power-ups, players love free stuff! Awarding daily gifts to players that return to your game boosts engagement, intrinsic motivation to check in regularly, and overall interest in your game. Daily rewards can also act as a precursor to introducing monetized in-app purchases in the future. This sample demonstrates how to grant randomized rewards on a timed cooldown. After a player claims their reward, they must wait a preset amount of time before claiming another reward.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

To see this use case in action, open the samples menu and navigate to Loot Boxes With Cooldown. To open this scene directly and interact with the use case:

The DailyRewardsSceneManager.cs script performs the following initialization tasks in its Start function:

When you click the Claim Daily Reward button, you receive a random amount of rewards from the available pool (indicated in the currency HUD). For demonstration purposes, the cooldown is set to 60 seconds. The following occurs:

This example also uses Cloud Code to access Cloud Save to implement a cooldown between rewards and returns:

Note: This sample also includes enhanced error handling to catch and resolve issues that arise from calling the Economy service too frequently (more than five times per second), which triggers the EconomyException exception with the RateLimited reason. This sample catches the exception, pauses .1 seconds with exponential back-off, and then retries until it succeeds.

To replicate this use case, you'll need the following Unity packages in your project:

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys all the necessary items.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Publish the following scripts in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resources in the Unity Dashboard:

**Examples:**

Example 1 (unknown):
```unknown
LootBoxesWithCooldownSample.unity
```

Example 2 (unknown):
```unknown
DailyRewardsSceneManager.cs
```

Example 3 (unknown):
```unknown
GrantTimedRandomReward
```

Example 4 (unknown):
```unknown
Deploy Selection
```

---

## Ecosystem

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/ecosystem

**Contents:**
- Ecosystem#
- The bigger picture#
- Multiplay Hosting integration#
  - Matchmaker integration flow#

Multiplay Hosting is a scalable game server hosting platform that removes the complexity of running and operating infrastructure at scale so your development team can focus on creating engaging player experiences.

The high-level components that form the Multiplay Hosting service consist of the scaling system, fleets, builds, build configurations, and servers. Visit the links below to learn more about each component.

The primary interaction point with the Multiplay Hosting service is the Unity Dashboard. However, there’s also the Multiplay Hosting API, the Multiplay Hosting SDK, and the Multiplay Hosting CLI.

Where does Multiplay Hosting fit into a typical game? Typically, a game developer or studio has expertise in areas directly related to game creation, such as gameplay, animation, and level design.

Managing the hosting and scaling of multiplayer games can be challenging, especially when you account for the time pressures of shipping your game. This can make multiplayer games difficult to implement, especially if you don't have enough servers to meet the player demands of a game.

Multiplay Hosting solves these issues for you by offering multiplayer game hosting and a scalable operating infrastructure so your development team can focus on creating engaging player experiences.

Most games require several components to host a multiplayer game session, including a game client, server, and matchmaker.

Multiplay Hosting handles the game server and hosting component, while the developer usually handles the game client. One of the main integration points of Multiplay Hosting is with a matchmaker, such as the Unity Matchmaker.

Other integration points include a lobby service (such as Unity Lobby) or a build service (such as Unity Build Automation). Refer to Multiplay Hosting integrations.

Matchmakers group players together before the game starts to give players the best game experience possible, considering player data (such as skill level) and location.

Note: It’s common for matchmakers to group players into a lobby, such as the Unity Lobby, before requesting a server from Multiplay Hosting.

Players using a game client to join a multiplayer game must connect to the game server hosting the game. But the connection usually isn’t as simple as a game client connecting to a game server, at least not in a production environment.

Typically, the player uses the game client to join their friends in a group or squad, then the matchmaker places them into a lobby (possibly along with other players). The players wait in the lobby while the matchmaker asks Multiplay Hosting to find the best game server for the players.

After the matchmaker asks Multiplay Hosting for a game server through an allocation request, Multiplay Hosting queues the request while it finds the best server for the request. When Multiplay Hosting finds a server, it prepares the information from the allocation request, then sends the game server information to the matchmaker.

The matchmaker sends the server information back to the game client so the players can join the game session on the server.

The players connect to the game server and play the game together until the game session completes.

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unreal/manual/Unreal/get-started

**Contents:**
- Get started#
- Set up Vivox#

Unity offers the Vivox service as a way for game developers to provide voice and text communications between users through a channel-style workflow without the need to invest in a self-hosted solution.

Plug in to your game and configure your project settings to immediately add communications to your project. Connect an unlimited number of users in 2D and 3D channels. Allow users to control voice volume, perform mute actions, and manage channels. Place users in team chat. Allow users to participate in multiple channels.

To set up Vivox Voice and Text for an Unreal project, complete the following steps.

Create an account and project on the Unity Dashboard: https://cloud.unity3d.com.

On the left pane, select Products. Under Community, select Vivox Voice Chat or Vivox Text Chat.

Follow the onboarding steps. During the onboarding process, select Unreal as your game engine.

Download the latest Unreal SDK for each of the platforms you are developing for.

Select the Windows platform and download Unreal Shooter Game (Source) and Unreal Shooter Game (Prebuilt).

Review the Vivox Unreal Developer Guide documentation, which includes general SDK usage information and code examples.

Implement Vivox Core Unreal.

Review the Access Token Developer Guide, which provides information on using access tokens to perform operations in the Vivox system.

---

## Server failures

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-failures

**Contents:**
- Server failures#

Server failures occur when a server instance encounters an event outside the server lifecycle, such as crashes, failures to start, exceeding usage allowances, or becoming unreachable. Multiplay Hosting can't detect server crashes unless you implement a query protocol.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/pending-changes-tab

---

## Add a new score

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/add-new-score

**Contents:**
- Add a new score#
- Add a new score with metadata#

To add or update an entry for the player in the specified leaderboard, use the AddPlayerScoreAsync method.

To add a score with metadata, use the Metadata option on the AddPlayerScoreOptions configuration object:

If a score that has stored metadata is updated with null metadata, the new metadata value will be null.

**Examples:**

Example 1 (unknown):
```unknown
AddPlayerScoreAsync
```

Example 2 (unknown):
```unknown
public async void AddScore(string leaderboardId, int score)
{
    var playerEntry = await LeaderboardsService.Instance
        .AddPlayerScoreAsync(leaderboardId, score);
    Debug.Log(JsonConvert.SerializeObject(playerEntry));
}
```

Example 3 (unknown):
```unknown
public async void AddScore(string leaderboardId, int score)
{
    var playerEntry = await LeaderboardsService.Instance
        .AddPlayerScoreAsync(leaderboardId, score);
    Debug.Log(JsonConvert.SerializeObject(playerEntry));
}
```

Example 4 (unknown):
```unknown
AddPlayerScoreOptions
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/monitor

---

## Get started with UGS

**URL:** https://docs.unity.com/ugs/manual/overview/manual/getting-started

**Contents:**
- Get started with UGS#
  - Prerequisites#
  - Games using the Unity Engine#
  - Games using REST API#
- Create a project in the Unity Hub#
- Create a project in the Unity Dashboard#
- Link your project in the Unity Editor#
- Install UGS packages#
- Import SDK namespace#
- Initialize Unity Services in your game code#

This topic describes how to set up your project to use Unity Gaming Services.

If you haven’t done so already, complete the following before starting the onboarding process:

To get started using UGS with your Unity project:

If you use a different gaming engine, you can implement UGS in your game using REST APIs. To start using UGS:

If you use the Unreal Engine, you can also implement some UGS features in your game, using:

The fastest way to create a new Unity Cloud connected project is via the Unity Hub.

Your new Unity project is automatically created in the Unity Dashboard and you don't need to connect them manually.

You can already begin browsing services in the Unity Dashboard. To integrate the services, proceed to Install UGS packages.

Manage your projects and services from the Unity Dashboard. To create a new project:

You can now configure your project in the Unity Dashboard and start to configure some services prior to integration with a Unity Editor project. For example, configure Economy items or create Game Overrides. Next, link your Unity Cloud project to a Unity Editor project.

Learn more about managing Unity projects.

To use Unity Gaming Services, you must link your project in the Unity Editor to a Unity Cloud project.

To link your project in the Editor:

Learn more about linking projects to the Unity Dashboard.

Install the corresponding packages for the services you want to implement in your project. To view and install packages applicable to UGS:

You can also type services in the search bar, which returns results for all the services except Remote Config.

In Editor versions 2022.1 or higher, the Package Manager’s Services tab displays all packages available for UGS.

To access the API for an SDK, you must import the SDK's namespace in your script. For example, for Analytics:

You must initialize the Services Core SDK before calling any of the services’ functionality. The recommended best practice is to initialize services early in your game’s runtime, preferably at launch.

Note: You don't need to install the com.unity.services.core package or include it in your package manifest. This is pulled automatically when you install a UGS package that depends on it.

To initialize Unity Services in your game code, create a script that imports the Services Core namespace (Unity.Services.Core), then call the InitializeAsync method. For example:

This method initializes all Unity Gaming Services that are installed in your project. You can use the State method to check the initialization status of your game at runtime. For more information, refer to the Services Core API documentation.

Custom server-authoritative economy logic or game logic is one of the most common uses for Unity Gaming Services. This Cloud Code walkthrough includes everything you’ll need to get started, including installation, initialization, dashboard configuration, and remotely executing a simple Cloud Code script from your game client.

**Examples:**

Example 1 (unknown):
```unknown
using Unity.Services.Analytics;
```

Example 2 (unknown):
```unknown
using Unity.Services.Analytics;
```

Example 3 (unknown):
```unknown
com.unity.services.core
```

Example 4 (unknown):
```unknown
Unity.Services.Core
```

---

## LOCK LIST

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/lock-list

**Contents:**
- LOCK LIST#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - The command shows a line for every lock in the specified server#
  - Examples#

Shows locks on a server.

cm lock list | ls [<revspec> [ ...]] [--server=<server>] [--repository] [--onlycurrentuser] [--onlycurrentworkspace] [--ignorecase] [--anystatus] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>] [--smartlocks]]

The command will display a list of the currently locked items in the default server. It also accepts a list of revision specifications. In this case, only the locks belonging to the selected items will be displayed. A '--server=<server>' can be used to set the default server to query.

For the --machinereadable without the --smartlocks option, the printed fields are:

cm lock list --server=myserver:8084

cm lock list --repository=repo@myserver:8084 --anystatus

cm lock ls serverpath:/src/foo.c#cs:99@default@localhost:8084

cm lock list revid:3521@default itemid:2381@secondary --onlycurrentuser

cm lock ls --onlycurrentuser

cm lock ls --onlycurrentuser --onlycurrentworkspace

cm lock list --machinereadable --startlineseparator=">" --endlineseparator="<" --fieldseparator=","

cm lock list --machinereadable --smartlocks --startlineseparator=">" --endlineseparator="<" --fieldseparator=","

**Examples:**

Example 1 (unknown):
```unknown
cm lock list | ls [<revspec> [ ...]] [--server=<server>] [--repository] [--onlycurrentuser] [--onlycurrentworkspace] [--ignorecase] [--anystatus] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>] [--smartlocks]]
```

Example 2 (unknown):
```unknown
cm lock list
```

Example 3 (unknown):
```unknown
cm lock list --server=myserver:8084
```

Example 4 (unknown):
```unknown
cm lock list --repository=repo@myserver:8084 --anystatus
```

---

## Evidence report HTTP request

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/text-evidence/evidence-report-http-request

**Contents:**
- Evidence report HTTP request#

The following example is a request with the additional parameters:

**Examples:**

Example 1 (unknown):
```unknown
curl 
https://services.api.unity.com/vivox/text-evidence-management/v1/organizations/<organization_id>/projects/<project_id>/text-evidence-report?target_uri=sip:confctl-g-your-issuer.moderation-testing2@yourdomainname.vivox.com&sender_uri=sip:your-issuer.username.1234.@yourdomainname.vivox.com&start_ts=1697117012&end_ts=1697117217&num_messages=2 -u service-acct-username:service-account-password
```

Example 2 (unknown):
```unknown
curl 
https://services.api.unity.com/vivox/text-evidence-management/v1/organizations/<organization_id>/projects/<project_id>/text-evidence-report?target_uri=sip:confctl-g-your-issuer.moderation-testing2@yourdomainname.vivox.com&sender_uri=sip:your-issuer.username.1234.@yourdomainname.vivox.com&start_ts=1697117012&end_ts=1697117217&num_messages=2 -u service-acct-username:service-account-password
```

---

## Use case sample: Wish players a happy new year

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/use-cases/happy-new-year

**Contents:**
- Use case sample: Wish players a happy new year#
- Prerequisites#
  - Authenticate using a Service Account#
  - Configure the UGS CLI#
- Set up Cloud Code#
- Schedule an event#
- Configure a trigger#
- Validate the result#
  - Prerequisites#
    - Link project#

This sample demonstrates how to set up a schedule to send a push notification to all users wishing them a happy new year at 00:00:00 UTC on January 1st

Note: You can only use push messages with Cloud Code modules.

You must first create a service account with required access roles and configure the UGS CLI.

Before you can call the Scheduling and Triggers services, you must authenticate using a Service Account.

Add Product roles and create a key:

For more information, refer to Authentication.

Follow the steps below to get stated with the UGS CLI:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Authenticate using the Service account you created earlier. Refer to Get Authenticated.

Define a module endpoint that sends a push notification to the player whose score was beaten.

Create a WishHappyNewYear module function with contents as below:

Refer to Deploying Hello World to learn how to deploy a module.

Note: If you are deploying the module using the UGS CLI, don't forget to add additional Service Account role of Cloud Code Editor.

After you have defined your Cloud Code module, you can create a schedule to send a push notification to all users wishing them a happy new year at 00:00:00 UTC on January 1st.

Run the new-file command to create a schedule configuration locally:

Update the schedule-config.sched file with the following configuration:

Deploy the configuration using the UGS CLI tool:

The correct response is similar to the following:

To connect your Cloud Code module to the scheduler event, create a trigger. The trigger executes the Cloud Code module when the event is fired at 00:00:00 UTC on January 1st.

Run the new-file command to create a trigger configuration locally:

Update the triggers-config.tr file with the following configuration:

Deploy the configuration using the UGS CLI tool:

You should get a response similar to the following:

Now you have a trigger that executes your Cloud Code module function when the scheduler event is fired at 00:00:00 UTC on January 1st.

To validate the result, set up a Unity project that subscribes to push messages.

Note: To test the event, you might want change the timestamp in the one-time field to a closer time.

To subscribe to push messages, you must first install the Cloud Code SDK and link your Unity Gaming Services project to the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

In the Unity Editor, select Edit > Project Settings > Services.

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

To install the latest Cloud Code package for Unity Editor:

Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

Subscribing to messages is available with Cloud Code SDK version 2.4.0+.

Set up a Monobehaviour script to subscribe to project-level messages.

Refer to Send push messages for more information.

You can use the sample code below for your MonoBehaviour script:

You should encounter a push message sent when the module runs in the Unity Editor:

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
WishHappyNewYear
```

Example 4 (unknown):
```unknown
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using Unity.Services.CloudCode.Apis;
using Unity.Services.CloudCode.Core;
using Unity.Services.CloudCode.Shared;

namespace WishHappyNewYear;

public class HappyNewYear
{
    private readonly ILogger<HappyNewYear> _logger;

    public HappyNewYear(ILogger<HappyNewYear> logger)
    {
        _logger = logger;
    }

    [CloudCodeFunction("SendProjectMessage")]
    public async Task SendProjectMessage(IExecutionContext context, PushClient pushClient, string message, string messageType)
    {
        try
        {
            await pushClient.SendProjectMessageAsync(context, message, messageType);
        }
        catch (ApiException e)
        {
            _logger.LogError("Failed to send project message. Error: {Error}",  e.Message);
            throw new Exception($"Failed to send project message. Error: {e.Message}");
        }
    }

}

public class ModuleConfig : ICloudCodeSetup
{
    public void Setup(ICloudCodeConfig config)
    {
        config.Dependencies.AddSingleton(PushClient.Create());

    }
}
```

---

## Push Notifications SDK

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/sdk

**Contents:**
- Push Notifications SDK#
- Platform support#
- Quick start#
- Registering for Push Notifications#
  - Notification Received callbacks#
  - Push Notifications settings#
  - Analytics#
    - Analytics-only mode#
- Testing the SDK integration#
- External Dependency Manager for Unity (EDM4U) support#

Use the Push Notifications SDK to send push notification campaigns, including rich push notifications with images to your users.

This SDK supports both iOS and Android. iOS 10+ and Android SDK >= 26 (Oreo) are supported.

The SDK comes with a sample script that will register for push notifications. Add this to your project and set the relevant settings in the editor under Project Settings.

To register for Push Notifications, three steps are required.

Note: Unity Analytics is required to ensure the events related to Push Notification data are sent correctly. For more details on how to handle privacy consent, refer to the Analytics documentation.

You can register a delegate to receive a C# event callback when a notification is received, to perform custom behavior at that point. To do this, add a delegate/method callback to PushNotifications.OnNotificationReceived as shown in the sample above.

The SDK requires a number of settings to function correctly. Some settings are only used on a certain platform, indicated in the setting name. The following Android (Firebase) settings can be set:

You can find these settings in the Unity Editor > Edit > Project Settings > Services > Push Notifications. The values for all the fields below is found in the Settings page of your Firebase dashboard.

If you don't have an Android App set up within Firebase, you need to add one. The Add app wizard will, besides creating your app in Firebase, also provide instructions on how to integrate the Firebase SDK immediately after. Note that you don't need to install the Firebase SDK, and can safely ignore all steps involving adding files or the Firebase SDK to your project.

If the Web API Key from above is blank in your project then you can find it located in project Settings > General > Your Apps > google-services.json.

These settings are set in Edit > Project Settings > Services > Push Notifications.

The SDK records two Analytics events:

Attention: This section is only applicable if you're trying to use the Unity Dashboard Push Notification service alongside a separate Push Notification implementation. For most users this section is not required or recommended as it'll lead to reduced functionality of the product.

It's possible to integrate the SDK with an existing push notification service if required. To do so, do not call the registration methods as indicated above, and instead use the two methods in PushNotificationsService.Instance.Analytics alongside your existing implementation.

RecordPushTokenUpdated should be called when you receive a new push token for a device. Note that the OS may create a new token at multiple points in the app's lifecycle, so call this whenever the token changes, and not just at startup. The full call is PushNotificationsService.Instance.Analytics.RecordPushTokenUpdated(token);

RecordNotificationOpened should be called when a notification is opened. It takes a dictionary that is the data the notification payload contained, and a boolean flag to indicate whether the app was launched from the notification or not. The full call is PushNotificationsService.Instance.Analytics.RecordNotificationOpened(notificationData);

Note that this should allow you to send and schedule notifications from the Unity Dashboard. However, it greatly depends on the other push notification implementation you have implemented, and may lead to missing images or other content in notifications, so it's strongly recommended to use the standard set up, with this SDK being the only Push Notifications solution integrated, if possible.

You can test the Push Notifications SDKs integration by following these steps within your app.

These require that you follow the steps within Get Started.

Within your app, fetch the PushNotificationsService token and write it to the log using `Debug.Log`.

Follow the debugging guide for Android or the Build and Run guide for IOS, depending on your target platform, to run your app.

Read the app logs to fetch the logged token.

Within the Unity Dashboard, go to an existing Push Notification Campaign or create a test one.

Inside the Content step, create your notification if necessary and select Test on Device.

Select the target device and input the fetched token.

Select Send and verify if the device receives the notification.

Note: Applicable to users integrating EDM4U or MDR alongside Push Notifications.

Other SDKs or Unity Packages, including Google’s Firebase unity packages, use the External Dependency Manager for Unity (EDM4U) or Mobile Dependency Resolver (MDR) to resolve their dependencies inside the Unity Project.

The Push Notifications SDK does not require the use of EDM4U or MDR to resolve its dependencies within the Unity project, nor does it redistribute or use EDM4U or MDR by default.

However, starting from version 3.0.1-pre.1, if either EDM4U or MDR is used, the Push Notifications SDK integrates with them by generating a dependency file (PushSDKDependencies.xml) for them to use inside the automatically generated Assets/Push Notifications/Editor/Android directory.

Before building your application, you should run Resolve or Force Resolve (Both under Assets -> External Dependency Manager -> Android Manager) to make sure that the dependencies for the Push Notifications SDK are resolved. You can verify these dependencies have been resolved by using the Display Libraries option (Assets -> External Dependency Manager -> Android Manager -> Display Libraries)

The following line should appear:

Note that the comment might be different if other packages also require the same dependency. If this is the case, EDM4U will list in the adjacent comment all files from where the dependency was extracted. So long as the dependency file path (Assets/Push Notifications/Editor/Android/PushSDKDependencies.xml:9) appears within the comment, you can be sure that EDM4U / MDR has detected and read the dependency file successfully.

If this line does not appear, ensure that the dependency file exists under the Assets/Push Notifications/Editor/Android directory, and try using the Force Resolve option again (Assets -> External Dependency Manager -> Android Manager -> Force Resolve).

If the dependency file hasn't been generated, re-open your project. The dependency file should be generated as part of this process.

**Examples:**

Example 1 (javascript):
```javascript
using Unity.Services.Analytics;
using Unity.Services.Core;
using Unity.Services.PushNotifications;
...

await UnityServices.InitializeAsync();

bool userGaveConsent = ...;

if (userGaveConsent)
{
	AnalyticsService.Instance.StartDataCollection();
}

try
{
    PushNotificationsService.Instance.OnRemoteNotificationReceived += notificationData =>
    {
        Debug.Log("Received a notification!");
    };

    string pushToken = await PushNotificationsService.Instance.RegisterForPushNotificationsAsync();
}
catch (Exception e)
{
    Debug.Log("Failed to retrieve a push notification token.");
}
```

Example 2 (javascript):
```javascript
using Unity.Services.Analytics;
using Unity.Services.Core;
using Unity.Services.PushNotifications;
...

await UnityServices.InitializeAsync();

bool userGaveConsent = ...;

if (userGaveConsent)
{
	AnalyticsService.Instance.StartDataCollection();
}

try
{
    PushNotificationsService.Instance.OnRemoteNotificationReceived += notificationData =>
    {
        Debug.Log("Received a notification!");
    };

    string pushToken = await PushNotificationsService.Instance.RegisterForPushNotificationsAsync();
}
catch (Exception e)
{
    Debug.Log("Failed to retrieve a push notification token.");
}
```

Example 3 (unknown):
```unknown
PushNotifications.OnNotificationReceived
```

Example 4 (unknown):
```unknown
PushNotificationsService.Instance.Analytics
```

---

## Plugin for TeamCity

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/teamcity-plugin

**Contents:**
- Plugin for TeamCity#
- Installation#
- Configuration#
  - Create a new Project in TeamCity#
  - Create a build Configuration#
  - Configure VCS Root using TeamCity UI#
  - Configure VCS Root using Kotlin DSL#
    - Supported Parameters#
    - Example Configuration#
  - Configure checkout from VCS mode#

The Unity Version Control (UVCS) plugin for TeamCity extends the capabilities of the TeamCity server, enabling it to manage continuous integration operations using source data that is under UVCS control.

To install the UVCS plugin for TeamCity:

Open "Plugins list" from TeamCity's Administration menu.

Click the "Upload plugin zip" link.

Upload the UVCS plugin for TeamCity: <UVCS installation directory>/client/plugins/teamcity/com.codicesoftware.plugins.teamcity.PlasticSCM.zip

Restart TeamCity Server. This way, the plugin will be automatically unpacked and loaded.

(Windows systems only) The plug-in runs UVCS commands with the user identity of the TeamCity Build Agent Service (Agent-side checkout mode). By default, this identity is the SYSTEM user account. We recommend changing this service's user account to a different one:

Go to Control Panel > Administrative Tools > Services.

Right-click TeamCity Build Agent Service and select Properties.

Go to the "Log On" tab and select another user who already has a valid UVCS configuration.

Start the TeamCity Server service.

First step is creating a new Project in TeamCity, which will be attached to UVCS later. To do that, Go to "Administration" > "Projects" and click on "Create new Project" button.

Type a valid Project name, ID and an optional description, and click on "Create" button.

After creating the Project, TeamCity wizard asks for a Build Configuration. Again, enter a valid name, ID and description and click "Create" button.

This is the wizard step where we attach our Project to UVCS.

Select "Plastic SCM" as a type of VCS, enter a VCS root name and ID, required by TeamCity.

The specific fields for UVCS plugin are the following:

(In the example above, all child branches of /main branch will be tracked, excepting those child branches that start with Release string in their name).

Click on "Test connection" to check whether the plugin can connect to the configured UVCS server, and if the test connection is successful, on "Create" button.

When using the TeamCity Kotlin DSL to configure your project's VCS Root, you can define parameters to customize the behavior of the UVCS integration. Below is a detailed explanation of the parameters you can use, along with an example configuration.

The following parameters are available for configuring VCS Roots:

Below is an example of configuring a VCS Root in Kotlin DSL, utilizing the parameters for branch filtering:

type Specifies the type of the VCS Root. For UVCS integrations, this value should always be set to "PlasticSCM" to indicate that the VCS Root is using PlasticSCM as the version control system.

name Defines a human-readable name for the VCS Root configuration. This name is used to identify the VCS Root in the TeamCity UI, and should be unique within your project.

server Specifies the UVCS server to connect to. This is typically the server name used to access Unity Version Control, such as a cloud organization or an on-premise server.

repository Defines the name of the repository within the UVCS server. This should match the exact name of the repository you want to connect to.

branch Defines the name of the default branch to watch within the repository. The default value is /main.

teamcity:branchSpec Specifies extra branches to monitor as a newline-delimited set of rules in the form of +:branch-name or -:branch-name, allowing the wildcard character *. For example, +:/main/* would include all child branches of /main, while -:/main/Release* would exclude those child branches of /main that start with "Release" in ther name.

enable-plastic-branch-filtering This parameter enables or disables branch filtering. If set to "true", the plastic-branch-filter parameter will be applied to filter branches.

plastic-branch-filter Specifies the query used to filter branches. For example, you can use status=resolved to include only branches with the status attribute set to resolved.

plastic-branch-filter-attr-failed Defines the attribute that marks branches as failed.

plastic-branch-filter-attr-succeed Specifies the attribute used to mark branches as succeeded.

plastic-branch-filter-attr-merged Indicates the attribute for marking branches as merged.

TeamCity supports two different VCS checkout modes to download the contents to be built from UVCS (plus the option to do not perform the VCS checkout automatically, and usually delegating this action to the project's "Build Steps" configuration phase by executing an user-defined script). We highly recommend the "Agent-Side checkout mode", already supported by UVCS TeamCity plugin:

Customize your specific project settings (such as selecting an user-defined checkout directory or VCS labeling on successful build) and when done, click on "Save" button.

This configuration depends on each specific project in order to trigger a build once the source code at a required version is downloaded.

This is the step that rules the way builds are triggered. In this example, we configure a VCS trigger so that builds are launched when TeamCity Server detects new changes in the tracked branches of the specified UVCS repository configured in the previous step: "Configure VCS root for the Project".

Although feature branches are already tracked by TeamCity (as we did in "VCS root" configuration step), we can define which of them will cause TeamCity to trigger a build or not, by setting up a "Branch filter". With the configured branch filter in the example above, any tracked branch will trigger a build when a new change is detected.

And that's it, the TeamCity project is ready to watch changes in UVCS repo and start building changes!

TeamCity is now ready to track changes from the configured feature branches in a repository. Let's see how TeamCity starts triggering builds when VCS changes are detected through a basic development cycle as an example with an existing repo in a UVCS server.

First of all, a developer submits (checks-in in UVCS jargon) new changes in the default tracked branch (in this case, /main branch). A couple of seconds later, TeamCity detects these new changes, checkouts source code from /main branch into the configured workspace folder (from "checkout options" step while configuring the VCS root of the TeamCity project), and starts executing the actions defined in "Build Steps" in order to perform a build:

Now, the same user (jesus in this example) creates a child branch in UVCS (/main/scm78453) to perform a couple of changes in order to fix a bug in the code. As the new branch name matches with the "Branch specification" pattern for feature branches to be tracked, TeamCity will trigger a build when detects changes in this new branch:

As the build of the newly created child branch is successful, the integrator decides to merge back to the parent, default /main branch in UVCS. When the merge in the /main branch is checked-in, TeamCity will trigger a build once it's detected. Let's see this new build ("#3") in the Change Log graph, along with the merge link:

The history in the VCS repository continues: a new branch (/main/scm81245) is created, some changes are submitted there, and then, this branch (along with the previous one) is merged into a release branch (/main/Release-792). After that, the release branch /main/Release-792 is also merged back to default /main branch. Let's see how TeamCity triggers new builds for changes in branch /main/scm81245 and /main, but not for the /main/Release-792 branch, as it matches with the configured exclusion pattern in the "Branch specification" defined when configuring the VCS root:

Let's see how the TeamCity's Change Log graph draws these new changes (blue dots) and corresponding builds (green dots).

**Examples:**

Example 1 (unknown):
```unknown
<UVCS installation directory>/client/plugins/teamcity/com.codicesoftware.plugins.teamcity.PlasticSCM.zip
```

Example 2 (unknown):
```unknown
"PlasticSCM"
```

Example 3 (unknown):
```unknown
"My Project VCS Root"
```

Example 4 (unknown):
```unknown
"organization@cloud"
```

---

## Data Access available views

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/data-access-views

**Contents:**
- Data Access available views#
- ACCOUNT_EVENTS#
- ACCOUNT_EVENT_JSON_KEYS#
- ACCOUNT_GAMES#
- ACCOUNT_USERS#
- ACCOUNT_FACT_EVENT_TYPE_USERS_DAY#
- ACCOUNT_FACT_WAU_USERS#
- ACCOUNT_FACT_MAU_USERS#
- ACCOUNT_FACT_MISSION_USERS_DAY#
- ACCOUNT_FACT_POTENTIAL_RETAINED_USERS_7_DAY#

Through the Data Access feature, you gain access to a number of views containing your account's data.

Note: The Data Access views use multiple timestamps:

This table lists all of the events that have been sent in from your application. Event-specific parameters can be found in the EVENT_JSON column as a JSON object. As the parameters are stored as a JSON object, you'll need to parse the content in order to query it.

This table contains data on the event fields that are used for your games.

This table lists all of the games that exist under your account.

This table lists all the users who have sent in an event in the past. For each user, the columns contain a variety of useful metrics.

This table lists all of the events a user has recorded in one day and how many times they have sent in each of those events.

This table lists all of the users that have sent in an event in the last week.

This table lists all of the users that have sent in an event in the last 30 days.

This counts how often a user has started, completed, failed and abandoned missions.

This table contains data on Users retained after installing in the last 7 days.

This table contains data on Users retained after installing in the last 14 days.

This table contains the number of products bought split out by the standard filter parameters. The data comes from the productsReceived object in the transaction event.

This table contains data on users retained after installing in the last 7 days.

This table contains data on users retained after installing in the last 14 days.

This table has a record for each user session. Each record contains a variety of user level aggregate KPIs for that session. If any of the dimensions in this table, excluding aggregate dimensions, change during a session (for example, AGE_GROUP or GENDER), a new record will be created for that session.

**Examples:**

Example 1 (unknown):
```unknown
EVENT_TIMESTAMP
```

Example 2 (unknown):
```unknown
LOADED_TIMESTAMP
```

Example 3 (unknown):
```unknown
ACCOUNT_EVENTS
```

Example 4 (unknown):
```unknown
ACCOUNT_NAME
```

---

## Deploy a Matchmaker environment

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/deployment/deploy-matchmaker-environment

**Contents:**
- Deploy a Matchmaker environment#
- Prerequisites#
- Install the required packages#
- Set up the Deployment window#
- Create a Matchmaker environment configuration#
- Edit a Matchmaker environment configuration#
- Deploy the Matchmaker environment configuration#
- Additional resources#

Use the Deployment window in the Unity Editor to deploy a Matchmaker environment.

An environment is a global container that represents an instance of a matchmaker (including development, staging, and production instances). You can deploy a Matchmaker environment configuration directly from the Unity editor.

Before you start, make sure you meet the following prerequisites:

To enable the integration between the Multiplayer Services SDK and Deployment, install the following packages:

You can deploy Matchmaker environment configurations to your cloud environment using the Deployment window. Once you install the Deployment package, you can access the Deployment window from the Unity Editor by selecting Services > Deployment.

To select the deployment environment, follow these steps before you can use the Deployment window:

To create an editable Queue configuration:

To edit the Matchmaker environment configuration either directly from the Unity Editor or from an IDE of your choice, do the following:

Alternatively, you can open the asset file directly in your favourite IDE, and edit the contents manually.

It is the recommended best practice to configure file type associations (Unity Services Web API Docs) in your IDE to work with Matchmaker files. This makes authoring the files significantly easier by providing auto-complete functionality in your preferred IDE. Refer to the Matchmaker environment config schema.

Refer to Filters for more information about the environment configuration.

To deploy the Matchmaker environment configuration:

**Examples:**

Example 1 (unknown):
```unknown
MatchmakerEnvironment
```

---

## Manage changesets

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/changesets

**Contents:**
- Manage changesets#
- Changeset options#
- Changeset view configuration#

Learn how to use the Changesets tab in Gluon.

Every time you run a check in action, Gluon creates a changeset. The changeset compiles all the changes that you check in at one time, and anyone with access to the repository can access the changesets. You can compare and diff these changesets with one another to find out what changes have been made.

The Changesets tab displays all of the changesets created in the repository that you work on.

If you right-click on a changeset, you have the following options:

By default, the Changesets tab displays all changesets in the repository created by any team member, grouped by creation date.

To customize the changesets that display, use filters. You can filter by the following categories:

To customize the query, select Advanced. You can also type in a quick filter. For example, use field_name:value to filter by a given field.

Gluon saves any customization you create for the workspace when you next open the Changesets tab.

**Examples:**

Example 1 (unknown):
```unknown
field_name:value
```

---

## MAU-based pricing

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/mau-based-pricing

**Contents:**
- MAU-based pricing#
- Additional resources#

Note: MAU applies to all projects and environments in your organization. MAU-based pricing is also available for Leaderboards.

MAU measures the total number of unique user IDs that have at least one session in an environment within a month. The unityInstallationID or any external user ID passed to the Analytics service counts toward the MAU, and it applies specifically to the Analytics product.

Important: You're charged when the number of MAU exceeds the free tier.

Each UGS product has its own billing unit and is separate from each other. The Analytics MAU meter is specific to the Analytics service and does not impact the pricing of other UGS services. If your Analytics usage exceeds the free tier, a line item appears on your bill.

The following table shows the pricing tiers based on the number of users:

**Examples:**

Example 1 (unknown):
```unknown
unityInstallationID
```

---

## LOG

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/log

**Contents:**
- LOG#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - The output parameters of '--csformat' are the following#
    - The output parameters of '--itemformat' are the following#
      - Short format and its corresponding long format#
    - These are valid output strings#

Gets info about revisions in changesets.

cm log [<csetspec> | <repspec>] [--from=<csetspec_from>] [--allbranches] [--ancestors] [--csformat=<str_format>] [--itemformat=<str_format>] [--dateformat=<str_date_format>] [--xml[=<output_file>]] [--encoding=<name>] [--repositorypaths | --fullpaths | --fp]

This command accepts a format string for the items ('--itemformat') and a format string for the changesets ('--csformat').

To specify the output format in which dates will be printed. See the supported formats specified at:

https://docs.microsoft.com/en-us/dotnet/standard/base-types/custom-date-and-time-format-strings

(Shows information about every changeset created in the last month in every branch.)

(Shows information about the changes done in the changeset 16 in the branch where the changeset was created.)

cm log cs:16 --csformat="{newline}Changeset {changesetid} created on {date};{tab} changed items: {items}."

(Shows the information in the specified format.)

cm log --from=cs:20 cs:50

(Shows the information about every revision contained in every changeset from the changeset 21 to the changeset 50.)

cm log --from=cs:20 cs:50 --allbranches

(Shows the information about every revision contained in every changeset from the changeset 21 to the changeset 50 in every branch of the repository.)

cm log rep:myrep@localhost:8084

(Shows information about the changes done in the specified repository. No workspace is required to run the command.)

cm log --from=cs:20@rep:mainRep@localhost:8084

(Shows the information about every revision contained in every changeset from the changeset 21. No workspace is required to run the command, because the full changeset spec was specified.)

**Examples:**

Example 1 (unknown):
```unknown
cm log [<csetspec> | <repspec>] [--from=<csetspec_from>] [--allbranches] [--ancestors] [--csformat=<str_format>] [--itemformat=<str_format>] [--dateformat=<str_date_format>] [--xml[=<output_file>]] [--encoding=<name>] [--repositorypaths | --fullpaths | --fp]
```

Example 2 (unknown):
```unknown
cm log cs:16
```

Example 3 (unknown):
```unknown
cm log cs:16 --csformat="{newline}Changeset {changesetid} created on {date};{tab} changed items: {items}."
```

Example 4 (unknown):
```unknown
cm log --from=cs:20 cs:50
```

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal Data Collected about App Users/Game Players#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent (Opt in) vs Opt out#
- Data Subject Requests#
- Dependencies#
- Data Retention#
- Child Privacy#
- Privacy Policy Requirements#

In-App Purchasing SDK - Expand your revenue opportunities across multiple stores and platforms with one SDK. Unity IAP supports industry-leading app stores, including Google Play, the App Store, and more.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected (always collected in order for the product to work)

Optional Personal Data Collected (personal data which may be collected at choice/action of the end user/Developer)

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## Find merges

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-merges

**Contents:**
- Find merges#
- Filtering options#
- Output options#
- cm find merge examples#
  - Find where a branch has been integrated#
  - Find branches integrated on a specific release#

Find, filter, and track merges.

The following list displays the different filtering options (where) that are available to use with the cm find merge command:

The following list displays the different output options (--format) available to use with the cm find merge command:

Track merges from and to a specific branch or changeset. The find merge command returns all types of merges: regular merges, cherrypicked merges, and subtractive merges.

Find which branches are integrated in a specific branch:

Customise the output to show only the branch name:

Customise the output so that it returns the source branch, destination branch, and the type of merge:

Find interval merges to a given branch:

**Examples:**

Example 1 (unknown):
```unknown
cm find merge
```

Example 2 (unknown):
```unknown
dstchangeset
```

Example 3 (unknown):
```unknown
srcchangeset
```

Example 4 (unknown):
```unknown
cm find merge
```

---

## Unity Version Control 3.x Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/3

**Contents:**
- Unity Version Control 3.x Release Notes#
- 3.0.187.40#
  - New#
    - Implemented support for symlinks on non Windows o…#
- 3.0.187.37#
  - New#
    - Implemented exclusive checkout menu action. Now i…#

This document contains all release notes for Unity Version Control major version 3.x, organized from newest to oldest.

Fast-Export: Implemented support for symlinks on non Windows operating systems.

Eclipse plugin: Implemented exclusive checkout menu action. Now it is possible to perform exclusive checkouts from the Eclipse plugin.

---

## Server readiness

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-readiness

**Contents:**
- Server readiness#

Game servers aren't always ready to start hosting a match or have players connect when the processes start up. They likely have an initialization process to run through for loading assets or connecting to external services.

Game server readiness is a feature that allows game servers to let Multiplay Hosting know, and by extension, the matchmaker or service that controls player connections, when they're prepared to accept players and when they're no longer ready to accept players through the Game Server SDK. The exact process for this is dependent on whether you are using the Multiplay Hosting SDK for Unity or the Multiplay Hosting SDK for Unreal Engine.

The feature enables a game server to complete its start-up logic before players try to connect. Without this feature, a game server with a long start-up time can reject players trying to connect, resulting in a bad experience.

The Multiplay Hosting allocations system only considers a game server to fulfill an allocation when it’s online and has announced itself as ready.

Game server readiness is an attribute associated with a build configuration. To establish the readiness, it must be configured during the creation of a build configuration.

Tip: Game server readiness can also function as an indication of server health. You can implement health checks at start-up and only flag a server as ready if it passes all health checks. This way, you ensure that Multiplay Hosting doesn’t use a potentially unhealthy server to fulfill an allocation.

The following flow chart illustrates where server readiness comes into the allocation flow.

---

## Revert to changeset

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/revert-to-changeset

**Contents:**
- Revert to changeset#

The revert to changeset feature allows you to go back to an earlier changeset, creating a check-in that skips the changesets between the selected and latest ones.

This is useful when you want to continue working from an older version of the workspace.

To revert to a selected changeset:

---

## Network connection management

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/manage-session-network-connection

**Contents:**
- Network connection management#
- Types of network#
- Configurable network options#
  - DirectNetworkOptions#
  - RelayNetworkOptions#
- Session and Netcode lifecycle separation#
- Network connection management examples#
  - Example: Creating a session with a client-hosted solution with overridden default relay options#
  - Example: Using a custom network handler#
  - Example: Starting Netcode at a later time#

Players can create and join sessions using different network connection types and configuration options.

Note: The Multiplayer Services SDK uses sessions to manage groups of players. Sessions relies internally on different combinations of Unity Gaming Services such as Relay, Distributed Authority, Lobby, Matchmaker and Multiplay Hosting, and thus contributes to the billing of those services.

By default, the following network connections types are available with the sessions system:

Refer to Class SessionOptions > Methods for more information.

Advanced users can provide additional connection types via a custom INetworkHandler implementation. Refer to Using a custom network handler for an example.

You can override the default network options of your sessions, including both direct and relay-based networking.

If you don't specify network options when calling the WithRelayNetwork(),WithDirectNetwork(), or WithDistributedAuthorityNetwork() methods, the session system automatically applies its default settings to configure the requested network type. For details about default values and behaviors for these methods, refer to Class SessionOptionsExtensions.

Configure direct network connections with DirectNetworkOptions. Use these options with WithDirectNetwork() when setting a SessionOption to override the default behavior. The following settings are available:

When a client-hosted game uses direct networking, the IP addresses of all players are visible to the host. To protect player privacy in client-hosted games, the recommended best practice is to use Relay or Distributed Authority to handle NAT, firewalls, and player IP addresses.

Not all platforms support IPv6 connections. Only use IPv6 addresses after you verify that your target platforms support it.

Configure relay protocol-based network connections with RelayNetworkOptions. Use it with the WithRelayNetwork() or WithDistributedAuthorityNetwork() when setting SessionOption to override the default behavior.

The following settings are available:

The following Relay protocols are supported:

The recommended Default protocol might vary between platforms.

Starting with Multiplayer Services SDK version 1.2, you have the option to start the network connection after a session is created. The decoupled network lifecycle gives you greater flexibility and control over your game flow. After the host initiates the network connection, clients are notified and use the connection information shared by the host to start their own network connections. The connection information is shared with clients via session properties.

The session's Network property exposes two different interfaces:

This separation has the following benefits:

The following examples demonstrate how to configure connection types, options, and lifecycle management for the networking solution tied to your session.

The following example demonstrates how to create a session using a Unity client-hosted solution with overridden options provided to the relay allocation:

The points from Example: Creating a session with a client-hosted solution also apply to this example, along with the following information:

Advanced users can specify a custom network handler by implementing INetworkHandler, which overrides the default integration with Netcode for GameObjects and Netcode for Entities. You can provide integration with any third-party networking solutions when implementing the INetworkHandler interface.

In some games, you might want to delay starting the network connection and gameplay until certain conditions are met, for example, until all players have joined and are ready. The following example demonstrates how to delay the connection using the Session API.

Consider the following details about how this example works:

Host(StartSessionAsHost):

Client(JoinSessionAsClient):

**Examples:**

Example 1 (unknown):
```unknown
Class SessionOptions > Methods
```

Example 2 (unknown):
```unknown
INetworkHandler
```

Example 3 (unknown):
```unknown
WithRelayNetwork()
```

Example 4 (unknown):
```unknown
WithDirectNetwork()
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/apple-privacy-survey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Lobby is available from version 1.2.1.

The following code sample displays the contents of the PrivacyInfo.xcprivacy manifest file for Lobby. This file is also available in the Lobby SDK version 1.2.1.

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

Example 2 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## UGS CLI for CCD

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDCLI

**Contents:**
- UGS CLI for CCD#
- Installation#
- Migration information#
  - Unified with UGS tooling#
    - Seamless integration#
  - Authentication updates#
    - Transition to service accounts#
  - Enhanced user experience#
    - Unified command interface#
    - Intuitive command arguments#

Note: The UCD CLI is officially deprecated and no longer receives updates so it's recommended that UCD CLI users transition to use this UGS CLI instead. You can still view the Deprecated UCD CLI documentation.

The command-line interface (CLI) is an efficient way to interact with Cloud Content Delivery (CCD). With the CLI, you can use the command line to control every aspect of your project, from file management to release pipeline organization.

The Unity Cloud Dashboard provides a lot of functionality, but you need to use the CLI for certain actions, such as to copy files to your bucket or synchronize entire folders.

For more information about the UGS CLI, refer to the Unity Gaming Services CLI documentation.

For information on how to install the CLI, refer to the Installation guide.

With the integration of CCD into the UGS CLI ecosystem, there are the improvements available that are designed to enhance your experience and streamline your workflows.

CCD is now a cohesive part of the UGS CLI ecosystem. This integration means that you no longer need to install and maintain a separate tool for CCD functionalities. Install the UGS CLI once, and you're set to manage multiple UGS services efficiently including CCD.

The CLI now uses service accounts for authentication to provide more secure, versatile and streamlined user verification.

For more information, refer to Authentication.

CCD has standardized the CLI's commands, inputs, and outputs to align with other UGS services and provide two output formats (JSON and plain text). The response are more detailed and aligned with the ccd rest api.

For more information, refer to the available outputs.

We now have more intuitive command arguments: Instead of asking for UUID arguments such as environment id, bucket id, badge id, release id, users should now use human friendly arguments such as environment names, bucket names, badge names, and release number.

If you already have a project, go to the next section. Otherwise, if you are using Unity services for the first time:

To download and install the CLI, follow this guide.

To set up CCD in the Unity Dashboard, select Products > Cloud Content Delivery > Launch. You can then fill in your details and access CCD.

CCD is now ready for you to use.

The basic form of a UGS CCD command in the CLI is as follows:

$ ugs ccd [command] [subcommand] [parameters]

To see the version of the CLI you are currently using, add the --version flag:

You can add the following global flags after any command:

Authenticates with CCD.

For detailed instructions on logging in, visit the UGS CLI Login Documentation.

The CLI offers two output formats to address diverse user needs for data representation: the default YAML and an optional JSON format. To obtain outputs in JSON, append -j or --json to your command. This feature simplifies data integration and processing to ensure a more efficient workflow. For example, you can do the following:

$ ugs ccd [command] --json

Environment setup for the UGS CLI is simple. You can use environment variables, CLI commands, or sometimes options within commands for configuration. You can use the following information to get started.

Environment variables allow you to configure the CLI without having to enter details every time you run a command. Open your terminal and run these commands to set your environment variables:

The CLI also supports direct configuration through commands. Here are some examples to set the active environment, project-id and bucket-name:

The CLI supports specifying a bucket for any ccd command using the option -b.

Manages buckets for a project.

Usage: ugs ccd buckets [command]

Manages entries for the current bucket.

Usage: ugs ccd entries [command]

To cancel an entries sync command, press Ctrl+C during the process. Any entries synced prior to cancellation remain uploaded, so you must delete them from your bucket.

Manages the releases for the current bucket.

Usage: ugs ccd releases [command]

Bucket and entry names are case-sensitive.

Manages badges for a release.

Usage: ugs ccd badges [command]

Here are some examples of how you might use the UGS CLI for CCD:

Note: For detailed help on any command, use -h or --help. For example, to get help on the list subcommand for buckets, you would use:

$ ugs ccd buckets list --help

These examples should give you a good starting point for using CCD with the UGS CLI. Remember that each command has additional flags and options which can be viewed by using the --help flag with the command.

For a sequential example of how to use the command-line interface, see Using CCD via the CLI.

The CCD UCD CLI is officially deprecated and will no longer receive updates. We recommend all users to transition to the UGS CLI instead to benefit from the latest features, security updates, and technical support.

The command-line interface (CLI) is the recommended method of interacting with Cloud Content Delivery (CCD). With this tool, you can use the command line to control every aspect of your project, from file management to organizing your release pipeline..

You can perform many similar functions in the Dashboard, but you need to use the CLI to copy files to your bucket, or synchronize entire folders.

To set up CCD for CLI:

If you already have a project, go to the next step. Otherwise, if you are using Unity services for the first time:

Create a Unity ID account (if you don’t already have one).

Log into the Unity Dashboard.

Select Projects > Create project. In the Create project window, fill in the required details.

To download the CLI, identify the version that aligns with your Operating System.

In the Unity Dashboard, select Products > Cloud Content Delivery.

In the left-side navigation bar, go to the API Key section.

Run the CLI on the machine from which you are uploading content.

Log into the CLI using your API key via the auth command.

CCD is now ready for you to use.

The basic form of a CCD command in the CLI is as follows:

Be sure to enter -h or --help at the end of any command to display any further parameters and flags for that command that might be available.

To see the version of the CLI you are currently using, add the --version flag:

You can add the following global flags after any command:

For CLI versions greater than 0.11.0, you need to add the --environment flag to most commands. See CLI examples and Using CCD via the CLI.

The following commands are available:

Authenticates with CCD.

Usage: ucd auth [command]

Manages badges for a release.

Usage: ucd badges [command]

Manages buckets for a project.

Usage: ucd buckets [command]

Manages options for setting and identifying the current bucket.

Usage: ucd config [command]

Manages entries for the current bucket.

Usage: ucd entries [command]

To cancel an entries sync command, press Ctrl+C during the process. Any entries synced prior to cancellation remain uploaded, so you must delete them from your bucket.

Manages the releases for the current bucket.

Usage: ucd releases [command]

Bucket and entry names are case-sensitive.

bucket_name is only a label you assign to a bucket upon creation. All other commands require the bucket_ID, which you can find using the buckets list command, or through CCD in the Unity Dashboard.

For CLI versions greater than 0.11.0, you need to add the --environment flag to most commands.

ucd buckets list --environment=[environment_id] [PROJECT_ID]

You can also save an environment to be used in all future commands by using the config environment command:

ucd config set environment [environment_id] --project=[project_id]

If you set the environment in config, you don’t need to add the --environment flag.

For a sequential example of how to use the command-line interface, see Using CCD via the CLI.

**Examples:**

Example 1 (unknown):
```unknown
$ ugs login
```

Example 2 (unknown):
```unknown
$ ugs ccd [command] [subcommand] [parameters]
```

Example 3 (unknown):
```unknown
$ ugs --version
```

Example 4 (unknown):
```unknown
$ ugs ccd [command] --json
```

---

## Unity Version Control 4.x Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/4

**Contents:**
- Unity Version Control 4.x Release Notes#
- 4.1.10.622#
  - Bug#
    - Add and checkin opertations were failing with sym…#
- 4.1.10.583#
  - New#
    - The update-merge operation (update that requires…#
  - Bug#
    - If an external application (typically an antiviru…#
- 4.1.10.573#

This document contains all release notes for Unity Version Control major version 4.x, organized from newest to oldest.

Add and checkin opertations were failing with symlinks whose targets cause a cycle. Now it's fixed.

The update-merge operation (update that requires a merge without conflicts) doesn't support cloaked rules yet. A restriction has been added to avoid misunderstandings. If there are cloaked rules, a regular merge will be launched.

If an external application (typically an antivirus) locks the files under the workspace's metadata directory ('.plastic' directory), workspace operations will fail when updating the workspace status.

As the operation on server was succesfully completed (typically a checkin operation), the workspace ends up being inconsistent. Fixed, now all the operations that need to write data on those files lock the '.plastic' files before performing any change.

Change in the TCP layer to improve counting of active and inactive threads.

Server: The changeset tree loading has been improved on MySql backend for big trees. Now, a temporary table with the involved revisiond is created when loading a tree.

This table will be created in the hard disk by default. To override this setting and create the temporary table in memory, the following parameter in the server's db.conf file can be set:

The 'LOAD DATA LOCAL' setting in MySql backend must be enabled. (This setting is already enabled by default).

http://dev.mysql.com/doc/refman/5.0/en/server-system-variables.html#sysvar_local_infile

Repository with 11 million revisions. Changeset tree loading measurement, with 418950 files and 27914 folders. Time to read all the changeset tree revisions (about 440.000 revisions):

Read 440.000 revisions from disk temp table -> 9688 ms.

Read 440.000 revisions from memory temp table -> 6084 ms.

The plasticlogstats server diagnostics app has been modified. It now supports grouping by hour (--hour) and output data in XML format to a file (--xml=outputfile.xml), which is useful for Excel data analysis. Now the flags are set with '--'.

Server: Improved memory performance when multiple replication operations are running in parallel.

Server: Improved memory usage when caching large number of changeset trees (> 300K items).

Office Plugin: Now the plugin for Office also supports the Microsoft Office 2007 and 2010 x64 versions.

Starting the GUI on Linux with several tabs opened crashed sometimes. Fixed.

Mergetool: Exception was thrown if clicking on Navigation buttons and there were no conflicts in the file. Fixed.

Mergetool: When the result encoding was set to NONE, mergetool checked the contributors encoding instead of saving the result without encoding. Fixed.

Admintool: when migrating databases from a backend to another, the data introduced in the form was cached and not renewed, so if the user typed it wrongly he was not able to fix it, unless he / she restarted the tool. Fixed.

TeamCity: now the plugin preserves executable permissions when creating the build patch so that the agent can run them. NOTE: To use this upgrade of the plugin, it is required to run TeamCity with Java 7.

Proxy Server: Now the Proxy server can be used in 64-bit machines.

Internal changes and improvements.

**Examples:**

Example 1 (unknown):
```unknown
<MySqlTmpTablesOnMemory>yes</MySqlTmpTablesOnMemory>
```

Example 2 (unknown):
```unknown
<MySqlTmpTablesOnMemory>yes</MySqlTmpTablesOnMemory>
```

---

## Billing

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/pricing-billing

**Contents:**
- Billing#

Multiplay Hosting is billed as part of one unified invoice for Unity Gaming Services. You can expect to receive your invoice at the beginning of the following month (for services used in the previous month).

Note: To view a real-time preview of your consumption, in the Unity Dashboard, select Administration > Costs and usage reporting.

---

## TUBE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/tube

**Contents:**
- TUBE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Runs commands related to Plastic Tube.

cm tube config -u=<user> -p=<password>

(Configures UVCS to use Plastic Tube with the specified user and password.)

cm tube create <remoteuser>

(Creates the tube "remoteuser -> myuser". The user "myuser" allows to "remoteuser" to connect to "myuser" server. Connections can be established from "remoteuser" to "myuser". Only tubes from other users to the current tube user can be created.)

cm tube remove <remoteuser>

(Removes the tube "remoteuser -> myuser".)

(Lists the local repositories shared in the local server and the users that it is shared with.)

(Lists the shared remote repositories that are shared with the current tube user.)

cm tube share <rep_spec>[ ...] -u=<remoteuser> -a=(pull | push | pull,push)

(Shares the local repository(s) with the remote user and sets the specified access mode. Use a whitespace to separate repository specs.)

cm tube unshare <rep_spec>[ ...] -u=<remoteuser>

(Unshares the local repository(s) with the remote user. Use a whitespace to separate repository specs.)

(Connects the UVCS server to Plastic Tube.)

(Disconnects the UVCS server from Plastic Tube.)

(Shows if the UVCS server is connected to Plastic Tube.)

Use the 'cm tube' command to manage Plastic Tube.

cm tube config -u=ruben@codicesoftware.com -p=rubenpassword

cm tube create pablo@codicesoftware.com

('pablo@codicesoftware.com' can connect to the current Plastic Tube user)

cm tube remove pablo@codicesoftware.com

cm tube share repo@server:8087 -u=pablo@codicesoftware.com -a=pull,push

cm tube share repo@server:8087 doc@server:8087 -u=pablo@codicesoftware.com -a=push

cm tube unshare repo@server:8087 -u=pablo@codicesoftware.com

**Examples:**

Example 1 (unknown):
```unknown
cm tube config -u=<user> -p=<password>
```

Example 2 (unknown):
```unknown
cm tube create <remoteuser>
```

Example 3 (unknown):
```unknown
cm tube remove <remoteuser>
```

Example 4 (unknown):
```unknown
cm tube local
```

---

## Task and issue tracking integrations

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/issue-tracking/issue-tracking

**Contents:**
- Task and issue tracking integrations#

Integrate Unity Version Control (UVCS) with issue tracking systems. You can use UVCS issue tracking integrations in two different working modes:

---

## PARTIAL UNDO

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-undo

**Contents:**
- PARTIAL UNDO#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - These are equivalent when executed from the /src directory#
  - Filters#
  - Examples#

Undoes changes in a workspace.

cm partial undo [<path>[ ...]] [--symlink] [-r | --recursive] [<filter>[ ...]] [--silent | --machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

The undo command is dangerous - it undoes work in an irreversible way. Once the undo has finished, it is not possible to recover the previous state of the files and directories affected by it. If no path is specified in the arguments, by default it will undo every change in the current directory, but not recursively.

cm partial undo file.txt code.cs /test

cm partial undo /src file.txt code.cs

If you want the operation to be recursive, you must specify the '-r' flag.

To undo all of the changes below a directory (including changes affecting the directory itself):

cm partial undo dirpath -r

If dirpath is a workspace path, every change in the workspace will be undone.

If no flag is specified, by default, all changes are undone, but the paths can be filtered using one or more of the flags below. If a file or directory matches one or more of the specified kinds of change, all of the changes on said file or directory will be undone. For example, if you specify both '--checkedout' and '--moved', if a file is both checkedout and moved, both changes will be undone.

(Undoes all changes in the current directory recursively. If executed from the workspace's root, undoes all changes in the entire workspace.)

cm partial co file.txt

cm partial undo file.txt

(Undoes the checkout on file.txt.)

echo content >> file.txt

cm partial undo file.txt

(Undoes the local change to file.txt.)

(Undoes changes to the src directory and its files.)

cm partial undo src/*

(Undo changes in every file and directory contained in src, without affecting src.)

(Undo changes to every file or directory that matches *.cs in the current directory.)

cm partial undo *.cs -r

(Undoes changes on every file or directory that matches *.cs in the current directory and every directory below it.)

cm partial co file1.txt file2.txt

echo content >> file1.txt

cm partial undo --unchanged

(Undoes the checkout of unchanged file2.txt, ignoring locally changed file1.txt.)

echo content >> file1.txt echo content >> file2.txt

cm partial co file1.txt

cm partial undo --checkedout

(Undoes the changes in checked-out file file1.txt, ignoring file2.txt as it is not checked-out.)

cm partial add file.txt

cm partial undo file.txt

(Undoes the add of file.txt, making it once again a private file.)

rm file1.txt echo content >> file2.txt

cm partial add file3.txt

cm partial undo --deleted --added *

(Undoes the file1.txt delete and file3.txt add, ignoring the file2.txt change.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial undo [<path>[ ...]] [--symlink] [-r | --recursive] [<filter>[ ...]] [--silent | --machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
cm partial undo
```

Example 3 (unknown):
```unknown
cm partial undo *
```

Example 4 (unknown):
```unknown
cm partial undo file.txt code.cs /test
```

---

## Server.json

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/concepts/server-json

**Contents:**
- Server.json#
- allocatedUUID#
- File location#

The server.json file is a file that has variable data, such as the current allocation ID, for each server. It’s automatically generated and populated for each server based on the configuration variables and the server data. It has all the built-in configuration variables and any custom values from your build configuration variables.

The server.json file exists within each server’s server ID directory. By default, it has all the built-in configuration variables, such as the allocation ID supplied by your matchmaker, and the connection port. But you can also add any number of configuration variables to track in the build configuration settings.

Here’s an example of what a server.json file might look like when populated with the configuration variables from a server:

The allocatedUUID variable is a special built-in configuration variable that changes each time a server is allocated or unallocated. When a server is allocated, the allocatedUUID field has the server’s allocation ID. When a server is unallocated, the allocatedUUID field has an empty string.

Note: Other configuration variables keep their value despite the server allocation status.

Here’s an example of a server.json file of an allocated server:

Here’s an example of a server.json file of an unallocated server:

You can track the allocation ID of a server by monitoring the server.json for changes. To detect changes, set up an event trigger that detects file changes or a process to check the file for changes at a regular interval.

Note: The recommended best practice is to use the API to subscribe to game server lifecycle events (Unity Services Web API Docs), rather than monitoring for changes because the interval check causes unnecessary resource usage.

The server.json file is available on disk in the following location:

**Examples:**

Example 1 (unknown):
```unknown
server.json
```

Example 2 (unknown):
```unknown
server.json
```

Example 3 (unknown):
```unknown
server.json
```

Example 4 (unknown):
```unknown
{
	"ipv6": "::1",
	"port": "9000",
	"allocatedUUID": "1a04a1ac-a31a-11ed-a5e3-00155d4f1a62",
	"serverID": "12345",
	"machineID": "6789",
	"fleetID": "c0a3e2a1-6955-415c-b1d4-af9199833e6a",
	"regionID": "f15a6c27-de2a-4848-abc3-9579fbfd2259",
	"regionName": "North America",
	"queryPort": "9010",
	"ip": "127.0.0.1",
	"queryType": "sqp",
	"serverLogDir": "/mnt/unity/logs/"
}
```

---

## Access control

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/access-control

**Contents:**
- Access control#
- Service Account controlled lobbies#

By default, Lobby accepts API calls from either an Authenticated Player or a Service Account. In some cases, you might want more control over how lobbies are created or joined. In those cases you can use Access Control.

In the following example, lobbies can only be created and players can only join via a Service Account. This allows you to control the lobby by restricting write access for Players.

Creating project policies via CLI with the following JSON definition will Deny all write access to Lobby service APIs, except the Reconnect, Heartbeat and Tokens endpoints. Note that any API that requires read access (HTTP GETs) will still be accessible.

Upsert the policies with ugs access upsert-project-policy -p <project-id> -e <env-name> <file-path>. At this point, any API call that violates the policy will be rejected with a 403 - Forbidden error.

**Examples:**

Example 1 (unknown):
```unknown
{
  "statements": [
    {
      "Sid": "DenyLobbyServiceWrite",
      "Resource": "urn:ugs:lobby:/v1/*",
      "Principal": "Player",
      "Action": ["Write"],
      "Effect": "Deny"
    },
    {
      "Sid": "AllowLobbyServiceReconnect",
      "Resource": "urn:ugs:lobby:/v1/*/reconnect",
      "Principal": "Player",
      "Action": ["*"],
      "Effect": "Allow"
    },
    {
      "Sid": "AllowLobbyServiceHeartbeat",
      "Resource": "urn:ugs:lobby:/v1/*/heartbeat",
      "Principal": "Player",
      "Action": ["*"],
      "Effect": "Allow"
    },
    {
      "Sid": "AllowLobbyServiceTokens",
      "Resource": "urn:ugs:lobby:/v1/*/tokens",
      "Principal": "Player",
      "Action": ["*"],
      "Effect": "Allow"
    }
  ]
}
```

Example 2 (unknown):
```unknown
{
  "statements": [
    {
      "Sid": "DenyLobbyServiceWrite",
      "Resource": "urn:ugs:lobby:/v1/*",
      "Principal": "Player",
      "Action": ["Write"],
      "Effect": "Deny"
    },
    {
      "Sid": "AllowLobbyServiceReconnect",
      "Resource": "urn:ugs:lobby:/v1/*/reconnect",
      "Principal": "Player",
      "Action": ["*"],
      "Effect": "Allow"
    },
    {
      "Sid": "AllowLobbyServiceHeartbeat",
      "Resource": "urn:ugs:lobby:/v1/*/heartbeat",
      "Principal": "Player",
      "Action": ["*"],
      "Effect": "Allow"
    },
    {
      "Sid": "AllowLobbyServiceTokens",
      "Resource": "urn:ugs:lobby:/v1/*/tokens",
      "Principal": "Player",
      "Action": ["*"],
      "Effect": "Allow"
    }
  ]
}
```

Example 3 (unknown):
```unknown
ugs access upsert-project-policy -p <project-id> -e <env-name> <file-path>
```

Example 4 (unknown):
```unknown
403 - Forbidden
```

---

## Recover deleted revisions

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/recover-deleted

**Contents:**
- Recover deleted revisions#

Restore deleted files in Gluon. For example, if you accidentally delete a file that you need, or change your mind, you can restore deleted files.

Recover a deleted revision:

Note: To recover deleted revisions with the command line, run the cm undelete command.

**Examples:**

Example 1 (unknown):
```unknown
cm undelete
```

---

## Data Access

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/data-access

**Contents:**
- Data Access#
- Additional resources#

Data Access provides access to your Unity Analytics data through Snowflake (a data warehouse).

You can then use Snowflake to view your Analytics data through a third-party visualization tool such as Tableau. Your data joins other Analytics data in your Snowflake account; you have access to your organization's entire Analytics data, rather than per project. The data is in a raw format, so you can perform advanced SQL queries, that aren't possible with Analytics, through Snowflake's Secure Data Sharing feature.

Unity supports Google Cloud Platform (GCP) EU-WEST4 and US-CENTRAL1 regions. To use Data Sharing, you need:

Due to data replication, it might take up to 1 hour and 30 minutes for event data to be available in GCP US-CENTRAL-1.

Note that only organization owners can access the Data Access settings in the Unity Dashboard.

---

## ISSUETRACKER

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/issuetracker

**Contents:**
- ISSUETRACKER#
- Description#
  - Usage#
  - Jira parameters (all are mandatory)#
- Help#
  - Examples#

Gets, updates, or finds the issue status in the specified issue tracker.

cm issuetracker <name> status get <task_id> <parameter>[ ...]

cm issuetracker <name> status update <task_id> <status> <parameter>[ ...]

cm issuetracker <name> status find <status> <parameter>[ ...]

cm issuetracker <name> connection check <parameter>[ ...]

cm issuetracker jira status get 11 --user=user@mail.es --password=pwd --host=https://user.atlassian.net --projectkey=PRJ

(Gets the status of the issue 11 for the 'PRJ' project.)

cm issuetracker jira status update 11 "Done" --user=user@mail.es --password=pwd --host=https://user.atlassian.net --projectkey=PRJ

(Updates the status to 'Done' of the issue 11 for the 'PRJ' project.)

cm issuetracker jira status find "Done" --user=user@mail.es --password=pwd --host=https://user.atlassian.net --projectkey=PRJ

(Gets the task ids whose status is set to 'Done' for the 'PRJ' project.)

cm issuetracker jira connection check --user=user@mail.es --password=pwd --host=https://user.atlassian.net --projectkey=PRJ

(Checks whether the configuration parameters are valid or not.)

**Examples:**

Example 1 (unknown):
```unknown
cm issuetracker <name> status get <task_id> <parameter>[ ...]
```

Example 2 (unknown):
```unknown
cm issuetracker <name> status update <task_id> <status> <parameter>[ ...]
```

Example 3 (unknown):
```unknown
cm issuetracker <name> status find <status> <parameter>[ ...]
```

Example 4 (unknown):
```unknown
cm issuetracker <name> connection check <parameter>[ ...]
```

---

## ADD

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/add

**Contents:**
- ADD#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Requirements to add items#
  - Reading input from stdin#
  - Examples#

Adds an item to version control.

cm add [-R | -r | --recursive] [--silent] [--ignorefailed] [--skipcontentcheck] [--coparent] [--filetypes=<file>] [--noinfo] [--format=<str-format>] [--errorformat=<str-format>] <item-path>[ ...]

The 'add' command can read paths from stdin. To do this, pass a single dash "-". Example:

Paths will be read until an empty line is entered. This allows you to use pipe to specify which files to add. Example:

dir /S /B *.c | cm add -

(In Windows, adds all .c files in the workspace.)

cm add file1.txt file2.txt

(Adds 'file1.txt' and 'file2.txt' items.)

cm add c:\workspace\file.txt

(Adds 'file.txt' item in path 'c:\workspace'.)

cm add -R c:\workspace\src

(Recursively adds 'src'.)

(Recursively adds all the contents of the current directory.)

cm add -R * --filetypes=filetypes.conf

(Recursively adds all the contents of the current directory, using 'filetypes.conf' to assign a type to each file based on its extension, instead of checking its content.)

cm add --coparent c:\workspace\dir\file.txt

(Adds 'file.txt' to source control, and performs a checkout of 'dir'.)

cm add -R * --format="ADD {0}" --errorformat="ERR {0}"

(Recursively adds all the contents of the current directory, printing 'ADD <item>' for successfully added files, and 'ERR <item>' for items that could not be added.)

**Examples:**

Example 1 (unknown):
```unknown
cm add [-R | -r | --recursive] [--silent] [--ignorefailed] [--skipcontentcheck] [--coparent] [--filetypes=<file>] [--noinfo] [--format=<str-format>] [--errorformat=<str-format>] <item-path>[ ...]
```

Example 2 (unknown):
```unknown
dir /S /B *.c | cm add -
```

Example 3 (unknown):
```unknown
cm add file1.txt file2.txt
```

Example 4 (unknown):
```unknown
cm add c:\workspace\file.txt
```

---

## Game server lifecycle

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-lifecycle

**Contents:**
- Game server lifecycle#
- Create#
- Start#
- Stop#
  - Internal stops#
    - Intentional exits#
    - Crashes#
  - External stops#
    - Game server misbehavior#
    - Build configuration ID change#

The server lifecycle is the lifecycle of the build executable as a process running on a machine with protected resources. It has three distinct stages:

The beginning and end of the server lifecycle varies depending on the requirements of your game. It might start well before or immediately before the allocation lifecycle, and it can end after each allocation or continue for many allocations.

The first stage of the server lifecycle involves creating a server slot on a machine. The server slot is akin to a placeholder of resources for a build executable to run in. When Multiplay Hosting provisions and starts a machine, it creates a number of server slots based on the server density calculation. The server density calculation finds the number of server slots that can fit on a machine based on the machine’s available resources and the fleet’s usage settings.

The second stage of the server lifecycle involves using information (such as the build and configuration options) to start the build executable (or Docker image) as a process in the server slot created during the first stage.

When the server starts depends on the requirements of your game. It usually starts in response to an allocation request or when Multiplay Hosting provisions a machine (depending on whether you have the start on provision setting enabled for the fleet).

Other situations in which a server starts include:

Note: Using allocation payloads might also change server start behavior.

The third stage of the server lifecycle involves stopping the server build executable process. This can occur in several ways, each triggering different responses from Multiplay Hosting. Both internal and external scenarios can cause a game server to stop and sometimes more than one scenario is involved (such as an exit and a crash).

Internal scenarios are events that originate from the game server itself (the process of the build executable). These scenarios include:

The following diagram illustrates the server lifecycle when an internal scenario triggers a server stop.

An exit refers to an intentional termination of a build executable process with an exit code of 0. When Multiplay Hosting detects that a build executable exits intentionally, it automatically deallocates the server slot, clearing the allocation ID in the server.json file and readying the server slot for the next allocation.

The recommended best practice for most games is to use a matchmaker flow where the build executable process exits after each session. Exiting in this way triggers an automatic deallocation.

A crash refers to an unintentional termination of a build executable process with any exit code other than 0 (opposed to an intentional exit). When Multiplay Hosting detects that a build executable crashed, it attempts to recover the server by restarting it with the same allocation ID. However, if the server continues to crash, Multiplay Hosting won’t keep restarting it. Refer to Crash backoff.

External scenarios are events that originate from an API call or an automated Multiplay Hosting action, either due to a configuration or a response to the game server’s behavior. These scenarios include:

The following diagram illustrates the server lifecycle when an external scenario triggers a server stop.

Misbehavior means something unexpected (other than a crash) happened with the build executable process. Usually, this means the build executable process is using more resources than the server slot allows or isn’t responding to queries for an extended period of time.

Note: Multiplay Hosting only checks if game servers respond to queries if you implement a query protocol in the build and specify it in the build configuration.

Note: If the intention is to manually Stop a currently Allocated server this will not work, instead you should send a Deallocation request.

Multiplay Hosting restarts (stops, then starts) a build executable process if you create an allocation, and Multiplay Hosting selects a server slot that’s using the wrong build configuration (a build configuration other than the one specified in the allocation request). In this case, Multiplay Hosting restarts the build executable with the correct build configuration. Changes to values in a build configuration currently in use by a server may not be reflected immediately. It is recommended that you follow the zero downtime releases model to update your build configurations.

Although there are commonalities between them, not all game servers follow the same lifecycle. The exact behavior depends on how you manage your game sessions. The two most common methods are:

Multi-session allocations is a game session management pattern where you reuse the same allocation for multiple game sessions. In this pattern, you keep game servers allocated between game sessions. Instead of exiting the game server executable between game sessions, you use another form of clean-up, such as resetting the game server state or exiting to a lobby.

Note: The recommended best practice for multi-session allocations is to enable the start on provision setting. This means game servers are ready for allocations when the machine provisioning completes.

The lifecycle of a game server with multi-session allocations uses the following process:

Single-session allocations is a game session management pattern with a one-to-one relationship between game sessions and allocations. In this pattern, you have your build executable exit and deallocate the game server each time a game session ends. Then, you create a new allocation for the next game session.

Note: The recommended best practice for single-session allocations is to disable the start on provision setting. This means game servers don’t start until you allocate them.

The lifecycle of a game server with single-session allocations uses the following process:

Server hold is a server management pattern which allows the server to remain capable of receiving an allocation or executing a reservation for a specified period of time. This is explained in more detail in the server hold section.

**Examples:**

Example 1 (unknown):
```unknown
server.json
```

---

## ADMIN READONLY

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/admin-readonly

**Contents:**
- ADMIN READONLY#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Enables/disables the server readonly mode.

cm admin readonly (enter | leave | status) [<server>]

Only the server administrator can enter the server readonly mode.

cm admin readonly enter diana:8086

cm admin readonly leave

**Examples:**

Example 1 (unknown):
```unknown
cm admin readonly (enter | leave | status) [<server>]
```

Example 2 (unknown):
```unknown
cm admin readonly enter diana:8086
```

Example 3 (unknown):
```unknown
cm admin readonly leave
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/ApplePrivacySurvey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Multiplay Hosting is available from version 1.2.2.

The following code sample contains the PrivacyInfo.xcprivacy manifest for Multiplay Hosting. This file is also available in the SDK. To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 3 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## Third-party license information

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unreal/manual/Unreal/third-party-license-information

**Contents:**
- Third-party license information#

The Vivox SDK uses various open-source packages. The following table lists the open-source software that's distributed with the Vivox SDK.

https://www.nuget.org/packages/expat

Expat XML Parser - BSD license

BSD 3-clause "New" or "Revised" License

https://www.nuget.org/packages/expat

Language Technologies Institute Carnegie Mellon University License (BSD-like)

https://github.com/festvox/flite/

getopt.c by Gregory Pietsch

License for getopt.c by Gregory Pietsch

https://github.com/eblot/newlib/blob/master/newlib/libc/stdlib/getopt.c

File + Dynamic Library

https://github.com/gradle/gradle/

BSD 3-clause "New" or "Revised" License

https://sourceforge.net/projects/kissfft/

Creative Commons Public Domain Dedication License

https://sourceforge.net/projects/libb64/

https://github.com/strophe/libstrophe/

MD5 - Command Line Message Digest Utility

MD5 CommandLine License (Public Domain)

http://www.fourmilab.ch/md5/

BSD 3-clause "New" or "Revised" License

https://opus-codec.org/

RSA Data Security-MD5 Message

RSA Message-Digest License

http://www.efgh.com/software/md5.htm

BSD 3-clause "New" or "Revised" License

https://www.speex.org/

BSD 3-clause "New" or "Revised" License

https://www.speex.org/

https://sourceforge.net/projects/tinyxml/

https://github.com/mattconte/tlsf

BSD 3-clause "New" or "Revised" License

https://webrtc.googlesource.com/src

---

## Loot boxes

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/LootBoxes

**Contents:**
- Loot boxes#
- Prerequisites#
- Overview#
  - Initialization#
  - Functionality#
- Setup#
  - Requirements#
  - Unity Cloud services configuration#
    - Using the Deployment package#
    - Using the Unity Dashboard#

Loot boxes are virtual items that players can win, earn, or purchase, and then open to receive a randomized selection of items. Rewards can vary greatly depending on the game's genre, theme, and virtual economy. They can positively impact retention, supplement live events, and pique the curiosity of old and new players alike. This sample demonstrates how to set up a basic loot box that grants random currency to players.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

To see this use case in action, open the samples menu and navigate to Loot Boxes. To open this scene directly and interact with the use case:

The LootBoxesSceneManager.cs script performs the following initialization tasks in its Start function:

When you click the Open Loot Box button, you receive a random amount of rewards from the available pool (indicated in the currency HUD). The following occurs:

To replicate this use case, you'll need the following Unity packages in your project:

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys all the necessary items.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Configure the following Currencies in the Unity Dashboard:

These comprise the potential reward pool for your loot box. For more information, see documentation on configuring Economy resources.

Publish the following script in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resources in the Unity Dashboard:

**Examples:**

Example 1 (unknown):
```unknown
LootBoxesSample.unity
```

Example 2 (unknown):
```unknown
LootBoxesSceneManager.cs
```

Example 3 (unknown):
```unknown
GetRandomCurrency
```

Example 4 (unknown):
```unknown
Deploy Selection
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/BattlePasses

---

## Audiences

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/Audiences

**Contents:**
- Audiences#

Audiences are players that are grouped by criteria such as behavior or location. Audiences can be targeted to personalize their game journey.

You can segment your audience based on in-game behaviors, such as a purchase in the last seven days. You can analyze groups of players and look for engagement opportunities, such as through targeted Game Overrides.

Standard audiences include Recently Active Players, New Players, and Churned Players. Audiences show information about how they interact with your game. For example, you can target Unengaged Players who only play occasionally (one or two days a week) with tailored game content to attract them into playing more often.

Standard audiences cannot be edited, but you can create Custom Audiences to suit your own needs. See the list of standard audiences or the how to create a custom audience tutorial.

---

## SHOWCOMMANDS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/showcommands

**Contents:**
- SHOWCOMMANDS#
- Description#
  - Usage#
- Help#

Shows all the available commands.

Bear in mind that there might be deprecated commands not displayed here but which functionallity remains due to retrocompatibility reasons.

**Examples:**

Example 1 (unknown):
```unknown
cm showcommands
```

---

## Google Play data safety section for Cloud Code

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/GoogleDataSafety

**Contents:**
- Google Play data safety section for Cloud Code#
- Data collection survey#
  - Data types#

Starting April 2022, Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Cloud Code. For your convenience, Cloud Code provides information on its data collection practices below.

Important: The data disclosures below are for the Cloud Code SDK only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please check the Google documentation.

*Player ID is collected. The Player ID is a random string of numbers generated by the Authentication SDK, which is used to identify returning and new players on different devices and external providers.

*Possible (developers can record whatever data they desire)

---

## Multiplay Hosting SDK for Unity

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/sdk/game-server-sdk-for-unity

**Contents:**
- Multiplay Hosting SDK for Unity#
- Requirements and limitations#
- Initialize the SDK#
- Configure the game server#
- Ready the game server#
- Unready the game server#
- Start server query handler#
- Subscribe to server events#
- Handle Multiplay Hosting events#
  - Allocate#

The Multiplay Hosting SDK for Unity has all the functionality necessary to use Multiplay Hosting scaling and game server services in your game. Unity.Services.Multiplay is the primary namespace for interacting with the Multiplay service.

Note: Refer to Get started with Multiplay Hosting and the integration requirements before continuing.

The Multiplay Hosting SDK for Unity works with Unity Editor version 2020.3 and later.

Warning: There's a known issue with Unity Editor version 2022 that prevents the SDK from working. If you use version 2022, ensure you use version 2022.2.3f1 or later.

Use the Instance method to create a singleton of the IMultiplayService. You can use the singleton to interact with the Multiplay Hosting API.

The ServerConfig class represents a game server configuration, and allows you to create a ServerConfig instance for the current game session.

Use the ServerConfig method (within the ServerConfig class) to create a ServerConfig instance for the current game session.

The following code example shows how to use the ServerConfig method to log information about a game server, such as the server ID, allocation ID, port number, query port number, and server log directory.

Use the ReadyServerForPlayersAsync method to let Multiplay Hosting know a game server is ready to receive players. Refer to Game server readiness.

Use the UnreadyServerAsync method to let Multiplay Hosting know that a game server is no longer ready to receive players. Refer to Game server readiness.

Use the StartServerQueryHandlerAsync method to connect to the game server’s SQP implementation with the provided parameters.

Multiplay Hosting uses the StartServerQueryHandlerAsyncparameters to initialize the server query handler.

After you initialize the server query handler, you can use the IServerCheckManager instance provided by this call to update the values at any time. You must call UpdateServerCheck() for the changes to take effect. Call UpdateServerCheck() when game server variables change. Refer to SQP for more information.

You should call UpdateServerCheck() often enough to ensure you send up-to-date data back to Multiplay Hosting when the query request happens every 60 seconds.

One of the best ways to do so is to call it in the Update loop. But you can also call it when specific game events occur, such as a player joining, a player leaving, or a game match starting.

Note: The currentPlayers field always starts at 0. You must update this value each time a player connects to (or disconnects from) the game server.

The following example shows how to start the server query handler.

Use the SubscribeToServerEventsAsync method to subscribe to server event callbacks for a game server.

The following example shows how to subscribe to and handle game server event callbacks, including OnAllocate, OnDeallocate, and OnError.

The MultiplayEventCallbacks class provides callbacks for responding to Multiplay Hosting events, such as allocations, deallocations, errors, and game server state changes.

The following code example shows how to respond to event callbacks, such as OnAllocate, OnDeallocate, and OnError.

Use the Allocate callback to respond to a MultiplayAllocation event.

Use the Deallocate callback to respond to a MultiplayDeallocation event.

Use the Error callback to respond to a MultiplayError event.

Use the SubscriptionStateChanged callback to respond to a MultiplayServerSubscriptionState event.

The Multiplay Authoring module (installed with the Multiplay package) allows you to optionally author and modify resources directly within the Unity Editor. You can then upload resources from the Unity Editor to the Dashboard by using the Deployment package.

Multiplay configurations existing in the Unity Editor allow users to treat their source control as the single source of truth (instead of the version in the cloud), simplifying actions such as rollbacks, bisection, and other common operations.

To use Multiplay in the Unity Editor:

To create Multiplay configurations within the Editor, install the following packages:

To install these packages:

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

In Unity Editor, select Edit > Project Settings > Services.

If your project doesn't have a Unity project ID:

If you have an existing Unity project ID:

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

The Multiplay Authoring module allows you to create, edit, and deploy Multiplay configurations directly within the Unity Editor.

Follow these steps to create an Multiplay configuration using the Multiplay Authoring module:

The new configuration is now visible in the Project window, and in the Deployment window, accessible by selecting Services > Deployment.

There is currently one method to edit an existing configuration:

The deployment window finds resources and assigns their type according to their file extension.

The configuration uses the yaml format to describe its contents and the .gsh file extension.

Example for new_multiplay_config.gsh:

The configuration describes 3 components within the file:

You can deploy a Multiplay configuration through the Deployment window. Refer to the Deployment package manual for more information.

Some configurations have dependencies on other resources,such as build configurations being dependent on the build itself.

When deploying, Builds will deploy first, then the Build Configurations, then the Fleets. A failure at one point in the chain will halt deployment for the configurations that depend on it.

The Deployment window is a core feature of the Deployment package. It allows all services to have a single cohesive interface for deployment needs, and allows you to upload cloud assets to their respective cloud services.

Refer to the Deployment package manual for more information.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.Multiplay
```

Example 2 (unknown):
```unknown
IMultiplayService
```

Example 3 (unknown):
```unknown
async void Example_InitSDK()
{
	try
	{
		await UnityServices.InitializeAsync();
	}
	catch (Exception e)
	{
		Debug.Log(e);
	}
}
```

Example 4 (unknown):
```unknown
async void Example_InitSDK()
{
	try
	{
		await UnityServices.InitializeAsync();
	}
	catch (Exception e)
	{
		Debug.Log(e);
	}
}
```

---

## The CustomEvent class

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/customevent-class

**Contents:**
- The CustomEvent class#

For simplicity and quick turn-around, the Analytics SDK offers a generic CustomEvent class that you can use for any custom event in a very similar way to the plain dictionary API used in earlier SDK versions. This comes at the cost of the type safety and validation options offered by using dedicated sub-classes for each type of event, but may be useful during migration or prototyping.

Warning: Although the parameter values are taken in as object type, values must actually be one of the following primitive types: string, int, long, float, double or bool. If you attempt to add a value of an unsupported type, the CustomEvent class throws an ArgumentException.

**Examples:**

Example 1 (unknown):
```unknown
CustomEvent
```

Example 2 (unknown):
```unknown
CustomEvent myEvent = new CustomEvent("MyEvent")
{
    { "fabulousString", "woah!" },
    { "peculiarBool", true },
    { "sparklingInt", 1337 },
    { "spectacularFloat", 313.37f }
};

AnalyticsService.Instance.RecordEvent(myEvent);
```

Example 3 (unknown):
```unknown
CustomEvent myEvent = new CustomEvent("MyEvent")
{
    { "fabulousString", "woah!" },
    { "peculiarBool", true },
    { "sparklingInt", 1337 },
    { "spectacularFloat", 313.37f }
};

AnalyticsService.Instance.RecordEvent(myEvent);
```

Example 4 (unknown):
```unknown
CustomEvent
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/privacy/apple-privacy-survey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Leaderboards is available from version 2.0.2.

The following code sample contains the PrivacyInfo.xcprivacy manifest for Leaderboards. This file is also available in the SDK.

To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
				<string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
				<string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## Scaling

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/scaling

**Contents:**
- Scaling#

Multiplay Hosting allows you to scale the number of servers in your fleet up and down in response to player demand per region using the scaling system. The scaling system controls when and how regions within a fleet scale up and down. Each region has independent scaling settings that allow you to tailor how they scale.

Multiplay Hosting uses each region’s scaling settings, the build configuration’s server density, and the current number of allocated servers to decide the number of available servers to keep per region.

The region’s scaling settings tell the scaling system the minimum number of servers you want be available within the region and the maximum number of servers that can be available in the region.

The scaling system considers all the build configurations within a fleet and uses the worst-case usage settings to find the number of servers that can run per machine. Multiplay Hosting uses the worst-case usage settings to prevent the fleet from re-scaling each time you change build configurations.

It’s essential to understand how the worst-case usage settings impact scaling. For example, if the usage settings allow for three servers to run per machine and the scaling settings require four available servers, the scaling system spins up two machines. The two online machines result in six available servers instead of four due to the usage settings.

Multiplay Hosting creates these two additional servers to make the most of the available capacity. By default, these additional servers are in a stopped state and offer a quick way of increasing server availability without needing to start a new machine.

Explore the following topics to learn more:

---

## CHECKIN

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/checkin

**Contents:**
- CHECKIN#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Reading input from stdin#
  - Examples#

Stores changes in the repository.

cm checkin | ci [<item_path>[ ...]] [-c=<str_comment> | -commentsfile=<comments_file>] [--all|-a] [--applychanged] [--private] [--update] [--symlink] [--noshowchangeset] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

Revision content should be different from previous revision in order to be checked in.

Set the PLASTICEDITOR environment variable to specify an editor for entering comments. If the PLASTICEDITOR environment variable is set, and the comment is empty, the editor will be automatically launched to allow you to specify the comment.

The 'checkin' command can read paths from stdin. To do this, pass a single dash "-". Example: cm checkin -

Paths will be read until an empty line is entered. This allows you to use pipe to specify which files to checkin. Example:

dir /S /B *.c | cm checkin --all -

(In Windows, checkins all .c files in the workspace.)

cm checkin file1.txt file2.txt

(Checkins the 'file1.txt' and 'file2.txt' checked-out files.)

cm checkin . -commentsfile=mycomment.txt

(Checkins the current directory and sets the comment in the 'mycomment.txt' file.)

cm checkin link --symlink

(Checkins the symlink file and not the target.)

cm ci file1.txt -c="my comment"

(Checkins 'file1.txt' and includes a comment.)

cm status --short --compact --changelist=pending_to_review | cm checkin -

(Lists the paths in the changelist named 'pending_to_review' and redirects this list to the input of the checkin command.)

cm ci . --machinereadable

(Checkins the current directory, and prints the result in a simplified, easier-to-parse format.)

cm ci . --machinereadable --startlineseparator=">" --endlineseparator="<" --fieldseparator=","

(Checkins the current directory, and prints the result in a simplified, easier-to-parse format, starting and ending the lines, and separating the fields with the specified strings.)

**Examples:**

Example 1 (unknown):
```unknown
cm checkin | ci [<item_path>[ ...]] [-c=<str_comment> | -commentsfile=<comments_file>] [--all|-a] [--applychanged] [--private] [--update] [--symlink] [--noshowchangeset] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
dir /S /B *.c | cm checkin --all -
```

Example 3 (unknown):
```unknown
cm checkin file1.txt file2.txt
```

Example 4 (unknown):
```unknown
cm checkin . -commentsfile=mycomment.txt
```

---

## License

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/license

**Contents:**
- License#
- Configure license autorenewal#
- Change license#

Configure the license autorenewal option or change your license.

In the License section of the server administration console, you can find all of your Unity Version Control (UVCS) license information such as type, licensed users, and license file.

To configure the autorenewal option for subscription licenses, you need your licence token.

To change your license, upload the license file. You can access the license file from the Version Control > Seats > On-Prem page of the Unity Dashboard.

**Examples:**

Example 1 (unknown):
```unknown
plastic.lic
```

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/privacy-and-consent

**Contents:**
- Privacy and consent#
- Privacy overview for Authentication#
- Apple privacy survey for Authentication#
- Google Play data safety for Authentication#
- Privacy overview for Unity Player Accounts#
- Google Play data safety for Unity Player Accounts#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## Connection data

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/connection-data

**Contents:**
- Connection data#

Connection data is a collection of opaque data that uniquely represents a player's connection to a Relay server. The primary purpose of connection data is to establish a communication channel between the host player and the joining players. Check out Connection flow.

A joining player receives the host player connection data from the Allocations service after requesting to join a session. After the player is bound to a Relay server, they can use the connection data to request permission to open a message channel with the host player. If the Allocations service accepts the request, the joining player can send messages through the Relay server to the host player.

To send messages through the Relay server, the message must have the allocation ID of the recipient. Players aren't aware of the allocation ID until they successfully request a connection to the Relay server and the host player.

---

## Track your spending and transactions

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/track-your-spending-and-transactions

**Contents:**
- Track your spending and transactions#
- Additional resources#

The Billing page displays a Spending Overview graph as well as the Transaction history. The Spending Overview graph shows a bar graph of your monthly spend. The Transaction history shows the invoices for paying for the services. These are filterable by month and searchable by invoice ID.

To view your monthly spending overview and transaction history, navigate to Usage > Billing.

---

## Custom data

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/custom-data

**Contents:**
- Custom data#
- Instance data#
- Additional resources#

The resources listed above have the option of attaching custom data. Custom data allows you to define additional information that you want to be stored against any resource definition. For example, this could be a resource description, the path to the texture that should be used to render the resource, or any additional resource properties that you want to change without having to rebuild your game. Custom data uses JSON format and is optional in your configuration. The maximum size for custom data is 5 KB.

For example, consider a Sword inventory item. You could add the following code in the Custom data field to assign the sword properties, as well as the path to find its image asset:

The Custom Data editor comes with a built-in validation tool for JSON. Click BEAUTIFY to automatically reformat the code to optimize its legibility.

An additional type of custom data is instance data, which is the data associated with a player’s instance of a particular inventory item. This data is set using the SDK or game API, uses the JSON format, and is visible using the Economy Find Player button in the Unity Dashboard. The main difference is that it does not relate to the configuration item, but to the specific player instance in the game.

**Examples:**

Example 1 (unknown):
```unknown
{
	"damage": 5,
	"strength": 10,
	"durability": 20,
	"assetPath": "/assets/sword.png"
}
```

Example 2 (unknown):
```unknown
{
	"damage": 5,
	"strength": 10,
	"durability": 20,
	"assetPath": "/assets/sword.png"
}
```

---

## Simulation Experience

**URL:** https://docs.unity.com/ugs/en-us/manual/game-overrides/manual/simulation-experience

**Contents:**
- Simulation Experience#

Use Simulation Experience to understand the Audience or player’s experience with your configured Game Overrides. In addition, you can add user IDs and their attributes, view the keys that would be overridden through Game Overrides, and look into any relevant conflicts.

For example, you might want to understand what Overrides your spenders would see. Or you might want to know why a single player didn’t receive the content from an Override you’ve configured.

Note: Simulation Experience only shows the Remote Config Overrides that your players are eligible to receive. Other Overrides such as Economy and Cloud Content Delivery are not currently shown.

In the Unity Dashboard, open Game Overrides.

Select Simulation Experience.

Select Group to simulate an Audience or Individual to simulate for a single player.

Enter the attributes you want to override for the Audience or Player. Refer to Conditions.

Select Complete to start the simulation.

View the results of your simulation, including which keys the Override changes.

You can access the following information for your simulation:

Group information: the Audience(s) or Player for this simulation and the attributes being overridden.

Membership: the number of Overrides and Audiences the player or group is included in with the number of keys being overridden.

Delivered settings: the keys being overridden for this group or player.

---

## Rate limits

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/rate-limits

**Contents:**
- Rate limits#

The Lobby service uses rate limits to help control network traffic by restricting the number of requests received by the API within any given second. The following table shows the rate limit for each of the Lobby service’s request types for players and service accounts. Because service accounts are allowed much more control and are likely to be managing multiple lobbies at a time, their rate limits are more relaxed.

Service Account rate limiting is on a per IP adress basis. The number of requests taken in account will be shared if several game servers are hosted on a same machine or if several machines are behind the same NAT gateway.

Service account rate limit

---

## Write configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/write-configuration

**Contents:**
- Write configuration#

Write configurations using different authoring methods.

---

## List of triggers

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/list-of-triggers

**Contents:**
- List of triggers#
  - Server-side triggers list#
  - Client side triggers list#

This is a complete list of all available events that you can bind triggers to. You can get a list of all supported trigger types on the command line client with the showtypes command:

**Examples:**

Example 1 (unknown):
```unknown
cm trigger showtypes
```

Example 2 (unknown):
```unknown
cm trigger showtypes
```

Example 3 (unknown):
```unknown
before-checkin
```

Example 4 (unknown):
```unknown
after-checkin
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/actions

---

## Scaling

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/scaling

**Contents:**
- Scaling#

Relay automatically scales to meet user demands without affecting costs at all. Unity takes full responsibility for maximizing CPU and network usage by performing automatic scaling for users.

Note: There is no logic to reroute allocations to nearby regions with capacity. If there isn’t enough capacity to fulfill a request at the time of an allocation, you must resend the allocation request.

The primary symptom of this occurring is a failed allocation request, in which case, you will need to retry the request. You can retry the request with the same region (there might be more capacity by that point) or with a different nearby region.

---

## Getting Started with Cloud Diagnostics

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/GettingStarted/GettingStartedwithCloudDiagnostics

**Contents:**
- Getting Started with Cloud Diagnostics#
  - Unity plans and Cloud Diagnostics tiers#
  - Basic setup requirements#
    - Key concepts explained#
  - Basic setup of Cloud Diagnostics#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Unity Cloud Diagnostics is a service that collects and reports data about errors (known as crashes or exceptions) in your game. Cloud Diagnostics can also be used to collect player feedback, such as bug reports or feature requests. Cloud Diagnostics connects to your project in the Unity Editor and can be managed from the Unity Dashboard.

The insights from Cloud Diagnostics help you to better diagnose any problems in your game so you can provide a better gameplay experience. Cloud Diagnostics is recommended for both the game development testing cycle and when your app is live.

The following article provides an overview of:

Cloud Diagnostics is a service automatically bundled with your Unity plan, whether you use Unity Personal, Pro, or Plus. Note that while Cloud Diagnostics is available across all Unity plans, feature capacity differs across Unity subscription types. Here’s a breakdown of what’s included with Cloud Diagnostics depending on your Unity plan:

Unity license free to individual users and includes basic access to products and features. Unity Personal includes basic access to Cloud Diagnostics.

25 Crash & Exception reports/day

10 user-generated reports/day

10 MB user-generated reports storage /day

7 days data retention

Unity licenses providing studios with more functionality and resources than the Unity Personal plan. Unity Pro, Enterprise, and Industry all include upgraded access to Cloud Diagnostics.

10,000 Crash & Exception reports/day

1,000 user-generated reports/day

1 GB user-generated reports storage /day

90 days data retention Detailed crash and exception logs Custom crash and exception metadata

To select a subscription or change your Unity plan, go to the Unity Store.

While Cloud Diagnostics is automatically bundled in your Unity plan, there are a few basic requirements you’ll need before setting up Cloud Diagnostics in your project.

To integrate with the Cloud Diagnostics service, you’ll need:

Unity plan: The basic subscription type you’re using with Unity, whether Unity Personal, Pro, Plus or Enterprise. A Unity subscription determines your usage and feature access for the Unity Editor and some Unity Dashboard services.

Unity ID and organization: A Unity ID is used to log in to the Unity Dashboard and an organization is a profile for managing your game development projects, teams, and services on the Dashboard.

Project: A game built in the Unity Editor.

Project ID: A unique identifier for your Unity project that enables use of any Unity Service on the Unity Dashboard for that project.

It’s helpful to view the Unity Editor as where you create your project, and the Unity Dashboard as where you manage your project, organization and its associated services.

To set up Cloud Diagnostics, ensure you have the basic requirements outlined in the section above. Note that you cannot activate Cloud Diagnostics without a project ID linking the service to your project.

To set up Crash and Exception Reporting, go to your project in the Unity Editor and go to Window > General > Services > Cloud Diagnostics. From the Cloud Diagnostics modal, toggle on Crashes and Exceptions. You can manage crash and exception reports and upload debugging symbols from the Unity Dashboard > Cloud Diagnostics page. For more information on setting up Crash and Exception Reporting, go to Setting up Crash and Exception Reporting.

To set up User Reporting, you’ll need to download the User Reporting SDK and integrate the SDK within your project on the Unity Editor. Once integrated, you can manage user report insights from the Unity Dashboard > Cloud Diagnostics page. For more information on setting up User Reporting, go to Setting up User Reporting.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/label

---

## Undo changes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/undo-changes

**Contents:**
- Undo changes#
- Undo a checkout#
- Undo changes#

Undo changes that you've made before you check in the changes.

If you want to unlock a file without checking in any changes, you can undo a checkout. When you undo a checkout, you discard any changes you might have made and remove the lock. To undo a checkout:

Note: To undo a checkout with the command line, run the cm partial undo checkout command.

If you change a file without checking out the file, the file has the status Changed. To discard changes and revert the file back to its original state, right-click the file and select Undo changes.

Note: To undo changes with the command line, run the cm undochange command.

**Examples:**

Example 1 (unknown):
```unknown
cm partial undo checkout
```

Example 2 (unknown):
```unknown
cm undochange
```

---

## Settings

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/settings/settings

**Contents:**
- Settings#

Safety Administrators can customize certain settings for Safe Text to control various aspects related to how the services function.

The various levels of customization are:

Access the Safe Text settings from the Shortcuts sidebar by navigating to Vivox > Safe Text > Settings.

---

## Seat management

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/pricing/seat-management

**Contents:**
- Seat management#
- How seat usage is determined#
- Add or remove seats#
- Assign and unassign seats#
- Additional resources#

A seat represents an individual license to use Unity DevOps.

If you are an administrator or owner of a Unity organization, you can manage your organization seats.

To assign DevOps seats in the Unity Dashboard, go to Version Control > Seats > Cloud.

To manage On-Prem seats, refer to the Unity Version Control On-Prem documentation.

Note: If you increase your seats, the original three seats are still free, you only pay for the additional seats.

If you increase seat count, changes apply immediately, and DevOps bills your account during the current billing cycle.

If you decrease seat count, your account is unaffected until the end of the current billing period.

To add or remove seats for your monthly subscription, any administrator can complete the following steps:

To manage seats, visit the Unity Dashboard and navigate to Version Control > Seats > Cloud.

You can assign and unassign seats for users in your organization.

Note: If you remove a user, they need another invite to rejoin the organization.

To assign seats in your organization:

To unassign seats in your organization:

---

## Multiplay Hosting

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/welcome/

**Contents:**
- Multiplay Hosting#
- Get started#
- Interfaces#

Welcome to Multiplay Hosting, Unity's scalable server hosting platform.

Note: Multiplay Hosting is Unity's self-serve experience for hosting and scaling your game. If you’re using the legacy version of game server hosting, refer to the Clanforge documentation.

Typically, a game developer or studio has expertise in areas directly related to game creation, such as gameplay, animation, and level design. However, successfully managing the hosting and scaling of multiplayer games can be challenging, and time pressures to ship your game. These obstacles can make multiplayer games challenging to implement, especially if you don't have enough servers to meet the player demands. Refer to the Ecosystem overview and Integrations to learn more.

Multiplay Hosting removes the complexity of running and operating infrastructure at scale, so your development team can focus on creating engaging player experiences. It also provides ways for you to:

Use the Get started guide to learn how to start leveraging Multiplay Hosting in your project.

Also check out the following samples to help you get started:

There are multiple ways to integrate and manage your application with Multiplay Hosting:

---

## Smart Locks

**URL:** https://docs.unity.com/devops/en/manual/smart-locks

**Contents:**
- Smart Locks#
- Smart Lock behavior#
- Lock rules#
- Retained locks#
- Destination branch#
- Smart Locks workflow#
  - Create the Lock#
  - Remove the lock#
- Technical considerations#

You can use Smart Locks, also known as exclusive check outs, in Unity Version Control (UVCS) to help you collaborate on projects. When you check out a file, you can lock it to prevent anyone else from modifying the file to avoid conflicts. For example, you can lock non-mergeable assets, such as 3D models, images, or audio files.

For more information, refer to Use Smart Locks.

When you check out a file you have two options: Checkout or Lock and checkout. If a file has existing lock rules, then the normal check out locks the file according to those rules regardless. If there are no existing lock rules and you select Lock and checkout, then UVCS prompts you to create a new lock rule for that context.

A locked file displays a lock icon to indicate that it’s locked. If you try to check out a locked file, a dialog informs you that the file is locked. You can't check out, check in, or merge any files that are locked by another user; whoever has the file locked is the only person who can update it. This prevents multiple users from changing the same file in parallel and ensures that only the latest revision is modified.

To avoid any loss of work, Smart Locks keep track of your repository to ensure that only the latest revision of a file can be locked. This lets you know if the latest revision of a file is on another branch and prevents you from checking out an outdated revision.

The following types of lock rule are available:

For more information, refer to Create lock rules.

When you check in a locked file on a branch that isn't the destination branch, the file status is set to Retained. To unlock the file, you need to merge the change to the destination branch.

If you try to check out a file with a retained lock, Unity Version Control informs you that there is a newer version of the file on another branch. Since retained locks are not held by the specific user who created the lock, any user can check out the latest revision of a file with a retained status.​ To remove the retained status, you can either check out the file from that branch and merge it to the destination branch, or you can contact the lock owner or an admin to remove the lock.

The destination branch is the source of truth when creating a new lock. The default destination branch is /main. If no current revision has the retained status, the revision loaded in the destination branch is considered the latest revision.

You can also set multiple destination branches so that you can lock the same files on different branches at the same time. For example, if the different or unrelated branches need to diverge or specialize:

First, you check out the file and create a lock from the latest revision of a file. The latest revision is either the version in the destination branch or a version with a retained status.

If you don’t make the lock from the latest revision of the file, the checkout operation fails and UVCS displays a message to inform you.

When you complete your changes, either check in the file or merge the changes to the destination branch to release the lock.

If the file was exclusively checked out in a different branch, when you check in the file the lock transitions from Locked to Retained status. You must then merge to the destination branch to remove the lock. While in the Retained status, any user can check out the file and make new changes, as this is now considered the latest revision.

Alternatively, lock owners or admins can manually release or remove the lock.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/get-started

---

## LOCK CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/lock-create

**Contents:**
- LOCK CREATE#
- Description#
  - Usage#
- Help#
  - Remarks#
  - Examples#

Create item locks on a server.

cm lock create | mk <branchspec> <itemspec>[ ...]

cm lock create /main/task@myrep itemid:56@myrep

(Creates a lock for the item id 56 in the branch /main/task@myrep.)

cm lock create br:/main/task item:/workspace/foo.psd item:/workspace/bar.psd

(Creates a lock for the selected item in the branch /main/task.)

**Examples:**

Example 1 (unknown):
```unknown
cm lock create | mk <branchspec> <itemspec>[ ...]
```

Example 2 (unknown):
```unknown
cm lock create /main/task@myrep itemid:56@myrep
```

Example 3 (unknown):
```unknown
cm lock create br:/main/task item:/workspace/foo.psd item:/workspace/bar.psd
```

---

## Unity Authentication

**URL:** https://docs.unity.com/authentication/en/manual/overview

**Contents:**
- Unity Authentication#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users in the unlikely event that Unity takes an action which impacts those end users under the DSA. To comply with this end user notification requirement, we developed a new notification API. If you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you need to integrate the new notification API by the effective date of the DSA, February 17, 2024. The following API is ready for adoption in late January 2024. Please refer to our DSA compliance efforts. Refer to DSA notifications to make your game compliant.

Apps typically need to know player identities to provide features and services to game developers and players that ensure security, consistency, and safety with every interaction.

Unity Authentication offers robust cross-platform account and authentication solutions that support cross-play and progression across all major devices and platforms. You can authenticate your players with anonymous, platform-specific, or custom sign-in solutions, making it easy for games with custom identity solutions to unlock the full power of UGS.

---

## Vivox communications and safety

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/communications-safety

**Contents:**
- Vivox communications and safety#

Unity offers a voice and text communications system with safety by design. Build large 3D worlds with positional voice chat, keep teams connected on non-positional channels, and keep communications safe with built-in features for detecting toxicity or harmful messages. Build a communication system that your players feel safe in.

With Vivox as your communication platform, you can offer cross-platform communications to your players and scale seamlessly as you grow.

Safe Text allows you to customize your players' experience by configuring the chat filter and censoring harmful messages as they occur without having to add any additional code to your project.

The Moderation SDK allows players to report each other, automatically pulling in evidence and analysis to the Moderation Platform for moderators.

---

## C++ integration

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/unreal-engine-sdk/cpp-integration

**Contents:**
- C++ integration#
- Add the Authentication SDK as a dependency#
- Authentication Subsystem#
  - SignInAnonymously#
  - GetUserInfo#
  - DeleteUser#
  - RegisterStateChangedCallback#
  - SignOut#
  - SwitchProfile#
  - ProfileExists#

The following section shows how to integrate with the Authentication SDK using Unreal Engine Subsystems. The Blueprint API provides the Authentication Subsystem to expose this functionality.

Before continuing, add Authentication as a public dependency of your module, then include the plugin header files in your classes.

Add Authentication as a dependency of your module to your Unreal project build file:

Include the plugin header files you wish to access in your own classes:

The Authentication Subsystem contains the interface to communicate with Unity Authentication servers, hold player profile information, and load/unload player preferences from local storage. It’s responsible for handling the authentication lifecycle and storing important authentication information for your project.

You can access the Authentication Subsystem by obtaining a reference from a UGameInstance.

Use the SignInAnonymously()) method to anonymously authenticate. This is a quick way to authenticate without any user information, and requires no interaction with external providers. If successful, this populates the current player profile with the retrieved credentials returned from the Unity Authentication servers.

SignInAnonymously()) takes an FAuthenticationSignInOptions struct as a parameter that changes the way a sign-in is performed. See the Unity API services documentation page for more information about these parameters.

The response from the SDK can be handled in a response handler which needs to take in an FAuthenticationResponse.

Use the GetUserInfo() method to retrieve information about the currently authenticated user. This includes their user Id, authentication timestamps, and any external Identity providers that are linked to their session.

The response from the SDK can be handled in a response handler which needs to take in an FAuthenticationUserResponse.

Use the DeleteUser() method to delete all information related to the currently authenticated player. This method also signs out the player, and deletes all player preferences and profiles connected to the player.

Note: If DeleteUser() Is called while using the default profile, then the profile information is cleared and the profile stays intact.

The response from the SDK can be handled in a response handler which needs to take in a bool: its value is true in case of successful deletion and false otherwise.

Use the RegisterStateChangedCallback() method to assign a callback function that invokes upon the state of the subsystem changing. For instance, the assigned function executes when a player has successfully authenticated and the subsystem state has changed to Authorized.

The response from the SDK can be handled in a response handler which needs to take in an AuthenticationStateChangedResponse.

Use the SignOut() method to sign-out of the currently authenticated player profile. This removes the current player profile and switches to the default profile. This method also has an optional parameter to remove any stored credentials associated with this player.

Note: If SignOut() is called while using the default profile, then the profile information is cleared and the profile stays intact.

Use the SwitchProfile() method to switch to or create a player profile.

Note: SwitchProfile() can only be called while signed-out. If a profile switch is invoked while authenticated, a warning is logged and nothing happens.

Use the ProfileExists() method to check if a given profile exists in the current session.

Note: ProfileExists() cannot detect profiles from previous sessions that have not been re-created in the current session.

Use the GetCurrentProfileName() method to retrieve the name of the current player profile.

Use the GetCurrentProfileName() method to retrieve a list of all player profile names being used in the current session.

Use the RegisterProfileChangedCallback() method to assign a callback function that invokes upon the player profile changing. For instance, the assigned function executes when SwitchProfile has executed successfully.

The response from the SDK can be handled in a response handler which needs to take in an AuthenticationPlayerProfileChangedResponse.

Use the RegisterProfileChangedCallback()) method to assign a callback function that invokes upon a player profile getting removed from the current session. For instance, the assigned function executes when SignOut has executed successfully.

The response from the SDK can be handled in a response handler which needs to take in an AuthenticationPlayerProfileChangedResponse.

Use the IsSignedIn() method to check whether the current player profile is signed-in. Being “Signed-In” is defined as being either Authorized or Expired.

Use the IsAnonymous()) method to check whether the current player profile is signed-in anonymously. This should return true after executing SignInAnonymously successfully.

Use the IsAuthorized() method to check whether the current player profile is signed-in and currently authorized. This should return true after executing any sign-in method successfully while the expiration time has not yet passed.

Use the IsExpired()) method to check whether the current player profile’s session has expired. This should return true when the expiry time returned from a successful sign-in response has passed.

Use the SessionTokenExists() method to check whether a session token exists in player preferences for the current player profile.

Use the GetUnityProjectId() method to retrieve the Unity Project Id associated with the current authentication session.

Use the GetUnityEnvironmentName() method to retrieve the name of the Unity Environment Id associated with the current authentication session.

Use the GetAccessToken() method to retrieve the access token for the current session. If none exists, this returns an empty string.

Use the GetSessionToken() method to retrieve the session token for the current session. If none exists, this returns an empty string.

Use the GetUserId()) method to retrieve the user Id for the current session. If none exists, this returns an empty string.

Note: This is different from the player profile name. The user Id is the unique user identifier returned from the Unity Authentication System.

Use the GetState()) method to retrieve the current state of the authentication session.

Use the SetUnityProjectId() method to set the Unity Project Id for the current authentication session. This overrides the Unity Project Id configured in Project Settings.

Use the SetUnityEnvironmentName() method to set the Unity Environment name for the current authentication session. This overrides the Unity Environment name configured in Project Settings.

**Examples:**

Example 1 (unknown):
```unknown
Authentication
```

Example 2 (unknown):
```unknown
Authentication
```

Example 3 (unknown):
```unknown
PublicDependencyModuleNames.AddRange(new string[] { "Core", "CoreUObject", "Engine", "InputCore", "Authentication" });
```

Example 4 (unknown):
```unknown
PublicDependencyModuleNames.AddRange(new string[] { "Core", "CoreUObject", "Engine", "InputCore", "Authentication" });
```

---

## REMOVE CONTROLLED

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/remove-controlled

**Contents:**
- REMOVE CONTROLLED#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Requirements#
  - Reading input from stdin#
  - Examples#

Deletes a file or directory from version control.

cm remove | rm <item_path>[ ...] [--format=<str_format>] [--errorformat=<str_format>] [--nodisk]

Items are deleted from disk. Removed items are removed from the parent directory in the source code control.

The 'remove' command can read paths from stdin. To do this, pass a single dash "-". Example: cm remove -

Paths will be read until an empty line is entered. This allows you to use pipe to specify which files to remove. Example:

dir /S /B *.c | cm remove -

(In Windows, removes all .c files in the workspace.)

(Removes 'src'. If src is a directory, this is the same as 'cm remove -R src'.)

cm remove c:\workspace\file.txt --format="{0} - REMOVED" --errorformat="{0} - ERROR REMOVING"

(Removes 'file.txt' from version control and from disk, writing "c:\workspace\file.txt - REMOVED" if the operation succeeded, or "c:\workspace\file.txt - ERROR REMOVING" otherwise.)

cm remove c:\workspace\file.txt --nodisk

(Removes 'file.txt' from version control, but keeps it on disk.)

**Examples:**

Example 1 (unknown):
```unknown
cm remove | rm <item_path>[ ...] [--format=<str_format>] [--errorformat=<str_format>] [--nodisk]
```

Example 2 (unknown):
```unknown
dir /S /B *.c | cm remove -
```

Example 3 (unknown):
```unknown
cm remove src
```

Example 4 (unknown):
```unknown
cm remove c:\workspace\file.txt --format="{0} - REMOVED" --errorformat="{0} - ERROR REMOVING"
```

---

## Network configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/network-config

**Contents:**
- Network configuration#

Use the server administration console to configure the ports where the Unity Version Control (UVCS) server listens for both encrypted and non-encrypted data.

Note: Don't forget to click Apply for changes to take effect.

Configure the required values:

---

## Advanced configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/advanced-config

**Contents:**
- Advanced configuration#
- Request processing#
- Global security settings#
- Worker thread pool#
- Buffer pools#
- Trigger variables#

Use the advanced configuration section of the server administration console to customize server features.

This is the thread pool that attends client requests. Each thread is reused for better performance.

Warning: Be aware of potential issues if you modify the thread pool value. For example, if you allocate more threads than your computer can handle (dependent on the number of cores), you can cause a decrease in performance.

Buffer pools reuse pre-allocated buffers to help reduce memory allocations. If you reduce allocations, you can significantly improve performance under heavy load.

In the trigger variables section, you can add the custom global variables that triggers use.

For more information on how triggers work and how to define them, refer to Triggers.

**Examples:**

Example 1 (unknown):
```unknown
ForceBuildNumberMatch
```

Example 2 (unknown):
```unknown
server.conf
```

Example 3 (unknown):
```unknown
AbortRequestIfSocketCloses
```

Example 4 (unknown):
```unknown
server.conf
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/apple-privacy-survey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Matchmaker is available from version 1.1.4.

The following code sample displays the contents of the PrivacyInfo.xcprivacy manifest file for Matchmaker. This file is also available in the Matchmaker SDK version 1.1.4.

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

Example 2 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## Unity Game Overrides

**URL:** https://docs.unity.com/ugs/en-us/manual/game-overrides/manual/overview

**Contents:**
- Unity Game Overrides#
- Additional resources#

Target specific player groups with dynamic configurations across multiple Unity services to enable personalized in-game experiences.

Use Unity Game Overrides to temporarily alter game configurations from other services, creating personalized in-game experiences specifically tailored to different groups of players, called audiences. For example, Game Overrides can suspend settings from Remote Config, Economy, Matchmaker, and Cloud Content Delivery to create unique rulesets around limited-timed events.

Game Overrides uses data from Unity Analytics to define audiences that can be grouped by criteria such as behavior, location, and frequency of gameplay.

With Game Overrides, you can perform the following actions:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-username-password

---

## Relationships

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/relationships

**Contents:**
- Relationships#

The Friends service manages relationships of different types. In general, most user relationships don’t change often; however, there are updates users often want to know about as soon as possible. To increase efficiency, the Friends SDK fetches all of a user’s relationships one time at startup, then keeps the list up to date using push notifications.

A relationship is a status between two users. Some relationship statuses require consent from both users and others only require consent from one user. The Friends SDK automatically groups the different relationships and exposes a collection for each relationship type. The relationship types include friend requests, friends, and blocks.

The Friends service treats all relationships the same. You can use the various properties of each relationship to decide how to treat that relationship. Each relationship has one or more members (players), each of which might have extra properties that identify that member’s role in the relationship. For example, a FRIEND_REQUEST relationship always has two members:

However, the members role changes to NONE when a FRIEND_REQUEST relationship changes to a FRIEND relationship.

The SDK provides some wrapper APIs for specific operations to increase the service’s usability.

For example, when you call the SendFriendRequestAsync method, it calls the CreateRelationship API and creates a new FRIEND_REQUEST relationship with the target user.

If there’s already a FRIEND_REQUEST relationship from the target user, it creates a new FRIEND relationship. Depending on the state, SendFriendRequestAsync can result in a FRIEND_REQUEST or a new FRIEND relationship.

Note: A relationship status is separate from a user's presence status.

When two users have a friend relationship, each user exists on the other user's friends list. This relationship type requires consent from both users, but only one user needs to start the creation of the relationship by sending a friend request.

Two users have a block relationship when one user blocks another user (by adding them to their block list). This relationship type only requires consent from the user performing the block.

**Examples:**

Example 1 (unknown):
```unknown
FRIEND_REQUEST
```

Example 2 (unknown):
```unknown
FRIEND_REQUEST
```

Example 3 (unknown):
```unknown
SendFriendRequestAsync
```

Example 4 (unknown):
```unknown
CreateRelationship
```

---

## 

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/unreal-engine-sdk/overview

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/get-started

**Contents:**
- Get started#
- Install Cloud Save SDK#
- Install Authentication SDK#
- Link your Unity project#
- Call the Cloud Save SDK#
- Cloud Save REST API#
- Additional resources#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

You can install the Package through the Unity Editor.

Navigate to Window > Package Manager and select Unity Registry from the Packages dropdown on the top left. You can either:

Note: The SDK includes code in Samples that shows how to read and write data and files using Cloud Save.

After installation the Cloud Save SDK is available from the Unity.Services.CloudSave namespace:

The Cloud Save package relies on the Authentication package. The Unity Authentication service creates an account to persist player scores where you can use anoynymous sign-in or platform-specific authentication.

The Authentication package is installed as a dependency when you install the Cloud Save package. For information on installing packages manually, refer to Install a package from a registry.

After installation the Authentication SDK is available in Unity scripts from the Unity.Services.Authentication namespace:

Once installed, the Authentication package prompts you to link your Unity project to a Unity Game Services Project ID.

If your project is not linked to a UGS Project ID, or if you want to check what UGS Project ID it is linked to, you can follow these steps to manually link your Unity project to a UGS Project ID:

You must initialize the Cloud Save SDK and its dependencies in a lifecycle callback before use.

This is done by initializing all installed services via the Core SDK by calling await UnityServices.InitializeAsync() from the Unity.Services.Core namespace.

After the SDK initialization is complete, the player is authenticated. The following example uses anonymous authentication to create an anonymous player account. Other methods of authentication are available as outlined in the Unity Authentication documentation.

For more examples of how to use the Cloud Save SDK with Unity, refer to the Unity SDK tutorial.

You can access data in Cloud Save using the REST API.

REST APIs provide more flexibility and allow you to automate your workflows by using your favorite language and game development engine or from a game server.

The Cloud Save service provides the following REST APIs:

The REST API tutorial has information on how to create a token and call the REST API.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.CloudSave
```

Example 2 (unknown):
```unknown
using Unity.Services.CloudSave;
```

Example 3 (unknown):
```unknown
using Unity.Services.CloudSave;
```

Example 4 (unknown):
```unknown
Unity.Services.Authentication
```

---

## Copy custom events to another environment

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/copy-custom-events-to-another-environment

**Contents:**
- Copy custom events to another environment#

You can copy multiple custom events to another environment using the Event Manager.

Note: You cannot copy an event to another environment if the event already exists there.

---

## Chat Channel Sample

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/chat-channel-sample/chat-channel-sample-overview

**Contents:**
- Chat Channel Sample#
- Chat Channel Sample package contents#
- Use the Chat Channel Sample#

The Chat Channel Sample displays how the Vivox SDK can integrate into a Unity game. It demonstrates a game integration with a lobby chat channel, and includes examples of the following Vivox processes and scenarios:

Note: These examples use Vivox APIs, but rely on additional game code.

The Chat Channel Sample system requirements are aligned with the latest Unity system requirements. For more information, refer to the Unity documentation on system requirements.

The Chat Channel Sample package contains a .tgz bundle with the following components:

The Chat Channel Sample system requirements are aligned with the latest Unity system requirements. For more information, refer to the Unity documentation on system requirements.

---

## SYNC

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/sync

**Contents:**
- SYNC#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Synchronize with Git.

cm synchronize | sync <repspec> git [<url> [--user=<usr_name> --pwd=<pwd>]] [(--txtsimilaritypercent | --binsimilaritypercent | --dirsimilaritypercent)=<value>] [--author] [--skipgitlfs] [--gitpushchunk=<value>]

cm sync default@localhost:8087 git git://localhost/repository

**Examples:**

Example 1 (unknown):
```unknown
cm synchronize | sync <repspec> git [<url> [--user=<usr_name> --pwd=<pwd>]] [(--txtsimilaritypercent | --binsimilaritypercent | --dirsimilaritypercent)=<value>] [--author] [--skipgitlfs] [--gitpushchunk=<value>]
```

Example 2 (unknown):
```unknown
cm sync default@localhost:8087 git git://localhost/repository
```

---

## SQL Data Explorer

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/sql-data-explorer

**Contents:**
- SQL Data Explorer#

Use SQL Data Explorer to write and execute read-only SQL queries on your data, plot the results into different types of visualizations, and add those to a dashboard. You can gain insights that might not be visible using other Analytics products.

SQL is a programming language used to communicate with databases. A basic understanding of writing SQL queries is required to use SQL Data Explorer.

NOTE: SQL Data Explorer queries are billable based on query seconds. For more information, see the Analytics billing page. For information about optimizing queries to make the most of your query seconds, see the optimize SQL Data Explorer queries tutorial.

For information about how to build and run queries, see the run a query with SQL Data Explorer tutorial.

---

## GETSTATUS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/getstatus

**Contents:**
- GETSTATUS#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - The output parameters of this command are the following#
    - Where status can take values among the following#
  - Reading input from stdin#
  - Examples#

Gets the status of an item.

cm getstatus | gs <item_path>[ ...] [--format=<str_format>] [--stats] [-R | -r | --recursive]

Output format parameters (--format option): This command accepts a format string to show the output.

The 'getstatus' command can read paths from stdin. To do this, pass a single dash "-". Example:

Paths will be read until an empty line is entered. This allows you to use pipe to specify which paths to get the status for. Example:

dir /S /B *.c | cm getstatus --format="Path {0} Status {1}" -

(In Windows, gets the status of all .c files in the workspace.)

cm getstatus file1.txt file2.txt

(Gets the status of the files.)

cm gs info\ -R --format="The item {0} has the status {1}"

(Gets the status of the directory and all of its items and shows a formatted output.)

**Examples:**

Example 1 (unknown):
```unknown
cm getstatus | gs <item_path>[ ...] [--format=<str_format>] [--stats] [-R | -r | --recursive]
```

Example 2 (unknown):
```unknown
cm getstatus -
```

Example 3 (unknown):
```unknown
dir /S /B *.c | cm getstatus --format="Path {0} Status {1}" -
```

Example 4 (unknown):
```unknown
cm getstatus file1.txt file2.txt
```

---

## WORKSPACE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/workspace

**Contents:**
- WORKSPACE#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to manage workspaces.

cm workspace | wk <command> [options]

cm workspace <command> --usage

cm workspace <command> --help

cm workspace create myWorkspace wk_path

cm workspace delete myWorkspace

**Examples:**

Example 1 (unknown):
```unknown
cm workspace | wk <command> [options]
```

Example 2 (unknown):
```unknown
cm workspace <command> --usage
```

Example 3 (unknown):
```unknown
cm workspace <command> --help
```

Example 4 (unknown):
```unknown
cm workspace create myWorkspace wk_path
```

---

## QUERY

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/query

**Contents:**
- QUERY#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Executes SQL queries. Requires SQL storage.

cm query <sql_command> [--outputfile=<output_file>] [--solveuser=<column_name>[,...]] [--solvepath=<column_name>[,...]] [--columnwidth=<value>] [--nocolumnname] [--columnseparator=<sep>] [--repository=<name>]

This command allows users to execute SQL queries in the server database.

In order to write SQL queries, use these two pre-defined functions to manage users and paths:

Also, you can use options to show query results in a human readable form.

You can use the options '--solveuser=<column_name>' and '--solvepath=<column_name>' to specify columns that query interpreter must convert to a legible text. You can specify more than one column name, comma separated.

cm query "SELECT * FROM revision" --columnwidth=25 --repository=reptest

(Retrieves data from 'revision' table from repository 'reptest'.)

cm query "SELECT b.sname as br_name, o.dtimestamp as date from branch b, object o, seid s where b.iobjid=o.iobjid and o.fidowner=s.iseidid and scode='SolveUser(john)'" --outputfile=query.txt (Outputs into a file the branches with owner 'john'.)

cm query "select r.iobjid, r.fiditem as path, s.scode as username FROM revision r, object o, seid s WHERE r.iobjid=o.iobjid and fidowner=s.iseidid and o.dtimestamp>04/25/2014" \ --solveuser=username --solvepath=path --repository=reptest@server2:9095 (Retrieves selected data from selected repository.)

cm query "SELECT * FROM revision WHERE fiditem=SolvePath(c:\mywkpath\info)"

(Retrieves all revision data of path 'info'.)

**Examples:**

Example 1 (unknown):
```unknown
cm query <sql_command> [--outputfile=<output_file>] [--solveuser=<column_name>[,...]] [--solvepath=<column_name>[,...]] [--columnwidth=<value>] [--nocolumnname] [--columnseparator=<sep>] [--repository=<name>]
```

Example 2 (unknown):
```unknown
cm query "SELECT * FROM revision" --columnwidth=25 --repository=reptest
```

Example 3 (unknown):
```unknown
cm query "SELECT b.sname as br_name, o.dtimestamp as date from branch b, object o, seid s where b.iobjid=o.iobjid and o.fidowner=s.iseidid and scode='SolveUser(john)'" --outputfile=query.txt (Outputs into a file the branches with owner 'john'.)
```

Example 4 (unknown):
```unknown
cm query "select r.iobjid, r.fiditem as path, s.scode as username FROM revision r, object o, seid s WHERE r.iobjid=o.iobjid and fidowner=s.iseidid and o.dtimestamp>04/25/2014" \ --solveuser=username --solvepath=path --repository=reptest@server2:9095 (Retrieves selected data from selected repository.)
```

---

## PARTIAL SHELVESET APPLY

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-shelveset-apply

**Contents:**
- PARTIAL SHELVESET APPLY#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Comparison methods#
  - Examples#

Applies a stored shelveset.

cm partial shelveset apply <sh_spec> [--encoding=<name>] [--comparisonmethod=(ignoreeol | ignorewhitespaces| ignoreeolandwhitespaces | recognizeall)]

The 'partial shelveset apply' command restores the contents of a stored shelveset.

cm partial shelveset apply sh:3

(Applies a stored shelve.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial shelveset apply <sh_spec> [--encoding=<name>] [--comparisonmethod=(ignoreeol | ignorewhitespaces| ignoreeolandwhitespaces | recognizeall)]
```

Example 2 (unknown):
```unknown
cm partial shelveset apply sh:3
```

---

## Configuring User Reporting

**URL:** https://docs.unity.com/cloud-diagnostics/en/manual/UserReporting/ConfiguringUserReporting

**Contents:**
- Configuring User Reporting#
- Create and sending Reports#
- Add metadata#
- Log events#
- Add sampling metrics#
- Add screenshots#
- Add attachments#
- Organize report dimensions#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

The default settings for User Reporting are suitable for normal use, but as your project develops you might want to make changes for specific needs. You might build your own UI that matches your application to introduce custom fields or change the appearance of a user report form. The sample provided in the package is functional, but acts as a starting point.

User reports contain useful information such as metadata, events, sampled metrics, screenshots, and file attachments. For example, you could attach a user’s game save files to their report, or log an event every time the player performs a certain action. You can also sample performance metrics in performance-intensive gameplay situations.

Use the API to configure maximum values of each data type in your report. The UserReportExample file (found in the sample imported into your Unity project) provides a demonstration of the different means of adding data to reports.

For example, you might customize the following settings to limit the maximum of specific data types in a report:

There are no limits to these settings, but if you set higher values the collected data affects the size of your reports. In particular, large high resolution screenshots can quickly increase the size of the report.

To configure User report settings, call the UserReportingService.Instance..Configure(UserReportingClientConfiguration configuration) method:

To create a report, call UserReportingService.Instance.UserReporting.CreateNewUserReport();.

To send a report, call UserReportingService.Instance.SendUserReport(Action<float> progressUpdate, Action<bool> result).

Observe the sample example to best understand action parameters. Sending a report is not required but recommended.

Use metadata to collect specific data for your game which appears with the device metadata included in User Reports by default.

To add custom metadata, call the UserReportingService.Instance.AddMetadata(string name, string value) method.

Adding metadata has negligible impact on performance.

To log custom events, call the UserReportingService.Instance.LogEvent(UserReportEventLevel level, string message) method.

Logging events has a negligible impact on performance.

To add custom sampling metrics, call the UserReportingService.Instance.SampleMetric(string name, double value) method.

The SampleMetric method is designed for you to call every frame with a little impact on performance. However, if you call the above method for every frame, each distinct name can add significant size to the report.

To add screenshots to your report, call the UserReportingService.Instance.TakeScreenshot(int maximumWidth, int maximumHeight) method. Screenshots are viewed as part of the report in the Dashboard.

Optionally you might specify a source for the screenshot, such as a Camera or RenderTexture using UserReportingService.Instance.TakeScreenshot(int maximumWidth, int maximumHeight, object source).

The image is scaled down until it fits within the size defined by the maximumWidth and maximumHeight parameters regardless of source.

When you select a maximum width and maximum height, user reports must be less than 10MB. The last screenshot taken serves as the thumbnail for the report in the Dashboard.

Note: Taking screenshots has an impact on performance. To avoid adverse effects for your users, take screenshots when performance isn't critical, for example if the player is idle.

Add attachments such as video and scene graphs.

Attachments are encoded as Base64 objects.

Use UserReportingService.Instance.AddAttachmentToReport(string title, string filename, byte[] data) to add attachments.

Use dimensions to filter user reports on the Unity Dashboard. You can add dimensions and metrics to your report before sending it by adding items to a dimensions property. Each dimension or metric has a name and a value. You can add a new dimension to your report by calling:

UserReportingService.Instance.AddDimensionValue(string dimension, string value);

For example, see three reports with the following dimensions:

See the following filtering options on the Dashboard:

You can also add different dimensions to different reports. For example, you might only want to add SystemLanguage as a dimension for localized reports.

Users can also add a single hash tag to a report summary. This hashtag appears as a dimension.

For example, the summary "I fell through the floor #FloorBug" appears as:

**Examples:**

Example 1 (unknown):
```unknown
FramesPerMeasure
```

Example 2 (unknown):
```unknown
MaximumMeasureCount
```

Example 3 (unknown):
```unknown
MaximumEventCount
```

Example 4 (unknown):
```unknown
MaximumScreenshotCount
```

---

## Get the player’s score from a Leaderboard version

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-player-score-version

**Contents:**
- Get the player’s score from a Leaderboard version#

Players can get their entry in the specified leaderboard archive version with the GetVersionPlayerScoreAsync method:

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetVersionPlayerScoreOptions configuration object:

For details on how to get available leaderboard version IDs, visit Get available leaderboard version.

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
GetVersionPlayerScoreAsync
```

Example 2 (unknown):
```unknown
public async void GetPlayerVersionScore(string leaderboardId, string versionId)
{
    var scoreResponse = await LeaderboardsService.Instance
        .GetVersionPlayerScoreAsync(leaderboardId, versionId);
    Debug.Log(JsonConvert.SerializeObject(scoreResponse));
}
```

Example 3 (unknown):
```unknown
public async void GetPlayerVersionScore(string leaderboardId, string versionId)
{
    var scoreResponse = await LeaderboardsService.Instance
        .GetVersionPlayerScoreAsync(leaderboardId, versionId);
    Debug.Log(JsonConvert.SerializeObject(scoreResponse));
}
```

Example 4 (unknown):
```unknown
IncludeMetadata
```

---

## Install and upgrade

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/install-and-upgrade

**Contents:**
- Install and upgrade#
- Prerequisites#
- Install the Multiplayer Services package#
- Migrate from UGS SDK#

To start using the Multiplayer Services package, you need to do the following:

Important: If you have already installed one of the Lobby, Matchmaker, Multiplay Hosting or Relay packages, follow the instructions to migrate any UGS SDKs to the Multiplayer Services SDK instead.

Before you continue, make sure you meet the following requirements:

To begin a multiplayer project in Unity using the Multiplayer Services SDK, install the Multiplayer Services package:

You can now start using the Multiplayer Services SDK.

The Multiplayer Services SDK unites the functionality of the standalone SDKs from the following services:

If you're already using any of the SDKs from these individual services in your project but want to move to the unified Multiplayer Services SDK, you must first migrate from the individual services' packages to the Multiplayer Services package. For migration instructions, refer to Migrate to the Multiplayer Services SDK.

**Examples:**

Example 1 (unknown):
```unknown
Universal 3D
```

Example 2 (unknown):
```unknown
Multiplayer Services
```

Example 3 (unknown):
```unknown
com.unity.services.multiplayer
```

---

## Fair usage limits

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/fair-usage-limits

**Contents:**
- Fair usage limits#
- Additional resources#

The fair usage limit sets a specific amount of usage capacity. If you exceed fair usage limits and are a paying Unity Analytics customer, Unity may contact you to discuss reducing usage or accepting special terms. This policy helps prevent abuse of Unity's services by customers performing excessive operations per MAU.

When you surpass the free tier, fair usage limits apply to ensure fairness and reliability. You are notified as you near the following limits:

Note that both valid and invalid events count toward the custom event limit. Make sure your queries are optimized for efficiency, especially when dealing with large datasets. Refer to the UGS SQL Cookbook (GitHub) for guidance. For any other questions or concerns, contact Unity Support or your Unity client partner.

---

## Example triggers

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/tutorials/example-triggers

**Contents:**
- Example triggers#
- Backup trigger#
- Validation triggers#
  - Label validation#
  - Check in validation#
- Web trigger notifications#
  - URI notification#
  - Discord notification#
  - Slack notification#

The following examples show you sample triggers that you can use to optimize your version control workflows.

Create a trigger that fires after setting a workspace selector, located at /home/scripts/plastic-backup at the server, and give it the name backup:

cm trigger create after-setselector backup /home/scripts/plastic-backup

Create a trigger called that fires before a label is created, that calls validate-label.bat at server myserver on port 8084:

cm trigger create before-mklabel "Validate label" "c:\tmp\triggers\validate-label.bat" --server=myserver:8084

Create a trigger that fires before a label is created in repository default and that label starts with bl or fix:

cm trigger create before-mklabel "label-bl-fix" "c:\tmp\triggers\label-bl-fix.bat" --filter="rep:default,bl*,fix*"

Create a trigger that validates check in contents before the check in is actually performed in the repository, on a Windows server:

cm trigger create before-checkin ensure-code-stds "c:\plastic\triggers\checkcode.bat"

Create a web trigger that fires after a check in action is performed, at URI https://www.mysite.com/api/team/checkin and name it Notify team:

cm trigger create after-checkin "Notify team" "webtrigger https://www.mysite.com/api/team/checkin"

A request body example of that web trigger would be as follows:

Create a web trigger that fires after a check in and send notifications from the server to the specified Discord channel:

cm trigger create after-checkin NotifyTeam "webtrigger-discord https://discordapp.com/api/webhooks/<channelId>/<token>" --server=localhost:18084

Create a web trigger that fires after a check in and send notifications from the server to the specified Slack channel:

cm trigger create after-checkin SlackWebTrigger "webtrigger-slack https://slack.com/api/chat.postMessage/<channelId or UserId>/xoxb-SlackBotToken" --server=localhost:18084

**Examples:**

Example 1 (unknown):
```unknown
/home/scripts/plastic-backup
```

Example 2 (unknown):
```unknown
cm trigger create after-setselector backup /home/scripts/plastic-backup
```

Example 3 (unknown):
```unknown
validate-label.bat
```

Example 4 (unknown):
```unknown
cm trigger create before-mklabel "Validate label" "c:\tmp\triggers\validate-label.bat" --server=myserver:8084
```

---

## Create SSL certificates

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/ssl/ssl-certificates

**Contents:**
- Create SSL certificates#
- Create SSL certificates on Windows#
  - Prerequisites#
  - Create a self signed certificate#
  - Create a CA signed certificate#
- Create SSL certificates on Linux and macOS#
  - Prerequisites#
  - Create a self signed certificate#
  - Create a CA signed certificate#
- Additional resources#

Use a self-signed SSL for application development and tests. If you create a certificate, you can avoid the cost of a certificate signed by an external certificate authority. You can create SSL certificates for Windows or Linux and macOS.

For Windows, you need the following tools:

Note: These tools are available in the Windows SDK. For more information, refer to the Microsoft Windows SDK documentation.

makecert (Makecert.exe) is a command line CryptoAPI tool that creates an X.509 certificate signed by a system test root key or another specified key. The certificate binds a certificate name to the public part of the key pair. The certificate saves to a file, a system certificate store, or both. For more information, refer to Microsoft MakeCert documentation.

pvk2pfx (Pvk2Pfx.exe) is a command line tool that transfers public key and private key information contained in .spc, .cer, and .pvk files to a Personal Information Exchange (.pfx) file. For more information, refer to the Microsoft Pvk2Pfx documentation.

Create a .pvk certificate is now ready to be used with the Unity Version Control (UVCS) server.

Note: Name the .pvk, .cer and .pfx files with the machine hostname where the UVCS server is installed. If you don't use the machine hostname, you continuously receive warnings to say that the certificate doesn't match the UVCS server hostname. In the example above, the server is called Tardis, so the resulting output files are labeled as Tardis.pvk, Tardis.cer and Tardis.pfx.

You can use the Certificate Authority (CA) certificate to generate additional SSL certificates for other sites and services such as the UVCS server.

For Linux and macOS, one of the most versatile SSL tools is openssl. This tool is an open-source implementation of the SSL protocol.

openssl is commonly used to create the Certificate Signing Request (CSR) and private key for many different platforms. This tool comes with almost every Linux distribution, so it is usually already installed and ready to use.

Create a .pfx file to use with the Unity Version Control (UVCS) server.

**Examples:**

Example 1 (unknown):
```unknown
makecert -n "CN=TARDIS" -r -a sha1 -sky exchange -sv Tardis.pvk Tardis.cer
```

Example 2 (unknown):
```unknown
pvk2pfx -pvk "Tardis.pvk" -spc "Tardis.cer" -pfx "Tardis.pfx" -pi <password>
```

Example 3 (unknown):
```unknown
makecert -n "CN=My Company" -r -a sha1 -sv MyCompanyCA.pvk MyCompanyCA.cer
```

Example 4 (unknown):
```unknown
makecert -n "CN=TARDIS" -iv MyCompanyCA.pvk -ic MyCompanyCA.cer -sky exchange -a sha1 -pe -sv
    "UvcsServerTardis.pvk" UvcsServerTardis.cer
```

---

## Syntax

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/cm-find-syntax

**Contents:**
- Syntax#
- General syntax#
- Date constants#
- Pagination#
  - Pagination examples#
- Sort#
  - Example sort#
- XML output#

Understand the syntax for your cm find queries.

Refer to the following information on how to format your cm find queries:

The following example shows the general syntax:

To filter by date, use date formats that follow your machine localization settings. For example, if your computer displays dates in the MM-dd-yy format, you can use a date such as 12-31-2021 in your queries.

The following constants are available for you to use to simplify your queries:

The following where clauses are valid for fields of type date:

Note: You can also use the between operator. For example, where date between '3 days ago' and 'one day ago'.

Use pagination to define a limit and an offset to manage the result size and starting point:

Display ten labels, starting from the twenty first, where you're the owner:

Display the first ten branches that you created:

Use the order by clause to sort certain objects by different fields. You can use the keywords asc or desc to sort your results in ascending or descending order, respectively. Dates and changeset IDs sort numerically, and text fields sort alphabetically.

You can sort the following objects by the specified fields:

Find your changesets and order the results by date in descending order:

Find all branches between two dates and sort by the branch name in descending order:

Set the output to XML so that you can save it to a file for later analysis:

**Examples:**

Example 1 (unknown):
```unknown
cm find branch
```

Example 2 (unknown):
```unknown
cm find branches
```

Example 3 (unknown):
```unknown
cm find branches "where owner='pablo' and changesets >= '2013/03/01'"
```

Example 4 (unknown):
```unknown
cm find branches "where owner='pablo' and changesets >= '2013/03/01'"
```

---

## Version Control settings

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/settings

**Contents:**
- Version Control settings#

The Version Control Settings page in the Unity Dashboard lets you view and manage options for your organization and users. From here, you can set up General settings, Lock rules, Integrations, Merge rules, Mergebots, Network allow lists, and Billing.

To view organization settings:

From the General tab you can edit the Organization Name and Description.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/ignore-files

---

## Quality of Service

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/advanced-topics-QoS

**Contents:**
- Quality of Service#
- QoS rules#
  - Relaxations#
- Using Unity QoS SDK#
- QoS considerations#
  - Party matchmaking and QoS#
  - Determine acceptable QoS limits#
  - QoS best practices#
- Additional resources#

Quality of service (QoS) service helps to dynamically determine the available regions where a client would expect to get the best connection for their online session.

Matchmaker allows game clients to provide QoS results information for each player in a matchmaking ticket. The QoS results contain information about the connection quality from the clients to the QoS servers that reside near the game servers that could potentially host a game. The Qos results are defined by region and contain the latency and packet loss ratio values. Matchmaker uses these results to match players together in regions where the connection quality satisfies the requirements of a game.

Note: The QoS results contain server IPs. These IPs are not game server IPs, but QoS server IPs.

QoS rules use the QoS results on a ticket to define what a good connection quality for their match should be.

Consider the following example where the latency of all the players in the match must be under 100:

When using QoS rules, it is important to apply some relaxation to allow matchmaking to happen even if the player population in a region is low.

Consider the following example to relax the latency rule after 30 seconds:

Unity provides an SDK that makes the QoS calculation easier for a fleet. The following code snippets shows how to retrieve QoS results from a game client.

If a Matchmaker for a project supports multiple fleets, then the QoS results on the ticket should only include the QoS from the fleet that is allocated.

For parties where more than one player is on a ticket, several strategies are possible to provide QoS information.

Most real-time games have thresholds for latency and packet loss above which gameplay quality is considered degraded (when gameplay quality is reduced, but is still technically playable) or impossible (when players are unable to maintain connection or the game logic does not function properly). Using QoS results in matchmaking prevents players from playing in regions where QoS is poor.

When determining these limits, remember to consider both the experience of the player with a poor connection and the experience of other players when playing in a game alongside a player that has a poor connection. For example, some game engines provide a reasonably good experience for a player with high latency or packet loss, but to other players, that player might appear to teleport to a degree that makes gameplay with that player impossible. In practice, this means that you have to process the per-region QoS results that are gathered by the client and then filter out the regions that are unacceptable or impossible for them to play in.

Consider the following best practices when you work with the Multiplay Hosting QoS protocol.

**Examples:**

Example 1 (unknown):
```unknown
"MatchRules": [
    {
        "Name": "QoS",
        "Type": "LessThanEqual",
        "Source": "Players.QosResults.Latency",
        "Reference": 100,
        "Not": false,
        "EnableRule": true
    }
]
```

Example 2 (unknown):
```unknown
"MatchRules": [
    {
        "Name": "QoS",
        "Type": "LessThanEqual",
        "Source": "Players.QosResults.Latency",
        "Reference": 100,
        "Not": false,
        "EnableRule": true
    }
]
```

Example 3 (unknown):
```unknown
"MatchRules": [
    {
        "Name": "QoS",
        "Type": "LessThanEqual",
        "Source": "Players.QosResults.Latency",
        "Reference": 100,
        "Not": false,
        "EnableRule": true,
        "Relaxations": [
            {
                "Type": "ReferenceControl.Replace",
                "AgeType": "Oldest",
                "Value": 150,
                "AtSeconds": 30
            }
        ]
    }
]
```

Example 4 (unknown):
```unknown
"MatchRules": [
    {
        "Name": "QoS",
        "Type": "LessThanEqual",
        "Source": "Players.QosResults.Latency",
        "Reference": 100,
        "Not": false,
        "EnableRule": true,
        "Relaxations": [
            {
                "Type": "ReferenceControl.Replace",
                "AgeType": "Oldest",
                "Value": 150,
                "AtSeconds": 30
            }
        ]
    }
]
```

---

## GETCONFIG

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/getconfig

**Contents:**
- GETCONFIG#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Obtains configuration info.

cm getconfig [setfileasreadonly] [location] [extensionworkingmode] [extensionprefix] [defaultrepserver]

cm getconfig setfileasreadonly

**Examples:**

Example 1 (unknown):
```unknown
cm getconfig [setfileasreadonly] [location] [extensionworkingmode] [extensionprefix] [defaultrepserver]
```

Example 2 (unknown):
```unknown
cm getconfig setfileasreadonly
```

---

## Explore your workspace

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/explore-workspace

**Contents:**
- Explore your workspace#
- Show details#
- Manual and Automatic modes#
- File search#
  - Edit files through search#

Learn how you can use the Explore workspaces tab to display and interact with your files.

The Explore workspaces tab displays the files that you have loaded in your workspace. After you configure your workspace, all of your loaded items have a Controlled status, which means that they are under version control.

To hide or display the details view, select Show details. When you select a file, this panel displays a preview or icon of the file, the file details, and the file history.

Gluon has two modes, depending on whether you specify files within the parent folder or select the complete parent folder.

If you select some of the files in a folder, Gluon identifies the folder as in manual mode. If you select the whole folder, Gluon identifies the folder as in automatic mode.

In the Explore workspace tab, you can search through all of the files in your workspace. In the Configuration window, you can also search through files in the repository that you haven’t downloaded to your workspace.

In either the Explore workspace tab or the Configure window, select Search files. In the Explore workspace search, select Include private to get results for files you haven’t added to source control.

To search through files, you can use patterns. For example, * matches any number of characters and ? matches any single character.

You can directly run the following operations from the search results. When you right-click a file in the search results, you have the following options:

---

## FIND

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/find

**Contents:**
- FIND#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - These are some valid output format strings#
    - XML and encoding considerations#
  - Examples#

Runs SQL-like queries to find UVCS objects. For more information about syntax and examples, refer to the cm find documentation.

cm find <object_type> [where <str_conditions>] [on repository '<repspec>' | on repositories '<repspec1>','<repspec2>'[,...]] [order by <sort_field> ['asc' | 'desc']] [[limit <maxresults>] [offset <offset>]] [--format=<str_format>] [--dateformat=<date_format>] [--nototal] [--file=<dump_file>] [--xml] [--encoding=<name>]

If no repository is specified, the search is made on the repository configured in the workspace.

When you run queries using comparison operators (>, <, >=, <=) from the command line, remember that the shell considers these operators as IO redirections. So you will need to enclose the queries in double quotation marks.

The 'cm find' command accepts a format string to show the output. Each output parameter is identified by a string and the user can refer it by typing the parameter number between '{' and '}' brackets. Output parameters usually correspond to the attributes of the object.

When the '--xml' option is specified, the command shows the command result as an XML text in the standard output. The operating system default encoding is used to show the text, so it is possible that not-ANSI characters are incorrectly visualized in the console. If you redirect the command output to a file, it will be correctly visualized. When both '--xml' and '--file' options are specified, the default encoding will be utf-8.

cm find revision "where changeset=23 and owner='maria'"

cm find branch "on repository 'rep1'"

cm find label "on repositories 'rep1', 'rep:default@localhost:8084'"

cm find branch "where parent='br:/main' on repository 'rep1'"

cm find revision "where item='item:.'" --format="{item}#{branch}"

cm find revision "where item='item:.'" --xml --file=c:\queryresults\revs.xml

cm find label "where owner='me' limit 10 offset 20"

cm find branches "where owner='me' order by branchname desc limit 10"

**Examples:**

Example 1 (unknown):
```unknown
cm find <object_type> [where <str_conditions>] [on repository '<repspec>' | on repositories '<repspec1>','<repspec2>'[,...]] [order by <sort_field> ['asc' | 'desc']] [[limit <maxresults>] [offset <offset>]] [--format=<str_format>] [--dateformat=<date_format>] [--nototal] [--file=<dump_file>] [--xml] [--encoding=<name>]
```

Example 2 (unknown):
```unknown
cm find revision
```

Example 3 (unknown):
```unknown
cm find revision "where changeset=23 and owner='maria'"
```

Example 4 (unknown):
```unknown
cm find branch "on repository 'rep1'"
```

---

## Monitor DevOps usage

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/pricing/cost-and-usage-reporting

**Contents:**
- Monitor DevOps usage#
- Cost and usage reporting#
- Unity Version Control storage usage#
  - Monitor project level storage usage#
  - Monitor repository level storage usage#
- Additional resources#

In the Unity Dashboard, the DevOps Overview page displays widgets that show your build usage and your storage usage for the current billing cycle.

Note: The storage usage displays in GB-Hours. You can use 5 GB storage for free, which in a 31-day billing cycle equates to 3720 GB-Hours.

For more detailed usage information, select Usage, which directs you to the Unity Cloud Cost and Usage Reporting page.

The page shows your total usage (current and historical) for products and SKUs. You can select either Cumulative or Daily to view your usage, and choose between two types of graphical representation.

To create the most useful view for understanding your cost trends in the Cost and Usage Reporting view, you can further filter the data:

To view project level storage usage in the Unity Dashboard, select Administration > Cost and usage, and use the Filters menu to filter by project.

To view repository level storage usage in the Unity Dashboard, select the Unity project and navigate to either of the following:

---

## Update your workspace

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/update-workspace

**Contents:**
- Update your workspace#

Before you perform a checkout action on any files, update your workspace to ensure you have the latest revision of the file. If you don’t have the latest revision, Gluon displays an error message that informs you that the file isn’t up to date.

If a file’s status is Out of date, then it means someone else has made changes to that file. You can update your files in two ways:

Note: To update a file with the command line, run the cm partial update command.

**Examples:**

Example 1 (unknown):
```unknown
cm partial update
```

---

## Create merge rules

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/merge-rules

**Contents:**
- Create merge rules#

As an administrator, you can set up conditions that branches must meet to be merged into other branches.

To create a Version Control merge rule in the Unity Dashboard:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/stores-supported

---

## CHECKCONNECTION

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/checkconnection

**Contents:**
- CHECKCONNECTION#
- Description#
  - Usage#
- Help#
  - Remarks#

Checks the connection to the server.

cm checkconnection | cc

**Examples:**

Example 1 (unknown):
```unknown
cm checkconnection | cc
```

---

## Presence

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/presence

**Contents:**
- Presence#

Presence refers to both the availability and activity of a user.

A user's presence availability is the status of a user. The status can be ONLINE, BUSY, AWAY, INVISIBLE, OFFLINE, or UNKNOWN.

A user's presence activity is an object you can use to store user metadata. An example of a user's presence activity might include any recent actions the user performed in your application, such as starting a game match.

---

## PARTIAL UNDOCHECKOUT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-undocheckout

**Contents:**
- PARTIAL UNDOCHECKOUT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Requirements#
  - Examples#

Undoes the checkout on an item.

cm partial undocheckout | unco <item_path>[ ...] [--silent] [--keepchanges | -k]

If an item is checked-out and you do not want to checkin it, you can undo the checkout using this command. Both files and folders can be unchecked out. The item will be updated to the state it had before checking it out.

cm partial undocheckout .

(Undoes checkouts in the current directory.)

cm partial undocheckout pic1.png pic2.png

cm unco c:\workspace\design01.png

(Undoes checkouts of the selected files.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial undocheckout | unco <item_path>[ ...] [--silent] [--keepchanges | -k]
```

Example 2 (unknown):
```unknown
cm partial undocheckout .
```

Example 3 (unknown):
```unknown
cm partial undocheckout pic1.png pic2.png
```

Example 4 (unknown):
```unknown
cm unco c:\workspace\design01.png
```

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/privacy-and-consent

**Contents:**
- Privacy and consent#
- Privacy overview#
- Apple privacy manifest#
- Google Play data safety#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/push

---

## Data Explorer V1 metrics

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/data-explorer-v1

**Contents:**
- Data Explorer V1 metrics#

The metrics available in Data Explorer V1 are:

Events can be further grouped by event parameters. Event parameters are extra information sent with the event.

For example, in a Fruit Machine-like game, spinSummary would be an event, and numberWinningLine would be an event parameter.

Use the aggregate filter based on event counts by the user. "Aggregate by Average" means the average event count across all users. "Aggregate by Max" means the maximum number of events sent by any given user, and so on.

You can summarize your data in a table view. You can select sum or average, which adds a selector, and a new row in the summary table of Data Explorer.

**Examples:**

Example 1 (unknown):
```unknown
transaction
```

Example 2 (unknown):
```unknown
adImpression
```

Example 3 (unknown):
```unknown
transaction
```

Example 4 (unknown):
```unknown
adImpression
```

---

## Data Explorer

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/data-explorer

**Contents:**
- Data Explorer#

Data Explorer is a data analysis tool that you can use to make customized visual representations of your data without SQL queries. You can use Data Explorer to create customized reports to suit your specific analytics needs. For example, you can use these reports to analyze custom events and monitor how your game activity, key metrics, and events change over time.

To view your Data Explorer reports in the Cloud dashboard, select Analytics > Data Explorer. This page shows all of your existing reports. To view or edit a report, select the report name. You can also create a new report from this page.

Note: There's a new version of Data Explorer, which provides you with a new experience and enhanced capabilities. To access Data Explorer V2 from the Unity Dashboard while it's in beta, select Analytics > Data Explorer > Try New Experience. You also have the option to select New Experience when you create a new report.

Data Explorer gives you the ability to filter and use your data based on metrics or events and group them by platform, country, or version. You can query your game data based on predefined metrics or events or event parameters, apply dimension filters, and group by which splits the series into each group in that dimension.

The Data Explorer uses graphs to provide data visualization. You can toggle your data representation between the following types of chart:

A Data Explorer report also contains a summarization table of your queried data. Each column shows the measures you select, grouped by the dimensions you select. The table consists of a static row of data with information related to the aggregation filter that you select from the dropdown: either Total, Average, or Median.

Unity Analytics has the following features:

For information about the exact capabilities of Data Explorer, see the appropriate page for each version:

---

## Setting up Crash and Exception Reporting

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/CrashandExceptionReporting/SettingupCrashandExceptionReporting

**Contents:**
- Setting up Crash and Exception Reporting#
  - Setting up customized reports with Advanced Cloud Diagnostics#
  - Triggering a test report#
  - Viewing your test report#
  - Setting up notifications for new reports#
  - Batch mode support#
  - What’s next?#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Before setting up Crash and Exception reporting for your project, make sure you’ve followed the basic setup requirements outlined in our Getting Started guide. It’s important to have a Project ID to connect the project to the Unity Dashboard. Once your Dashboard is set up with your basic project credentials, you can enable Crash and Exception Reporting for your project in the Unity Editor.

To enable Crash and Exception Reporting:

By default, crash and exception reports are configured with standard metadata such as device OS. With Advanced Cloud Diagnostics, you can also add custom metadata for even more debugging capacity. This custom metadata can be captured at any point, such as when the game first initializes, a new level loads, or even when the player takes a specific action.

Crash and exception reports include a CrashReportHandler class for configuring crash reports and custom metadata. Use the SetUserMetadata method to add up to 64 custom metadata entries to your report.

Request a new piece of metadata to track with this statement:

Test the Cloud Diagnostics service by triggering a report and viewing it within the Unity Dashboard. Create a report by throwing an exception or logging an exception message via the Debug.LogException()method. To do this, locate a method within your C# script where you’d like the test exception to occur, such as the one that runs when the first screen is loaded, and add the following line:

Save the script and run your game in Play Mode. You should be able to view the Debug.LogException message in your console within the Editor.

View Cloud Diagnostic reports from the Unity Dashboard:

Cloud Diagnostics supports report notifications via integration so you can connect your development workflow to non-Unity tools. Instead of manually checking the Dashboard to see if any new problems have been reported, you can instead receive a notification via 3rd party integrations such as email, Slack, Discord, Trello, and more.

To set up report notifications:

Open the Unity Dashboard.

Select your project from the project selector on the top navigation menu.

From the main navigation menu, select Projects.

From the expanded dropdown list, select Project settings > Integrations.

Select the New Integration button and follow the instructions in the pop-up modal.

As of 2018.4.1+ and 2019.1.3+, native crash reporting is now supported when running Unity in -batchmode. Native crash reporting is also supported when running apps as a Server Build. Be sure to specify both -username and -password in the command line when running in batch mode to avoid running into a USYM_UPLOAD_AUTH_TOKEN error.

Now that you’ve enabled Crash and Exception reports, learn how to understand and manage them.

**Examples:**

Example 1 (unknown):
```unknown
UnityEngine.CrashReportHandler.CrashReportHandler.SetUserMetadata(“key”, “value”);
```

Example 2 (unknown):
```unknown
UnityEngine.CrashReportHandler.CrashReportHandler.SetUserMetadata(“key”, “value”);
```

Example 3 (unknown):
```unknown
Debug.LogException(new Exception(“Testing Cloud Diagnostics reports”));
```

Example 4 (unknown):
```unknown
Debug.LogException(new Exception(“Testing Cloud Diagnostics reports”));
```

---

## Migrate to Diagnostics in the Unity Dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/CloudDiagnostics/Migration

**Contents:**
- Migrate to Diagnostics in the Unity Dashboard#
- Migrate from Cloud Diagnostics#

Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity.

In Unity 6.2 and later, the built-in Diagnostics service replaces Cloud Diagnostics for the following services:

User Reporting is available as a separate package that's compatible with Diagnostics in Unity 6.2 and later. For information about installing this package, refer to Unity User Reporting.

To migrate from Cloud Diagnostics to the built-in Diagnostics service in the Unity Dashboard, do the following:

For privacy reasons, Cloud Diagnostics data is retained for only 7 or 90 days, depending on which Unity plan you have. During this retention period, you can access your existing data, and download specific reports in JSON format.

After you upgrade to Unity 6.2 or later, all new diagnostic data is available in the Diagnostics service in the Unity Dashboard.

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/privacy/overview

**Contents:**
- Privacy overview#
- Personal data collected#
  - Developer defines#
- Relationship under privacy laws#
- Legal basis for processing#
- Consent (opt in) vs opt out#
- Data subject requests#
  - Access#
  - Deletion#
- Dependencies#

The Leaderboards service enables game developers to provide ranking of scores to their players. This includes (or will include) a number of specific applications, such as providing a top scorer list, showing scores around a player and player rank, resetting leaderboards (e.g. weekly leaderboards), or tiered/bucketed leaderboards.

Personal data collected about app users/game-players.

Personal data which is always collected in order for product to work:

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are an Independent Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they should do so within their application.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them.

You can action them by using the documented SDK or REST API functions for the Leaderboards service:

This service has native functionality to support data deletion requests.

This can be done using the Leaderboards Admin API: https://services.docs.unity.com/leaderboards-admin/v1/index.html#tag/Leaderboards/operation/deleteLeaderboardPlayerScoreAllLeaderboards

Please note: this functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests. To delete the Player ID created by the Unity Authentication SDK, please use the Authentication API.

This product is dependent on the Unity Authentication service. By using this product, you will also be using the Unity Authentication service and you should refer to the Unity Authentication SDK documentation for more information.

By default, personal data is retained indefinitely – or until a Leaderboard is reset, at which point it will be discarded or archived if archives are enabled. If archives are enabled it will be retained indefinitely.

This service is not intended to be used in applications with child users, unless you, the developer, have obtained Verified Parental Consent where required as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your own privacy policy.

Additionally, you will need to link out to our Privacy Policy from within your own, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## Ignore files

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/ignore-files

**Contents:**
- Ignore files#

When you create a project with Unity Version Control (UVCS), UVCS creates an ignore file. The ignore file contains a default list of file types and paths to exclude from source control.

If there are other files in your project that you want to exclude from the shared repository, you can add them to the ignore file. You can ignore specific file names, whole folders, or all files with a specific extension:

Refer to information on the recommended ignore file configuration for Unity projects.

---

## Unity Gaming Services CLI

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/configuration/cli

**Contents:**
- Unity Gaming Services CLI#
- Prerequisites#
- Using the CLI#
  - Deploy configurations#
  - Retrieve configurations#
  - Environment synchronization#
  - Delete configuration#

You can use the Unity Gaming Services CLI to interact with Leaderboard configurations. The CLI allows you to create, deploy, and manage Leaderboard configurations from the command line.

For a deep dive into the CLI, follow the steps in the Unity Gaming Services CLI Get Started guide.

To follow this guide, you must first complete the following actions:

Refer to the Leaderboards Command Line documentation for a full reference of all commands and options.

Note: The ugs leaderboards command is also available as ugs lb.

Run the new-file command to create a configuration with default content locally:

You can use the Deploy command to promote your local configurations to the remote environment. The local configurations must be deployed to become available to the game client.

To retrieve information about the deployed configurations, run the following command:

You can also list all configurations currently deployed to Leaderboards by running the following command:

You can use the Fetch command to retrieve multiple Leaderboards configurations from remote at once. The provided path is a directory where the configurations will be fetched to:

You can move all your configurations from one environment and deploy them to another environment.

You can then fetch the configurations and deploy them to another environment by running the following commands:

To delete an existing leaderboard, run the following command:

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
ugs leaderboards
```

Example 4 (unknown):
```unknown
ugs leaderboards new-file <file-name>
```

---

## Servers

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/servers

**Contents:**
- Servers#
- Server lifecycles#
- Server density and slots#
- Server readiness#
- Server events, failures, and signals#
- Server logs, files and analytics#

A server is an instance of a build executable process running on a machine within a fleet region. More than one server instance can run per machine, and the number of servers that can run per machine is called the server density. Each server runs in a server slot, which is a slice of machine resources (including the CPU and RAM) that’s loosely reserved for an individual server instance based on the server-density.

Each server has the following information displayed on the Unity Cloud Dashboard:

Explore the following sections to learn more about game servers and how they relate to the rest of the Multiplay Hosting ecosystem.

Game servers have two distinct lifecycles: the server lifecycle and the allocation lifecycle.

Server density refers to the number of server slots that can fit per machine in a fleet. It’s calculated using the machine resources (CPU and RAM) and the fleet usage settings.

Server slots are logical segments of machine resources (CPU and RAM) loosely reserved for instances of a build executable process. Multiplay Hosting uses the server density to calculate the number of server slots during the machine provisioning process. The exact resources allocated per server slot depend on the usage settings you define in the fleet. By default, Multiplay Hosting allows build executable processes to exceed the allocated resources of its server slot by a small margin of tolerance. If the process exceeds this margin of tolerance consistently, Multiplay Hosting considers the server as misbehaving.

Game server readiness refers to whether a build executable process is ready to fulfill an allocation request. The ability to manage server readiness is a feature that enables game servers to let Multiplay Hosting know, and by extension, the matchmaker or service that controls player connections, when they're prepared to accept players and when they're no longer ready to accept players through the Game Server SDK.

Game servers meet many events throughout their lifecycles, including unusual and unexpected events, such as misbehavior and crashes and normal events that occur as part of the server and allocation lifecycles. Multiplay Hosting handles unexpected events, such as failures and exceeding resource allowances, with server signals.

Server files include application-level logging information from your build executable. You can specify where servers save these files through a launch parameter, configuration variable, or both. Multiplay Hosting surfaces files through the Unity Dashboard.

Server analytics include information gathered from the implemented server query protocol (if one exists).

---

## Server analytics

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-analytics

**Contents:**
- Server analytics#
  - Concurrent users#
  - Crashes#
  - Major events#
  - Usage#
  - Server events#
  - Server actions#

Multiplay Hosting tracks specific analytic data for each server. This data includes concurrent users, usages, crashes, and major events. The analytics for servers is similar to the analytics for fleets.

Each analytic data is displayed on the server view of the Unity Dashboard as a graph or chart.

Concurrent users encompasses the number of users connected to a server at a given time. The Concurrent users graph displays the number of live concurrent players connected to the server across time.

Crashes occur when a server within the fleet exits unexpectedly or with an error code. The Crashes graph displays the number of server crashes the server experienced over time.

Major events include servers restarting and servers crashing. Most server events, apart from crashes, are triggered by performing a server action. The major events graph displays the number of major events. The major events graph displays the number of major events.

Server usage is the amount of CPU and memory servers consume, tracked across time. You can view the usage statistics for each server through the Unity Dashboard. The CPU usage is tracked as a percentage of the total CPU power available and the memory is tracked in gigabytes.

Server events include server actions and server failures. The Server events view lists the events associated with the server along with the time stamp of each event and the machine the server was running on at the event time.

Server actions are actions performed on a server, and change the status of the server. These actions are performed automatically by Multiplay Hosting and manually by account users. The actions include:

---

## Write configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/write-configuration

**Contents:**
- Write configuration#

Write configurations using different authoring methods.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/concepts/write-locks

---

## The Sessions Viewer

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/session-viewer

**Contents:**
- The Sessions Viewer#
- Access the Sessions Viewer#
- Additional resources#

Debug active multiplayer sessions in Play Mode by viewing real-time session information in the Unity Editor.

The Sessions Viewer allows users to debug the currently-joined sessions in Play Mode, by displaying the currently active session information.

Note: The Sessions Viewer is a tool built into the Multiplayer Services package.

To open the Sessions Viewer:

If no session has been joined or hosted yet, the window is empty. The window is automatically populated as soon as a session is joined or hosted.

---

## Ways to join a session

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/join-session

**Contents:**
- Ways to join a session#
- Join code#
- Browsing sessions in a list#
- Reconnect to a session#
- Additional resources#

Implement ways for joining multiplayer sessions by entering a join code, browsing available sessions, or reconnecting after a disconnection.

Note: The Multiplayer Services SDK uses sessions to manage groups of players. Sessions relies internally on different combinations of Unity Gaming Services such as Relay, Distributed Authority, Lobby, Matchmaker and Multiplay Hosting, and thus contributes to the billing of those services.

A player can join a previously-created session in the following ways:

A unique and human-friendly join code is generated when a host starts a session. A host can then share this join code with other players to invite them to play the same session. The codes use a combination of letters and numbers and are designed to be short and easy to type or spell out loud.

Refer to JoinSessionByCodeAsync.

You can use a session query to list sessions.

Query results include all non-full, public sessions a player can join. Players can select a session from a list displaying only public properties of the session (such as its name), and join directly by session ID.

Note: You can use queries to discover a session as long as its IsPrivate property is set to false. A session's ID is not the same as its join code.

If a player is disconnected from a session but remains a member of it, they can reconnect to the same session. Implement the following code in your game to handle the cases when a player disconnects.

Note: Reconnection is designed specifically for cases when a user hasn't yet been removed from the session by either the host or the service. If the player has already been removed, then they need to join the session again.

To reconnect a user, do the following:

Fetch all the sessions the current user is part of using GetJoinedSessionIdsAsync:

Note: If a session type was provided when creating and/or joining the session, you have to save the mapping between the session ID and the session type. The Multiplayer SDK does not save this information.

To reconnect to the chosen session, call ReconnectAsync:

You can add a custom network handler implementation to your reconnect request by specifying a ReconnectSessionOptions that uses your own network handler implementation:

**Examples:**

Example 1 (unknown):
```unknown
await MultiplayerService.Instance.JoinSessionByCodeAsync(joinCode);
```

Example 2 (unknown):
```unknown
await MultiplayerService.Instance.JoinSessionByCodeAsync(joinCode);
```

Example 3 (unknown):
```unknown
await MultiplayerService.Instance.QuerySessionsAsync(queryOptions);
```

Example 4 (unknown):
```unknown
await MultiplayerService.Instance.QuerySessionsAsync(queryOptions);
```

---

## LISTUSERS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/listusers

**Contents:**
- LISTUSERS#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Lists users and groups.

cm listusers | lu <repserverspec> [--onlyusers] [--onlygroups] [--filter=<str_filter>]

cm listusers | lu <repserverspec> --group=<group_name>

(Lists all users in the server.)

cm listusers localhost:8084 --onlyusers --filter=m

(Lists only the users in the server that contains "m".)

cm listusers codice@cloud --group=Administrators

(Lists only the users in the group Administrators in the 'codice@cloud' org.)

**Examples:**

Example 1 (unknown):
```unknown
cm listusers | lu <repserverspec> [--onlyusers] [--onlygroups] [--filter=<str_filter>]
```

Example 2 (unknown):
```unknown
cm listusers | lu <repserverspec> --group=<group_name>
```

Example 3 (unknown):
```unknown
cm lu localhost:8084
```

Example 4 (unknown):
```unknown
cm listusers localhost:8084 --onlyusers --filter=m
```

---

## Friends

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/friends

**Contents:**
- Friends#

A friend is a relationship status between two users that requires consent from both users.

From the current user's perspective, a friend is another user on their friends list. A user can become a friend (of the current user) in the following ways:

A friend relationship only lasts while both users consent. The current user can end a friend relationship at any time by:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/how-authentication-works

---

## PROFILE LIST

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/profile-list

**Contents:**
- PROFILE LIST#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Output format parameters (--format option)#
    - The output parameters of this command are the following#
  - Examples#

Lists the server connection profiles configured on the client.

cm profile [list | ls] [--format=<str_format>]

This command accepts a format string to show the output.

(Lists all the profiles using the default format)

cm profile --format="{index,2} {server,-20}"

(Writes the profile index in 2 spaces, aligned to the right, then two blanks, and then the repository server in 20 spaces, aligned to the left.)

cm profile --format="{0,2} {2,-20}" (Writes the same output as the previous example.)

**Examples:**

Example 1 (unknown):
```unknown
cm profile [list | ls] [--format=<str_format>]
```

Example 2 (unknown):
```unknown
cm profile --format="{index,2} {server,-20}"
```

Example 3 (unknown):
```unknown
cm profile --format="{0,2} {2,-20}" (Writes the same output as the previous example.)
```

---

## REPOSITORY CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/repository-create

**Contents:**
- REPOSITORY CREATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Creates a repository on a server.

cm repository | repo <rep_name>

cm repository | repo <repserverspec> <rep_name>[ ...]

cm repository | repo [create | mk] <rep_name>

cm repo 192.168.1.140:8087 Rep01 Rep01/ModuleA Rep01/ModuleB

**Examples:**

Example 1 (unknown):
```unknown
cm repository | repo <rep_name>
```

Example 2 (unknown):
```unknown
cm repository | repo <repserverspec> <rep_name>[ ...]
```

Example 3 (unknown):
```unknown
cm repository | repo [create | mk] <rep_name>
```

Example 4 (unknown):
```unknown
cm repository MyRep
```

---

## Game server lifecycle

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/concepts/server-lifecycle

**Contents:**
- Game server lifecycle#
- Create#
- Start#
- Stop#
  - Internal stops#
    - Intentional exits#
    - Crashes#
  - External stops#
    - Game server misbehavior#
    - Build configuration ID change#

The server lifecycle is the lifecycle of the build executable as a process running on a machine with protected resources. It has three distinct stages:

The beginning and end of the server lifecycle varies depending on the requirements of your game. It might start well before or immediately before the allocation lifecycle, and it can end after each allocation or continue for many allocations.

The first stage of the server lifecycle involves creating a server slot on a machine. The server slot is akin to a placeholder of resources for a build executable to run in. When Multiplay Hosting provisions and starts a machine, it creates a number of server slots based on the server density calculation. The server density calculation finds the number of server slots that can fit on a machine based on the machine’s available resources and the fleet’s usage settings.

The second stage of the server lifecycle involves using information (such as the build and configuration options) to start the build executable (or Docker image) as a process in the server slot created during the first stage.

When the server starts depends on the requirements of your game. It usually starts in response to an allocation request or when Multiplay Hosting provisions a machine (depending on whether you have the start on provision setting enabled for the fleet).

Other situations in which a server starts include:

Note: Using allocation payloads might also change server start behavior.

The third stage of the server lifecycle involves stopping the server build executable process. This can occur in several ways, each triggering different responses from Multiplay Hosting. Both internal and external scenarios can cause a game server to stop and sometimes more than one scenario is involved (such as an exit and a crash).

Internal scenarios are events that originate from the game server itself (the process of the build executable). These scenarios include:

The following diagram illustrates the server lifecycle when an internal scenario triggers a server stop.

An exit refers to an intentional termination of a build executable process with an exit code of 0. When Multiplay Hosting detects that a build executable exits intentionally, it automatically deallocates the server slot, clearing the allocation ID in the server.json file and readying the server slot for the next allocation.

The recommended best practice for most games is to use a matchmaker flow where the build executable process exits after each session. Exiting in this way triggers an automatic deallocation.

A crash refers to an unintentional termination of a build executable process with any exit code other than 0 (opposed to an intentional exit). When Multiplay Hosting detects that a build executable crashed, it attempts to recover the server by restarting it with the same allocation ID. However, if the server continues to crash, Multiplay Hosting won’t keep restarting it. Refer to Crash backoff.

External scenarios are events that originate from an API call or an automated Multiplay Hosting action, either due to a configuration or a response to the game server’s behavior. These scenarios include:

The following diagram illustrates the server lifecycle when an external scenario triggers a server stop.

Misbehavior means something unexpected (other than a crash) happened with the build executable process. Usually, this means the build executable process is using more resources than the server slot allows or isn’t responding to queries for an extended period of time.

Note: Multiplay Hosting only checks if game servers respond to queries if you implement a query protocol in the build and specify it in the build configuration.

Note: If the intention is to manually Stop a currently Allocated server this will not work, instead you should send a Deallocation request.

Multiplay Hosting restarts (stops, then starts) a build executable process if you create an allocation, and Multiplay Hosting selects a server slot that’s using the wrong build configuration (a build configuration other than the one specified in the allocation request). In this case, Multiplay Hosting restarts the build executable with the correct build configuration. Changes to values in a build configuration currently in use by a server may not be reflected immediately. It is recommended that you follow the zero downtime releases model to update your build configurations.

Although there are commonalities between them, not all game servers follow the same lifecycle. The exact behavior depends on how you manage your game sessions. The two most common methods are:

Multi-session allocations is a game session management pattern where you reuse the same allocation for multiple game sessions. In this pattern, you keep game servers allocated between game sessions. Instead of exiting the game server executable between game sessions, you use another form of clean-up, such as resetting the game server state or exiting to a lobby.

Note: The recommended best practice for multi-session allocations is to enable the start on provision setting. This means game servers are ready for allocations when the machine provisioning completes.

The lifecycle of a game server with multi-session allocations uses the following process:

Single-session allocations is a game session management pattern with a one-to-one relationship between game sessions and allocations. In this pattern, you have your build executable exit and deallocate the game server each time a game session ends. Then, you create a new allocation for the next game session.

Note: The recommended best practice for single-session allocations is to disable the start on provision setting. This means game servers don’t start until you allocate them.

The lifecycle of a game server with single-session allocations uses the following process:

Server hold is a server management pattern which allows the server to remain capable of receiving an allocation or executing a reservation for a specified period of time. This is explained in more detail in the server hold section.

**Examples:**

Example 1 (unknown):
```unknown
server.json
```

---

## Edit a custom dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/edit-custom-dashboard

**Contents:**
- Edit a custom dashboard#

To edit your dashboard, select Edit Dashboard in the top right corner of the dashboard.

Once in edit mode, you can perform a number of different operations:

Select Save changes in the top right, to make your changes available on your dashboard.

---

## Google Play data safety section for Relay

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/GoogleDataSafety

**Contents:**
- Google Play data safety section for Relay#
- Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Relay. For your convenience, Friends provides information on its data collection practices in the following sections.

Important: The data disclosures below are for this service only. You are also responsible for providing any additional disclosures for your app, including other third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

Analytics and app functionality

Analytics and app functionality

---

## ACTIVATEUSER

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/activateuser

**Contents:**
- ACTIVATEUSER#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Activates a licensed user.

cm activateuser | au <user-name>[ ...] [--server=<rep-server-spec>]

To activate a user, it must have been previously deactivated. By default, a user is activated the first time they perform a write operation in UVCS. The user is automatically activated only if the maximum number of users has not been exceeded.

(See the 'cm help deactivateuser' command for more information about deactivating UVCS users.)

cm activateuser david "mary collins"

cm au peter --server=localhost:8087

**Examples:**

Example 1 (unknown):
```unknown
cm activateuser | au <user-name>[ ...] [--server=<rep-server-spec>]
```

Example 2 (unknown):
```unknown
cm activateuser john
```

Example 3 (unknown):
```unknown
cm activateuser david "mary collins"
```

Example 4 (unknown):
```unknown
cm au peter --server=localhost:8087
```

---

## Friends sample

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/samples/friends-sample

**Contents:**
- Friends sample#
- Download the sample project#
- Enable the Friends service#
  - Link your Friends project with the Unity Editor#
  - Install the Friends package#
  - Turn Friends on#
- Running the sample in-Editor#
- Drag and dropping the assets into your project#
  - Get the assets#
  - Resolving dependencies#

Before continuing, download and install the Unity Hub and a supported version of the Unity Editor. The Friends service supports the following Unity Editor versions:

Download the Friends sample project from GitHub and open it in a supported version of the Unity Editor. You’ll want to have the sample project open while you enable the Friends service.

Note: You can skip this step if you've already linked your project through the Unity Engine. You can also link your project after enabling the Friends service.

Note: If you meet any conflicts with other services, deactivate the Friends service. You can turn Friends on or off at any time.

Use the following instructions to set the sample up locally:

This sample works as a plug-in to your project. It gets you up and running with Friends in no time at all!

Either drag the entire Assets/FriendsSample/ folder from the sample project into your project, or export the folder as a .unitypackage.

This project depends on two non-standard Unity package dependencies:

For 2020.3, the sample supports Canvas-Style UI and for 2021.1+, the sample supports UIToolkit style UI. Study the sample scenes to view the Hierarchy and general setup. You can also drag the RelationshipsManager into any scene and the UI will display it and work.

At this point, you have the sample project open in the Unity Editor. It’s time to interact with the sample.

Note: If you haven’t already, log into the Unity Editor and link your Unity project before continuing.

The sample project consists of a simple user interface that allows you to interact with the Friends service and perform the following actions:

Use the following table as a reference for the meaning of buttons and user interface elements.

You must start the sample Scene before you can interact with the sample user interface.

After the scene launches, the sample Friends user interface will display.

To test this project alone, you must have the Unity Editor open and a build of the project open.

You can send a friend request to another player using the player’s ID and the Add Friend button.

If a player has blocked you, they will appear as offline to you. If you block a player, they will appear in your block list.

There are two ways to block another player: from your friends list and from your friend request inbox.

Block a player from your friends list:

Block a player who sent you a friend request:

You can view and unblock blocked players in your block list.

You can unblock a player by viewing your block list, then selecting the Unblock button next to the player’s name.

You can remove a friend from your friends list by selecting the Remove friend button next to the player’s name in your friends list.

You can set your presence status by selecting the down arrow next to your current status, then selecting the new status. For example, to change your status from ONLINE to BUSY:

INVISIBLE is a special status, that makes you appear offline to all your friends.

You can set your activity status by selecting the text to the right of the Presence dropdown. For example, you can set custom statuses based on the player's activity in the game they're currently playing.

Note: The Friends service doesn't automatically save presence or activity when the user goes offline. To support persisting the same presence or activity when logging back on, save the presence or activity locally or via a data storage service like Cloud Save.

You can view your friends list by selecting the Friends List button.

You can view your friend request list by selecting the Request list button.

You can view your block list by selecting the Block list button.

**Examples:**

Example 1 (unknown):
```unknown
Assets/FriendsSample/
```

Example 2 (unknown):
```unknown
.unitypackage
```

---

## Friends list

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/friends-list

**Contents:**
- Friends list#

The friends list is a list of users with which the current user has a friend relationship. A user can remove another user from their friends list at any time, ending the friend relationship.

---

## PARTIAL MOVE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-move

**Contents:**
- PARTIAL MOVE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Format#
  - Examples#

Moves or renames a file or directory.

cm partial move | mv <src_path> <dst_path> [--format=<str_format>]

This command moves or renames an item in the repository. Changes are done in the local filesystem too.

If the source path is a file, the destination path can be a file or a directory. In the first case, the file will be renamed; otherwise, the item will be moved.

If source path is a directory, the destination path must be a directory.

The item to move or rename must exist.

cm partial move file.png file-blue.png

cm partial mv .\file-blue.png .\blueFiles

(Moves 'file-blue.png' to 'blueFiles'.)

cm partial move .\design .\marketing

(Renames a directory.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial move | mv <src_path> <dst_path> [--format=<str_format>]
```

Example 2 (unknown):
```unknown
cm partial move file.png file-blue.png
```

Example 3 (unknown):
```unknown
cm partial mv .\file-blue.png .\blueFiles
```

Example 4 (unknown):
```unknown
cm partial move .\design .\marketing
```

---

## CRYPT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/crypt

**Contents:**
- CRYPT#
- Description#
  - Usage#
- Help#
  - Remarks#
  - Examples#

cm crypt <mypassword>

This command encrypts a given password passed as argument. It is designed to encrypt passwords in configuration files and increase safety.

cm crypt dbconfpassword -> ENCRYPTED: encrypteddbconfpassword

(Encrypts the password in the database configuration file: 'db.conf'.)

**Examples:**

Example 1 (unknown):
```unknown
cm crypt <mypassword>
```

Example 2 (unknown):
```unknown
cm crypt dbconfpassword -> ENCRYPTED: encrypteddbconfpassword
```

---

## Relay locations and regions

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/locations-and-regions

**Contents:**
- Relay locations and regions#
- Americas, Europe#
- Asia, Australia#
- How region selection works#
- Fallback for retired regions#

As a developer using Relay, you can allow players to select a Relay server from a list of available regions. By selecting the closest Relay server, the player can minimize the potential latency and guarantee the smoothest possible experience for their game session.

The following table has the Relay regions available across the globe:

Normally, you do not need to specify a region in an allocation request:

Passing an explicit region identifier overrides this behavior. It is recommended you programmatically check this value against the region listing response and not hardcode any values.

You can retrieve a list of all available regions with the Allocations API GET /v1/regions endpoint.

Retired regions are not visible in the regions listing endpoint. Explicit requests to retired regions are automatically redirected to a replacement region; see tables above for mappings.

**Examples:**

Example 1 (unknown):
```unknown
us-central1
```

Example 2 (unknown):
```unknown
southamerica-east1
```

Example 3 (unknown):
```unknown
europe-north1
```

Example 4 (unknown):
```unknown
europe-central2
```

---

## Update files before checkout

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/tutorials/checkout-sample

**Contents:**
- Update files before checkout#
  - Trigger creation command (Windows)#

This sample is a Ruby script that ensures that files are up to date before you check them out.

cm trigger create before-clientcheckout "update before co" "ruby c:\plastic\triggers\update-before-co.rb"

**Examples:**

Example 1 (unknown):
```unknown
#!/usr/bin/ruby

files = ''

STDIN.readlines.each do |line|
  files << " " << line
end

system("cm update #{files}")
```

Example 2 (unknown):
```unknown
#!/usr/bin/ruby

files = ''

STDIN.readlines.each do |line|
  files << " " << line
end

system("cm update #{files}")
```

Example 3 (unknown):
```unknown
cm trigger create before-clientcheckout "update before co" "ruby c:\plastic\triggers\update-before-co.rb"
```

---

## Game Overrides integration with CCD

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDGameOverrides

**Contents:**
- Game Overrides integration with CCD#
- Install the Remote Config package#
- Link your Project ID#
- Create an Override#
- Integrate Remote Config into your game code#
- Retrieve the appropriate assets from CCD#

Game Overrides allow you to target content to specific audiences, for example, by running A/B tests, and customizing content to geographical location and specific periods of time. Badges identify the intended content, and Remote Config tests that content without affecting live players, while also distributing badged content to specific players.

To integrate Game Overrides, complete the following steps:

For information about installing packages, see Package Manager.

These steps may vary depending on which version of the Unity Editor you’re using.

If you haven’t done so already, you must link your Unity project to a Project ID.

To link your project from the Unity Editor:

You can create an Override on the Unity Dashboard either from the Game Overrides service or from the Cloud Content Delivery service. For more information, refer to the Game Overrides Get started page.

Select Products > Game Overrides.You can alternatively navigate to the Overview page by selecting Create Override in the Targeting tab of your bucket in the Cloud Content Delivery service itself.

Select Create Game Override.

Give your Override a name and select Next.

Choose which players to target by specifying a JEXL condition, and then specify what percentage of these players to target. Select Next.

Select + Choose content type, and then select Cloud Content Delivery > Badge. Select Done.

To create an Override by using a regular Remote Config configuration instead of targeting a CCD badge, select Config Overrides. See Remote Config.

Select Choose a bucket, and then pick the bucket you want to use.

Select Choose your badge, and then pick the badge you want to use. Select Choose, then select Next.

Choose the Start and End Date to run your Override. Select Finish.

Select Enable to activate your Override.

The RemoteConfig API is included in the Unity.Services namespace, which you must include in your game script. For more information on its classes and methods, see the Remote Config Scripting API documentation.

The Remote Config service has an accessible RemoteConfigService instance to handle fetching and applying your configuration at runtime. In this example, you use it to fetch the key-value pair for your CCD configuration defined by your Override. The key for this pair is the static string CCD_CONFIG_KEY. You then invoke your ApplyCcdConfig function when the retrieval succeeds. ApplyCcdConfig takes a ConfigResponse struct, which represents the response to a fetch request.

After you have successfully fetched the CCD configuration, you can then extract your bucket information and badge name to retrieve the appropriate assets from CCD.

Start by defining a CcdConfig class.

In your ApplyCcdConfig function, you can then extract these values from the fetched CCD configuration and use them to retrieve the appropriate assets from CCD.

The CCDManager class uses CCD’s client API to fetch the asset. You must attach the CCDManager to a game object in each scene.

If your assets are large, consider fetching them asynchronously.

Your CCDManager class might look something like the following code sample:

You have now successfully retrieved the assets defined by your Override.

**Examples:**

Example 1 (unknown):
```unknown
RemoteConfig
```

Example 2 (unknown):
```unknown
Unity.Services
```

Example 3 (unknown):
```unknown
RemoteConfigService
```

Example 4 (unknown):
```unknown
CCD_CONFIG_KEY
```

---

## Overview of services

**URL:** https://docs.unity.com/ugs-overview/en/manual/unity-gaming-services-home

**Contents:**
    - Unity Gaming Services is an end-to-end platform that is designed to help you build, engage, and grow your game.#
- Overview of services#
- Build your foundation#
  - Accounts#
  - Content management#
  - DevOps#
  - Multiplayer#
- Engage your players#
  - Analytics and player engagement#
  - Communications and Safety#

Take your game to the next level without having to worry about maintaining or scaling your back-end infrastructure. UGS simplifies many game development tasks and challenges. Examples include:

Unity Gaming Services supports your entire development lifecycle. Use them to build your foundation, engage your players, and grow your game.

---

## Virtual shops

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/VirtualShops

**Contents:**
- Virtual shops#
- Prerequisites#
- Overview#
  - Initialization#
  - Functionality#
    - Inventory button#
    - Gain currency debug button#
    - Virtual Purchases#
    - Category buttons#
    - Back button#

Virtual shops are a key feature in most free-to-play games. They allow players to purchase items and exchange resources within the game environment to facilitate the in-game economy. When properly implemented as part of your core game loop, they can drive engagement and provide opportunities for players to express their unique play styles.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

To see this use case in action:

At startup, this scene reads the Remote Config for the Virtual Shops use case sample as well as all required Virtual Purchases. It sets up sprites for all Currency and Inventory Items for use in the Shops display, initializes the Currency HUD with correct values and presents the first Category's Virtual Purchases to the player for purchase.

When the scene loads, the VirtualShopsSceneManager.cs script performs the following initialization tasks:

Initializes Unity Gaming Services.

Signs in the player anonymously using the Authentication service. If you’ve previously initialized any of the other sample scenes, Authentication will use your cached Player ID instead of creating a new one.

Retrieves and updates the player's currency balances from the Economy service.

Queries the Remote Config service to fetch the Virtual Shops configuration data. This includes:

The client updates the shop UI based on the Remote Config data.

The inventory button in the top-right corner opens a pop-up showing all currently-owned inventory items. Use it to confirm that purchased items were added to your inventory appropriately. Note that inventory items appear in random order, so new purchases may appear in the middle of the list.

The +30 Coins button in the top-right corner adds currency for testing purposes.

The shop interface shows the items for sale, along with their respective costs. Click any item to attempt a Virtual Purchase through the Economy service. A pop-up appears to confirm if the purchase succeeded or failed.

Note: Most games will disable buttons for purchases the user cannot afford. However, this sample allows you to attempt all purchases regardless, to facilitate testing how the Economy service verifies Virtual Purchases.

You can change purchase categories by clicking the tabs to the left of the purchase grid. Choose between Currencies, Items, and IAP to display the corresponding list of purchases as specified by the Remote Config JSON.

Note: The IAP category is currently unavailable for this sample.

Pressing the back button in the top-left corner returns you to the Start Here scene.

To replicate this use case, you need the following Unity packages in your project:

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys all the necessary items.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Configure the following resources in the Unity Dashboard:

* This sample uses Addressable Assets to implement the sprite icons for all Economy resources. As the developer, you can add the Addressables address of the icon for each currency directly in the Economy dashboard, and then retrieve it at runtime without needing to change your code. This is helpful if for example, you want to update currency icons by changing the address in your dashboard instead of updating your app. To do this for each resource:

When the client needs to initialize sprites (for example, to display the costs and rewards for each virtual purchase for sale in the shop), the resource’s ID acts as a dictionary key to quickly find the associated spirit. The client calls the AddressablesManager.cs script’s PreloadAllEconomySprites() method at startup to initialize the dictionary with all icon sprites, and the preloadedSpritesByEconomyId dictionary is used to look up Economy IDs to find the associated sprite to use in the shop display.

In addition, configure the following virtual purchases for the shops:

Set up the following config values in the Unity Dashboard:

SHOP_CONFIG JSON values

**Examples:**

Example 1 (unknown):
```unknown
VirtualShopsSample.unity
```

Example 2 (unknown):
```unknown
VirtualShopsSceneManager.cs
```

Example 3 (unknown):
```unknown
Virtual Shop
```

Example 4 (unknown):
```unknown
Deploy Selection
```

---

## Moderation automations

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/automation

**Contents:**
- Moderation automations#
- Set-up automations#
- Calling Moderation APIs#

The Moderation platform can take automatic actions on newly created incident through the use of Unity Cloud Code.

After you set up Moderation automations, the Cloud Code script will execute every time Moderation receives a player report or a text detection

Navigate to Vivox > Safe Voice and Safe Text > Automations in the Unity Dashboard to choose a Cloud Code script to use for automations.

If you haven't yet created an Automation script, select Add/Configure the template to be redirected to Cloud Code to begin the process.

On the Cloud Code page, select Add Script and select the Moderation incidents automation template, which contains examples of how to use the script.

Note that by using this template, Cloud Code will add an event parameter to the script, which will receive the event emitted by Moderation.

If you already have a Cloud Code script or you completed the above flow, return to the Automation setup page in Moderation. Select the pencil icon next to Automation settings to enable the dropdown where you can select your script.

You can call Moderation APIs to perform certain actions in your Automation scripts.

The Moderation incident automation template has an example of how to perform a call to the Moderation API to close an incident. Use this example if you want to automatically close incidents with relatively low impact on your community, so that your moderation team can focus on high impact incidents.

You must create a service account in order to send calls to the Moderation API through Cloud Code.

Assign the Multiplayer > Safety Admin role to your service account to authorize the service account to call Moderation APIs.

To see the list of available API, refer to the moderation service web api docs

---

## Host migration

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/host-migration

**Contents:**
- Host migration#
- Migration data#
- Migration data flow#

Host migration is the act of transferring the lobby host role from one player to another.

This process can occur in the following scenarios:

In the scenarios where the host does not specify a new host, the new host is selected randomly from the other players who are currently in the lobby.

Note: If the host is removed due to inactivity, the underlying relay connection is destroyed. To continue receiving automatic disconnects, the new host must create a new relay, and then have the other players join it and set their Allocation ID/ Connection info per the instructions in the Relay integrations section.

Host migration data facilitates the transfer of binary game data during host migration events in a lobby. The migration data flow uses the migrationdatainfo endpoint to provide secure, pre-signed URLs for both retrieving and storing binary migration data.

These URLS have the following characteristics:

Remember to keep migration data compact by only including essential data needed for seamless host transitions, and by avoiding the inclusion of sensitive player information.

At any time, hosts can request the migration data information and use the URLs to manage binary game data in Lobby:

Note: Implement data validation to verify data integrity after download and before upload.

This approach ensures data integrity and provides a reliable mechanism for preserving lobby state during host transitions. Include version information to handle compatibility between different game versions, as well as retry logic and fallback mechanisms for network failures.

Important: If the URLs expire, call migrationdatainfo again to obtain new URLs. Always check response status codes and handle expired URL scenarios.

Note: The binary data format is entirely controlled by your application. Unity Lobby service treats the migration data as opaque binary content and does not validate or modify the data structure.

**Examples:**

Example 1 (unknown):
```unknown
UpdateLobby
```

Example 2 (unknown):
```unknown
migrationdatainfo
```

Example 3 (unknown):
```unknown
content-type
```

Example 4 (unknown):
```unknown
application/octet-stream
```

---

## Add an inventory item to your game

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/add-inventory-item

**Contents:**
- Add an inventory item to your game#
- Additional resources#

The following instructions describe how to add an inventory item to your game’s economy system.

The new inventory item now appears on the Configuration page of Economy.

---

## Manage users

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/users-settings

**Contents:**
- Manage users#
- Unity organization permissions#
- Version control user permissions#
  - View user permissions#
  - Manage DevOps seats#

In the Unity Dashboard, you can edit user permissions for Unity Version Control.

You can edit user types and roles on for your Unity organization. For more information, refer to the following resources:

If you have an owner or manager user type, you can configure item-level (files, attributes, etc.) and repository-level permissions per user.

To view user permissions from the Unity Dashboard:

You can manage DevOps seats from DevOps > Version Control > Seats, where you can view, assign, and un-assign DevOps seats for Unity organization members, including project guests.

---

## Plugins for Unity Version Control (UVCS)

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/vcs-plugins

**Contents:**
- Plugins for Unity Version Control (UVCS)#
- Officially supported plugins for Unity Version Control#
  - Game Engines#
    - Unity#
    - Unreal#
  - IDEs#
    - Visual Studio#
    - Visual Studio Code (VSCode)#
    - IntelliJ IDE#
  - CI/CD#

Unity Version Control (formerly Plastic SCM) has a wide set of plugins ready to connect to different tools and services.

Please find all the information here.

Please find all the information here.

Please find all the information here.

UVCS versions and patches after January 9th don't include support for this plugin. For more information, submit a ticket or send an email to devops-vcs-support@unity3d.com.

Please find all the information here.

Please find all the information here.

Please find all the information here.

Please find all the information here.

Please find all the information here.

Please find all the information here.

Please find all the information here.

UVCS versions and patches after January 9th don't include support for this extension. For more information, submit a ticket or send an email to devops-vcs-support@unity3d.com.

The following plugins are discontinued and not officially supported.

---

## Push submodules to UVCS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gitserver/gitserver-submodules

**Contents:**
- Push submodules to UVCS#
- Customize GitHub submodule mappings to UVCS Xlinks#
- Skip GitHub submodules#

Push GitHub submodules to your Unity Version Control (UVCS) server. When you push a GitHub submodule, GitServer translates them into UVCS Xlinks.

If you push GitHub changes to GitServer, the operation can fail if submodules point to GitHub repositories that Gitserver doesn’t know how to resolve:

In this case, there's a submodule that points to a repository called mduem that GitServer doesn't find as a valid UVCS repository. To solve the issue, create a repository named mduem in UVCS and push the submodule repository to Gitserver:

In this case, the Git submodule definition is as follows:

To customize the mapping between the GitHub submodule and the UVCS Xlink, add the following entry to the gitserver.conf file:

This example means that the mduem repository translates to mduem-xlinked in UVCS.

To skip GitHub submodules so that they don’t map to a UVCS repository, edit your gitserver.conf files as follows:

You can add as many ignore.submoduleUrl entries as you need.

**Examples:**

Example 1 (unknown):
```unknown
>git push --all git://localhost/default
Counting objects: 143, done.
Writing objects: 100% (143/143), 106.43 KiB | 0 bytes/s, done.
Total 143 (delta 0), reused 143 (delta 0)
error: invalid ref status from remote: The specified repository couldn't be found: mduem.
To git://localhost/default
 ! [remote failure]  master -> master (remote failed to report status)
error: failed to push some refs to 'git://localhost/default'
```

Example 2 (unknown):
```unknown
>git push --all git://localhost/default
Counting objects: 143, done.
Writing objects: 100% (143/143), 106.43 KiB | 0 bytes/s, done.
Total 143 (delta 0), reused 143 (delta 0)
error: invalid ref status from remote: The specified repository couldn't be found: mduem.
To git://localhost/default
 ! [remote failure]  master -> master (remote failed to report status)
error: failed to push some refs to 'git://localhost/default'
```

Example 3 (unknown):
```unknown
>cm repository create mduem
```

Example 4 (unknown):
```unknown
>cm repository create mduem
```

---

## Matchmaking into a session

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/matchmake-session

**Contents:**
- Matchmaking into a session#
- Find a session with Quick Join using Unity Lobby service#
- Find a session using Unity Matchmaker service#
  - Network choice when matchmaking#
  - Cancel matchmaking#
  - Matchmaking results#
- Additional resources#

Find and join the most suitable multiplayer sessions for a given player.

Matchmaking uses a set of parameters to find and connect players to the most suitable session. The Multiplayer Services SDK supports two ways to find a session:

Use the Lobby service to have a player randomly join any session that's compatible with the parameters and filters passed to the MatchmakeSessionAsync method.

The following example demonstrates how to find and join a session in a single operation:

This code tries to join a session that has at least 1 available slot and the property map 1. MatchmakeSessionAsync continues searching for a session until the set timeout of 5 seconds is reached.

At this point, if the player can't join a session for any reason, such as all available sessions being full, the quick join operation can optionally create a new session using the CreateSession parameter. Note that the new session is only created after the set timeout has expired, if set.

When the quick join operation finds or creates a session, it configures networking to use Relay connections.

Use the Unity Matchmaker service to have a player join the best-suited session using more advanced rules.

Note: Unity Matchmaker is offered free of charge when you're using Multiplay Hosting or a client-hosted solution provided by Unity (Relay and [Distributed Authority]).

Matches can be tuned for network quality using Quality of Service (QoS) rules on the pool configuration. This type of rule ensures that players in the match do not exceed a specified latency to the host or server. For a given match, these rules also select the most suitable region in which to allocate a server or relay.

Note: The Multiplayer Services SDK automatically performs QoS measurements, and includes the results with the matchmaking request.

The following example demonstrates how to find and join a session using Matchmaker:

For Matchmaker to find a session for the player, the user is expected to configure the matchmaking rules.

Note: To test this code, create a queue named Friendly and use the default pool.

If the player wants to stop the matchmaking process, use the following code:

This indicates to the Multiplayer Services SDK to delete the matchmaking ticket that was sent in the background to the service, and stop the search for a session.

The session also provides access to the Matchmaking Results with the information about the match and the players that are going to connect to the session (their teams and their data).

Some information, such as team breakdown and custom ticket data, is only available through matchmaking results. The results also include the list of expected players, which is handy as it is available immediately and authoritatively before the players join the session and connect.

You can access the matchmaking results with the following code:

**Examples:**

Example 1 (unknown):
```unknown
MatchmakeSessionAsync
```

Example 2 (unknown):
```unknown
var quickJoinOptions = new QuickJoinOptions()
{
    Filters = new List<FilterOption>
    {
        new(FilterField.AvailableSlots, "1", FilterOperation.GreaterOrEqual),
        new (FilterField.StringIndex1, "map 1", FilterOperation.Equal)
    },
    Timeout = TimeSpan.FromSeconds(5),
    CreateSession = true
};

var sessionOptions = new SessionOptions()
{
    MaxPlayers = 2,
    Type = "Session",
}.WithRelayNetwork();

ISession session = await MultiplayerService.Instance.MatchmakeSessionAsync(quickJoinOptions, sessionOptions);
```

Example 3 (unknown):
```unknown
var quickJoinOptions = new QuickJoinOptions()
{
    Filters = new List<FilterOption>
    {
        new(FilterField.AvailableSlots, "1", FilterOperation.GreaterOrEqual),
        new (FilterField.StringIndex1, "map 1", FilterOperation.Equal)
    },
    Timeout = TimeSpan.FromSeconds(5),
    CreateSession = true
};

var sessionOptions = new SessionOptions()
{
    MaxPlayers = 2,
    Type = "Session",
}.WithRelayNetwork();

ISession session = await MultiplayerService.Instance.MatchmakeSessionAsync(quickJoinOptions, sessionOptions);
```

Example 4 (unknown):
```unknown
MatchmakeSessionAsync
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/overview-and-community-health

---

## Integrate with Unity Editor

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/configuration/unity-editor

**Contents:**
- Integrate with Unity Editor#
- Prerequisites#
  - Link project#
  - Install required packages#
- Authoring within the Unity Editor#
  - Create a configuration#
  - Edit a configuration#
  - Deploy a configuration#
- Deployment window#

The Leaderboards Authoring module (installed with the Leaderboards package) allows you to optionally author and modify Leaderboards configurations directly within the Unity Editor. You can then upload leaderboards from the Unity Editor to the Dashboard by using the Deployment package.

Authoring of Leaderboards configurations in the Unity Editor is only supported in Unity 2021.3 and above.

Leaderboards configurations existing in the Unity Editor allow users to treat their source control as the single source of truth (instead of the version in the cloud), simplifying actions such as rollbacks, bisection, and other common operations. For example, the Leaderboards Authoring module facilitates tasks like keeping client configurations in sync with remote configurations.

To use Leaderboards configurations in the Unity Editor, you must first install the Leaderboards SDK and link your Unity Gaming Services project to the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

To create Leaderboards configurations within the Editor, you must install the following packages:

Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

To install these packages and add them to your list of available packages:

The Leaderboards Authoring module allows you to create, edit, and deploy Leaderboards configurations directly within the Unity Editor.

Follow these steps to create a Leaderboards configuration using the Leaderboards Authoring module:

The new configuration is now visible in the Project window, and in the Deployment window, accessible by selecting Window > Deployment.

For more information on how to create and modify Leaderboards configurations, refer to Leaderboard assets.

To edit an existing Leaderboards configuration, double-click the configuration in the Project window. Leaderboards configurations are in .json format and use the .lb file extension.

You can deploy a configuration through the Deployment window. For more information, refer to Deployment package.

The Deployment window is a core feature of the Deployment package. It allows all services to have a single cohesive interface for deployment needs, and allows you to upload cloud assets to their respective cloud services.

For more information, refer to Deployment package.

**Examples:**

Example 1 (unknown):
```unknown
UnityEditor.CloudProjectSettings.projectId
```

Example 2 (unknown):
```unknown
com.unity.services.deployment
```

Example 3 (unknown):
```unknown
com.unity.services.leaderboards
```

---

## Stores

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/stores

**Contents:**
- Stores#
- Store extensions#
- Fake Store#

A store is a digital distribution platform where users purchase products for your application, such as the Apple App Store or the Google Play Store.

It is important to distinguish between a digital distribution platform and Unity's own store implementation. The digital distribution platform is the external service (for example, Google Play), while the Unity IAP store implementation is the code within the IAP package that communicates with that platform's purchasing APIs.

Some stores provide features that go beyond the standard cross-platform purchase flow. Unity IAP makes these features available through store extensions, which your application can access after Unity IAP initializes successfully.

For a list of store extension properties, refer to Properties.

The Fake Store is a mock store in the Unity Editor.It simulates real app store behavior, including successful purchases and failed transactions. Use the Fake Store to test your IAP implementation without building to a device. This helps you quickly check your IAP logic during development.

---

## UGS Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/overview/manual/release-notes

**Contents:**
- UGS Release Notes#
    - How to access the latest package features#
- August 2025#
  - In-App Purchasing SDK 5.0.1#
    - Changed#
    - Fixed#
  - In-App Purchasing SDK 5.0.0#
    - Added#
    - Fixed#
    - Changed#

Please follow the installation instructions to upgrade your packages. If you don't see a package's latest version available in the Editor, make sure you update to the latest LTS or Tech Stream release.

Some new features are pre-releases; these are identified with the pre tag. Learn more about working with Pre-release packages.

-Tentative fix to dotnet hang -Changed exit condition , it seems only indefinite wait for exit will always work

Added: Implementations to the Deployment API DeploymentWindow.

Added: Ability to copy text straight from the Deployment details pane.

Added: View in Deployment Window button in .ddef file.

Fixed: Issue where the status panel had an excessively large initial size.

Fixed: Issue where relative paths were not supported in the ExcludePaths of the Deployment Definitions.

Fixed: Issue where placeholder text was displayed in an item's status field on tab switch.

Fixed: Issue where progress bars could disappear on tab switch.

Fixed: Issue where the GUI state of dragline position + pane size was not persisted between window instances and resulted in an unwanted state upon opening the window.

Added: DeploymentWindow API which allows easy interaction with the Deployment Window and its operations. This API is leveraged by new UIs in the supported packages.

Fixed: SetStatusSeverity was flipping message and detail.

Fixed: Made main operations of Deployment Window publicly available.

Fixed: Added auxiliary interfaces and classes for CLI interoperability.

Added: View in Deployment Window button in .ccmr and .js files, dependent on Deployment package version 1.4.0.

Added: View in Dashboard button in inspector for .ccmr and .js files.

Added: View in Dashboard context menu in Deployment Window for .ccmr and .js files.

Added: Open Solution button to .ccmr inspector.

Added: Enum support for Cloud Code Bindings generation.

Fixed: Support for various primitive types in Cloud Code Modules binding generation.

Fixed: In-script parameters analysis throws an exception in Unity 6.

Fixed: Browse... button in .ccmr inspector now opens the current solution folder properly.

Fixed: Cloud Code Binding generation of primitive types.

Fixed: Binding Generation attempts to run in the latest available runtime. This can be disabled with CLOUD_CODE_AUTHORING_DISABLE_VERSION_DETECT flag.

Fixed: Compatibility with Deployment 1.3.

Added: Package released out of experimental

Changed: Moved functionality from multiple services under the ENABLE_SERVICES_EXPERIMENTAL_APIS define symbol

Fixed: Deserialization error in Observability GetLogs function

Added: API to interact with Admin API

Added: API to interact with deployment capabilities

Changed: Made upload more robust in some cases of partial success

Fixed: Issue where gsh deploy upload may fail in some cases. A partial upload would not be retried and a subsequent build version would fail to be created

Fixed: With the upload command. It would not wait for sync if there was nothing to do.

Added: [Game Server Hosting] Added support for Google Cloud Storage (GCS) as a source for Builds and Build Configurations.

Changed: [Game Server Hosting] Mark options: --speed, --cores and --memory for CREATE and UPDATE of gsh build configuration as deprecated to allow for backwards compatibility.

Changed: New usage should be set on the fleet using server density configuration

Fixed: [Remote Config] Fixed import and export on an empty environment.

Fixed: [Cloud Content Delivery] Now normalizing the path to always use forward slashes even on windows platform.

Added: Adding the ability to update the session published port (NetworkConfiguration.UpdatePublishPort) to enable auto-port selection in network handlers.

Added: View in Deployment Window button for Multiplay Hosting and Matchmaker config as code resource files, dependent on Deployment package version 1.4.0.

Changed: Updating direct network options default values: listenIp and publishIp default to 127.0.0.1, port defaults to zero

Changed: Updating network support in sessions for netcode for entities to version 1.3.0-pre.2.

Changed: Updating network support in sessions for netcode for game objects v2 to version 2.0.0-pre.1 (required for distributed authority)

Fixed: Fix issue where gsh deploy upload may fail in some cases

Added: Google Play- IGooglePlayStoreExtensions.GetObfuscatedAccountId(Product product) has been added to obtain the obfuscated account ID of the purchase set with IGooglePlayConfiguration.SetObfuscatedAccountId.

Added: Google Play- IGooglePlayStoreExtensions.GetObfuscatedProfileId(Product product) has been added to obtain the obfuscated profile ID of the purchase set with IGooglePlayConfiguration.SetObfuscatedProfileId.

Added: Apple - Added visionOS support

Changed: Google Play- Billing Library updated to 6.2.1 (was previously 5.2.1). No new feature support was added. Subscriptions must still have only 1 base plan.

Changed: Google Play- Dependencies are now injected in the gradle files. The Billing aar is no longer included.

Changed: Google Play- Updated the internal implementation to use productDetails instead of skuDetails to solve the setOfferToken warning issued by Google.

Changed: Google Play- IGooglePlayStoreExtensions.GetPurchaseState(Product product) has been updated to use the getPurchaseState() instead of getOriginalJson(). This change will make the purchase state more reliable.

Changed: Google Play- IGooglePlayStoreExtensions.ConfirmSubscriptionPriceChange has been marked [Obsolete] as it is no longer supported since Google Play Billing Library 6.0.0. For alternatives, see the price changes guide.

Changed: Google Play- IStoreListener.OnInitializeFailed for InitializationFailureReason.PurchasingUnavailable will now return the BillingResponseCode when product retrieval is successful, but an error occured and no products were returned.

Changed: Apple - Retrieved purchases from the store will be considered as appleProductIsRestored.

Changed: Apple - Product.appleProductIsRestored will no longer be sent to ProcessPurchase since they have already been processed.

Changed: Apple - The changes above will improve Analytics data by avoiding duplicate purchase events.

Changed: Upgraded com.unity.services.core from 1.8.2 to 1.12.5 to include their Apple privacy manifest.

Fixed: Fixed OnPurchaseFailed - It now returns the productId (previously the transactionId) in the PurchaseFailureDescription when the product isn't available for purchase.

Fixed: Fixed a NullReferenceException when retrieving products on Unity Engine 2020.

Fixed: Google Play- Fixed errors related to CloneReference on Unity Engine 2021.1.

Fixed: Google Play- Fixed an issue where dependencies were added after dependency resolution happened resulting in an error.

Fixed: Google Play- Fixed Product.receipt's price_amount_micros returning the price instead of the price in micro-units.

Fixed: Google Play- Fixed NullReferenceException occurring when retrieving products on Unity Engine 2021.2 and earlier.

Fixed: Google Play- Fixed OnProductReceived callback not being fired with an invalid ProductID.

Fixed: Google Play- Fixed an issue that happens on Windows when disabling the IAP Dependencies.

Fixed: Google Play- Fixed an InvalidOperationException that could occur when obtaining purchases. (Since Unity IAP 4.6.0)

Removed: Google Play- The iconUrl and skuDetailsToken sub-entry to the Product.receipt's "Payload"'s "skuDetails" will now return an empty string since they are no longer supported.

Removed: Removed unnecessary Android dependency, androidx.activity:activity-compose:1.3.1, which could cause conflicts with other plugins.

Added: Cloud Save module service commands. Run ugs cloud-save -h to show usage.

Added: Support for Matchmaker to Deploy and Fetch.

Fixed: Now supporting multiple entries on --services and --key options.

Fixed: Cloud Content Delivery issue of content upload failure or timeouts for large files.

Added: A MessageBytesReceived callback has been added to the available subscription event callbacks

Added: Service registration to the core services registry

Added: Service access through the core services registry (UnityServices.Instance.GetCloudCodeService())

Added: A button to browse your files when choosing a path for a Cloud Code Module

Changed: The MessageReceived callback will no longer be fired upon receiving bytes via the event subscription

Fixed: Bindings generation is broken when ILogger dependency injection is used

Fixed: Cloud Code modules now cleans up compilation artifacts after deploying or generating bindings

Fixed: Cloud Code runtime timeout increased to 30 seconds

Fixed: Moved create Cloud Code Asset menu items under "Services"

Added: Support for services instances and global point of access.

Added: Apple privacy manifest to comply with Apple's new privacy requirements. More details on how the Unity Engine supports this can be found here.

Changed: Upgraded com.unity.services.core from 1.12.0 to 1.12.5 to include their Apple privacy manifest.

Changed: Upgraded com.unity.services.authentication from 3.1.0 to 3.3.1 to include their Apple privacy manifest.

Added: Apple privacy manifest to comply with Apple's new privacy requirements. More details on how the Unity Engine supports this can be found here.

Changed: Upgraded com.unity.services.core from 1.9.0 to 1.12.5 to include their Apple privacy manifest.

Changed: Upgraded com.unity.services.authentication from 2.5.0 to 3.3.1 to include their Apple privacy manifest.

Added: Apple privacy manifest file (PrivacyInfo.xcprivacy).

Fixed: Issue with the optional FEATURE_SERVICES_INSTANCES preprocessor define.

Fixed: Improved Cloud Code script in-script parameter wrong argument type parsing error.

Fixed: Cloud Content Delivery Module Service commands. Run ugs ccd -h to show usage.

Changed: The env list command now outputs as a table.

Added: Support for running different profiles when using Multiplayer Play Mode.

Added: Apple Privacy Manifest.

Fixed: AuthenticationState is left in invalid state when event handlers of PlayerID, AccessToken or SessionToken throw exceptions.

Fixed: NullReferenceException in Player Accounts SDK if not properly set up and the application received a deep-link request.

Changed: The use cases are now compatible with the Deployment package and can deploy most of their service configuration using the Deployment window.

Changed: Reverted project to be on 2021.3 by default so that we enable an easier compatibility with all current LTS version.

Changed: Removed CCD addressable features and the Over the Air Content use case. Addressables and CCD are demonstrated in a number of other samples already.

Changed: Removed Ads features and the Ads use case. Ads are demonstrated in a number of other samples already.

Fixed: Battle Pass README had the incorrect key name for its virtual purchase. The correct key name is BATTLE_PASS_PURCHASE.

Fixed: Battle Pass README didn't list the entire Game Override content for the BATTLE_PASS_REWARDS_FREE and BATTLE_PASS_REWARDS_PREMIUM keys. That has been added in separate Game Overrides documentation files.

Fixed: Seasonal Events README had the wrong name for its Cloud Code scripts. Both should start with the prefix SeasonalEvents_.

Fixed: Removed legacy fields that prevented remote config from being parsed.

Fixed: WebGL compatibility issues with Cloud Code and the Virtual Shop.

Added: IGooglePlayConfiguration.SetMaxConnectionAttempts(int maxConnectionAttempts) to specify the max connection attempts to the Google Play Store.

Added: Privacy manifest to comply with Apple's new privacy requirements. For more details on how the Unity Engine supports, refer to the forum.

Added: ConfigurationBuilder.logUnavailableProducts to specify if unavailable products should be logged.

Changed: Google Play- The default max connection attempt to the Google Play Store has been increased from 1 to 3. See IGooglePlayConfiguration.SetMaxConnectionAttempts to configure this to a different value.

Changed: Apple - The log when retrieving products (SKProductsResponse) now also contains the invalid products count.

Changed: Improved IStoreListener.OnInitializeFailed for InitializationFailureReason.NoProductsAvailable by adding a message to clarify whether the store returned products or not.

Fixed: Google Play- Fixed AndroidJavaObject not being disposed causing a global reference table overflow in an edge case.

Fixed: Google Play- Fixed bug causing BillingClient duplication resulting in ANR.

Fixed: Apple - Fixed isFamilyShareable on tvOS to be only available on supported versions (14.0 and above).

Fixed: Apple - Error codes when a purchase fails now always returns the code from Apple instead of defaulting to SKErrorUnknown.

Fixed: Analytics' transactionServer being null.

Added: Support to -no-cloud-project-bind-popup flag, to prevent the popup from showing.

Fixed: Bug where the project linking popup window would appear on Editor start after reimporting packages, even if the user's project was linked.

Fixed: Issue with .NET Standard target.

Added: Improved in-script parameter parsing error feedback.

Added: Added references of the latest javascript services SDKs for autocompletion.

Added: Cloud Code bindings generation.

Fixed: Error when selecting CloudCodeModuleReference assets in the Project window.

Fixed: JS script import when Node project is not initialized.

Added: Added Apple Privacy Manifest.

Added: Support for Access Classes when interacting with Player Data, via the addition of optional options objects to existing methods in the CloudSaveService.Instance.Data.Player API. For more information on Access Classes, please refer to the documentation.

Added: Support for Querying in both Public Player Data and Default Custom Data, via the new QueryAsync method. For more information on Querying, please refer to the documentation.

Changed: The existing CloudSaveService.Instance.Data.Player.DeleteAsync has been marked as Obsolete, with a new version added that accepts options of type CloudSave.Models.Data.Player.DeleteOptions instead of CloudSave.DeleteOptions. This enables the addition of new options to support Access Classes (see above in Added).

Added: Added new service module Scheduler.

Added: new-file for deployment.

Added: list to see live schedules.

Added: Support for support Scheduler service to Deploy and Fetch.

Added: Fetch for Triggers.

Added: --readiness option to gsh build configuration create command.

Added: --readiness option to gsh build configuration update command.

Added: Game Server Hosting core-dump command to configure an external storage location for core dumps (GCS only).

Added: --build-version-name option to gsh build create/create-version commands.

Fixed: New-file command error for directory that does not exist.

Fixed: Deploy no longer requires permissions for services not being deployed, unless reconcile is specified.

Fixed: Fixed Economy fetch issue making it not idempotent.

Fixed: Fixed issue where issues after loading were not reported when deploying CloudCode modules.

Fixed: Fixed issue where deploying a solution as Cloud Code Module will be logged with the solution path and not the generated ccm.

Changed: Improved the error description when failing to deploy a solution with no clear main entry project, for Cloud Code Modules deployment.

The new experimental Cloud Services APIs package provides low-level access to all public APIs by using our OpenAPI specifications. This enables you to extend UGS and build your own solutions.

To install the package in the Unity Editor, in the Package Manager, select Install package by name and add the package name com.unity.services.apis.

For more information on this package, refer to the Unity forum.

Added: LastNotificationDate field to inform the client of the player's notifications last created date.

Added: GetNotificationsAsync method so the client can request the player's notifications.

Added: Notifications field to cache the notifications after GetNotificationsAsync is called.

Added: BannedUser error code to identify an exception when a user has been banned.

Fixed: Authentication refresh and expiration scheduling relying on device time which could cause edge cases.

Changed: Custom Token Exchange ID provider to Custom ID.

Added: GetCustomId method to PlayerInfo.

Added: SignInWithSteamAsync method with appId parameter for Multiple App Id Support.

Added: LinkWithSteamAsync method with appId parameter for Multiple App Id Support.

Added: Additional App IDs to Steam ID Provider for Multiple App Id support.

Fixed: Serialization of player accounts settings.

Added: Support for usage settings under gsh fleet commands.

Added: gsh server files list and gsh server files download.

Fixed: Economy deserialization error message when receiving invalid response.

Fixed: Issue where deploying a leaderboard would fail to remove Tiering and Reset config.

Added: Bash installer to download and install the UGS CLI on MacOS and Linux

Added: Config as code support for economy module

Added: Config as code support for access module

Added: new-file commands for economy resources

Added: support for .sln files on deploy

Added: .sln files now are compiled and zipped into .ccm before deploying

Added: Added config as code support for triggers

Changed: Services can support multiple file extensions

Changed: Updated server states in ugs gsh machine list

Fixed: Handle exceptions when using Deploy with a Remote Config file that has unsupported config types.

Fixed: Issue where if a leaderboard fails to load, it incorrectly deploys as a empty leaderboard and it is not reported

Fixed: Added correct description when Cloud Code deploy has duplication file error during dry-run.

Fixed: Issue with ugs gsh fleet-region update not ensuring the fleet region is brought online by default.

Fixed: Handle exception for mis-spelt bool input params for ugs gsh fleet-region update command.

Fixed: Issue with Deploy and Fetch on Remote Config containing JSON arrays.

Released: 4.0.0-pre.1 version

Changed: You can now only subscribe to OnNotificationReceived before calling RegisterForPushNotificationsAsync

Changed: Updated com.unity.services.analytics dependency to 5.0.0

Changed: Updated com.unity.services.core dependency to 1.10.1

Changed: Added com.unity.mobile.notifications version 2.2.0 as a dependency.

Fixed: Behaviour when the app is launched from a push notification is now consistent between iOS and Android (incoming push notification data is broadcast after RegisterForPushNotificationsAsync flow is complete)

Added: Leaderboards now supports the ugs deploy and ugs fetch commands at the root.

Added: Leaderboards now supports new-file, to create an empty file for leaderboards.

Added: Game Server Hosting Module Service commands. Run ugs gsh -h to show usage.

Added: Supports builds, build configurations, fleets, fleet regions and servers.

Added: Deployment Definitions to the Deploy and Fetch commands.

Added: Analytics related to command usage and options used.

Added: Deploy/Fetch return an array in a table-like format with -json flag enabled.

Added: Deploy sends file configurations into the service.

Added: Fetch updates local files based on service configuration.

Changed: Removed Leaderboards support to create and update commands in favor of deploy and fetch.

Fixed: Implement JsonConverters to prevent NotImplementedException when converters are invoked by reflection.

Fixed: A bug with the login command when stdin is redirected.

Fixed: A bug preventing Remote Config fetch dry run to update the fetched file name.

Added: IServerAccessToken and IServerEnvironmentId components for packages that want to support running operations in the context of a server.

Added: IAccessTokenObserver component for packages to be notified of changes to the IAccessToken value.

Fixed: A bug logging an additional error when deploying a file.

Changed: Dropped support for Unity 2020.3, minimum supported is 2021.3 now

Changed: Removed 2.x namespace and corresponding API's for backward compatibility with 2.x implementation

Changed: Removed static ConfigManager class

Changed: Updated SDK documentation regarding caching and unity attributes

Changed: Updated com.unity.services.core dependency from 1.5.2 to 1.8.1

Changed: Promote Candidate Experimental package to Verified Production

Changed: Updated delivery endpoint from https://config.unity3d.com/settings to https://config.services.api.unity.com/settings

Fixed: Added fix for inadvertently persisted auth token

Added: Added define constraints to the package assembly to don't load on Unity versions < 2022.

Changed: Adjusted package accordingly to Unity Build Automation rebranding.

Fixed: Fixed documentation and dashboard links.

[Breaking Change]: Cloud Code list command for Modules and Scripts is more descriptive. [Breaking Change]: Messages are directed to StdErr and Output into Stdout. [Breaking Change]: Cloud Code create, delete, get, list, new-file, publish and update commands are now under a parent command scripts and can be called with cloud-code scripts <command>. [Breaking Change: Deploy and Fetch output have been modified to match each other.

Statuses have been updated to reflect what is happening in the editor.

Changed: Using standardized output for all Import/Export implementations.

Changed: Plain text Deploy/Fetch Output now prints full path.

Fixed: Cloud Code files that failed to read now reported properly in the output.

Fixed: Cloud Code deleted files properly reported in the Deploy output.

Fixed: Remote Config Entries properly reported in the Deploy output.

Fixed: Remote Config Fetch properly bubbles issues in loading files.

Fixed: An issue where fetching a file from Cloud Code that had no parameters would keep appending module.exports.parameters = {}.

Fixed: Using Cloud Code fetch and deploy multiple times no longer appends new lines.

Fixed: Improved error handling to provide more detail on certain unhandled exceptions.

Fixed: Cloud Code script with invalid parameters will fail to fetch and show in the "failed" result section.

Added: Serverless Multiplayer Game sample demonstrates how to utilize game lobbies and compete in a simple real-time arena-style game where players collect coins for points.

Changed: Upgraded the project from Unity Editor version 2020.3.20f1 to 2020.3.41f1.

Changed: Updated various non-UGS packages to their latest versions that are verified for Unity Editor 2020.3.41f1.

Changed: Removed RemoteConfigService.instance.SetCustomUserId() call from ClientVersionCheck.cs as calling that method is only necessary for specific circumstances, and ClientVersionCheck is not one of those circumstances.

Changed: Minor refactors to files to support newly applied linting rules.

Changed: Add popups to explain cause when client is forced back to the main menu in Serverless Multiplayer Game due to host leaving or kicking player out of lobby.

Changed: Turned off Interpolate in the Serverless Multiplayer Game to improve responsiveness in the game scene and reduce the 'host advantage' in gameplay. The flag is located in the player avatar prefabs' ClientNetworkTransform component.

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.core
```

Example 2 (unknown):
```unknown
ProcessPurchase
```

Example 3 (unknown):
```unknown
Product.hasReceipt
```

Example 4 (unknown):
```unknown
Product.receipt
```

---

## Triggers

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers

**Contents:**
- Triggers#
- Events#
- Scheduler#
- Triggers#
- Filters#
- Next steps#

Triggers enable the automation of server side actions at a set moment in time or as the result of another server event from Unity Gaming Services (UGS).

They enable Cloud Code scripts and modules to be run automatically, without the need for a client to make a request to the server.

An event defines a change in state that has occurred in the server. Events can be emitted by internal Unity Gaming Services, such as the Authentication service, or by the Scheduler service.

For example, every time a player signs in, the Authentication service emits an event.

Refer to Events and Supported UGS events for more information.

Use the Scheduler service to emit events at a set or recurring moment in time.

For example, a scheduler enables you to do the following:

The Triggers service monitors a stream of internal events, emitted by Unity Gaming Services and the Scheduler service. Triggers allow users to define rules to automatically perform a chosen action (for example, run a Cloud Code script) when UGS emits a particular event.

A trigger can enable use cases such as:

Filters are optional conditions that you can add to a trigger to define when the trigger fires. For example, you can define a filter to only fire a trigger for a Leaderboard event when a player submits a score of 100 or more.

Refer to Filters for more information.

Take a look at the following guides to learn more about Triggers:

---

## Lobby events

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/lobby-events

**Contents:**
- Lobby events#
- Receive updates#
  - KickedFromLobby#
- Apply changes to a lobby#
- Lobby versions#
- Troubleshooting#
  - OnLobbyEventConnectionStateChanged#
- API#
  - Interfaces#
    - ILobbyServiceSDK#

Important: Lobby events are only available in version 1.0.0 and later. If you're using the Multiplayer Services SDK, use LobbyService.Instance instead of Lobbies.Instance. Refer to Migrate from Lobby.

The Lobby package includes the Lobby Events system, which allows you to subscribe to real-time lobby events. Events are sent every time member-observable player/lobby state is changed. For example, when a player joins or leaves, a player updates public/member data, or the host updates public/member lobby data. Events are not sent if a player or the host updates a private property of the lobby.

Using events can be more efficient than polling for lobby state through gets, especially because it requires no action until some data is changed. Events are efficient when the number of gets per second is significantly larger than the number of events received per second. Furthermore, event payloads only contain patches, so in general, they have the additional benefit that their payloads are much smaller than those returned by a get. The biggest downside to events is that they are unreliable and do not guarantee in-order delivery. Refer to Lobby versions.

Note: Events can be unreliable and do not guarantee in-order delivery.

Call the SubscribeToLobbyEventsAsync method on a Lobby instance to subscribe to receiving updates for that instance. Once subscribed, the Lobby service invokes the LobbyChanged event each time a change occurs. You can also use the ApplyToLobby helper method to apply the changes to the Models.Lobby object.

To subscribe to a lobby’s real-time updates, you must call:

Note: A player can only receive events for a lobby if they are in that lobby.

The following code sample demonstrates how to create a lobby and subscribe to it:

Note: In the preceding code sample, OnLobbyChanged, OnKickedFromLobby and OnLobbyEventConnectionStateChanged handle the events.

The following code sample provides an example handler for OnLobbyChanged. It demonstrates how to handle a deleted lobby instance.

The Lobby Event service uses the KickedFromLobby handler to remove a user from the lobby. This can happen for a number of reasons. For example, when the connection fails or if the host removes the user from the lobby. When a user gets kicked out of a lobby, they receive a message that the lobby event connection state has changed ( LobbyEventConnectionStateChanged) to unsubscribed.

The following code sample provides an example handler for OnKickedFromLobby:

The following code sample provides an example handler for OnLobbyEventConnectionStateChanged:

Note: When there’s an error with the connection to Lobby Events, Lobby will not attempt to reconnect.

When you subscribe to the LobbyEventCallbacks.LobbyChanged event, you receive a set of changes each time the lobby updates. It’s possible for a lobby to have a large number of changes at any given time, so the Lobby package includes a helper function to apply these changes to a lobby.

The following code snippet shows how to use the ApplyToLobby helper function to apply lobby changes:

Calling changes.ApplyToLobby updates all fields that have changed on a lobby in-place. When changes occur to a lobby in-place, the call modifies the values of the lobby object that were passed into the ApplyToLobby function. If you need to check whether a specific change was applied, check the ChangedLobbyValue members on the ILobbyChanges interface.

The following code sample demonstrates how to check these values:

Lobby versions are useful for checking if a newly-fetched lobby has changed since the last observed lobby. Every lobby exposes a Version property. Versions start at 1 and are incremented every time the member-observable player/lobby state is changed.

If the version associated with a new set of lobby changes is not exactly one greater than the last observed lobby version, an update has been received out of order or lost. If you have a missing message, use GetLobbyAsync(string) to retrieve the latest version.

Make sure you handle all of the events provided, particularly OnLobbyEventConnectionStateChanged and OnKickedFromLobby as these may indicate that the Lobby Events have stopped.

The connection status for the Lobby Events indicates whether or not you will be receiving events.

The following are the connection statuses:

The following error codes have been added:

**Examples:**

Example 1 (unknown):
```unknown
LobbyService.Instance
```

Example 2 (unknown):
```unknown
Lobbies.Instance
```

Example 3 (unknown):
```unknown
SubscribeToLobbyEventsAsync
```

Example 4 (unknown):
```unknown
LobbyChanged
```

---

## Debug with logs

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/server-authority-debug

**Contents:**
- Debug with logs#

In a server authoritative game, your code isn't on the player client. This means it's important to have proper observability to debug issues in a server authoritative game. To monitor your game, you can use logs, which Cloud Code and Triggers automatically generate.

To avoid blind spots in complex cloud code, you need detailed logs. You can add your own custom log statements in Cloud Code to record debugging information. For example, you can strategically log steps, inputs, outputs and errors to increase observability and help you pinpoint bugs.

For more information, refer to Logging.

---

## LABEL RENAME

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/label-rename

**Contents:**
- LABEL RENAME#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

cm label rename <lbspec> <new_name>

This command renames a label.

cm label rename lb:BL001 BL002

(Renames the label 'BL001' to 'BL002'.)

**Examples:**

Example 1 (unknown):
```unknown
cm label rename <lbspec> <new_name>
```

Example 2 (unknown):
```unknown
cm label rename lb:BL001 BL002
```

---

## BRANCH HISTORY

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/branch-history

**Contents:**
- BRANCH HISTORY#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Shows the history of a branch.

cm branch | br history <brspec> [--dateformat=<date_format>] [--machinereadable]

cm branch history br:/main/scm001@myrepository@myserver:8084

(Displays the history of '/main/scm001' branch of 'myrepository' repository on 'myserver' server.)

cm br history main --dateformat="yyyy, dd MMMM" --machinereadable

(Displays the history of the 'main' branch of the current repository, with a given date format, and in an easy-to-parse format.)

**Examples:**

Example 1 (unknown):
```unknown
cm branch | br history <brspec> [--dateformat=<date_format>] [--machinereadable]
```

Example 2 (unknown):
```unknown
cm branch history br:/main/scm001@myrepository@myserver:8084
```

Example 3 (unknown):
```unknown
cm br history main --dateformat="yyyy, dd MMMM" --machinereadable
```

---

## Download the desktop client

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/version-control-desktop-client

**Contents:**
- Download the desktop client#
- Install the Unity Version Control desktop client#
- Additional resources#

Install the Unity DevOps Version Control Desktop Client.

Use the following links to download the latest version of the desktop client for your operating system:

---

## Access Control

**URL:** https://docs.unity.com/ugs-overview/en/manual/access-control

**Contents:**
- Access Control#
- How Access Control works#
- How to use Access Control#
  - Example policies#
  - Error responses#
- Policy selection in Access Control#
- Resource URNs and Query Parameter Handling#
  - Rules for Query Parameter Handling in Resource URNs#
  - Backward Compatibility#
- Best practices#

Access Control for Unity Gaming Services (UGS) allows you to defend your game state and logic in UGS from cheaters and exploiters. Access Control (also known as API Authorization) is important as it lets you control who can access, modify, or delete game data and resources in order to protect the game from unauthorized access.

API authorization for UGS is the process of determining what actions a user is allowed to perform once they have been authenticated. Authentication verifies that a user is who they claim to be. Together, authentication and authorization provide a secure way to control access to APIs and access to resources. UGS provides an Authentication solution that works with API authorization described in this documentation.

Without authentication, anyone can access the API and potentially perform unauthorized actions. For example, if an API allows users to view sensitive information or make changes to data, and there is no authentication in place, anyone can access that information or make changes without permission.

Authentication establishes the identity of the user, and authorization controls what actions they are allowed to perform. Authentication provides the necessary foundation for authorization to work. It’s like a key that unlocks the door of the API, but the authorization decides if the user is allowed to enter, and what they can do once they are in.

Access Control in UGS is configured using resource policies. UGS services enforce rules for who can access those services and what actions they are allowed to perform.

When a user attempts to access a UGS service, the service checks the user's identity against the configured policies and either denies or allows an API request.

A resource policy is a collection of statements. The statements are defined in terms of the user’s identity (the Principal attribute), what actions (the Action attribute) are restricted or allowed (the Effect attribute), and the resource the policy applies to (the Resource attribute). A policy also contains a Sid attribute (Statement Identifier), a user-defined descriptive name for the given policy which can only contain alphanumeric characters and hyphens.

The resources in the policies are defined as Uniform Resource Names (URNs), which typically end in API paths that make up the component parts of the URN.

Resource policies are configured on a per-project or per-player basis. A project policy is evaluated for all Principals that call UGS services for that project. A player policy is only evaluated for an individual player within the scope of a project and environment.

Here is an example of a valid URN in the Economy service:

It uses a glob pattern to match a set of resources that share a common pattern. The following table describes the different components of this URN.

Because URN matching uses glob patterns, the above URN can also be defined as the following.

urn:ugs:economy:/**/currencies/gold

When no Access Control policies are created, Access Control defaults to allowing all authenticated API calls from authenticated players. That could be described using the following resource policy.

The following example shows how to create a valid policy to allow authenticated players to read, but not change (write), the gold currency in Economy via an API call.

Alternatively, to completely deny access to authenticated players to all APIs within Economy:

Use the REST API or the UGS CLI to create resource policies for UGS. These policies only need to be created once and are evaluated and enforced for each API call to UGS within the context of the authenticated caller.

Do not allow Players to execute any Cloud Code scripts:

This resource policy denies access to all actions on cloud code scripts in the project that a Player is authenticated for. Cloud Code only provides an execute API as a POST request to that API, which falls under the Write Action in the above policy statement.

Below is another example of what a resource policy for Cloud Save could be:

This resource policy denies write access to all the cloud save data for any authenticated player for the project, including all nested paths and subfolders under items for a user or group with a Player identity. This effectively prevents Players from directly writing data to Cloud Save. Combining this policy with the previous policy for Cloud Code, means a developer could write data to Cloud Save via Cloud Code and implement any additional game logic within Cloud Code.

Below are the different components that make up a policy and what they do.

When a player attempts to access a resource for which they don't have appropriate permissions, an error response is returned with a status code of 403 Forbidden. The exact format of the error response depends on the type of access control policy in place.

If a player is restricted from accessing a resource based on a project-based policy, the error response includes the following fields:

If a player is restricted from accessing a resource based on a player-based policy, the error response includes the following fields:

If the player is temporarily banned, the error response also includes an expiresAt field which indicates when the ban expires:

If the player is permanently banned, the error response doesn't include an expiresAt field. You should handle these error responses appropriately in your application code to ensure a smooth user experience.

When Access Control policies are evaluated, only the most specific rule wins and its effect is applied.

Below are three example policies.

If a request is made to */currencies/silver, the second rule, allow /currencies/*, is applied because it is more specific than the first rule.

If a request is made to */currencies/gold, the third rule, deny */currencies/gold, is applied because it is the most specific rule that matches the request.

If there are multiple policies that list the exact same Resource, then the Deny Effect always takes precedence.

Resource URNs support query parameter-specific matching for flexible policy definitions. The rules governing how query parameters are evaluated depend on the structure of resource URNs in policies.

Access Control policies evaluate resource URNs as follows:

1.URNs with Query Parameters

If the defined policy URN includes specific query parameters (?), such as:

The policy matches requests that contain the exact path and query parameters specified in the URN. This enables precise control over requests based on the path and query parameter values.

2.URNs with a Wildcard(*)

If the defined policy URN ends with a *, such as:

The policy matches requests with the specified path (up to the wildcard) and any query parameters attached to the request.

3. URNs Without Query Parameters or Wildcard (*)

If the defined policy URN does not contain a ? or end with a *, such as:

Query parameters from the request are stripped during evaluation. This ensures that the policy applies strictly to the path, preventing misuse of query parameters to bypass authorization policies.

Resource URN matching rules are designed to maintain backward compatibility with existing policies. Policies created before this update that do not define query parameters (or use wildcards * at the end) will continue to evaluate requests based only on the path, excluding query parameters.

This avoids unintended bypasses or behaviors while enabling query parameter matching for newly defined or updated policies.

Start with a default policy of denying all access and explicitly grant access to specific APIs or resources.

Grant only the minimum permissions required for an API or resource.

Create policies for specific API methods and resources, rather than for all APIs and resources.

The URNs for the services are listed below. Note that Friends are Player Name use the same URN prefix, so you may need to add the routes you want to block into the resource field.

Regularly review and update API policies to ensure they reflect the current state of the game and to remove unnecessary permissions.

The Access Control APIs are accessible via web endpoints, or REST APIs. REST APIs provide flexibility to automate your workflows using your favorite language and game development engine.

Refer to the Access Control REST API documentation for more information. Refer to the Service Account Authentication documentation for more information on how to authenticate your API calls.

The following example shows how to set a resource policy using the REST APIs with the cURL tool.

To apply your configuration, you must deploy the configuration to the Access Control service.

To deploy Access Control configurations in the Unity Editor you must first install the required packages and link your Unity Gaming Services project to the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

In the Unity Editor, select Edit > Project Settings > Services.

If your project doesn't have a Unity project ID:

If you have an existing Unity project ID:

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

To create Access Control configurations within the Editor, you must install the following packages:

Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

To install these packages and add them to your list of available packages:

Follow these steps to create an Access Control configuration:

The new configuration is now visible in the Project window, and in the Deployment window, accessible by selecting Window > Deployment.

There are two methods to edit an existing Access Control configuration:

Use the UGS Access Control CLI for simpler management and automation of your Access Control configuration.

To configure the UGS CLI:

Run the following command:

ugs deploy <path-to-access-control-file>

**Examples:**

Example 1 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/*/currencies/gold
```

Example 2 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/*/currencies/gold
```

Example 3 (unknown):
```unknown
urn:ugs:economy:/v2/project/
```

Example 4 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/
```

---

## In-game mailboxes

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/InGameMailbox

**Contents:**
- In-game mailboxes#
- Prerequisites#
- Overview#
- Initialization#
  - Functionality#
    - Open a message#
    - Claim an attachment#
    - Claim all attachments#
    - Delete a message#
    - Delete all read and claimed attachments#

In-game mailboxes allow game developers to communicate with their players. You can use them to tell players about in-game events, gift them useful resources, or help keep them coming back to your game.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

When a player loads the scene for the first time, they see an inbox with a list of messages waiting for them to read. On subsequent loads, the inbox is either in the state they left it, or an updated state due to messages expiring between sessions.

Players can interact with the messages, claim their attachments, delete messages, or reset the inbox to a brand new state.

To see this use case in action:

When the scene loads, the InGameMailboxSceneManager script performs the following initialization steps:

Initializes Unity Gaming Services.

Signs in the player anonymously using the Authentication service. If you’ve previously initialized any of the other sample scenes, Authentication will use your cached Player ID instead of creating a new one.

Refreshes the Economy configuration data. If new Economy items were created since the last time the player opened the app, this will initialize those items in the player's configuration.

Retrieves and updates currency balances from the Economy service for that authenticated user.

Uses the sprite addresses stored in the Economy item configuration's custom data to load all possible currency and inventory item sprites from Addressables.

Retrieves the updated message info for the player's inbox:

Displays the updated list of inbox messages in the scene.

The left panel in the scene displays the list of messages in the player's inbox. This list updates over time as messages expire, or based on player interaction.

Below the list, a counter displays how many messages are in the inbox and the max number of messages that can be in the inbox at any given time. When a player loads the scene for the first time, the inbox is full.

When all messages have been deleted from the inbox (either through player interaction or message expiration), a pop-up appears prompting the player to reset the inbox.

Note: This pop-up is a usability feature of the sample, and would not be an expected interaction in a real-world implementation.

When you select a message from the list, the following occurs:

If the message has an attachment, there is also an indication of which Economy items are attached, along with a button to claim them.

When you press the Claim button, the client code calls the Messages_ClaimAttachment.js Cloud Code script with the selected message's ID included as a parameter. The following occurs on the backend:

When you press the Claim All button, the client code makes a call to the Messages_ClaimAllAttachments.js Cloud Code script. The following occurs on the backend:

The client requests inbox data from Cloud Save.

Cloud Save returns a list of inbox messages filtered to only show messages with message.metadata.hasUnclaimedAttachment set to true.

For each message in this filtered list:

Once all message attachments are claimed, the updated message list is saved in Cloud Save.

Note: Saving changes in Cloud Save after each attachment is claimed would make the process more fault tolerant. However, it would also require more server calls and therefore be less efficient than the selected approach. It is up to the developer which advantage to prioritize.

When you press the Delete button for a message:

When you press the Delete Read button:

At the bottom of the scene, you can reset the inbox while impersonating a particular audience:

Each of the non-default audiences adds a message to the message list that is specific to that particular audience. These messages are determined by Game Overrides.

When you reset the inbox for the given audience, the following occurs:

When you press the inventory bag icon, the following occurs:

To replicate this use case, you need the following Unity packages in your project:

Note: Although it is listed as a package and requires separate dashboard configuration, Game Overrides doesn't actually have an SDK to install from Package Manager. It is a server-side offering that affects values returned from other services.

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys the following items:

The Deployment package doesn't support the following items:

To configure them, refer to Using the Unity Dashboard.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Publish the following scripts in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resources in the Unity Dashboard:

In addition, configure the following virtual purchases:

* There is no cost associated with these Virtual Purchases because they are all gifts to the player reading the message.

Set up the following config values in the Unity Dashboard:

Configure the following Overrides in the Unity Dashboard:

Select JEXL with the following JEXL code*:

After finishing creating the Game Override, click Enable.

Select JEXL with the following JEXL code*:

After finishing creating the Game Override, click Enable.

Select JEXL with the following JEXL code*:

After finishing creating the Game Override, click Enable.

Select JEXL with the following JEXL code*:

After finishing creating the Game Override, click Enable.

* This sample determines which Game Override data to return based on a JEXL match with the audience value specified in the client. This allows the sample to simulate a player being in different audiences on-demand. In a real app, the Game Overrides would likely be set up to use built-in or custom-defined Analytics audiences for targeting. For example, during the Game Override targeting step, you could choose Stateful (Audiences) and check the appropriate Analytics audience from the list or click Build a new Audience.

**Examples:**

Example 1 (unknown):
```unknown
InGameMailboxSample.unity
```

Example 2 (unknown):
```unknown
InGameMailboxSceneManager
```

Example 3 (unknown):
```unknown
Messages_ClaimAttachment.js
```

Example 4 (unknown):
```unknown
makeVirtualPurchase
```

---

## Player inventory

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/SDK-player-inventory

**Contents:**
- Player inventory#
- GetInventoryAsync#
  - GetInventoryOptions#
  - GetInventoryResult#
- AddInventoryItemAsync#
  - AddInventoryItemOptions#
- DeletePlayersInventoryItemAsync#
  - DeletePlayersInventoryItemOptions#
- UpdatePlayersInventoryItemAsync#
  - UpdatePlayersInventoryItemOptions#

The methods in the PlayerInventory namespace allow you to retrieve and update the player's inventory instances.

These methods will return inventory data for the currently signed in player from the Authentication SDK.

All the methods in this namespace can throw an EconomyException.

Retrieves the current inventory item instances associated with the currently signed in player.

This method optionally takes a GetInventoryOptions object. This can be used to set the number of items per fetch and for filtering.

You can filter the inventory items using a list of configuration item IDs and/or PlayersInventoryItem IDs. If you use these filter options then only players items that have the specified configuration item IDs and PlayersInventoryItem IDs will be returned.

The following sample code retrieves the first five items for the current user, and then retrieves the next five.

This next sample code retrieves only the player's SWORD items.

These methods return a GetInventoryResult.

The options object for a GetInventoryAsync call. It has the following fields:

A GetInventoryResult provides paginated access to the list of player's inventory items retrieved. It has the following field:

It has the following methods:

Adds an item to the player's inventory.

This method optionally takes an AddInventoryItemOptions object. This is used to set a custom PlayersInventoryItemId — if null, one is autogenerated. Can also be used to set a dictionary of instance data.

Returns a PlayersInventoryItem representing the inventory item added to the player's inventory.

The options object for a AddInventoryItemAsync call. It has the following fields:

Deletes an item from a player's inventory.

This method optionally takes a DeletePlayersInventoryItemOptions object used to set the write lock. If a write lock is provided, it will only delete the item if the write lock is accepted by the Economy service. If no write lock is provided then the operation is forced through.

The options object for a DeletePlayersInventoryItemAsync call. It has the following field:

Updates an item with new instance data.

Returns the updated players inventory item.

This method optionally takes an UpdatePlayersInventoryItemOptions object used to set the write lock. If a write lock is provided, it will only update the item if the write lock is accepted by the Economy service. If no write lock is provided then the operation is forced through.

The options object for a UpdatePlayersInventoryItemAsync call. It has the following field:

A PlayersInventoryItem represents a single unique item in a player's inventory. It contains the following fields:

It also has the following helper method:

This method fetches the configuration of this player's inventory item, type of InventoryItemDefinition.

This event can be subscribed to in order to be notified when the SDK updates a specific item in the player's inventory. The subscriber is passed the playersInventoryItem ID of the item that was updated.

This event is only called for SDK initiated actions (for example, updating player's inventory, making purchases). It will not be called for any updates from other devices / service side changes.

Use InstanceDataDeserializable to add custom data for specific items in a player's inventory. It is passed in as type object and fetched as type IDeserializable. This allows you to pass in your own custom classes as instance data.

For example, a player's shield may have a durability rating. This could be set and updated using InstanceDataDeserializable:

You can deserialize the instance data by doing the following:

**Examples:**

Example 1 (unknown):
```unknown
PlayerInventory
```

Example 2 (unknown):
```unknown
GetInventoryOptions
```

Example 3 (unknown):
```unknown
PlayersInventoryItem
```

Example 4 (unknown):
```unknown
PlayersInventoryItem
```

---

## TRIGGER EDIT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/trigger-edit

**Contents:**
- TRIGGER EDIT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

cm trigger | tr edit <subtype_type> <position_number> [--position=<new_position>] [--name=<new_name>] [--script=<script_path>] [--filter=<str_filter>] [--server=<repserverspec>]

Web triggers: A web trigger is created by typing "webtrigger <target-uri>" as the trigger command. In this case, the trigger will execute a POST query against the specified URI, where the request body contains a JSON dictionary with the trigger environment variables, and a fixed INPUT key pointing to an array of strings.

cm trigger edit after-setselector 6 --name="Backup2 manager" --script="/new/path/al/script"

cm tr edit before-mklabel 7 --position=4 --server=myserver:8084

cm trigger edit after-add 2 --script="webtrigger http://myserver.org/api"

**Examples:**

Example 1 (unknown):
```unknown
cm trigger | tr edit <subtype_type> <position_number> [--position=<new_position>] [--name=<new_name>] [--script=<script_path>] [--filter=<str_filter>] [--server=<repserverspec>]
```

Example 2 (unknown):
```unknown
cm trigger edit after-setselector 6 --name="Backup2 manager" --script="/new/path/al/script"
```

Example 3 (unknown):
```unknown
cm tr edit before-mklabel 7 --position=4 --server=myserver:8084
```

Example 4 (unknown):
```unknown
cm trigger edit after-add 2 --script="webtrigger http://myserver.org/api"
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/overview/manual/getting-started

---

## Connection flow

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/connection-flow

**Contents:**
- Connection flow#
- The host player requests an allocation#
- The Allocations service selects a Relay server#
- The Allocations service sends the connection data to the host player#
- The host player binds to the Relay server#
- The host player requests a join code#
- The Allocations service returns a join code to the host player#
- The host player shares the join code with joining players#
- The joining players use the join code#
- The Allocations service sends connection data to the joining player#

The connection flow is the process by which the Allocations service reserves slots on a Relay server to group players into a match. The process involves two types of players: a host player and joining players. The following list describes the high-level steps involved in the connection process.

The host player initiates the connection flow by requesting an allocation from the Allocations service. The allocation request includes the maximum number of connections the allocation can allow. It can also include a specific region. If the request doesn’t include a region, the Allocations service uses QoS to select the best region for the request.

The Allocations service receives the host player's request and selects an appropriate Relay server. The Relay server selection depends on the maximum connections allowed and the region.

When the Allocations service finds a Relay server, it reserves a space on the Relay server for the game session. At this point, the Relay server also generates a unique secret key. The Relay server returns the secret key to the Allocations service, in addition to the Relay server IP, the Relay server ports, and the connection data.

The Allocations service sends the Relay server connection data to the host player's game client.

The host sends a BIND message to the selected Relay server using the data received from the response from the allocation request. The BIND message has the connection data, the accept mode, nonce, and HMAC. If the host doesn’t send the bind to the Relay server within 60 seconds after making the allocation, the allocation times out from inactivity.

If the information in the request is accurate, the Relay server acknowledges the bind request by sending a BIND_RECEIVED message back to the host client.

Note: You typically send BIND messages after calling the allocate and join APIs, which retrieve the Relay server’s destination address for use with the BIND message.

Once bound to the Relay server, the host player can request a join code from the Allocations service.

The Allocations service generates and returns a join code to the host player. The join code the Allocations service returns uniquely represents the host player’s allocation to the Relay server, and allows joining players to bind to the same Relay server and connect to the host player.

The host player shares the unique join code with other players through any method, including verbally, through a text message, or through a Lobby. The join codes are short and easy to remember to ease sharing.

The players that use the join code with a join request to the Allocations service become the joining players.

Note: Any number of joining players can use the same join code so long as the number doesn't exceed the maximum number of connections specified in the initial allocation request.

The joining players use the join code from the host player to send a join request to the Allocations service.

Note: A “join” is when a joining player (a non-host player) client joins the host client’s game session. Under the hood, it’s another allocate call to the Relay backend service.

The Allocations service uses the join code to look up the host player’s allocation and returns the data to the joining players.

The response from the Allocations service has the Relay server IP address, the Relay server port, the secret key, the encrypted joining player’s connection data, the joining player’s allocation ID, and the encrypted host connection data. The joining player can then use the secret key to decrypt and use the host connection data to connect to the host.

The joining player sends a BIND message to the Relay server using its connection data it received from the response to the join request made to the Allocations service.

Upon success, the Relay server acknowledges by sending aBIND_RECEIVED message to the joining player's game client.

Note: You should typically send BIND messages after calling the allocate and join APIs, which retrieve the Relay server’s destination address for use with the BIND message.

Once bound to the same Relay server as the host player, the joining player then sends a connection request to the host player. If the connection request is successful, the joining player and the host player can send data to each other through the Relay server.

**Examples:**

Example 1 (unknown):
```unknown
BIND_RECEIVED
```

Example 2 (unknown):
```unknown
BIND_RECEIVED
```

---

## Attribution support

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/attribution-support

**Contents:**
- Attribution support#
- Grow your game using user aquisition data#

The gaming industry has become increasingly competitive, and acquiring users through organic growth is becoming more difficult. Nowadays, all successful game studios display ads in other games or platforms to reach their desired audience and redirect them to their game. This is what's called user acquisition.

Ads are distributed through ad networks, like Unity Ads. To start acquiring users with Unity, refer to User acquisition.

By analyzing your user acquisition data, you can quickly see which ad networks and campaigns bring the most valuable users to your game. User acquisition data helps you focus your budget only on effective networks and, over time, refine your ads and bring only valuable users to your games.

You can also personalize the early content of your game depending on what is presented in the ad shown to each user. For example, in an RPG game, if you know the user clicked on an ad showing a warrior, the player can play the same warrior in the tutorial and not the default mage.

To learn how to implement attribution support using the acquisitionSource event, refer to Track user acquisition.

**Examples:**

Example 1 (unknown):
```unknown
acquisitionSource
```

---

## Welcome to Cloud Diagnostics

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/CloudDiagnostics/WelcometoCloudDiagnostics

**Contents:**
- Welcome to Cloud Diagnostics#
  - Getting Started#
  - Crash and Exception Reporting#
  - Debugging Symbols#
  - User Reporting#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Unity Cloud Diagnostics is a suite of cloud-enabled tools that help collect and identify possible issues in your Unity-built game. Collect crash and exception reports as well as user feedback so you can better diagnose issues and ensure a smooth gameplay experience.

Cloud Diagnostics includes:

The following documentation explains how to set up and use crash and exception reporting, debugging symbols, and user reporting. Let’s get started!

---

## Use case sample: Reward top players with in-game currency at the end of season

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/use-cases/reward-top-players

**Contents:**
- Use case sample: Reward top players with in-game currency at the end of season#
- Prerequisites#
  - Authenticate using a Service Account#
  - Configure the UGS CLI#
- Examine the reset event#
- Create deployment files#
  - Set up Economy#
  - Set up Leaderboards#
  - Set up Cloud Code#
    - Cloud Code C# module#

This use case sample demonstrates how to reward your top players with in-game currency at the end of a season. The sample uses the reset event emitted by the Leaderboards service, and rewards the top players with in-game currency in Economy.

First, you need to create a service account with the required access roles and configure the UGS CLI.

Before you can call the Triggers service, you need to authenticate with a service account.

Add Product roles and create a key:

For more information, refer to Authentication.

Follow the steps below to get started with the UGS CLI:

Use the following to configure your Project ID and Environment:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Use the service account you authenticated earlier to authenticate. Refer to Get Authenticated.

The Leaderboards service emits a reset when a leaderboard is reset. The event payload looks like this:

The event payload passes on to Cloud Code as parameters.

Refer to the Leaderboards Reset event for more information.

This sample implements by deploying configuration files for each service with the UGS CLI.

To implement the use case sample, you need to set up the following files:

Create a folder called reward-top-players to store all the files. You can deploy them all at once.

To reward your top players with in-game currency, you need to create a virtual currency in Economy.

Create a Economy config file using the UGS CLI:

Add the following content to the COIN.ecc file:

The configuration defines a virtual currency and the name Coin. The file name corresponds to the currency ID.

Create a Leaderboard config file using the UGS CLI:

Add the following content to the leaderboard.lb file:

The configuration defines a leaderboard with ascending sort order and keeps the best score. The file name corresponds to the leaderboard ID.

You need to create either a Cloud Code module or script to define logic for rewarding your top players with in-game currency when the leaderboard is reset.

You can use the Economy and Leaderboards Client SDKs to interact with the Economy and Leaderboards services.

Create a new Cloud Code module using the UGS CLI:

Then, add the following contents to the sample solution. Create a module function with a string argument leaderboardId:

You can achieve the same outcome by creating a Cloud Code script.

Create a new Cloud Code script using the UGS CLI:

Then, add the following contents to the sample script file:

To connect your Cloud Code resource to the schedule, create a trigger. The trigger executes the Cloud Code script or module when the event fires, for example, when the leaderboard resets.

If you created a Cloud Code module, use the following configuration:

If you created a Cloud Code script, use the following configuration:

You should have the following files in your reward-top-players folder:

And one of the following:

You can deploy them all at once using the UGS CLI:

You can run the following Cloud Code script to add scores to the leaderboard from the Unity Dashboard. Make sure to select the Generate icon to regenerate the Player ID token on every test run to add a new player.

This allows you to add scores to the leaderboard and test the use case sample.

To validate the result, note down a player ID from the leaderboard before it's reset:

Then, reset the leaderboard:

To validate that the player has been rewarded with 10 coins, follow the steps below:

To learn more about how to configure your leaderboard resets to compliment your game logic, refer to Resets.

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
{
  "leaderboardId": "string",
  "leaderboardVersionId": "string"
}
```

Example 4 (unknown):
```unknown
{
  "leaderboardId": "string",
  "leaderboardVersionId": "string"
}
```

---

## Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/logging/concepts/authentication

**Contents:**
- Authentication#
- Authenticate players#
- Authenticate trusted clients (Basic authentication)#

The Logging API only accepts authenticated requests. The service can only be authenticated using Service Account Authentication.

The Logging API currently does not support player authentication.

You can use the Logging API with Service Account Authentication.

To access the Logging API, use Basic authentication.

Add Product roles and create a key:

Check Service Account Authentication for more information.

**Examples:**

Example 1 (unknown):
```unknown
<KEY_ID>:<SECRET_KEY>
```

Example 2 (unknown):
```unknown
Authorization
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-range-score-player-centered

---

## Glossary

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/glossary

**Contents:**
- Glossary#
    - Allocation#
    - Assignment#
    - Dedicated Game Server (DGS)#
    - Default pool#
    - Default queue#
    - Environment#
    - Filter#
    - Game client#
    - Match#

After a match is found, Matchmaker spins up a dedicated game server and updates the match with the server details. In the case of Multiplay Hosting, you must configure a fleet before making allocations from the matchmaker.

A field on a matched ticket that holds the details of the match and server, once allocated.

This is the game server binary that handles the game logic and where the Matchmaker allocates and routes the game clients upon successful matches.

A default pool is the first pool created within a queue and does not have any filters. Tickets that are not matched with other pools in the queue are placed in the default pool.

A default queue is the first queue created. Tickets created without queue properties or with empty queue properties will be routed to the default queue.

An environment is a global container that represents an instance of a matchmaker. For example, development, staging, and production.

A filter defines how a ticket is routed to the correct pool.

Players use the game client to play the game and interact with the matchmaker.

A match represents a group of tickets that are matched together into a game.

This is the core of Matchmaker. Analyze how the matchmaking logic can best enhance your game.

A player is a user trying to play a multiplayer game. Each player is represented by a unique ID.

A pool represents a dynamic separation of tickets within a queue. Each pool except the default pool contains a number of filters.

This represents the quality of the connection to different game servers. Specifically, the packet loss, latency, and an ID representing the region in which the game server resides.

A queue represents a predefined logical separation of matchmaking tickets within an environment. A queue has one or more pools.

Matchmaking rules determine how to logically pair tickets into matches when tickets are associated with a bucket.

A matchmaker ticket represents a player's (game client's) intent to find a match.

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/apple-privacy-survey

**Contents:**
- Apple privacy manifest#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

Note: Push Notifications is dependent on Unity Analytics. Refer to its manifest file for applicable data practices.

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

---

## Regions

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/regions

**Contents:**
- Regions#

Regions are geographic locations in which a fleet can host servers. Each fleet can have access to one or more regions. Each region within a fleet has independent scaling settings.

You can select a region and configure the scaling settings for that region when you create a fleet, or later from the Fleet scaling settings view in the Unity Dashboard.

Explore the following links to learn more:

---

## Integrate using Blueprints

**URL:** https://docs.unity.com/ugs/manual/matchmaker/manual/unreal-engine-sdk/integrate-using-blueprints

**Contents:**
- Integrate using Blueprints#
  - Install the Matchmaker SDK plugin#
  - Matchmaker Client Blueprint API#
    - CreateTicket#
    - DeleteTicket#
    - GetTicketStatus#
  - Matchmaker Server Blueprint API#
      - CreateBackfillTicket#
      - ApproveBackfillTicket#
      - UpdateBackfillTicket#

The following section shows how to integrate with the Matchmaker SDK using Blueprints in the Unreal Engine.

The two Matchmaker interfaces you can interact with within the Unity Gaming Services SDK are the:

Before continuing, add the MatchmakerSDK as a public dependency of your module, then include the plugin header files in your classes as shown below.

Add MatchmakerServer and MatchmakerClient to your module's dependencies to your Unreal project build file (YourProjectName.Build.cs):

The Matchmaker client subsystem controls the client portion of matchmaking and finding matches. This includes creating, deleting, and polling matchmaking tickets.

Use the static functions from UMatchmakerClientBlueprintApi to interact with the Matchmaker client subsystem through the following Blueprints:

To use CreateTicket, place a Create Ticket node in your blueprint. Populate the Players and Options fields for the inputs to create a ticket.

The following example shows how to pass in a single player and a queue name to create a ticket. It also shows an event that handles the response to get an FString output for the TicketId.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the event's Response struct pin and select Split Struct Pin to access all the individual values in CreateTicketResponse.

Use the DeleteTicket blueprint to issue a delete ticket call, passing in the TicketId to delete.

Below is a simple example demonstrating how to use Delete Ticket and how to handle the response.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the event's Response struct pin and select Split Struct Pin to access all the individual values in DeleteTicketResponse.

Use GetTicketStatus to poll the matchmaker for a match using the TicketId retrieved from the CreateTicket blueprint.

After polling completes either successfully or not, or if the user wishes to manually cancel matchmaking, use the DeleteTicket blueprint to stop considering the player(s) for matchmaking.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the event's Response struct pin and select Split Struct Pin to access all the individual values in GetTicketStatusResponse].

The image above shows an example of polling a matchmaking ticket with the Set Timer by Event node. When the looping condition is true, this node triggers its event continuously in the frequency that is set in the Time variable. In this case, Time is set to 5; therefore this event occurs every five seconds until the timer handler is canceled. The return value is the timer handler which you can use to cancel the timer using a Clear and Invalidate Timer by Handle.

The Timer handle gets passed from the Set Timer by Event node to the Clear and Invalidate Timer by Handle node. You should have some conditional logic to trigger Clear and Invalidate Timer by Handle. You must make most consecutive calls to GetTicketStatus before a match is returned. After the status no longer returns as InProgress, it's safe to stop polling and delete the ticket.

The following image shows a basic example of how to handle a polling response and trigger a Clear and Invalidate Timer.

The Matchmaker Server Subsystem controls the server portion of matchmaking. This includes creating, approving, deleting, and updating backfill tickets.

You can use the UMatchmakerServerBlueprintApi to:

You need to create a new backfill ticket after a player (or players) leaves a full match, and the server needs to fill the empty slots. Use the Create Backfill Ticket blueprint to create a new backfill ticket for the server.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the events Response struct pin and select Split Struct Pin to access all the individual values in CreateBackfillTicketResponse.

Use the Approve Backfill Ticket blueprint to periodically approve your backfill ticket to let new players into the server.

It's recommended to approve backfill tickets no faster than once a second. If a ticket goes for 20 seconds without approval, the Matchmaker service deletes it.

In the example above, approval runs in a loop every second. Be sure to use a Clear and Invalidate Timer by Handle node after deleting the backfill ticket.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the events Response struct pin and select Split Struct Pin to access all the individual values in ApproveBackfillTicketResponse.

Unity recommends caching the values from the response and using them to build the BackfillTicket in UpdateBackfillTicket.

Update the backfill ticket whenever:

This can include but isn't limited to party invites, direct connections, and friend invites.

Use the Update Backfill Ticket blueprint to update a server's current backfill ticket.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the events Response struct pin and select Split Struct Pin to access all the individual values in UpdateBackfillTicketResponse.

You should call this no more than once every three seconds or after ApproveBackfillTicket sees a change in the backfill ticket to guarantee a matchmaking cycle has passed.

Important: Updating a backfill ticket too often can cause players to never backfill into the match. See Matchmaking Logic Sample to learn more.

Unity recommends calling ApproveBackfillTicket first and using the BackfillTicket returned from ApproveBackfillTicket to modify as needed and pass into the UpdateBackfillTicket.

You can delete a backfill ticket after a match becomes full and the server no longer needs to accept new players. You should also do this after a match ends.

Use the Delete Backfill Ticket blueprint to stop backfill on a server.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the events Response struct pin and select Split Struct Pin to access all the individual values in DeleteBackfillTicketResponse.

Due to limitations in Blueprints, JSON data types (such as FJsonObject and FJsonValue) are not natively compatible and don’t support direct manipulation. The SDK implements a set of utility functions that allow you to manage JSON data as part of the API:

MatchmakerCore is included as a dependency when adding MatchmakerClient or MatchmakerServer.

In the MatchmakerClient module there is MatchmakerClientBlueprintUtil with

You can use this blueprint to add a string data field to a player’s CustomData object.

This returns true if the data is set successfully; otherwise, it returns false.

You can use this blueprint to add a number data field to a player's CustomData object.

This returns true if the data is set successfully; otherwise, it returns false.

You can use this blueprint to remove a data field from a player’s CustomData object.

This returns true if the player’s CustomData contains a Key and it was removed. It returns false if a Key wasn't found.

In the MatchmakerClient module there is MatchmakerClientBlueprintUtil with

Use this blueprint to add a string-based attribute to a CreateTicketOptions object. This returns true if the attribute is set successfully, and false otherwise.

Use this blueprint to add a number-based attribute to a CreateTicketOptions object. This returns true if the attribute is set successfully, and false otherwise.

Use this blueprint to remove an attribute from a CreateTicketOptions object.

This returns true if CreateTicketOptions contains the attribute and it was removed. If the attribute wasn't found, it returns false.

In the MatchmakerServer module, there’s MatchmakerServerBlueprintUtil with

You can use this blueprint to add a string-based attribute to a CreateBackfillTicketOptions object. This returns true if the attribute is set successfully, and false otherwise.

This blueprint is used to add a number-based attribute to a CreateBackfillTicketOptions object.

This returns true if the attribute is set successfully, and false otherwise.

Use this blueprint to remove an attribute from a CreateBackfillTicketOptions object. This returns true if CreateBackfillTicketOptions contains the attribute and it was removed, and false if the attribute wasn't found.

**Examples:**

Example 1 (unknown):
```unknown
MatchmakerSDK
```

Example 2 (unknown):
```unknown
MatchmakerServer
```

Example 3 (unknown):
```unknown
MatchmakerClient
```

Example 4 (unknown):
```unknown
YourProjectName.Build.cs
```

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/GetStarted

**Contents:**
- Get started#
- Set up Remote Config#
- SDK installation#

To get started with Remote Config, perform the following actions:

You can set up and manage Remote Config through the Unity Dashboard:

When you launch Remote Config for the first time, this adds Remote Config to the Shortcuts section on the sidebar and opens the Config page.

To access Remote Config, developers must meet the following requirements:

To get started with Remote Config, complete the following steps:

Although you must implement Unity Remote Config in your game code, you can update any rules and settings stored by the service by using Unity’s REST API or in the Unity Dashboard. To start segmenting, create a Game Override on the config value.

When using Remote Config in the Editor, go to Windows > Package Manager > Remote Config, and then install and import into your project. You see a representation of your settings in the Editor, similar to the Unity Dashboard.

Remote Config can work statelessly, which means that Unity does not store user data or look up user data for segmentation. In addition, you can use your own analytics solutions or data tracking solutions.

**Examples:**

Example 1 (unknown):
```unknown
Remote Config
```

---

## Sample app package contents

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unreal/manual/Unreal/vivox-unreal-sample-app/sample-app-package-contents

**Contents:**
- Sample app package contents#

The Unreal Shooter Game sample app package contains the following resources:

---

## Modify files

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/modify-files

**Contents:**
- Modify files#
- Open files from the Unity Dashboard#
- Modify files in the GUI#

To modify a file, open its local copy in your editing software and edit it as normal. UVCS detects any changes that you make and adds them to version control.

You can view and modify your files in your Workspace Explorer tab. Right-click a file or folder to open the context menu:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/cheat-prevention

---

## Merge rules

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/merge-rules/merge-rules

**Contents:**
- Merge rules#

Create merge rules to determine what conditions a merge needs to meet before you can merge successfully. When you merge a branch, the Unity Version Control (UVCS) server checks whether any rules apply to the involved source and destination branches.

A merge rule defines the following values:

**Examples:**

Example 1 (unknown):
```unknown
mergerules.conf
```

---

## Globally configure the branch explorer

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/branch-explorer-global

**Contents:**
- Globally configure the branch explorer#
- Global branchexplorer.conf file example#

Configure the branch explorer and use global configuration so that all clients have the same settings by default.

Refer to the following example of a global branchexplorer.conf file:

Note: The first rule is rule0.

A local branchexplorer.conf contains user-specific information too:

The GUI combines the global and local filters. The following example shows the resulting configuration for filters:

As a result of the combined rules in the example above:

**Examples:**

Example 1 (unknown):
```unknown
C:\Users\user\AppData\Local\plastic4\branchexplorer.cfg
```

Example 2 (unknown):
```unknown
$HOME/.plastic4/branchexplorer.conf
```

Example 3 (unknown):
```unknown
branchexplorer.conf
```

Example 4 (unknown):
```unknown
branchexplorer.conf
```

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/get-started

**Contents:**
- Get started#
- Safe Text guided setup#
- Supported languages#

To set up Safe Text for a Unity project, complete the following steps.

The following guide will be prompted after you select Begin guided setup from the Safe Text product page in the Unity Dashboard.

Note: The Moderation SDK is available in the following version of Unity in the Package Manager:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/use-anon-sign-in

---

## Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/authentication

**Contents:**
- Authentication#
- Server Authentication#
  - Scripting API with Authentication package#
  - Manually obtaining the token#
- Service accounts#
- Unity Services Gateway#
  - Example (list builds)#
- Unity Game Gateway#
  - Example (list allocations):#

The methods you must use for authentication vary slightly across the Multiplay Hosting service.

Administration API calls that change Multiplay Hosting resources use the Unity Service Gateway.

Game lifecycle API calls, such as allocating and deallocating, use the Unity Game Gateway.

Server Authentication is associated with the server, and can be obtained when running on a Multiplay Hosting machine.

It can be used for the Gaming Gateway.

You can retrieve a Multiplay Hosting token in the following ways:

Using the following call from the Authentication package:

You can also authenticate using a service account:

Note: Service accounts must have the Unity Environments Viewer role to look up available environments.

Refer to service accounts.

The token may also be obtain manually through a local request:

The request would return a response in the format below:

All API authentication require service accounts.

If you don't have a service account with a role appropriate for the request you intend to perform, refer to Create a service account.

Service Accounts and authentication are mainly for administrative privileges. Server Authentication are instead of trusted-game services.

Use the Unity Services Gateway (USG) to authenticate administrative APIs, such as managing builds, build configurations, fleets, and other Multiplay Hosting resources.

Use basic authentication to authenticate the API call.

This means that you create a string that has the KeyID and Secret key separated by a colon, then base64 encode it.

Many HTTP libraries and tools have built-in support for basic authentication. In this case you can use KeyID as the username and Secret key as the password.

Here is an example of creating the header and using it in a curl request to list builds:

You create a string containing Key ID and Secret key (separated by a colon), then base64 encode it.

This gives you the following value:

Which can now be used in an authorization header as follows:

For more information about this endpoint, and parameters used such asprojectID, environmentID refer to the Game Server API documentation.

The Unity Game Gateway uses a bearer token for authentication. To get a bearer token, you must first use your service account to request a time limited token from the Unity Game Gateway.

The Access Token follows is a JWT following RFC 7519 which can be interpreted by any JWT library to extract the exact an expiration time.

This example shows how to use make a request to the list allocations endpoint. This consists of two steps:

And receive the response:

The string accessToken string can be used with bearer authentication on subsequent requests to the Unity Game Gateway services. For example to list allocations:

For more information about this endpoint, and parameters used such as projectID, environmentID, and fleetID, refer to the Game Server API documentation.

**Examples:**

Example 1 (unknown):
```unknown
https://services.api.unity.com
```

Example 2 (unknown):
```unknown
https://multiplay.services.api.unity.com
```

Example 3 (unknown):
```unknown
await ServerAuthenticationService.Instance.SignInFromServerAsync();
var token = ServerAuthenticationService.Instance.AccessToken;
```

Example 4 (unknown):
```unknown
await ServerAuthenticationService.Instance.SignInFromServerAsync();
var token = ServerAuthenticationService.Instance.AccessToken;
```

---

## Verify label creation

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/tutorials/label-sample

**Contents:**
- Verify label creation#
- Validate that a label name starts with 'RELEASE'#
  - Trigger creation command#

You can create a trigger that runs before anyone creates a new UVCS label. In the following example, if the user enters a label name that doesn't start with release, the label creation fails.

if (ENV['PLASTIC_LABEL_NAME'] !~ /^release/) then exit(1) end

cm trigger create before-mklabel "check label name" "ruby c:\plastic\triggers\validate-label.rb"

**Examples:**

Example 1 (unknown):
```unknown
if (ENV['PLASTIC_LABEL_NAME'] !~ /^release/) then exit(1) end
```

Example 2 (unknown):
```unknown
cm trigger create before-mklabel "check label name" "ruby c:\plastic\triggers\validate-label.rb"
```

---

## Sample app examples of Vivox functionality

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unreal/manual/Unreal/vivox-unreal-sample-app/sample-app-vivox-examples

**Contents:**
- Sample app examples of Vivox functionality#

The Unreal Shooter Game sample app includes the following examples of Vivox functionality:

Note: The following features use Vivox APIs, but rely on additional game code.

---

## Unity Authentication

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/overview

**Contents:**
- Unity Authentication#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users in the unlikely event that Unity takes an action which impacts those end users under the DSA. To comply with this end user notification requirement, we developed a new notification API. If you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you need to integrate the new notification API by the effective date of the DSA, February 17, 2024. The following API is ready for adoption in late January 2024. Please refer to our DSA compliance efforts. Refer to DSA notifications to make your game compliant.

Apps typically need to know player identities to provide features and services to game developers and players that ensure security, consistency, and safety with every interaction.

Unity Authentication offers robust cross-platform account and authentication solutions that support cross-play and progression across all major devices and platforms. You can authenticate your players with anonymous, platform-specific, or custom sign-in solutions, making it easy for games with custom identity solutions to unlock the full power of UGS.

---

## PARTIAL SWITCH

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-switch

**Contents:**
- PARTIAL SWITCH#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Sets a branch as the working branch.

cm switch <branch_spec> [--report | --silent] [--workspace=<path>] [--noinput]

(Sets the working branch and updates the workspace.)

cm switch <branch_spec> --configure <+|-path>[ ...] [--silent] [--ignorefailed] [--ignorecase] [--workspace=<path>]

(Sets the working branch and runs a workspace configuration like the 'cm partial configure' command does.)

This command allows users to update the working branch. After updating the branch, the command updates the workspace to the new branch as the 'cm partial update' command would do. However, if the '--configure' option is specified, the command allows to configure the workspace using the new branch configuration as the 'cm partial configure' command would do.

cm switch br:/main/task

(Sets /main/task as working branch and updates the workspace.)

cm switch br:/main/task --configure +/art/images

(Sets /main/task as working branch and configures the workspace to load the /art/images folder.)

**Examples:**

Example 1 (unknown):
```unknown
cm switch <branch_spec> [--report | --silent] [--workspace=<path>] [--noinput]
```

Example 2 (unknown):
```unknown
cm switch <branch_spec> --configure <+|-path>[ ...] [--silent] [--ignorefailed] [--ignorecase] [--workspace=<path>]
```

Example 3 (unknown):
```unknown
cm switch br:/main/task
```

Example 4 (unknown):
```unknown
cm switch br:/main/task --configure +/art/images
```

---

## Use Xlinks

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/xlink-create

**Contents:**
- Use Xlinks#
- Use Xlinks in the GUI#
  - Create an Xlink#
- Modify an Xlink#
- Use Xlinks in the CLI#
  - Create an Xlink#
    - Create a partial Xlink#
    - Create a writable Xlink#
  - Modify an Xlink#

You can use Xlinks to share components between different repositories. For more information about what Xlinks are and how you can use them, refer to Xlinks.

You can create Xlinks in the UVCS desktop application.

Note: You can only create partial Xlinks through the command line.

You can also optionally set the writable and relative server options for the Xlink:

If you create a writable Xlink, you can set the expansion rules.

To modify an Xlink, right-click on the Xlink and select Edit Xlink. In the Edit Xlink dialog, you can edit the target changeset of the Xlink. If you have a writable Xlink, you can edit the expansion rules.

To create an Xlink, you need to use the cm xlink command. For more information, you can refer to the xlink CLI reference, or use the cm help xlink command.

For example, you can create the following Xlink:

Note: You can also specify a label instead of a changeset. Since a label is a pointer to a changeset, the two specifications are interchangeable. If you specify an xlink with a label, the xlink only uses the label to retrieve the changeset and sets the xlink to it. This means that if you move the label, the xlink still points to the original changeset.

Use a partial Xlink to mount a subdirectory in your repository. A partial Xlink has to be read only. For example:

In the above example, the Xlink ensures that any files in cs:478@mylibrary that exist in the subdirectory /src/dll appear as read only files under the /component1Src directory in the current workspace.

To create a writable Xlink, you need to specify the -w modifier, for example:

To modify an existing Xlink, you can use the -e modifier. For example, you can modify an existing Xlink component1 to point to changeset 5 on repository mylibrary:

For more information about how to modify an Xlink in the command line, refer to the xlink CLI reference, or use the cm help xlink command.

**Examples:**

Example 1 (unknown):
```unknown
cm help xlink
```

Example 2 (unknown):
```unknown
cm xlink component1 / 1@mylibrary
```

Example 3 (unknown):
```unknown
cm xlink component1 / 1@mylibrary
```

Example 4 (unknown):
```unknown
1@mylibrary@servername:8087
```

---

## 

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/sdk/unreal-engine-sdk/blueprint-integration

---

## Multiplay Hosting support

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/game-server-hosting-support

**Contents:**
- Multiplay Hosting support#
- Server allocation with Multiplay Hosting#
- Authentication#
- Server readiness#
- Backfilling#
- Build configuration launch parameters#

Integrate Multiplayer Services sessions with Multiplay Hosting to allocate servers, manage authentication, enable backfilling, and configure server readiness.

Multiplayer Services sessions are compatible with Multiplay Hosting to provide advanced multiplayer features. The Multiplayer Services package provides out-of-the-box support for Multiplay Hosting's Server query protocol, to retrieve information about a running game server using UDP/IP packets.

The easiest way to allocate a server on Multiplay Hosting is to use and configure it through Unity Matchmaker, which automatically allocates the game server. Unity's Multiplayer Services package helps with configuring the required hooks in Multiplay Hosting.

The following code demonstrates how to start an SQP-backed session on the server:

Note: When using Matchmaker, even though the maximum number of players in a match is defined on the configuration, it is necessary to set it here, as well. Make sure that the maximum number of players defined here is at least as large as the one defined on the Matchmaker.

This code automatically creates a session for players to connect to when the server becomes allocated. It should be called as soon as the server is ready to receive players.

Warning: A session created using Multiplay Hosting is automatically deleted when the server leaves the session, or stops.

Refer to Multiplay Hosting

If Multiplay Hosting's Server readiness feature is enabled in the build configuration, and the MultiplayServerOptions override the autoReady property, it is possible to set the server as ready to receive player connections using the following code:

When using Matchmaker, if the feature is enabled, the player is only assigned to the server once the server is ready.

Note: If you want to manually handle server readiness, set MultiplayServerOptions to false to override the autoReady property. Refer to the example in Multiplay Hosting support.

If the server was allocated with Matchmaker, it's possible to automatically request new players to join in order to backfill empty slots as a result of players leaving the session or because the match was created eagerly to minimize matchmaking time:

This code starts the backfilling process as soon as Multiplay Hosting allocates the server (if the session is not full). Additionally, this code automatically starts the backfilling process when the session has one more empty slot.

Note: If MaxPlayers defined here is not equal to the one in the matchmaking configuration, backfilling does not work as expected.

It is also possible to manually start and stop the backfilling process using the following code:

Starting and stopping the backfilling of a session can be useful if certain times are not appropriate for players to be joining (for example, if the session is about to end, or if a cinematic is in progress).

Refer to WithBackfillingConfiguration() for more information on the backfilling configuration.

The default launch parameters for games using sessions are the following:

Refer to Multiplay Hosting's Launch parameters for more information.

**Examples:**

Example 1 (javascript):
```javascript
#if UNITY_SERVER || ENABLE_UCS_SERVER

    // Please refer to the linked Server Query Protocol documentation.
    private const ushort k_DefaultMaxPlayers = 10;
    private const string k_DefaultServerName = "MyServerExample";
    private const string k_DefaultGameType = "MyGameType";
    private const string k_DefaultBuildId = "MyBuildId";
    private const string k_DefaultMap = "MyMap";

    IMultiplaySessionManager m_SessionManager;

    async Task ConnectToMultiplay()
    {
        if (UnityServices.Instance.GetMultiplayerService() != null)
        {
            // Authenticate
            await ServerAuthenticationService.Instance.SignInFromServerAsync();
            var token = ServerAuthenticationService.Instance.AccessToken;

            // Callbacks should be used to ensure proper state of the server allocation.
            // Awaiting the StartMultiplaySessionManagerAsync won't guarantee proper state.
            var callbacks = new MultiplaySessionManagerEventCallbacks();
            callbacks.Allocated += OnServerAllocatedCallback;

            var sessionManagerOptions = new MultiplaySessionManagerOptions()
            {
                SessionOptions = new SessionOptions()
                {
                    MaxPlayers = k_DefaultMaxPlayers
                }.WithDirectNetwork(),

                // Server options are REQUIRED for the underlying SQP server
                MultiplayServerOptions = new MultiplayServerOptions(
                    serverName: k_DefaultServerName,
                    gameType: k_DefaultGameType,
                    buildId: k_DefaultBuildId,
                    map: k_DefaultMap,
                    autoReady: false
                ),
                Callbacks = callbacks
            };
            m_SessionManager = await MultiplayerServerService.Instance.StartMultiplaySessionManagerAsync(sessionManagerOptions);

           // Ensure that the session is only accessed after the allocation happened.
           // Otherwise you risk the Session being in an uninitialized state.
            async void OnServerAllocatedCallback(IMultiplayAllocation obj)
            {
                var session = m_SessionManager.Session;
                await m_SessionManager.SetPlayerReadinessAsync(true);
                Debug.Log("[Multiplay] Server is ready to accept players");
            }
        }
    }
#endif
```

Example 2 (javascript):
```javascript
#if UNITY_SERVER || ENABLE_UCS_SERVER

    // Please refer to the linked Server Query Protocol documentation.
    private const ushort k_DefaultMaxPlayers = 10;
    private const string k_DefaultServerName = "MyServerExample";
    private const string k_DefaultGameType = "MyGameType";
    private const string k_DefaultBuildId = "MyBuildId";
    private const string k_DefaultMap = "MyMap";

    IMultiplaySessionManager m_SessionManager;

    async Task ConnectToMultiplay()
    {
        if (UnityServices.Instance.GetMultiplayerService() != null)
        {
            // Authenticate
            await ServerAuthenticationService.Instance.SignInFromServerAsync();
            var token = ServerAuthenticationService.Instance.AccessToken;

            // Callbacks should be used to ensure proper state of the server allocation.
            // Awaiting the StartMultiplaySessionManagerAsync won't guarantee proper state.
            var callbacks = new MultiplaySessionManagerEventCallbacks();
            callbacks.Allocated += OnServerAllocatedCallback;

            var sessionManagerOptions = new MultiplaySessionManagerOptions()
            {
                SessionOptions = new SessionOptions()
                {
                    MaxPlayers = k_DefaultMaxPlayers
                }.WithDirectNetwork(),

                // Server options are REQUIRED for the underlying SQP server
                MultiplayServerOptions = new MultiplayServerOptions(
                    serverName: k_DefaultServerName,
                    gameType: k_DefaultGameType,
                    buildId: k_DefaultBuildId,
                    map: k_DefaultMap,
                    autoReady: false
                ),
                Callbacks = callbacks
            };
            m_SessionManager = await MultiplayerServerService.Instance.StartMultiplaySessionManagerAsync(sessionManagerOptions);

           // Ensure that the session is only accessed after the allocation happened.
           // Otherwise you risk the Session being in an uninitialized state.
            async void OnServerAllocatedCallback(IMultiplayAllocation obj)
            {
                var session = m_SessionManager.Session;
                await m_SessionManager.SetPlayerReadinessAsync(true);
                Debug.Log("[Multiplay] Server is ready to accept players");
            }
        }
    }
#endif
```

Example 3 (unknown):
```unknown
MultiplaySessionManager
```

Example 4 (unknown):
```unknown
MultiplayServerOptions
```

---

## Get scores for a certain tier

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-score-by-tier

**Contents:**
- Get scores for a certain tier#

This method fails when your leaderboard is not configured with tiers. When you retrieve scores by tier, the returned LeaderboardEntry response tiers are contextual to the rank. For example, if a rank named Silver starts at rank 100 and a player’s global rank is 101, their rank within the Silver tier is 1.

Get the scores for a certain tier with the GetScoresByTierAsync method. By default this method returns the top 10 scores from the specified tier:

Paginated access to all scores within the tier is available by specifying the optional GetScoresByTierOptions object with the optional Offset and Limit pagination arguments.

Offsetis the number of entries to skip when retrieving the leaderboard scores and defaults to 0.

Limit is the number of leaderboard scores to return and defaults to 10.

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetScoresByTierOptions configuration object:

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
LeaderboardEntry
```

Example 2 (unknown):
```unknown
GetScoresByTierAsync
```

Example 3 (unknown):
```unknown
public async void GetScoresByTier(string leaderboardId)
{
    var scoresResponse = await LeaderboardsService.Instance
        .GetScoresByTierAsync(leaderboardId, "silver");
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 4 (unknown):
```unknown
public async void GetScoresByTier(string leaderboardId)
{
    var scoresResponse = await LeaderboardsService.Instance
        .GetScoresByTierAsync(leaderboardId, "silver");
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/sdk/unreal-engine-sdk/get-started

**Contents:**
- Get started#
- Understand the requirements#
  - Build the Engine from Source#
- Download the Multiplay Hosting SDK#
  - From the Unreal Engine Marketplace website#
  - From the Epic Games Launcher#
  - Building the project including the SDK#
  - Configure the Multiplay Game Server SDK#
- What's next ?#

The following instructions teach you how to install and configure the Multiplay Game Server SDK plug-in. After you’ve installed and configured the Multiplay Game Server SDK for your project, you can use the C++ or Blueprints integration.

The Multiplay Game Server SDK plug-in for Unreal Engine supports the Unreal Engine versions 4.27 to 5.3.

Unreal Engine requires you to use a source build to set up a dedicated server. Refer to Setting Up Dedicated Servers (Unreal Engine).

Perform the following steps to build the Unreal Engine from source:

At this point, you should have an Unreal Engine binary.

Refer to Building Plugins (Unreal Engine)

Multiplay generates the server.json file from information about the game server instance, such as the IP address, port number, and server ID. It also includes any configuration variables from the active build configuration.

The Multiplay Game Server SDK uses the server.json file to access the server query port variable ($$query_port$$) and the server ID variable ($$serverid$$).

To configure the server.json file in the Unity Dashboard, access Multiplay Hosting, then select Build Configurations.

You must include at least the queryPort and the serverID in the server.json file for your project. Refer to the following example server.json file.

Note: Refer to the server.json documentation.

Proceed with either integrations:

**Examples:**

Example 1 (unknown):
```unknown
Unity Gaming Services SDK for Unreal Engine
```

Example 2 (unknown):
```unknown
C:\Program Files\Epic Games\UE_5.3\Engine\Plugins\Marketplace
```

Example 3 (unknown):
```unknown
UnityGamingServicesSDK
```

Example 4 (unknown):
```unknown
MultiplayGameServerSDK
```

---

## PARTIAL CHECKOUT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-checkout

**Contents:**
- PARTIAL CHECKOUT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - To checkout an item#
  - Examples#

Marks files as ready to modify.

cm partial checkout | co [<item_path>[ ...]] [--resultformat=<str_format>] [--silent] [--ignorefailed]

If locks are configured on the server (lock.conf exists), then each time a checkout on a path happens, UVCS checks if it meets any of the rules and if so, the path will be in exclusive checkout (locked) so that none can simultaneously checkout. You can get all the locks in the server by using 'cm lock list'. Check the Administrator Guide to learn how locking works:

https://www.plasticscm.com/download/help/locking

cm partial checkout pic1.png pic2.png

(Checkouts 'pic1.png' and 'pic2.png' files.)

(Checkouts all png files.)

cm partial checkout .

(Checkouts current directory.)

cm partial checkout -R c:\workspace\src

(Recursively checkouts 'src' folder.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial checkout | co [<item_path>[ ...]] [--resultformat=<str_format>] [--silent] [--ignorefailed]
```

Example 2 (unknown):
```unknown
cm partial checkout pic1.png pic2.png
```

Example 3 (unknown):
```unknown
cm partial co *.png
```

Example 4 (unknown):
```unknown
cm partial checkout .
```

---

## Web triggers

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/webtriggers

**Contents:**
- Web triggers#
- Web trigger notifications#
- Additional resources#

You can use web triggers to connect your UVCS server with an external system. The UVCS server executes HTTPS POST requests to a configured URL and sends a JSON payload that contains information about the UVCS operation. The request body is a JSON dictionary that contains the trigger variables. Additionally, the standard input data appears as an array under the INPUT dictionary key.

You can use the endpoint that receives the JSON payload to create extensions to your UVCS server. For example, you can use a web trigger to ensure that any changesets created have a valid comment, or to send deployment requests.

Note: You can build your own web server to process web trigger requests made from the UVCS server, which allows you to create complex triggers. Otherwise, you can use a software integration service such as zapier.com, which integrate with a variety of popular applications.

You can use web triggers to send notifications about operations in your UVCS server. For example, you can set up the following:

---

## AUTOCOMPLETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/autocomplete

**Contents:**
- AUTOCOMPLETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Allows to implement autocomplete suggestions in a line at the cursor position.

cm autocomplete install

(Installs 'cm' command completion in the shell.)

cm autocomplete uninstall

(Uninstalls 'cm' command completion from the shell.)

cm autocomplete --line <shell_line> --position <cursor_position>

(Returns autocomplete suggestions for 'shell_line' to be inserted at 'cursor_position'.)

This command is not intended to be used by the final user, but it is documented in case it is needed to extend autocompletion support for the shell of choice.

cm autocomplete --line "cm show" --position 7

(Shows a list of commands starting with "show". In this case: showcommands, showfindobjects, showacl, showowner, showpermissions, showselector.)

**Examples:**

Example 1 (unknown):
```unknown
cm autocomplete install
```

Example 2 (unknown):
```unknown
cm autocomplete uninstall
```

Example 3 (unknown):
```unknown
cm autocomplete --line <shell_line> --position <cursor_position>
```

Example 4 (unknown):
```unknown
cm autocomplete --line "cm show" --position 7
```

---

## FASTIMPORT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/fastimport

**Contents:**
- FASTIMPORT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Imports Git fast-export data into a repository.

cm fast-import | fi <repspec> <fast-export-file> [--import-marks=<marks_file>] [--export-marks=<marks_file>] [--stats] [--branchseparator=<chr_separator>] [--nodata] [--ignoremissingchangesets] [--mastertomain]

cm fast-import mynewrepo@atenea:8084 repo.fast-export

(Imports the contents exported in the 'repo.fast-export' file into 'mynewrepo' repository on server 'atenea:8084'.)

cm fast-import repo@atenea:8084 repo.fast-export --export-marks=rep.marks

(Imports the contents exported in the 'repo.fast-export' file into 'repo' repository on server 'atenea:8084' and creates a marks file to perform incremental imports later.)

cm fast-import repo@server:8084 repo.fast-export --import-marks=repo.marks --export-marks=repo.marks

(Imports the contents of the 'repo.fast-export' file. Only the new changesets that were not in the marks file are imported. The same marks file is used to save the list of changesets again for the next incremental import.)

**Examples:**

Example 1 (unknown):
```unknown
cm fast-import | fi <repspec> <fast-export-file> [--import-marks=<marks_file>] [--export-marks=<marks_file>] [--stats] [--branchseparator=<chr_separator>] [--nodata] [--ignoremissingchangesets] [--mastertomain]
```

Example 2 (unknown):
```unknown
cm fast-import mynewrepo@atenea:8084 repo.fast-export
```

Example 3 (unknown):
```unknown
cm fast-import repo@atenea:8084 repo.fast-export --export-marks=rep.marks
```

Example 4 (unknown):
```unknown
cm fast-import repo@server:8084 repo.fast-export --import-marks=repo.marks --export-marks=repo.marks
```

---

## Query parameter values with SQL Data Explorer

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/query-parameters-sql

**Contents:**
- Query parameter values with SQL Data Explorer#
- Queries#
  - 1. Average potions used over a specific time range (day by day)#
  - 2. Average potions used over a specific time range (total time range)#
  - 3. Average potion used per dungeon name#
  - 4. Percentage of character use in dungeons per character name#
  - 5. Pivot table to count the character used per dungeon name#

Use the SQL Data Explorer tool to analyze the values of specific parameters.

Below are multiple ways of analyzing a parameter value with practical examples and comments on the queries to help you better understand how to replicate those for your game.

Use the below example if you want to understand the average potions used per player to see consumption at one point in time.

Use the below example to better understand where players are using potions in the game to balance your dungeons.

Use the below example to see the most popular characters in the game.

Use the below example to have a clear view of the number of times a character is used per dungeon name. This will help better balance characters and dungeons.

**Examples:**

Example 1 (unknown):
```unknown
with potionsStats as (
select
EVENT_DATE,
EVENT_JSON:potionsUsed::Integer as potions
FROM EVENTS where EVENT_DATE > CURRENT_DATE-7 and EVENT_DATE < current_date and EVENT_NAME='dungeonCompleted'
)
select EVENT_DATE as "Date", round(avg(potions)) as "Average Potions Used"
from potionsStats
group by EVENT_DATE
order by EVENT_DATE
```

Example 2 (unknown):
```unknown
with potionsStats as (
select
EVENT_DATE,
EVENT_JSON:potionsUsed::Integer as potions
FROM EVENTS where EVENT_DATE > CURRENT_DATE-7 and EVENT_DATE < current_date and EVENT_NAME='dungeonCompleted'
)
select EVENT_DATE as "Date", round(avg(potions)) as "Average Potions Used"
from potionsStats
group by EVENT_DATE
order by EVENT_DATE
```

Example 3 (unknown):
```unknown
potionsStats
```

Example 4 (unknown):
```unknown
potionsUsed
```

---

## CCD in the Unity Dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDDashboard

**Contents:**
- CCD in the Unity Dashboard#
- Buckets#
- Entries#
- Releases#
- Badges#

You can use Cloud Content Delivery (CCD) in the Unity Dashboard to create and maintain buckets, entries, badges and releases. You can also view helpful metrics concerning downloads and instances of errors related to your Cloud Content Delivery usage.

As an example scenario, you can use the Unity Dashboard to interactively manage an application’s assets using a more visual user interface than the CLI provides.

To access CCD in the Unity Dashboard:

If you already have a project, go to the next step. Otherwise, if you are using Unity services for the first time:

From the Unity Dashboard, select Products > Cloud Content Delivery.

Select the project you want to use with CCD from the projects dropdown.

By default, the production environment should be selected. However, you can switch environments using the Environments dropdown at the top of the Buckets page. We encourage our users to have at least a production and a development environment.

In the Cloud Content Delivery page for your project, you need to create buckets to host your content.

In the Create Bucket window, give the bucket a name and an optional description.

Specify whether you want to restrict write access to this bucket. Choose between:

To restrict read access to this bucket, select Enable Bucket Privacy. Private buckets only allow users with an access token to read the content.

You cannot change the bucket privacy settings after you create the bucket.

You can select the environments in which you want your bucket to be created. You can specify different privacy and write access settings for each bucket.

If the environment you’re in doesn’t have any buckets, but you have another environment with buckets, you can duplicate your buckets' setup from that environment by selecting Copy from Environment.

Then, in the dialog, take the following steps:

In the bucket list view, you can see the selected environment at the top, and then a list of all buckets from that environment. Each bucket has a details row that contains the following information:

An icon with a tooltip indicating whether the bucket is open to all (open box icon) or eligible for promotions only (closed box icon)

If the bucket is Private, a label with a closed lock image and the text "Private Bucket"

The description of the bucket

A snapshot of the current state.

For more information about a bucket, select its name in the list view. In the bucket details screen, there are the following tabs:

Latest: Shows the current state of the bucket, and the latest versions of all its content. From here, you can create a release. The asset list is paginated, searchable, and contains a filter. If your bucket does not have any unreleased changes, you can move a release from this bucket to another using the Promote Release button.

Releases: Displays all the releases you have created for this project.

Badges: Lists all the badges available for the releases of this bucket.

Targeting: Lists all game overrides using one of the bucket's badges.

You can delete a bucket by clicking on the Delete Bucket button, which appears in the header of the bucket details screen.

Buckets require content in order to create releases. This content comes in the form of entries (files) that you upload from a local source.

To add entries via the Unity Dashboard:

Files are uploaded at the root of the bucket. To update files in a child directory, you can either update the files manually in the entries list, or drag and drop your root directory, which will update all nested directories and files already in your bucket.

To cancel an entries sync command, press Cancel during the process. Any entries synced prior to cancellation remain uploaded, so you must delete them from your bucket.

After uploading your files, a box appears summarizing the process. Click Refresh Page to update the status of the bucket's information.

Select the name of an entry to access its details. A dialog opens displaying the following information:

The entry's file path

The type of content (set via the API)

The MD5sum content hash value

The current version of this entry in a format required for the Addressable URL

The Addressable URL of this entry

If you are using the Unity Addressables packages with your project, you can use this URL for your remote load paths.

A Copy to clipboard button appears to easily copy the Addressable URL.

Click the More Items menu (⋮) at the end of an entry's row to gain access to two buttons:

After changing your entries, each entry receives one of the following labels: Added, Modified, Unchanged, Removed. You can sort through any of these labels by using the dropdown found in the Current Entries list.

You can manage the releases you have created for your project on the Releases tab.

After you create a release, it appears in the list in the Releases tab, with its creation date and any associated badges. You can assign a badge and edit the release notes of a release via the More Items menu (⋮) at the end of a release’s row.

When you click on the Release # of a release in the list, you see the following information:

The GUIDs related to that release:

The Addressable remote path URLs for that release and its related badges

If you are using the Unity Addressables packages with your project, you can use this URL for your remote load paths.

Useful CLI commands that you can easily copy to clipboard using the available button

Some situations in your project’s release pipeline might require you to move a release from one bucket to another, which is a process called promotion. If your bucket does not have any unreleased changes, you can see the Promote Release button in your release’s details row.

To promote a release:

Attaching a badge to a release allows your application to load content from whichever release the badge is assigned to.

The badge now appears in the badge list in the Badges tab.

In the Badges table, you can see the following information:

The release to which the badge is assigned

The Addressables URL of the badge

If you are using the Unity Addressables packages with your project, you can use this URL for your remote load paths.

A button to quickly copy the Addressables URL

You can edit a badge’s associated release, or delete the badge via the More Items menu (⋮) at the end of a badge’s row. You can only assign a badge to a single release at a time, but you can associate multiple different badges to a release.

---

## Server slots

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-slots

**Contents:**
- Server slots#

Server slots are logical segments of machine resources (CPU and RAM) loosely reserved for instances of a build executable process. Multiplay Hosting uses the server density to calculate the number of server slots during the machine provisioning process. The exact resources allocated per server slot depend on the server density you define in the fleet. By default, Multiplay Hosting allows build executable processes to exceed the allocated resources of its server slot by a small margin of tolerance. If the process exceeds this margin of tolerance consistently, Multiplay Hosting considers the server as misbehaving.

---

## UPDATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/update

**Contents:**
- UPDATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Updates the workspace and downloads latest changes.

cm update [<item_path> | --last] [--changeset=<csetspec>] [--cloaked] [--dontmerge] [--forced] [--ignorechanges] [--override] [--recursewk] [--skipchangedcheck] [--silent] [--verbose] [--xml[=<output_file>]] [--encoding=<name>] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]] [--forcedetailedprogress] [--noinput]

The 'update' command only downloads needed files.

The command assumes recursive operation.

When the '--last' option is used, it is not necessary to specify a path. In this case, the workspace the current working directory belongs to will be updated. (Remember that specifying this flag could cause the workspace selector to be changed to a branch configuration if the selector was previously pointing to a changeset or a label.)

(Updates all in the current workspace.)

(Updates current directory, and all children items.)

cm update . --forced --verbose

(Forces retrieval of all revisions.)

cm update . --machinereadable --startlineseparator=">"

(Updates current directory and prints the result in a simplified easier-to-parse format, starting the lines with the specified strings.)

**Examples:**

Example 1 (unknown):
```unknown
cm update [<item_path> | --last] [--changeset=<csetspec>] [--cloaked] [--dontmerge] [--forced] [--ignorechanges] [--override] [--recursewk] [--skipchangedcheck] [--silent] [--verbose] [--xml[=<output_file>]] [--encoding=<name>] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]] [--forcedetailedprogress] [--noinput]
```

Example 2 (unknown):
```unknown
cm update .
```

Example 3 (unknown):
```unknown
cm update . --forced --verbose
```

Example 4 (unknown):
```unknown
cm update --last
```

---

## Unity Analytics

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/overview

**Contents:**
- Unity Analytics#
- Additional resources#

Note: By using Unity Analytics you agree that you have read and agree to the Terms of Service.

Unity Analytics provides an end-to-end data and analysis solution designed to support your entire studio. Analytics lets you easily understand game performance and player behaviors, providing valuable insights to help optimize overall gameplay.

Use Analytics to make informed decisions and enhance your game's success. Apply powerful engagement features and gather user behavior data on your experimental features, including core metrics analysis, A/B testing, and targeted push notifications. Segment players using Audiences, harness data-driven insights, and customize experiences for various player groups.

---

## Security

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/security

**Contents:**
- Security#
- Administration console password#
- Server administrator#

Use the security section of the server administration console to configure the following settings:

The administration console password is the password you enter to access the Unity Version Control (UVCS) Server Administration Console to apply the required changes to the server settings. This password is independent from the UVCS repository server permissions, users, and groups.

The server administrator is the owner of the repository server. You can reset the server administrator, for example, if the server administrator lost access to the server.

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal data collected about app users/game-players#
    - Developer defines#
- Relationship under privacy laws#
- Legal basis for processing#
- Consent#
- Data subject requests#
  - Access#
  - Deletion#
- Dependencies#

The Lobby service provides a way for players to discover and connect to each other to accomplish a variety of multiplayer gaming scenarios. The Lobby can persist for the duration of the game session to provide a mechanism for users to re-join an existing game session or facilitate host-migration after an unexpected disconnect.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default personal data collected (always collected in order for product to work)

Optional Personal Data Collected (personal data which may be collected at choice/action of the end user/Developer)

While this product allows for the collection of developer-defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they must implement it client-side in a way determined by the developer.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Unity Gaming Services support team with the Player ID of the end user that requested access.

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Unity Gaming Services team with the Player ID of the end user that requested data deletion.

Please note: This functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data access requests. To delete the Player ID created by the Unity Authentication SDK (if enabled), please use the Authentication API.

This product is dependent on the Unity Authentication product. By enabling this product, you will also be enabling the Authentication product and you should refer to Unity Authentication SDK for more information.

Lobby does not store IP Addresses or Player ID. However, the Player ID in Lobby logs has a retention period of up to 30 days.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## Moderation SDK

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/moderation-sdk

**Contents:**
- Moderation SDK#
- Report a player#
- Report reason#
- Actions#
- Evidence management#

Once the setup is complete, you can report players by using their UAS ID and providing a reason for the report.

Once the player is reported, you can navigate to the Unity Dashboard to review incidents with the attached report information.

If you’re using the Vivox v16.0.0 package or higher, the last 15 minutes of the conversation from the channel that the reporter and the reported were in will be attached to the report.

The following is an example of submitting a report:

Reasons are defined by Unity and are available as an array to display in your game:

The constants for each reason are in Moderation > Runtime > Models > ReportReasons.cs.

Actions are applied through the Dashboard when reviewing incidents.

When an action is applied, and the actioned user logs in, you will receive various error messages from the different UGS packages integrated with the Moderation services. Errors will follow the access control convention described in Error responses. This is the expected behavior.

Some SDKs will provide a mechanism to wrap those errors into exceptions of their own, for example, the Vivox SDK will emit a MintException when a policy is preventing a user from accessing communications.

Supported sanctions error list:

If you are using Vivox version 16.0.0 or higher in your project, the SDK automatically includes the list of channels both the reporter and reported players are part of. As well as the list of extra players that were part of those channels.

This information is used to add details to the evidence in the report.

To better control the report context, you can alter the list of channels and players included in the report before it's sent.

**Examples:**

Example 1 (unknown):
```unknown
using Unity.Services.Moderation;
using Unity.Services.Moderation.Models;
using Unity.Services.Moderation.Exceptions;

public async void Report(string userId)
{
    // userId should be the UAS id of the reported player
    // eg: the currently logged in user id is accessible with
    // var MyUserId = AuthenticationService.Instance.PlayerId

    try {
        var report = Moderation.Instance.NewReport(userId,
            new ReportReason(ReportReason.Threat));
        await Moderation.Instance.ReportPlayer(report);
        Debug.Log("Report submitted!");
    } catch (ModerationServiceException e){
        if (e.Reason == ModerationServiceExceptionReason.SelfReportError) {
            Debug.Log("Error: you can’t report yourself");
        } else {
            Debug.Log($"Error: {e.Reason}");
        }
    }
}
```

Example 2 (unknown):
```unknown
using Unity.Services.Moderation;
using Unity.Services.Moderation.Models;
using Unity.Services.Moderation.Exceptions;

public async void Report(string userId)
{
    // userId should be the UAS id of the reported player
    // eg: the currently logged in user id is accessible with
    // var MyUserId = AuthenticationService.Instance.PlayerId

    try {
        var report = Moderation.Instance.NewReport(userId,
            new ReportReason(ReportReason.Threat));
        await Moderation.Instance.ReportPlayer(report);
        Debug.Log("Report submitted!");
    } catch (ModerationServiceException e){
        if (e.Reason == ModerationServiceExceptionReason.SelfReportError) {
            Debug.Log("Error: you can’t report yourself");
        } else {
            Debug.Log($"Error: {e.Reason}");
        }
    }
}
```

Example 3 (unknown):
```unknown
using Unity.Services.Moderation.Models;

public ListReasons()
{
  foreach (var reason in ReportReason.PossibleReasons)
  {
      Debug.Log(reason);
  }
}
```

Example 4 (unknown):
```unknown
using Unity.Services.Moderation.Models;

public ListReasons()
{
  foreach (var reason in ReportReason.PossibleReasons)
  {
      Debug.Log(reason);
  }
}
```

---

## Pricing and billing

**URL:** https://docs.unity.com/ugs/en-us/manual/overview/manual/signing-up-for-ugs

**Contents:**
- Pricing and billing#
- View data usage#

Unity Gaming Services follow a pay-as-you-go pricing model. This means you only pay for services beyond the free tier limits.

Some services require you to enter payment information before you can access them. Services that require payment information display this requirement on the service landing page. For other services, you can get started without entering payment information. You can use services with a free tier up to the monthly usage limit.

If you exceed the free tier limit for any service, your access to all UGS services and APIs is blocked, and you can’t make configuration changes. You must enter payment details to re-enable full access to UGS. If you haven’t entered payment details within 30 days, the services are disabled for your project and your users won’t be able to access them.

You can monitor your data usage for services in the Service Usage page.

To view your data usage for services, in the Unity Dashboard, select Administration > Service Usage.

The Service Usage page displays an overview of all your data usage for all services. If you select a card in the Service Usage page, the Dashboard redirects you to the landing page for the service. This displays more information on the monthly limit for the specific service.

---

## Google Play data safety disclosures for Cloud Diagnostics

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/Privacy/GoogleDataSafety

**Contents:**
- Google Play data safety disclosures for Cloud Diagnostics#
- Data collection survey#
  - Data types#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Starting April 2022, Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Cloud Diagnostics. For your convenience, Cloud Diagnostics provides information on its data collection practices below.

Important: The data disclosures below are for the Cloud Diagnostics SDK only. You are responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please access Google's documentation.

To understand what data is collected by Cloud Diagnostics, refer to the tables below. Please note that while Cloud Diagnostics does not collect most of the following data types by default, some of these items may be collected if you have defined custom metadata fields.

---

## Unity SDK sample

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/tutorials/unity-sdk-sample

**Contents:**
- Unity SDK sample#

This sample shows how to use the Cloud Save SDK to save and load data.

You can find the sample in Unity by selecting Package Manager > Cloud Save > Samples.

**Examples:**

Example 1 (unknown):
```unknown
using System;
using System.Collections.Generic;
using System.IO;
using System.Text;
using System.Threading.Tasks;
using Unity.Services.Authentication;
using Unity.Services.CloudSave;
using Unity.Services.CloudSave.Models;
using Unity.Services.Core;
using UnityEngine;

namespace CloudSaveSample
{
    [Serializable]
    public class SampleObject
    {
        public string SophisticatedString;
        public int SparklingInt;
        public float AmazingFloat;
    }

    public class CloudSaveSample : MonoBehaviour
    {
        private async void Awake()
        {
            // Cloud Save needs to be initialized along with the other Unity Services that
            // it depends on (namely, Authentication), and then the user must sign in.
            await UnityServices.InitializeAsync();
            await AuthenticationService.Instance.SignInAnonymouslyAsync();

            // Player Data
            // first set of data saved without a write lock
            await ForceSaveSingleData("primitive_key", "value!");

            SampleObject firstSample = new SampleObject
            {
                AmazingFloat = 13.37f,
                SparklingInt = 1337,
                SophisticatedString = "hi there!"
            };
            string objectKey = "object_key";
            string writeLock = await ForceSaveObjectData(objectKey, firstSample);
            SampleObject incomingSample = await RetrieveSpecificData<SampleObject>(objectKey);
            Debug.Log(
                $"Loaded sample object: {incomingSample.AmazingFloat}, {incomingSample.SparklingInt}, {incomingSample.SophisticatedString}, write lock {writeLock}"
            );

            // second set of data saved with a write lock
            SampleObject secondSample = new SampleObject
            {
                AmazingFloat = 42.26f,
                SparklingInt = 4226,
                SophisticatedString = "hi there... again!"
            };
            string updatedWriteLock = await SaveObjectData(objectKey, secondSample, writeLock);
            SampleObject updatedSample = await RetrieveSpecificData<SampleObject>(objectKey);
            Debug.Log(
                $"Loaded updated sample object: {updatedSample.AmazingFloat}, {updatedSample.SparklingInt}, {updatedSample.SophisticatedString}, write lock {updatedWriteLock}"
            );

            // deletion with wrong write lock, this will fail with a validation error
            await DeleteSpecificData(objectKey, "incorrect-write-lock");

            // force delete without write lock
            await ForceDeleteSpecificData(objectKey);
            await ListAllKeys();
            await RetrieveEverything();

            // Custom Data, read-only
            string customTestId = "custom-test-id";
            await ListAllCustomKeys(customTestId);
            await RetrieveAllCustomData(customTestId);

            // Files
            var inputBytes = Encoding.UTF8.GetBytes("test content for file bytes");
            var inputStream = new MemoryStream(
                Encoding.UTF8.GetBytes("test content for file stream")
            );

            string bytesFileKey = "bytes-test-file";
            string streamFileKey = "stream-test-file";
            await SaveFileBytes(bytesFileKey, inputBytes);
            await SaveFileStream(streamFileKey, inputStream);

            await ListAllFiles();
            await GetFileMetadata(bytesFileKey);
            await GetFileMetadata(streamFileKey);

            var fileBytes = await LoadFileBytes(bytesFileKey);
            Debug.Log(
                $"Loaded sample file containing content: {Encoding.UTF8.GetString(fileBytes)}"
            );

            using var fileStream = await LoadFileStream(streamFileKey);
            using var streamReader = new StreamReader(fileStream);
            Debug.Log(
                $"Loaded sample file containing content: {await streamReader.ReadToEndAsync()}"
            );

            await DeleteFile(bytesFileKey);
            await DeleteFile(streamFileKey);
        }

        private async Task ListAllKeys()
        {
            try
            {
                var keys = await CloudSaveService.Instance.Data.Player.ListAllKeysAsync();

                Debug.Log($"Keys count: {keys.Count}\n" + $"Keys: {String.Join(", ", keys)}");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task ListAllCustomKeys(string customId)
        {
            try
            {
                var keys = await CloudSaveService.Instance.Data.Custom.ListAllKeysAsync(customId);

                Debug.Log(
                    $"Keys count for custom ID {customId}: {keys.Count}\n" + $"Keys: {String.Join(", ", keys)}"
                );
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task ForceSaveSingleData(string key, string value)
        {
            try
            {
                Dictionary<string, object> oneElement = new Dictionary<string, object>();

                // It's a text input field, but let's see if you actually entered a number.
                if (Int32.TryParse(value, out int wholeNumber))
                {
                    oneElement.Add(key, wholeNumber);
                }
                else if (Single.TryParse(value, out float fractionalNumber))
                {
                    oneElement.Add(key, fractionalNumber);
                }
                else
                {
                    oneElement.Add(key, value);
                }

                // Saving the data without write lock validation by passing the data as an object instead of a SaveItem
                Dictionary<string, string> result =
                    await CloudSaveService.Instance.Data.Player.SaveAsync(oneElement);

                Debug.Log(
                    $"Successfully saved {key}:{value} with updated write lock {result[key]}"
                );
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task<string> ForceSaveObjectData(string key, SampleObject value)
        {
            try
            {
                // Although we are only saving a single value here, you can save multiple keys
                // and values in a single batch.
                Dictionary<string, object> oneElement = new Dictionary<string, object>
                {
                    { key, value }
                };

                // Saving data without write lock validation by passing the data as an object instead of a SaveItem
                Dictionary<string, string> result =
                    await CloudSaveService.Instance.Data.Player.SaveAsync(oneElement);
                string writeLock = result[key];

                Debug.Log($"Successfully saved {key}:{value} with updated write lock {writeLock}");

                return writeLock;
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return null;
        }

        private async Task<string> SaveObjectData(string key, SampleObject value, string writeLock)
        {
            try
            {
                // Although we are only saving a single value here, you can save multiple keys
                // and values in a single batch.
                // Use SaveItem to specify a write lock. The request will fail if the provided write lock
                // does not match the one currently saved on the server.
                Dictionary<string, SaveItem> oneElement = new Dictionary<string, SaveItem>
                {
                    { key, new SaveItem(value, writeLock) }
                };

                // Saving data with write lock validation by using a SaveItem with the write lock specified
                Dictionary<string, string> result = await CloudSaveService.Instance.Data.Player.SaveAsync(oneElement);
                string newWriteLock = result[key];

                Debug.Log(
                    $"Successfully saved {key}:{value} with updated write lock {newWriteLock}"
                );

                return newWriteLock;
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return null;
        }

        private async Task<T> RetrieveSpecificData<T>(string key)
        {
            try
            {
                var results = await CloudSaveService.Instance.Data.Player.LoadAsync(
                    new HashSet<string> { key }
                );

                if (results.TryGetValue(key, out var item))
                {
                    return item.Value.GetAs<T>();
                }
                else
                {
                    Debug.Log($"There is no such key as {key}!");
                }
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return default;
        }

        private async Task RetrieveEverything()
        {
            try
            {
                // If you wish to load only a subset of keys rather than everything, you
                // can call a method LoadAsync and pass a HashSet of keys into it.
                var results = await CloudSaveService.Instance.Data.Player.LoadAllAsync();

                Debug.Log($"{results.Count} elements loaded!");

                foreach (var result in results)
                {
                    Debug.Log($"Key: {result.Key}, Value: {result.Value.Value}");
                }
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task RetrieveAllCustomData(string customId)
        {
            try
            {
                // If you wish to load only a subset of keys rather than everything, you
                // can call a method LoadAsync and pass a HashSet of keys into it.
                var results = await CloudSaveService.Instance.Data.Custom.LoadAllAsync(customId);

                Debug.Log($"{results.Count} elements loaded from custom Id {customId}!");

                foreach (var result in results)
                {
                    Debug.Log($"Key: {result.Key}, Value: {result.Value.Value}");
                }
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task ForceDeleteSpecificData(string key)
        {
            try
            {
                // Deletion of the key without write lock validation by omitting the DeleteOptions argument
                await CloudSaveService.Instance.Data.Player.DeleteAsync(key);

                Debug.Log($"Successfully deleted {key}");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task DeleteSpecificData(string key, string writeLock)
        {
            try
            {
                // Deletion of the key with write lock validation
                await CloudSaveService.Instance.Data.Player.DeleteAsync(
                    key,
                    new DeleteOptions { WriteLock = writeLock }
                );

                Debug.Log($"Successfully deleted {key}");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task ListAllFiles()
        {
            try
            {
                var results = await CloudSaveService.Instance.Files.Player.ListAllAsync();

                Debug.Log("Metadata loaded for all files!");

                foreach (var element in results)
                {
                    Debug.Log($"Key: {element.Key}, File Size: {element.Size}");
                }
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task GetFileMetadata(string key)
        {
            try
            {
                var results = await CloudSaveService.Instance.Files.Player.GetMetadataAsync(key);

                Debug.Log("File metadata loaded!");

                Debug.Log($"Key: {results.Key}, File Size: {results.Size}");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task SaveFileBytes(string key, byte[] bytes)
        {
            try
            {
                await CloudSaveService.Instance.Files.Player.SaveAsync(key, bytes);

                Debug.Log("File saved!");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task SaveFileStream(string key, Stream stream)
        {
            try
            {
                await CloudSaveService.Instance.Files.Player.SaveAsync(key, stream);

                Debug.Log("File saved!");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task<byte[]> LoadFileBytes(string key)
        {
            try
            {
                var results = await CloudSaveService.Instance.Files.Player.LoadBytesAsync(key);

                Debug.Log("File loaded!");

                return results;
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return null;
        }

        private async Task<Stream> LoadFileStream(string key)
        {
            try
            {
                var results = await CloudSaveService.Instance.Files.Player.LoadStreamAsync(key);

                Debug.Log("File loaded!");

                return results;
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return null;
        }

        private async Task DeleteFile(string key)
        {
            try
            {
                await CloudSaveService.Instance.Files.Player.DeleteAsync(key);

                Debug.Log("File deleted!");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }
    }
}
```

Example 2 (unknown):
```unknown
using System;
using System.Collections.Generic;
using System.IO;
using System.Text;
using System.Threading.Tasks;
using Unity.Services.Authentication;
using Unity.Services.CloudSave;
using Unity.Services.CloudSave.Models;
using Unity.Services.Core;
using UnityEngine;

namespace CloudSaveSample
{
    [Serializable]
    public class SampleObject
    {
        public string SophisticatedString;
        public int SparklingInt;
        public float AmazingFloat;
    }

    public class CloudSaveSample : MonoBehaviour
    {
        private async void Awake()
        {
            // Cloud Save needs to be initialized along with the other Unity Services that
            // it depends on (namely, Authentication), and then the user must sign in.
            await UnityServices.InitializeAsync();
            await AuthenticationService.Instance.SignInAnonymouslyAsync();

            // Player Data
            // first set of data saved without a write lock
            await ForceSaveSingleData("primitive_key", "value!");

            SampleObject firstSample = new SampleObject
            {
                AmazingFloat = 13.37f,
                SparklingInt = 1337,
                SophisticatedString = "hi there!"
            };
            string objectKey = "object_key";
            string writeLock = await ForceSaveObjectData(objectKey, firstSample);
            SampleObject incomingSample = await RetrieveSpecificData<SampleObject>(objectKey);
            Debug.Log(
                $"Loaded sample object: {incomingSample.AmazingFloat}, {incomingSample.SparklingInt}, {incomingSample.SophisticatedString}, write lock {writeLock}"
            );

            // second set of data saved with a write lock
            SampleObject secondSample = new SampleObject
            {
                AmazingFloat = 42.26f,
                SparklingInt = 4226,
                SophisticatedString = "hi there... again!"
            };
            string updatedWriteLock = await SaveObjectData(objectKey, secondSample, writeLock);
            SampleObject updatedSample = await RetrieveSpecificData<SampleObject>(objectKey);
            Debug.Log(
                $"Loaded updated sample object: {updatedSample.AmazingFloat}, {updatedSample.SparklingInt}, {updatedSample.SophisticatedString}, write lock {updatedWriteLock}"
            );

            // deletion with wrong write lock, this will fail with a validation error
            await DeleteSpecificData(objectKey, "incorrect-write-lock");

            // force delete without write lock
            await ForceDeleteSpecificData(objectKey);
            await ListAllKeys();
            await RetrieveEverything();

            // Custom Data, read-only
            string customTestId = "custom-test-id";
            await ListAllCustomKeys(customTestId);
            await RetrieveAllCustomData(customTestId);

            // Files
            var inputBytes = Encoding.UTF8.GetBytes("test content for file bytes");
            var inputStream = new MemoryStream(
                Encoding.UTF8.GetBytes("test content for file stream")
            );

            string bytesFileKey = "bytes-test-file";
            string streamFileKey = "stream-test-file";
            await SaveFileBytes(bytesFileKey, inputBytes);
            await SaveFileStream(streamFileKey, inputStream);

            await ListAllFiles();
            await GetFileMetadata(bytesFileKey);
            await GetFileMetadata(streamFileKey);

            var fileBytes = await LoadFileBytes(bytesFileKey);
            Debug.Log(
                $"Loaded sample file containing content: {Encoding.UTF8.GetString(fileBytes)}"
            );

            using var fileStream = await LoadFileStream(streamFileKey);
            using var streamReader = new StreamReader(fileStream);
            Debug.Log(
                $"Loaded sample file containing content: {await streamReader.ReadToEndAsync()}"
            );

            await DeleteFile(bytesFileKey);
            await DeleteFile(streamFileKey);
        }

        private async Task ListAllKeys()
        {
            try
            {
                var keys = await CloudSaveService.Instance.Data.Player.ListAllKeysAsync();

                Debug.Log($"Keys count: {keys.Count}\n" + $"Keys: {String.Join(", ", keys)}");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task ListAllCustomKeys(string customId)
        {
            try
            {
                var keys = await CloudSaveService.Instance.Data.Custom.ListAllKeysAsync(customId);

                Debug.Log(
                    $"Keys count for custom ID {customId}: {keys.Count}\n" + $"Keys: {String.Join(", ", keys)}"
                );
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task ForceSaveSingleData(string key, string value)
        {
            try
            {
                Dictionary<string, object> oneElement = new Dictionary<string, object>();

                // It's a text input field, but let's see if you actually entered a number.
                if (Int32.TryParse(value, out int wholeNumber))
                {
                    oneElement.Add(key, wholeNumber);
                }
                else if (Single.TryParse(value, out float fractionalNumber))
                {
                    oneElement.Add(key, fractionalNumber);
                }
                else
                {
                    oneElement.Add(key, value);
                }

                // Saving the data without write lock validation by passing the data as an object instead of a SaveItem
                Dictionary<string, string> result =
                    await CloudSaveService.Instance.Data.Player.SaveAsync(oneElement);

                Debug.Log(
                    $"Successfully saved {key}:{value} with updated write lock {result[key]}"
                );
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task<string> ForceSaveObjectData(string key, SampleObject value)
        {
            try
            {
                // Although we are only saving a single value here, you can save multiple keys
                // and values in a single batch.
                Dictionary<string, object> oneElement = new Dictionary<string, object>
                {
                    { key, value }
                };

                // Saving data without write lock validation by passing the data as an object instead of a SaveItem
                Dictionary<string, string> result =
                    await CloudSaveService.Instance.Data.Player.SaveAsync(oneElement);
                string writeLock = result[key];

                Debug.Log($"Successfully saved {key}:{value} with updated write lock {writeLock}");

                return writeLock;
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return null;
        }

        private async Task<string> SaveObjectData(string key, SampleObject value, string writeLock)
        {
            try
            {
                // Although we are only saving a single value here, you can save multiple keys
                // and values in a single batch.
                // Use SaveItem to specify a write lock. The request will fail if the provided write lock
                // does not match the one currently saved on the server.
                Dictionary<string, SaveItem> oneElement = new Dictionary<string, SaveItem>
                {
                    { key, new SaveItem(value, writeLock) }
                };

                // Saving data with write lock validation by using a SaveItem with the write lock specified
                Dictionary<string, string> result = await CloudSaveService.Instance.Data.Player.SaveAsync(oneElement);
                string newWriteLock = result[key];

                Debug.Log(
                    $"Successfully saved {key}:{value} with updated write lock {newWriteLock}"
                );

                return newWriteLock;
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return null;
        }

        private async Task<T> RetrieveSpecificData<T>(string key)
        {
            try
            {
                var results = await CloudSaveService.Instance.Data.Player.LoadAsync(
                    new HashSet<string> { key }
                );

                if (results.TryGetValue(key, out var item))
                {
                    return item.Value.GetAs<T>();
                }
                else
                {
                    Debug.Log($"There is no such key as {key}!");
                }
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return default;
        }

        private async Task RetrieveEverything()
        {
            try
            {
                // If you wish to load only a subset of keys rather than everything, you
                // can call a method LoadAsync and pass a HashSet of keys into it.
                var results = await CloudSaveService.Instance.Data.Player.LoadAllAsync();

                Debug.Log($"{results.Count} elements loaded!");

                foreach (var result in results)
                {
                    Debug.Log($"Key: {result.Key}, Value: {result.Value.Value}");
                }
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task RetrieveAllCustomData(string customId)
        {
            try
            {
                // If you wish to load only a subset of keys rather than everything, you
                // can call a method LoadAsync and pass a HashSet of keys into it.
                var results = await CloudSaveService.Instance.Data.Custom.LoadAllAsync(customId);

                Debug.Log($"{results.Count} elements loaded from custom Id {customId}!");

                foreach (var result in results)
                {
                    Debug.Log($"Key: {result.Key}, Value: {result.Value.Value}");
                }
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task ForceDeleteSpecificData(string key)
        {
            try
            {
                // Deletion of the key without write lock validation by omitting the DeleteOptions argument
                await CloudSaveService.Instance.Data.Player.DeleteAsync(key);

                Debug.Log($"Successfully deleted {key}");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task DeleteSpecificData(string key, string writeLock)
        {
            try
            {
                // Deletion of the key with write lock validation
                await CloudSaveService.Instance.Data.Player.DeleteAsync(
                    key,
                    new DeleteOptions { WriteLock = writeLock }
                );

                Debug.Log($"Successfully deleted {key}");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task ListAllFiles()
        {
            try
            {
                var results = await CloudSaveService.Instance.Files.Player.ListAllAsync();

                Debug.Log("Metadata loaded for all files!");

                foreach (var element in results)
                {
                    Debug.Log($"Key: {element.Key}, File Size: {element.Size}");
                }
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task GetFileMetadata(string key)
        {
            try
            {
                var results = await CloudSaveService.Instance.Files.Player.GetMetadataAsync(key);

                Debug.Log("File metadata loaded!");

                Debug.Log($"Key: {results.Key}, File Size: {results.Size}");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task SaveFileBytes(string key, byte[] bytes)
        {
            try
            {
                await CloudSaveService.Instance.Files.Player.SaveAsync(key, bytes);

                Debug.Log("File saved!");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task SaveFileStream(string key, Stream stream)
        {
            try
            {
                await CloudSaveService.Instance.Files.Player.SaveAsync(key, stream);

                Debug.Log("File saved!");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }

        private async Task<byte[]> LoadFileBytes(string key)
        {
            try
            {
                var results = await CloudSaveService.Instance.Files.Player.LoadBytesAsync(key);

                Debug.Log("File loaded!");

                return results;
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return null;
        }

        private async Task<Stream> LoadFileStream(string key)
        {
            try
            {
                var results = await CloudSaveService.Instance.Files.Player.LoadStreamAsync(key);

                Debug.Log("File loaded!");

                return results;
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }

            return null;
        }

        private async Task DeleteFile(string key)
        {
            try
            {
                await CloudSaveService.Instance.Files.Player.DeleteAsync(key);

                Debug.Log("File deleted!");
            }
            catch (CloudSaveValidationException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveRateLimitedException e)
            {
                Debug.LogError(e);
            }
            catch (CloudSaveException e)
            {
                Debug.LogError(e);
            }
        }
    }
}
```

---

## Installation

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/SDK-installation

**Contents:**
- Installation#
- Get started#
- Using the SDK#
- Economy in the Unity Dashboard#
- Environments#
- IL2CPP builds#

To get started with the Economy SDK:

The Economy SDK requires that an authentication flow from the Authentication SDK has been completed prior to using any of the Economy APIs, as a valid player ID and access token are required to access the Economy services. See Unity Authentication.

The Economy SDK is ready to use immediately when sign in with the Authentication SDK is complete. You may then call any of the methods in this guide to start interacting with the Economy data.

The functionality of the SDK is only available when you have published your first Economy configuration from the Economy Configuration page in the Unity Dashboard.

Environments are logical partitions for Unity Game Services that contain data associated with your project.

You can set the target environment in the Economy Configuration page in the Unity Dashboard and in your initialization scripts. For more information, refer to Unity Environments.

Economy does not currently support using Unity Editor's Faster (smaller) builds option when building with IL2CPP as the scripting backend. Instead, in Editor, select Build Settings > IL2CPP Code Generation > Faster runtime.

**Examples:**

Example 1 (unknown):
```unknown
await UnityServices.InitializeAsync()
```

---

## Lobby error messages

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/lobby-error-messages

**Contents:**
- Lobby error messages#
- Error Status#
- Error Details#
- Error codes#

The Lobby service returns errors in the "problem details" format (RFC 7807) including some additional fields that are consistent with most other UGS services.

The code property of an error response from the Lobby service can be used to programmatically identify the type of problem that has occurred. These codes are used by the SDK to automatically resolve certain issues (for example, refreshing an expired token, retrying a request that failed due to a transient error) and they are exposed to the developer in the exceptions thrown by the SDK so that the client can react appropriately.

Common error codes will be in the range 0-999. These are usually seen when there is an issue with some component in between the client and the lobby service (such as network connectivity, an authentication failure, or rate limit). In cases where these aren't handled transparently, they will usually indicate more serious errors with the service and should generally be more rare.

Lobby specific error codes will be in the range 16000-16999. These are used to identify specific error cases in the lobby service. Many of these are common and will occur during normal operation of the service and should be handled by the game developer to provide a smooth user experience. For example, when performing a Join action you may get the error LobbyNotFound (16001), which could just mean that the lobby you tried to join was deleted since the query results were returned and the game client should handle this gracefully.

It may seem like there is some overlap between certain common and lobby specific error codes (NotFound being the most obvious example), but they should not be handled the same way. The common NotFound error code likely indicates a functional problem with the SDK or API client (such as an incorrectly configured request URL). You should examine the error details for more information about the specific problem to identify how to resolve it.

**Examples:**

Example 1 (unknown):
```unknown
{
  "title": "Bad Request",
  "status": 400,
  "code": 16000,
  "detail": "request failed validation",
  "details": [
    {
      "errorType": "validation",
      "message": "count in body should be less than or equal to 100"
    }
    {
      "errorType": "validation",
      "message": "skip in body should be greater than or equal to 0"
    }
  ],
  "type": "http://unity3d/lobby/errors/validation-error"
}
```

Example 2 (unknown):
```unknown
{
  "title": "Bad Request",
  "status": 400,
  "code": 16000,
  "detail": "request failed validation",
  "details": [
    {
      "errorType": "validation",
      "message": "count in body should be less than or equal to 100"
    }
    {
      "errorType": "validation",
      "message": "skip in body should be greater than or equal to 0"
    }
  ],
  "type": "http://unity3d/lobby/errors/validation-error"
}
```

Example 3 (unknown):
```unknown
LobbyNotFound
```

---

## Use server read-only mode

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/readonly-mode

**Contents:**
- Use server read-only mode#
- Enter read-only mode#
- Leave read-only mode#
- Retrieve read-only status#

Change the Unity Version Control (UVCS) server between normal mode and read-only mode.

When the server is in read-only mode, the server only allows read operations, so no data changes. This is useful with the Jet back end because it allows you to perform backup operations without stopping the server.

To change read-only mode, use the cm admin readonly command.

Note: Only the UVCS server administrator can run this command.

To enter read-only mode, run the command: cm admin readonly enter.

The command waits for all current write operations to end before it switches the server to read-only.

To leave read-only mode, run the command: cm admin readonly leave.

To retrieve the read-only mode status, run the command: cm admin readonly status.

**Examples:**

Example 1 (unknown):
```unknown
cm admin readonly
```

Example 2 (unknown):
```unknown
cm admin readonly enter
```

Example 3 (unknown):
```unknown
cm admin readonly leave
```

Example 4 (unknown):
```unknown
cm admin readonly status
```

---

## Matchmaker Overview

**URL:** https://docs.unity.com/matchmaker/en/manual/matchmaker-overview

**Contents:**
- Matchmaker Overview#
- Features#
- Get started#

Matchmaker is part of Unity's growing suite of multiplayer services that are designed to help you create and operate multiplayer games no matter what engine you're using.

Note: Unity Matchmaker is offered free of charge when you're using Multiplay Hosting or a client-hosted solution provided by Unity (Relay and Distributed Authority).

With almost limitless customizability, Matchmaker is ready to grow and adapt with your game.

Visit the Support page to learn how to contact the Unity Matchmaker support team.

Use the Get started guide to learn how to start leveraging Matchmaker in your project.

Check out the following samples to help you get started:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/deallocations

---

## Atlassion JIRA integration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/issue-tracking/jira/jira

**Contents:**
- Atlassion JIRA integration#

Set up and work with the Atlassian JIRA integration in Unity Version Control (UVCS).

---

## Find changesets

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-changesets

**Contents:**
- Find changesets#
- Filtering options#
- Output options#
- cm find changesets examples#
  - Show changeset comments#
  - Filter by a specific word#
  - Find replicated changesets#
  - Find the parent of a specific changeset#

Find and filter changesets and changeset comments. To retrieve more information in regards to changesets, run the cm log command.

The following list displays the different filtering options (where) that are available to use with the cm find changesets command:

Note: The conditions changesetid, date, and owner, correspond to the Name, Creation date, and Created by columns in the Changesets tab of the UVCS desktop application.

The following list displays the different output options (--format) available to use with the cm find changesets command:

The following example shows the date and comment for all changesets that belong to the branch main/scm12800:

To filter for changeset comments that include a specific word, use the SQL syntax like and use the % characters for an approximate search:

Query changesets by the replication date. For information on how to find the last replication date, refer to replication log.

Use the returnparent to get the parent of a specific changeset:

**Examples:**

Example 1 (unknown):
```unknown
cm find changesets
```

Example 2 (unknown):
```unknown
changesetid
```

Example 3 (unknown):
```unknown
replsrcdate
```

Example 4 (unknown):
```unknown
replsrcrepository
```

---

## Cold copy back up and restore

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/backups/cold-copy

**Contents:**
- Cold copy back up and restore#
- Backup#
- Restore#

Stop and restart your Unity Version Control (UVCS) server to perform backup and restore operations. Both of these operations require that you stop and start your UVCS server.

Note: You can also create a cold copy with rdiff.

---

## Sort order

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/concepts/sort-order

**Contents:**
- Sort order#
- Highest to lowest#
- Lowest to highest#

You can can configure the sort order of scores on a leaderboard from highest to lowest or lowest to highest.

If you wanted to rank players by number of points scored in a game you might use highest to lowest so that the players with the most points rank at the top of a leaderboard.

If you wanted a leaderboard to rank how long it took a player to do something you might use lowest to highest so that players with the fastest time (lowest value) rank at the top.

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/privacy-and-consent

**Contents:**
- Privacy and consent#
- Privacy overview for Cloud Save#
- Apple privacy survey for Cloud Save#
- Google Play data safety for Cloud Save#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/get-started-end-users

**Contents:**
- Get started#
- Set up DevOps#
  - Sign up for Unity DevOps#
  - Set up DevOps in the Unity Dashboard#
- Use DevOps services#

Unity DevOps includes two services you can use to integrate, deliver and deploy your projects to compute platforms: Unity Version Control, and Build Automation.

Note: If you are added to a Unity organization or Unity Cloud project that uses DevOps, you only need a Unity ID to start working on the project.

When you complete the sign-up, the DevOps Overview page displays a series of onboarding tasks. You can complete the steps on the Overview page to help you get started with the DevOps service, including:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/repository-storage

---

## Relay message protocol

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/relay-message-protocol

**Contents:**
- Relay message protocol#
- Message types#
- Accept mode types#
- Standard header#
- Message bodies#
  - BIND message#
    - Security#
  - BIND_RECEIVED message#
  - PING message#
  - CONNECT_REQUEST message#

If you’re using the Relay SDK with UTP or with NGO for your project, the Relay message protocol is already supported. However, if you want to use an alternative engine or networking solution, you’ll need to implement the Relay message protocol before using it. Use the Relay message protocol specifications to implement the Relay message protocol.

The Relay message protocol expects you to express field values in big-endian order, also known as the “network order,” where the most significant byte occurs first.

Messages aren't authenticated except for the BIND message, which uses an HMAC signature.

Players can only connect and relay messages with other players from the same Unity project and environment. Relay rejects any attempts to communicate across Unity environments.

All messages have a standard header and a message-specific body. Check out Standard header and Message bodies.

The accept mode defines how a Relay server handles requests from clients trying to connect.

Relay only supports the AUTO accept mode. A connection mode of AUTO means the Relay server automatically accepts the connection if its capacity allows it (the number of connections must not exceed the maximum number of allowed connections).

All message types share a standard header that has a signature, the Relay message protocol version, and the message contained in the body of the packet.

The following table describes each field found in the standard header.

The value should be 0 for the initial release.

BIND messages are sent from a client to a Relay server to create a mapping from a client’s IP address and port for a specific allocation. This message is authenticated to verify the identity of the client.

The response received from the Allocations service has the information necessary for the client to authenticate its BIND messages. The response from the Allocations service to the BIND message shows the binding status.

Clients can send identical BIND messages as long as the client’s IP address and port haven't changed. For example, if a client sends a BIND message on a following connection after changing its IP address or port, the Nonce value must be greater than the previously supplied value.

The following table describes each field found in a BIND message.

Currently, only the AUTO accept mode is supported.

See Accept mode types.

The maximum allowed value is 255.

This field’s length is variable. The maximum length is 255 bytes.

You must sign the HMAC with the secret key returned from the Allocations service. If the HMAC is invalid, the Relay server silently rejects the BIND message.

The Relay server also validates the nonce value to mitigate message replay attacks by bad actors. If the Relay server determines that a nonce is invalid, it silently rejects it. If it’s the first time the client is binding to a Relay server with a BIND message, the nonce value can be 0.

Relay servers send BIND_RECEIVED messages to requesting clients to confirm they have successfully bound to the Relay server through a BIND message. After receiving the confirmation, the requesting client can initiate communication with a target client using a CONNECT_REQUEST message.

Note: The Relay server sends a BIND_RECEIVED message to the client for each successfully processed BIND request.

PING messages are simple messages that keep the binding between a client and a Relay server alive by resetting the client timeout. Relay servers automatically disconnect clients after 10 seconds of inactivity. Any message received by the Relay server involving this client, either as a sender or receiver, resets this timeout. For games with a lower message frequency, the PING message allows clients to reset the disconnection timer.

Tip: Clients must send PING messages every second or two in addition to the other messages to ensure the connection doesn’t timeout. If you’re using Relay with NGO, the network manager automatically keeps the connection alive. However, if you’re using Relay with UTP, you must manually keep the connection alive.

Each PING message has the client’s allocation ID and an arbitrary number that identifies the message.

When a Relay server receives a PING message from a client, it sends the packet back to the client without altering it. This allows you to use PING messages to check connectivity and measure round trip time.

The Relay server doesn't send back an error message if the allocation ID has expired.

Warning: Clients must bind with the Relay server through a BIND message before sending a PING message. The following scenarios will result in the Relay server returning a ErrClientPlayerMismatchERROR message:

The following table describes each field found in a PING message.

CONNECT_REQUEST messages are sent from a requesting client to a Relay server to establish a connection to a target client. The target player the requesting client wants to connect to (or the target client) is represented by ToConnectionData, which the Relay server decrypts to determine which player to connect with.

Warning: The target client and the requesting client must be on the same Unity project and environment.

Note: Relay servers have no formal idea of player groups (often referred to as sessions. All players within a logical game session are bound to the same Relay server. By extension of this, Relay doesn’t make any assumptions about the length of a player’s bindings and connections in relation to the game session. It’s up to the game client to determine whether players unbind from the Relay server at the end of a session or use the same binding for multiple sessions.

The following table describes each field found in a CONNECT_REQUEST message.

The maximum allowed value is 255.

This field has a variable length. The maximum byte length is 255.

A Relay server sends an ACCEPTED message to a requesting client after a successful connection to a target client.

Note: The Relay server returns the ACCEPTED message to the requesting client if the target client has fewer than their specified maximum connections.

The following table describes each field found in an ACCEPTED message.

The DISCONNECT message is the inverse of the CONNECT_REQUEST handshake and allows a client to disconnect from another client. A client can disconnect from any other client it has connected with by sending a DISCONNECT message to the Relay server.

When the Relay server receives the message, it removes the specified allocation ID from the requesting client’s list of connected players. The Relay server also forwards the DISCONNECT request to the host client so the client can update its map of connected players to remove the requesting client's Allocation ID.

The Relay server then sends the DISCONNECT message back to the client as a confirmation. If either of the allocation IDs in the message body is invalid, the Relay server sends an ERROR message instead.

Once a client has disconnected, the Relay server rejects all RELAY messages sent to that client’s allocation ID. A disconnected client can re-establish a connection with a CONNECT_REQUEST message.

Note: The host and connecting clients can both send a DISCONNECT messages. However, if a host client sends a DISCONNECT message, the client must migrate the joined players to a new host or disconnect them all. Relay doesn't handle host migration.

The following table describes each field found in a DISCONNECT message.

RELAY messages allow clients to send messages containing any arbitrary payload of bytes between each other without awareness of each other’s IP addresses and ports.

Before sending a RELAY message between clients, the Relay server ensures the client sending the packet has previously been authenticated as the FromAllocationID through a BIND message. If the client hasn't previously bound, the Relay server returns an ErrClientPlayerMismatch ERROR message.

The Relay server also ensures the two clients have an established connection through a earlier CONNECT_REQUEST exchange. The Relay server returns an ErrNotConnectedERROR message if the clients aren't connected.

If all validations pass, the Relay server sends the entire message to the ToAllocationID as-is. The Relay server doesn't send any confirmation message to the FromAllocationID.

Note: The maximum length of a RELAY message isn't guaranteed at the protocol level. It's defined by the configuration of the Relay server itself, which has a default maximum content length of **1400 **bytes and results in a RELAYmessage maximum size of **1438 **bytes.

The following table describes each field found in a RELAY message.

The maximum value is 1400.

CLOSE messages are idempotent messages that allow a client to unbind and deallocate from a Relay server. Clients should send a CLOSE message to the Relay server when leaving their game session or when closing the game client. Clients can only close their own bindings to the Relay server; they can't close another client’s binding.

Clients should send CLOSE messages multiple times to increase the chance of successful delivery. Because CLOSE messages are idempotent, there’s no risk of the Relay server sending an ERROR message if the client has already been disconnected.

The CLOSE message is a best effort to gracefully terminate an allocation, and there is no guarantee it will succeed. Because Relay servers can deallocate clients with a timeout, Relay servers don't rely on a CLOSE message to remove a client allocation.

The client sending the CLOSE message must be bound to the Relay server through a earlier BIND request. If the client isn't bound to the Relay server (or the client’s IP address has changed), the Relay server will silently reject the message. Use PING messages to prevent unintended allocation timeouts.

Note: Unbound clients still expire through timeout. See Client timeouts.

The following table describes each field found in a CLOSE message.

Relay servers use ERROR messages strictly to inform the client that an error has occurred.

The following table describes each field found in an ERROR message.

The following table describes each of the possible error messages a Relay server can send to a client.

Clients should use PING messages to prevent this error.

It's intended to inform the client that the IP address they're using has changed from the one the Relay server is aware of.

This error message indicates the client should re-bind with a new BIND message.

**Examples:**

Example 1 (unknown):
```unknown
BIND message
```

Example 2 (unknown):
```unknown
BIND message
```

Example 3 (unknown):
```unknown
BIND_RECEIVED message
```

Example 4 (unknown):
```unknown
BIND_RECEIVED
```

---

## How to use UVCS Jira extension

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/jira-plugin

**Contents:**
- How to use UVCS Jira extension#
- Configure Unity Jira connection in UVCS Desktop#
  - Client configuration parameters#

The UVCS desktop client provides support to work with Jira issue tracker, adding some nice features as:

In order to have synchronized the Desktop client with a Jira server (Jira), follow the next steps.

Note: Important for Jira Cloud users: If you use Jira Cloud, the User name must be the email address of the account, and the Password must be an API token. You can find out how to generate API tokens for your Atlassian Cloud account in their official documentation.

Note: Important for Next-gen projects Next-gen projects do not support this field. Leave the Custom Field ID blank to have the check in info added as a comment.

**Examples:**

Example 1 (unknown):
```unknown
Name=Issue types;Value=Bug,Task;Type=Text;IsGlobal=False
```

---

## View incident details

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/incident-details

**Contents:**
- View incident details#
- Incident details#
- Evidence#
  - Player Reports#
  - Safe Text incidents#
- Activity#

You can view the details of an incident by selecting the incident ID. Incident details are grouped into three categories on the incident page:

Details available include the ID, a timestamp, offense type, reporter, and offender.

If your project is connected to Safe Text, a risk score is listed representing the highest risk in Safe Text detections.

Safe Text behaviours will also appear if applicable.

You can assign a user to an incident from the incident page by selecting a user from the Assign to list.

Evidence is broken down into Text sessions and Event Logs.

Text Sessions list the sessions included in the incident and contextual text detections generated by context analysis. For more information about these details, refer to Context analysis.

Events available in the Event Logs view include the events around the incident report.

Events included in the Event Logs include:

Event logs include players leaving and joining the channel when an incident involves a Vivox channel.

For more information on how to populate incidents with evidence, refer to the Evidence documentation page.

When accessing Safe Text detections, the evidence section directly shows the text session screen.

Activities available in the Activity view include all the activities linked to the incident, such as creating the incident and assigning an Organization Owner or User.

Activities include the following actions:

You can add comments to an incident report from the Activity view by typing into the comment field, then selecting Submit.

---

## Find labels

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-labels

**Contents:**
- Find labels#
- Filtering options#
- Output options#
- cm find label examples#
  - Find all labels in a specific repository#
  - Find all labels created in a specific branch in a repository#
  - Find a branch with a specific label#
  - Find changesets created between two labels#

Find and filter labels.

The following list displays the different filtering options (where) that are available to use with the cm find label command:

Note: The condition date corresponds to the Creation date column in the Labels view of the UVCS desktop application.

The following list displays the different output options (--format) available to use with the cm find label command:

**Examples:**

Example 1 (unknown):
```unknown
cm find label
```

Example 2 (unknown):
```unknown
replsrcdate
```

Example 3 (unknown):
```unknown
replsrcrepository
```

Example 4 (unknown):
```unknown
replsrcserver
```

---

## PARTIAL ADD

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-add

**Contents:**
- PARTIAL ADD#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Requirements to add items#
  - Examples#

Adds an item to version control.

cm partial add [-R | -r | --recursive] [--silent] [--parents] [--ignorefailed] [--skipcontentcheck] <item_path>[ ...] [--format=<str-format>] [--errorformat=<str-format>]

cm partial add pic1.png pic2.png

(Adds 'pic1.png' and 'pic2.png' items.)

cm partial add c:\workspace\picture.png

(Adds 'picture.png' item in path 'c:\workspace'.)

cm partial add -R c:\workspace\src

(Recursively adds 'src'.)

cm partial add --parents samples\design01.png

(Adds 'design01.png' file and 'samples' parent folder.)

(Recursively adds all the contents of the current directory.)

cm partial add -R * --format="ADD {0}" --errorformat="ERR {0}"

(Recursively adds all the contents of the current directory, printing 'ADD <item>' for successfully added files, and 'ERR <item>' for items that could not be added.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial add [-R | -r | --recursive] [--silent] [--parents] [--ignorefailed] [--skipcontentcheck] <item_path>[ ...] [--format=<str-format>] [--errorformat=<str-format>]
```

Example 2 (unknown):
```unknown
cm partial add pic1.png pic2.png
```

Example 3 (unknown):
```unknown
cm partial add c:\workspace\picture.png
```

Example 4 (unknown):
```unknown
cm partial add -R c:\workspace\src
```

---

## Multiplay Hosting

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/welcome-to-multiplay

**Contents:**
- Multiplay Hosting#
- Get started#
- Interfaces#

Welcome to Multiplay Hosting, Unity's scalable server hosting platform.

Note: Multiplay Hosting is Unity's self-serve experience for hosting and scaling your game. If you’re using the legacy version of game server hosting, refer to the Clanforge documentation.

Typically, a game developer or studio has expertise in areas directly related to game creation, such as gameplay, animation, and level design. However, successfully managing the hosting and scaling of multiplayer games can be challenging, and time pressures to ship your game. These obstacles can make multiplayer games challenging to implement, especially if you don't have enough servers to meet the player demands. Refer to the Ecosystem overview and Integrations to learn more.

Multiplay Hosting removes the complexity of running and operating infrastructure at scale, so your development team can focus on creating engaging player experiences. It also provides ways for you to:

Use the Get started guide to learn how to start leveraging Multiplay Hosting in your project.

Also check out the following samples to help you get started:

There are multiple ways to integrate and manage your application with Multiplay Hosting:

---

## CHANGEUSERPASSWORD

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/changeuserpassword

**Contents:**
- CHANGEUSERPASSWORD#
- Description#
  - Usage#
- Help#
  - Remarks#
  - Examples#

Changes the user's password (UP).

cm changepassword | passwd

This command is only available when the security configuration is UP (user/password). See the Administrator Guide for more information:

https://www.plasticscm.com/download/help/adminguide

The old and new passwords are required.

**Examples:**

Example 1 (unknown):
```unknown
cm changepassword | passwd
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/privacy-overview

---

## Unity Version Control 6.x Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/6

**Contents:**
- Unity Version Control 6.x Release Notes#
- 6.0.16.1832#
  - New#
    - replica now shows detailed progress during metada…#
  - Bug#
    - When swiching between files in the pending change…#
- 6.0.16.1820#
  - New#
    - Gluon for Linux is also here!#
    - New cm help objectspec command includes the defin…#

This document contains all release notes for Unity Version Control major version 6.x, organized from newest to oldest.

Windows: replica now shows detailed progress during metadata transfer.

Mac GUI: When swiching between files in the pending changes view or the diff view, sometimes the first difference was not correctly displayed in the diff viewer. Now it's fixed.

Gluon for Linux is also here!

This is the second preview of the upcoming Plastic SCM 7.0 version, and the greatest thing we are showing is Gluon for Linux and OS X. The artist-centric UI we created to simplify workflows in game dev teams goes beyond the Windows land.

New cm help objectspec command includes the definition of the different object specs supported by Plastic.

Improved the help of the acl command. Marked some old commands as deprecated.

Moved the help of the cm from an embedded resource to a .txt file.

Server now gracefully rejects proxy server requests in PlasticProto saying "method not found" instead of throwing a null (made wrongly to the wrong server).

The checkin operation of an outdated item (i.e. a locally changed item unaffected by a previous update operation) should fail with the error "The parent revision of the item 'path' is inconsistent with the loaded one in the changeset cs:number'. However, when the checkin also includes an xlink under the same directory of the outdated item, under some special circumstances (depending on the internal children order) it was failing with a null reference error. Now, the null reference error is fixed and the expected "The parent ..." error is received.

Mac GUI: The client showed a message reporting about an unexpected error when the user closed a workspace window that had previously displayed the pending changes view. Fixed.

The checkin operation logged an error on the server if the contents of a deleted directory (item X) were moved inside an added directory with the same name, and both changes came directly from a merge (merge source in this case). The logged error message ' No revision has been found on the result tree for the merge change: item srcrev: type: Moved'. Despite this logged error, the checkin operation succeeded and its result was also OK. We've fixed this scenario so no confusing error message is logged anymore.

Mac GUI: Clicking the OK button in the Preferences window after changing any of the settings caused the whole client to close if the configuration files (client.conf, guiclient.conf) were read-only. Fixed.

Windows GUI: Some submodules were not visible in the Window GUI when they were displayed in "tree mode" and the user did not have permissions for "read/view" in the parent repository. Now it's fixed.

Gluon for OS X is here!

This is the first preview of the upcoming Plastic SCM 7.0 version, and the greatest thing we are showing is Gluon for OS X. The artist-centric UI we created to simplify workflows in game dev teams goes beyond the Windows land.

Gluon for OS X also features a redesigned overall style if you compare it to Plastic on OS X, and some of the key ideas will be soon applied to the rest of Mac UIs.

Gluon for OS X enables a work cycle that differs from the regular Plastic one, based on the following concepts: no branching, sparse checkouts, per-file like versioning (no need to sync the entire working copy before checking in a file).

Gluon is the perfect tool not only for artists in game development, but also for team members working on documents, binary assets and any other typically unmergeable content.

Together with Gluon we are also introducing image diff for OS X, capable of comparing images in many different formats.

This is the first outcome of the Gluon cross-platform effort, and the Linux version will follow shortly.

CLI: improved the way the "cm showacls" command formats the ACLs table. Now, it is easier to read and understand.

Mac GUI: The following UI improvements were added to the Branch Explorer view:

When using the right button, now the object clicked is selected before displaying the context menu. This way you can use the right button to select and show the context menu for an object with a single click (previously you need to left click to select the object, and then use the right button to show the context menu).

When searching for a branch, now we focus the ending part of the branch bounds. Normally the user wants to pay attention to the end of the branch, instead of the beggining.

Aesthetic change: Removed the progress spinner in the middle of the view that appeared after selecting an object.

GTK/Mac: The workspace explorer search field is not case-sensitive anymore.

Gtk GUI: Fixed a drawing issue in cross-branch parent links. Sometimes, when the parent changeset was very far in the x-axis the parent changeset link was wrongly drawn due to a Cairo issue. Workaround the issue using a clippign algorithm to draw only the screen-visible portion of the for parent links.

Gtk GUI: Fixed a search problem in the branch explorer. Sometimes, after refreshing the branch explorer, after clicking the search button the object was not focused in the visible clip. Now it's fixed.

The external image diff viewer focused the "onion skin" button, when the default view mode is "side by side". Now is fixed.

Gluon in Windows was trying to connect to do check connection in the main thread incorrectly (configuration dialog).

Scan network: fixed a null reference error that might be thrown while searching for Plastic SCM servers when the client machine was having unreachable networks configured.

Server webadmin: allow migrating from deprecated Oracle backend to another currently supported backend.

GTK & MAC: the "Allow to merge with pending changes" preference was not saved so when you close the GUI it's lost. Now the preference value is saved.

Windows Branch Explorer: strange undesired movements happened while navigating. Like you were looking for the beginning of a branch, dragging the diagram, and then the inertia scrolled unexpectedly in the Y axis.

It was hard to figure out, but it seems when Y movement was zero something weird happened. Now it is fixed :-)

Jet backend: From now on, the so-called 'high performance mode' will be enabled by default. This change won't replace any existing jet.conf config file setting (highperf=true|false).

REMARK: the 'high performance mode' will slighly increase plastic server's memory footprint.

Windows GUI: The progress indicator (this round figure that moves when an operation is in progress, like a merge) was not properly animated. Now it's fixed. We broke it when supporting high DPI because now gifs need to be properly resized to the current screen DPI.

GUI: Fixed a "null reference" error when clicking the "display full branch names" option from the branch explorer without server connection.

Linux and OS X: a workspace with pending changes failed to update when the "merge with pending changes" was not allowed. In reality this setting has nothing to do with this type of update (what we call update-merge), so it is now allowed (like it is on Windows).

First connection to Tube was always failing with "TubeWorkingMode is only valid through PlasticTube calls". It is fixed now.

PlasticProtocol (the super optimized protocol we are using as default since 6.0 and also supported by latest 5.0 and 5.4) is now capable of doing "retries".

What does it mean? You are sending a replication package to a remote server, connection is killed (you change network or whatever), Plastic will try to reconnect instead of just aborting the operation.

This has been supported in Remoting (the other protocol we have, which we want to deprecate soon) for years.

No-data replica is now ready! Grab metadata but skip data to have light but fully workable local repos.

You can use the --nodata flag in the cm replicate command to pull metadata to your repo while skipping the actual data.

== What is replica no-data all about ==

The motivation is clear: huge local repos (dozens of GB) are painful because you end up with tons of data you won't be using most of the time. Why not simply replicate the metadata so you can effectively branch and checkin, while getting the actual data from the original server on demand?

== An example is worth a thousand words ==

You just create a clean local repo, then replicate a single branch from the remote server, without data. You can branch from it, checkin, do whatever, and freely push changes back correctly, but your local repo will be tiny.

cm mkrep game-of-cores@localhost:8087

cm replicate main@game-of-cores@volantis:8087 game-of-cores@localhost:8087 --nodata.

cm mkbr main/got-1023

cm switch main/got-1023

Since localhost:8087 doesn't have any data, files will be downloaded from the original server volantis:8087 during update.

Your working copy will be fully operational, and your local repo will be tiny.

By the way, as soon as you checkin locally, new data will be entered in your local repo, no problem about that.

Finally, you will be able to push your newly created branch back to volantis:8087

cm replicate main/got-1023@game-of-cores game-of-cores@volantis:8087 --push

== What is the vision ==

Our vision here is: working distributed is the way to go but since we are online most of the time, why not take advantage of it?

All checkins go super-fast locally (waiting to checkin is a productivity killer), but we are online, so let's grab actual data from the central.

== What if I really need to go offline ==

First, if you updated your workspace while connected... well, you already have the data locally, so chances are we got you covered.

Alternatively, you can always continue using regular replica, which is fine.

Finally, there is a way to simply "hydrate" certain changesets (or branches) while the rest of the repo remains data-less :-P

== Hydrate - nodata perfect companion ==

Nodata replication has a perfect companion: the cm replicate hydrate command, which lets you download data for a certain changeset to your local repo from a given specified source.

cm replicate hydrate cs:1724@myrepo quake@central:8087

And you can also hydrate a branch if you want to (which will actually hydrate all its changesets):

cm replicate hydrate main@myrepo quake@central:8087

The revert operation was not locking (getting the exclusive checkout) the reverted files. Now the lock is done as expected.

The cloaked exception rules were not working inside a cloaked xlink. See an example:

Before the fix, all the workspace content was cloaked and no content was downloaded. The second line ('*.jpg') didn't affect the xlinked contents.

Now, that rule is properly applied to the whole tree and only these items will be downloaded:

REMARKS: this fix requires both server and client to be updated.

When configuring ignored/cloaked rules, the workspace-relative paths are still allowed by prepending the text "$workspace". But it was not properly working for exception rules.

$workspace/myproject/*

!$workspace/myproject/code.cs

Windows GUI: In the pending changes view, the diff viewer was not refreshed after checking in or undoing changes. Now it's fixed.

Server stopped listening to the input of a given network connection after discarding an unsupported method in PlasticProto only if the first request was bigger than 80KB.

It was all an issue with buffered reading being handled incorrectly under quite rare circumstances.

Modified replica code for push in the server so that fetching a huge amount of metadata doesn't end up with a cancelled remote transaction due to inactivity. The issue was that we were creating a remote transaction (plastic type of transactions, not database) on the remote server at the very beginning, then if the fetch took too long (like more than 30 minutes), the remote transaction was aborted and the replica failed after finishing the fetch phase on the local server and when connecting the remote to transfer the metadata.

Server was mistakenly closing sockets when the method call took more than 60 secs (extremely unusual but doable). This was because we entered a protection mechanism to prevent clients to stay connected forever, but we didn't consider that the socket is being monitored for closing (so we do a read) before the method finishes. Fixed now.

Windows installer: If the server was configured using auto-renewal token license, the upgrade could override port and authentication working mode. Fixed.

Windows GUI: In the pending changes view, the diff viewer was not refreshed after checking in or undoing changes. Now it's fixed.

Gluon: Allow to resize checkin comments textbox. Also support Ctrl+A to select all the text in the textbox.

Mac/GTK: Nested dynamic views weren't disposed correctly if their parent dynamic view was closed. Fixed.

Fixed a null during parallel update introduced in 6.0.16.1675

GTK: A new 'Browse repository on this changeset' context menu option was added to the Changesets View and the Branch Explorer changeset selection. It will show a dynamic view to navigate the repository contents in the selected changeset.

Mac: A new 'Browse repository on this changeset' context menu option was added to the Changesets View and the Branch Explorer changeset selection. It will show a dynamic view to navigate the repository contents in the selected changeset.

GTK: The new 'Browse repository on this changeset' view has been completed adding a context menu with the following options:

Diff with previous revision

Mac: The new 'Browse repository on this changeset' view has been completed adding a context menu with the following options:

Diff with previous revision

CLI: the unco command wrongly performed a full unco if it was called with a wildcard argument (e.g 'cm unco src\f*') that didn't match any contents on disk.

The wildcard arguments expand to generate a set of disk paths matched by the argument. When there are no matches, the "unco" command is called with an empty set, resulting in a full undo checkout operation (the same way as executing "cm unco" without arguments).

We fixed the wildcard argument behavior to avoid a full "undo checkout" operation if no disk paths are matched.

Release 1699 was unable to migrate data when Plastic Server ran as a Windows Service. All because a temporary db.conf file created in the wrong location (full path not specified ended up creating the file in an unexpected place running as SYSTEM account).

webadmin - the new web based server administration console.

The new web user interface will replace the old Windows-only admintool and configureserver and it is available on Linux and OS X. This way we close one long term request: cross-platform admin tool.

webadmin also implements an interface to configure users and groups (users.conf and groups.conf) replacing the previous Windows-only umtoolgui.exe.

webadmin provides not only a way to finely tune the server but also comprehensive documentation about what each parameter means and how to use it, and links to more information when needed.

The new admin console allows you to:

Configure the network, including ports (TCP, SSL), the auto-discovery service and more (REMARK: UDT is not working at this point, but it will be ready soon).

Configure authentication: to select the authentication mode (user-password, LDAP, Active Directory, etc), finely tune each mode (different params in LDAP, for instance) and even configure users and groups in UP.

Repository storage: to tune params and migrate to a different backend.

Advanced parameters like forcing specific client versions, timeouts, threadpool settings and more.

Configure the audit log.

Configure lock rules: that now are also auto-reloaded without having to restart the server.

Comprehensive license configuration: both during evaluation and server operation.

A new support functionality to easily create "support bundles" to send relevant info in seconds when an issue happens.

Monitor: a server monitoring panel to track health and performance parameters.

Quite simple, just open a browser to your server address like this: http://0.0.0.0:7178. We do not support HTTPS yet. So, don't open it up to the Internet.

Create support bundle not yet working on OS X.

UDT configuration not yet working.

Comment limit is not correctly working on the SQL backends yet.

HTTPS NOT supported yet, so do not open it up on public Internet.

Tube was not working with LDAP servers that had the Token configured.

Detected a performance issue in LDAP+UP groups with +3700 groups => groups.conf were reloaded each time group membership was checked, which was extremely slow. Fixed.

clconfigureserver: Entering an invalid key for some values (language, working mode...) in interactive mode caused the tool to exit. Fixed.

The server can now reload server.conf while running, which means authentication and many other settings can now be reloaded dynamically.

Now the server can change storage backend (entirely, or just individual settings) without restarting. In case key params like the database path are modified, the caches will be reloaded and all connections closed.

Fixed how sent and recv bytes were tracked in both plasticproto and remoting so that detailed checkin progress (and detailed save as added to Gluon) can show movement in slow networks.

Now the server watches for changes in remoting.conf and can reload the network configuration without restarts.

The server checks remoting.conf for changes every couple of seconds (checks the write time of the file previous to read its contents).

Example: suppose the server is listing on port 8087, and now you change it to work on 8088. Current active connections to 8087 won't be stopped, but new ones will be only accepted to 8088.

Remark: config reloading won't run if --port or --sslport arguments are used to launch plasticd.

lock.conf now is reloaded by the server if the file changes. No need to restart the server anymore to load lock rules.

Gluon configuration broken: it wasn't unable to list repositories. Fixed now.

It was a regression of a task to improve the handling of aliases introduced in 6.0.16.1533.

P4 sync: Now, if a Ctrl+C key combination is detected while a changeset is synced (exported or imported), the sync process will wait until the current changeset fully synced to prevent data mismatch between plastic and p4. After that, the sync process is gracefully stopped.

The Ctrl+C key won't be deteced if the sync operation is run in "cm shell" mode.

When issuing a Ctrl+C, the printed results about "changesets involved" could not match with changesets actually synced.

Windows GUI: Improved the pending changes autorefresh feature. Now, after the pending changes view is refreshed, we maintain all the UI state of the diff viewer (scroll position, current diff, ...), if the file did not change on disk. When the file changed on disk, we refresh the diff viewer as usual.

Now, merge changes can be undone without requiring the rest of the workspace changes to be undone as well. Additionally, non-merge workspace changes can be undone independently. The only current requirement is to undo all merge changes together: the undo must target either none or all of them at the same time.

Windows GUI: Pending changes view showed an error in a border case move operation without changing its contents: move an item in two steps so the final path it's the same as the original. Example:

The cm partial ci is not printing the right changeset. Instead of the created changeset, it was printing the branch head when the checkin was done (that was the parent changeset of the created changeset). Now it's printing the right one.

Server network layer: modified the way in which requests handle SSL auth. Now they are enqueued to the threadpool before doing any network reading, to free the network callback as soon as possible. This should fix a weird deadlock detected on a Linux server after hours of intense work (while others with even more load go fine).

Windows: The cm diff command wasn't using the appropriate file extension when downloading temporary files. This caused the image diff to fail if a particular changeset was used in the revision spec. Fixed.

CLI: The cm diff command failed (throwing a null reference exception) when a revision was specified by ID. Fixed.

Plastic will now consider the external tool exit code when performing file merges. This means that a merge tool that creates the output file and then crashes will be considered as a failed merge, whereas before just creating the output file was considered as a success.

Mac OS GUI: Mac OS X High Sierra (10.13) is now fully supported!

WebUI: The WebUI was unable to work against a Plastic SCM server configured in LDAPWorkingMode or UPWorkingMode due to a bug in the network layer that was overriding the user credentials introduced at login with the ones loaded from the WebUI client.conf file, which, in this case, does not have any. Fixed.

Resource dictionaries were not loaded properly in the windows GUI.

Triggers: changeset information in before-chattvalue and after-chattvalue was blank. Fixed.

Sometimes an unexpected error occurred when switching from list mode to tree mode in the pending changes view (working with changeslists). Now it's fixed.

Fixed the image alignment of the diff maximize/restore buttons.

Using the plastic protocol and the SSL channel, the server memory is unexpectedly growing. The problem was a memory leak on the plastic protocol detection. Now it is fixed.

clconfigureclient: The client configuration CLI tool now accepts generic --user and --password parameters for UPWorkingMode and LDAPWorkingMode. Forget about old style parameters (--LDAPuser and --LDAPpassword) because they are deprecated from now on. Oh, and its help text is now easier to read!

CLI: The 'cm partial checkout' command was ignoring the -R option, so directory contents weren't recursively checked out. Fixed.

CLI: The 'cm checkout' and 'cm partial checkout' commands were skipping files passed as command line arguments if the -R option was set. Only directories were affected. Fixed.

CLI: Running the 'cm partial add -R' command on a partial workspace resulted in an error, as the 'cm' utility was trying to expand the 'add' command as if it were a path because of the -R flag (that is why non-recursive add operations worked OK). Now it is fixed.

Windows GUI: The comments textbox on the Branch Explorer now has a vertical scrollbar to ease navigation through long comments, and all of the text can be selected at once with the CTRL + A shortcut. This closes the following Uservoice request: Extend Editing Existing Comments

CLI: The 'cm partial ci' command on a partial workspace was not printing the information about the items involved in the checkin, nor the resulting changeset spec. Fixed.

Previously, a user with permissions on the 'plastic-global-config' repository couldn't use the global configuration when he didn't have the view permission on the repository server. Now, a user only needs to have permissions on the plastic-global-config' repository to use the global configuration.

Windows GUI, gtk and mac clients: As requested in user voice Add an option to hide merge info in the diff viewer, we implemented a toggle button that allows to "skip merge tracking" in the diff view. The button is only visible when several merge sources have been detected. When you click the button, diffs are not groupes by merge.

Server admin tool: Now it is possible to select a different backend from Jet on new Plastic SCM installations.

REMARK: Migration from a non-empty Jet database is still unsupported.

Fixed some specific scenario where GitSync was not pushing and pulling the changesets in one single step.

After the changes made to fix an issue with server aliases (serveralias.conf) and LDAP server, the branches and tags created in Git do not get an owner on the Plastic side when pushed, which can lead to problems. Now it's fixed

When editing text files with some IDEs (e.g. Visual Studio) the target file is moved to a temporary path and then the new contents are written into the original path while the previous (renamed) file is deleted.

The Plastic Tracker service acknowledges this workflow, but it was not handled for added files. As a result, Plastic showed a private file on the original added path and locally deleted file on the temporary path.

Now, this workflow is handled for added files and Plastic shows the added file on the original path with the new content (without any locally deleted file on the temporary path).

The following cases for the match patterns - used to cloak, ignore, etc. - were fixed.

1- Rules like /Simulator/Runtime/videos/** were affecting both the directory (/Simulator/Runtime/videos) and everything under it (such as /Simulator/Runtime/videos/scene_1/movie.mp4). This was fixed to be applied only to the directory contents, not the directory itself.

2- Given this set of rules:

The expected behavior should be to match everything except the content under directory paths ending with Development/Programming/Sql. That means /src/foo.c should match but /src/Development/Programming/Sql/project_1/data.txt should be spared. However, it turned out that everything was matched except those directories whose path ended with Development/Programming/Sql themselves (which was kind of weird). This was fixed and it should be working as expected now.

WARNING this release has issues with GitServer. If you are running GitServer, do not upgrade to this release.

After the changes made to improve aliases, we realized the branches and tags created in Git do not get an owner on the Plastic side when pushed, which can lead to problems.

TeamCity plugin: The Plastic SCM TeamCity plugin now supports the automatic merge feature. Yay!

Windows GUI: The checkboxes in the 'pending changes' view are now bigger, according to the following User voice:

Make regular plastic client 'Pending Changes' checkboxes more like Gluon

Fixed issues with server aliases (serveralias.conf) and LDAP servers.

cm lrep unreachable.com:9090 having client.conf to unreachable:9090 but an alias to reachable:9090 => failed with "can't connect to server" because the code doing the login to LDAP was not handling aliases (normal calls were, but not the login).

cm lrep unreachable.com:9090 having client.conf already pointing to reachable:9090 and again an alias to reachable:9090 (typical case when you switch servers) => failed. The alias worked, but credentials were not recalculated, so it didn't work.

Both issues have been fixed and new tests added to avoid regressions.

Windows GUI: The pending changes view is now autorefreshed when it gets the focus, as requested in our UserVoice: Auto Refresh Pending Changelist Option. A new option has been added in the "pending changes view" options dialog to enable/disable this feature (disabled by default).

Windows GUI, macOS GUI and Linux (GTK) GUI: Now, the JIRA issue tracker extension is able to change the status of the associated issue to a branch / changeset based on a changeset comment. To do so, you can define your own keyword-status mappings: if the keyword is present on the changeset comment, the issue status will be changed to the defined status. The format of the mappings is as follows:

One example of this is:

If your changeset includes in its comment the keyword "[FIXED]" (with the brackets), your issue status will change to "Ready for QA". Bear in mind that the transition between statuses must be allowed by your JIRA workflow.

To configure this in Windows, you can go to Preferences > Issue Trackers > (JIRA configuration) > Status transitions.

To do the same on macOS or Linux, you must open your jira.conf file and add the following line, replacing the value:

This feature works binding issues to both branches and changesets. It is NOT necessary to have the Plastic SCM custom field ID set for this to work.

This feature closes the following UserVoice request: Jira integration should be able to transition issues through Jira workflow and maintain all data

Working on LDAP authentication mode, the proxy server could fail with the error 'Object 'SecurityHandler' has been disconnected or does not exist at the server.'. Fixed

When a shelve that contains a file that matches some "lock.conf" rules, the apply shelve operation was failing with the error 'The file XXX requires exclusive checkout, but it is not up-to-date in your workspace'. Fixed

Gluon: The "Undo changes" context menu option in the "Explore workspace" view didn't persist the workspace changes: the previous file contents were properly downloaded but the "controlled" state was lost when Gluon was closed. Fixed.

When there were path permissions defined on the repository, The 'apply shelve' operation was failing with the error 'You are working with out-of-date objects. Maybe your client or workspace is out of date, please update it.'. Fixed

The USN journal Change Tracker service was not installed properly if the PlasticSCM server was not installed. Now it's fixed.

JIRA extension: while building the necessary Uris to access the JIRA server, the extension was deleting the path were the JIRA server was running at. For example, if JIRA was running at https://myserver/jira, the extension would use only https://myserver to build the Uris. Fixed!

Linux (GTK) GUI and macOS GUI: if the gtkgui.conf / macgui.conf configuration files had an invalid workspace set as current, you were prompted with the "First use" welcome dialog even if you had perfectly valid workspaces in your plastic.workspaces configuration file! Not anymore ;)

Gluon: The program file is now a 64-bits executable file.

GUI: A new configuration file called 'externaltools.conf' is now available to run actions on the selected objects. It can be included in the plastic-global-config repository at /externaltools/externaltools.conf.

It allows you to define external applications and how they'll receive the selected object properties. This is the syntax:

objectType: the name of the targeted object. It can be either item, label, changeset or branch. They can be combined using ':' to separate them.

toolName: The name of the tool to be displayed in the context menu

pathToExecutable: Absolute path to the targeted application. Spaces don't need to be escaped or protected.

args: The arguments line to be passed to the targeted application. There are three currently supported placeholders: @object (replaced with the object name), @repository (replaced with the repository of the object) and @wkpath (replaced with the current workspace path). Please note that the replaced values might contain blank spaces, so they'll probably need to be surrounded with quotes.

This actions will apear as a new menu item called "External tools" in:

Branches view context menu

Changesets view context menu

Labels view context menu

History side panel context menu (only GTK & Mac)

This actions will appear appended to the "open" menu item submenu in:

History view (only Windows)

Cloud: Now, the comment of an object can be updated on the Cloud server.

Using some SQL backends, the update operation failed when an empty cloaked.conf was added to the repository. Fixed.

Windows GUI: The #regions in the C# language were not correctly collapsed when the diff option "collapse regions wihtout diffs" was enabled. Now it's fixed.

The global configuration system always loaded the default server global configuration (i.e. the server defined in the client.conf file) instead of the current workspace repository server. Fixed.

The Branch Explorer submenu in the branch explorer context menu of selected branches didn't enable the appropriate actions. GTK never allowed to navigate to the branch base and Mac submenu was always empty. Fixed.

Cloud: the upload performance of the checkin operation has been greatly improved. Now uploading big files (bigger than 4MB) is 3 times faster. For example uploading a file of 262MB takes 17 seconds now vs the 46 seconds before this change. This has been achieved with multi-thread uploads :-)

Now the checkin operation can upload the data in parallel to a standard server (not Cloud server). By default, a single uploader is used. For example: to use 5 uploaders, add the following entry in the client.conf file: <Upload_SendDataThreadCount>5</Upload_SendDataThreadCount>

Remember that the checkin operation was already uploading the data in parallel to the Cloud server. By default, the number blob writers used is 10 and it can be configured using the entry <NumBlobWriters>10</NumBlobWriters> in the client.conf.

Window GUI: Several UI improvements in the annotate view:

Removed the horizontal gradient in the metadata panel.

Automatic change the metadata foreground color, based on the background. When the background is dark, we chose a light color and vice versa, to maximize the contrast.

Show a tooltip with info when you place the mouse over the metadata line.

Included a "Annotate previous version" action in the context menu, next to "Diff contents of branch/changeset ..." actions.

When right-clicking a line and choosing "Diff contents of branch/changeset ...", the file that you are currently annotating is now be pre-selected in the diff window that appears.

GUI: The order of categories in the pending changes view, the merge view and the diff window has been altered. From now on, added items will be grouped at the bottom instead of being in second place.

This solves a popular request in our UserVoice: https://plasticscm.uservoice.com/forums/15467-general/suggestions/4078928-put-added-and-private-items-at-the-end-of-a-pendin

Plastic Change Tracker service for Windows is now automatically installed and started up.

When editing text files with some IDEs (e.g. Visual Studio) the target file is moved to a temporary path and then the new contents are written into the original path while the previous (renamed) file is deleted. Now, the Plastic Change Tracker acknowledges this workflow and shows the edited files as changed, instead of a private file on the original path and locally deleted file on the temporary path.

Added a new before-merge trigger. This trigger could be used to deny the merge of some branches if certain conditions are not met.

The trigger can be register using the following command:

Check the triggers reference to check all the available info on the merge trigger.

Remarks: the client and the server should be updated to use this functionality

Using the up/down arrow keys did not updated the scroll position in the annotate view. Now it's fixed.

Windows GUI: Now Plastic SCM client ask for pending changes before changing from "text based diffs" to "semantic based diffs". This prevents for loosing pending changes when switching between diff modes when the right file is editable.

CLI: Running the 'cm command' with the --xml and the --nostatus args at the same time caused a null reference exception. Fixed.

Windows GUI: Syntax highlight and method history were not available in the annotate view. Now it's fixed.

Using a client version newer than 6.0.16.1331 and a server version older than 6.0.16.1271, the update operation could fail with the error: "End of file". Fixed

Update on Linux, OS X can now skip setting permissions of files and directories (chmod) if you set IgnoreFsProt to yes in client.conf.

windows GUI: Included "ignore whitespaces" | "ignore EOL" | "ignore EOL and whitespaces" | "recognize all" options in annotate.

The server closes client socket connections correctly now and monitors for abandoned connections and is able to close them.

Clients were closing unused connections every 30 seconds (if conn was not used for 30 seconds) but a bug was preventing conns to close correctly. This provoked lots of conns to pile up.

The server is now capable of correctly handling closed conns and as said before, to deal with older clients and force-close abandoned conns (established but unused for a more than 1 minute).

New administration command: cm admin readonly.

This command allows switching the server between normal mode and read-only mode.

When the server is in read-only mode only read operations are allowed, so no data will be changed. This is useful using Jet backend because it allows backup operations to be performed without stopping the server.

The cm admin readonly command allows to:

Enter in read-only mode using 'cm admin readonly enter'. Once it's executed no more write operation will be allowed. The command will wait for all currently running write operations to end before it finishes.

Leave read-only mode using 'cm admin readonly leave". This action brings the server back to normal mode (i.e. write operations are allowed again).

Retrieve the read-only mode status using 'cm admin readonly status'.

This command can only be executed by the server administrator.

Mergetool: The 'Split conflict blocks' option was not working when a single line is added next to a single modified line. Fixed.

It was requested in the following UserVoice improve merge algorithm for additional lines

Linux CLI/GUI: The Plastic SCM client now takes advantage of the FTS functions to traverse the file system. This causes a 15% improvement in execution times, particularly in the cm status command.

CLI: A new 'editcomment' subcommand was added to the 'cm changeset' command. It allows to edit comments of existing changesets in a repository.

We fixed an issue with override permissions. Check the following example:

John belongs to groups "developers" and "leaders".

At rep server level, we enable "view" and "read" for both "developers" and "leaders".

Now in "code" repo, for "developers" we override "view" and "read" and they are left unchecked (not enabled or disabled).

Since John belongs to "leaders" too => he should be able to see "code" repo. But he didn't.

Now the update operation is cloaking the tree on the server side instead of on the client, so only the needed tree is sent from the server to the client. This is important when the repository is huge and we are working only with a small part of it using cloaked, as the sent tree will be only a few MB (or even KB) instead of hundred of MB that could be the size for a tree with millions of items.

The tree is cloaked taking into account the same cloaked configuration than the client:

The cloaked.conf of the workspace

The cloaked.conf of the client

The cloaked.conf of the global configuration

Windows GUI: now, the update and the checkin operations show theirs progress on Windows taskbar (starting from Windows 7). This way, you can still see the progress while doing other things.

This resolves the following UserVoice: use windows taskbar api

Big files (greater than 4MB by default) were downloaded even if the diff control was displaying a warning message acknowledging that the diff operation would take a long time. Now, this kind of files will be downloaded only when the "show diff" button is clicked. This affects the Pending Changes view, the Diff window and the Code Review window.

Windows GUI: Some of the dialogs shown around the checkin and the replica process did not have a parent. This could cause, if the user abandoned the GUI during a long running operation, that when said operation finished the user could find the GUI blocked because of a dialog that appeared elsewhere on the desktop, instead of on top of the Plastic SCM GUI. Fixed.

The Axosoft OnTime extension threw a NullReferenceException while loading the stored configuration if no configuration file was present. Fixed.

Gluon: the height of the "Undelete item" dialog (the one that lets you choose a path to recover a deleted file) was too short, almost hidding dialog buttons. Fixed.

Visual Studio Plugin: An unexpected ActiPro license dialog arised when diffing a branch, a changeset or current pending changes. Fixed.

Windows, Linux (GTK) and macOS GUIs, and CLI tools: now, by default, if you have pending changes to be checked in in your workspace, the Plastic SCM clients (both the GUI clients and the cm tool) will prevent you from performing a merge.

We introduced this to avoid issues while undoing merges to newcomers, but if you are familiar with how merge works, it is safe to disable this extra check.

To do so, you can do it from the GUIs under Preferences / Diff and merge / Allow to merge with pending changes, or manually editing your client.conf file adding the following key:

Before performing a merge, the GUIs will look for the same kind of changes that you have checked to look for on your "Pending changes" view preferences, meaning that, if you have a locally changed file, but you have the "Show changed items" option disabled on the Pending changes view, the GUI client will not prevent the merge even if the "Allow to merge with pending changes" option is disabled.

The cm CLI tool does not take into account the GUI settings, so it will look not only for checked out files, but also for locally changed, deleted, and moved files.

Windows GUI: moved paths were rendered in the "pending changes" and "diff" views as follows:

/dir/foo.c to /dir/bar.c

This was hard to read, specially when the path was long.

Now we highlight the changed portion of the path to make it more obvious, using the same colors used in diffs.

NOTE: We only highlight diffs in moved paths when the changes/diffs are displayed as a list. When they are displayed as a tree, diffs are not displayed.

Running the merge operation in a workspace with cloaked rules left the workspace in an inconsistent state for some uncommon scenarios. This happened when processing all merge conflicts, leaving the file conflict of a cloaked item unresolved and then processing all merges again. The operation then failed and no pending changes could be undone or checked-in. Fixed.

The "bug" section was not correctly formatted in the release notes viewer.

Build 1271 is the first 6.0 version to make it to the main downloads page.

It is being a while since we published 6.0.16.804 in Labs, back on January 23rd. While 6.0 has always been stable and ready for production, we decided to wait for some changes to be merged into 6.0 before going official.

This is a small summary of the major changes between 5.4 and 6.0:

Jet – the super-fast repository storage – unbeatable speed for all kinds of repos, shines with huge ones.

Floating licenses – the licensing solution for globally distributed enterprises.

Fast network protocol – reduces network footprint & enables backwards compatibility: 6.0 is now compatible with all versions since 5.0.

Heavily improved filter performance (cloaked, ignored, etc.)

Windows: 4k support + new workspace switcher design + multi-screen diff + integrated help links + non-locking checkin & update.

Linux/OS X: usability improvements, built-in SemanticDiff, merge explanation diagram, Branch Explorer filters plus a number of changes to create a smother experience.

All: Branch Explorer global configuration.

Visual Studio 2017 support.

Continuous Integration: GoCD support, heavily improved TeamCity, Bamboo and Jenkins (pipeline support).

Jet - the super-fast repository storage.

We have designed a new storage for our repositories. It is super-fast and scalable and it has been designed specifically to deal with the way in which Plastic handles data and metadata read and writes. As a special purpose storage, it is hard to beat in terms of efficiency.

We still support SQL databases (MySQL, SQL Server, SQLite, Firebird and a few others) but the goal is to enable Jet as default backend replacing SQLite and eventually make it the default even for large teams.

We created support for 2 different workloads in Jet:

Small server workload support: perfect to handle local repository replicas on laptops and workstations and even small team servers. It focuses on performance and not scalability.

High-scalability workload support: a more complex alternative focused on scalability workloads.

Right now, Jet is not enabled by default but you can use the admin tool on Windows to migrate your repos to Jet.

To configure Jet from scratch, simply create a jet.conf file in the same place where your current db.conf is located, with the following content:

basepath=the path to a directory where you want you Jet repos to live.

In terms of performance Jet runs circles around all the other alternatives. It is about 10 to 40 times faster than SQLite and SQL Server in metadata reads and writes, which makes the server up to 3-5 times faster in operations like big checkins. Jet is so fast that we were able to find other hotspots once the data layer was no longer the slow part, and we continue optimizing the server thanks to it. We will share the results of the benchmarks we ran both on Windows and Linux to compare to the other databases and also Git, which we now consistently beat even on Linux.

Floating license system.

We have implemented a new system for companies who require floating licenses.

The traditional licenses so far are based on "named users". If you have 3 licenses, then John, Mike and Sara can access Plastic and consume the 3 licenses. If Sara leaves the company, then the admin will need to deactivate Sara to allow Paul to use the server.

With floating it is different. The server handles a number of free spots. On startup, all spots are free. And as soon as users access the server, spots are reserved. Spots stay reserved for a given time then can be renewed or taken by a different user. The floating licenses tend to reflect the number of active users in the system during the labor day. As such, the leased time is set to a minimum of 8 hours.

Consider the same scenario described above but this time with floating licenses. We have 3 spots. Then Sara accesses the server and one license spot is reserved and kept for a period of time. Later John does the same and then Mike. Suppose Paul wants to access immediately after: since you only have 3 licenses, his connection will be rejected. But as soon as Sara, Mike or John reserved spots expire, Paul will gain access, without administration intervention.

Floating licenses are great for teams with a central server and offices around the globe: if you have 20 users in Madrid and 20 in Seattle, you won’t need 40 licenses but only 20 floating ones.

Full backwards compatibility.

A 6.0 client can connect to a 5.4 server, and a 5.4 client can connect successfully to a 6.0 server. This greatly simplifies upgrades because a "big-bang" deployment is no longer required.

Our intention is to keep backward compatibility even between major versions from now on.

Linux GUI Branch Explorer learns to filter.

A new "Branch explorer" submenu has been added to the Branch Explorer view context menu. It contains the previous "Go to branch base" menu item and three new options: 'Filter selected branches', 'Filter selected and related branches' and 'Filter pending merges for selected branches'. Each of them will refresh the Branch Explorer, showing only those branches affected by the selected filter. A new "Remove filter" button will appear. Clicking on it will clear the filter and refresh the Branch Explorer using the previous conditional filter settings (if present).

During the last six months version 6.0 didn’t stop evolving. We improved our internal working cycle (more here: http://blog.plasticscm.com/2017/04/how-we-do-trunk-based-development-with.html) and now releases are even more frequent, which means new features and improvements never stop arriving.

Take a look at the release notes of the 6.0 releases under Labs to get all the details, and don’t forget to check our new features at https://www.plasticscm.com/features/index.html

Linux (GTK) and Mac OS GUIs: If the file system watcher (used to calculate the current workspace changes) fails because it overran the maximum number of watches, the Pending Changes view will display a warning message informing the user about how to increase that limit.

IntelliJ IDEA plugin: The IDEA plugin has been upgraded to be compatible with IDEA 2016 and 2017. From now on only a single JAR file including all code dependencies will be published (instead of the previous plastic4idea.jar + core JAR pair). Support for older IDEA versions (8/11) has been dropped.

Windows, Linux (GTK) and Mac OS GUIs, and CLI tools: Since the release 6.0.16.960, the Plastic SCM GUIs (Windows, Linux, macOS) and the cm CLI tool are able to monitor the performance of the status operation, but you had to enable that feature through a setting in the client.conf file. Now, it is enabled by default.

To disable it, you must add to your client.conf configuration file the following key:

Cloud: the number of calls to the server performed by the move, rename and checkout operation has been reduced. For example, the move from the Plastic GUI items view is immediate.

New setting in remoting.conf to avoid the server to kill the thread attending a request when the client closes the connection.

The reason to add this is the following: we experienced crashes on servers on Linux. We think it is related to Mono 4.6, and it will be solved once we upgrade. We introduced the ability to cancel running requests, which is very useful. Suppose you run a cm find revs and then do CTRL-C. The server will keep processing. Killing the thread avoids that. But some Linux servers are having issues, so we add this new setting to disable this behavior.

IntelliJ IDEA plugin: the VCS status wasn't being updated after performing any of the available operations. This led to data inconsistency across the IDE. Fixed.

CLI: The getstatus command was crashing when ran with the '-R' parameter in a directory with no controlled children. Fixed.

Jet: Starting from this release number, the default server backend will be 'Jet' (database backend based on filesystem) for new installations of Plastic SCM.

(Previous installations will keep the configured settings).

From now on, the default communication protocol will be 'PlasticProto' (custom Plastic communication layer protocol), instead of .NET remoting based one.

This will reduce significantly network traffic, and it will improve overall performance too.

Triggers: The 'editreview' trigger will be launched now every time a review comment is created, edited or deleted.

JIRA extension: A new 'Resolved statuses' configuration entry has been added to the JIRA configuration. This new entry will hold a comma-separated list of status names to be considered as 'resolved'. The default value is 'Done', so no issues with status 'Done' will be shown in the task list on the New Branch dialog by default.

An awesome new feature: Plastic Change Tracker service for Windows to precisely track file moves and renames beyond heuristic guessing.

It is in experimental mode at this point. This new service takes advantage of the file system internals to precisely track file renames and moves, something we could only guess before (quite well, but just an heuristic after all).

It means binary file renames and moves (where diffing does not apply) will be incredibly precise now.

You need to install the new service: plasticchangetrackerservice.exe --installservice. Then you can start it with --start or simply going to the service control panel.

Use plasticchangetrackerservice.log.conf to configure log if needed.

Enable it in your client.conf creating a new XML entry named: UseChangeTrackerService, set it to YES.

Changes will only be precisely tracked while your client is open. You can do the changes directly in Explorer, but you need the Plastic client to be opened. We plan to improve this later.

How do you see it is working? Well, every move won't be "moved locally" but just "moved" now because the change is applied immediately.

PlasticProtocol now supports sending the "author" of commits for Git/P4 and fast-import syncs. So far only remoting supported this.

Windows GUI: Fixed some UI issues when using high DPI screens:

Diff view tree columns grew over and over when you opened the diff view several times.

Replication Source panels in Branch Explorer grew over and over when you refreshed the Branch Explorer view several times.

The Replication form content was not fully visible.

Windows GUI: The "Show in Branch Explorer" context menu option was not properly working for changesets, labels or branches from repositories different from the workspace repository. This happened when there were multiple Branch Explorer views in the same workspace.

The replica operation might leave duplicated branch names in the destination repository if the pushed/pulled branch name already existed in destination with a different parent id.

Windows GUI: Improved the memory consumption of the diff editors by 25Mb-50Mb (depending on the scenario) when displaying .NET files (C#, VB).

Triggers: Executable paths surrounded with single quotes weren't being properly identified. Fixed.

Command Line Interface: cm status command: The --cutignored option was acting as the --ignored option as well.

From now on, the --cutignored option will require the --ignored option to have effect. Example:

Let's say this is the cm status --private --ignored output in an example workspace:

If the command cm status --private --cutignoredd is run, only private items will appear:

However, if the --ignored argument is included (cm status --private --ignored --cutignored), ignored items will be displayed but the contents of ignored directories will be skipped:

Windows GUI: Repository-related views (such as 'repositories' view, 'create new repository' dialog, repository selection dialog and the server selection in the replication dialog) had their server text boxes replaced with a combo box containing a list of recently used servers. This makes easier for users to type in their desired server addresses.

Windows GUI: Support for high DPI screens. Now, fonts, icons and controls are correctly drawed when they are displayed in a high-res (retina) display.

Linux: Pending changes performance is now 40% faster with lots of privates (it affects both GUI and 'cm status' command). This is because we improved the path comparison performance. Disk-intensive operations will take advantage of this improvement too.

Mac OS GUI: Implemented dynamic diff window functionality to make it easier for users to diff their code in multi-screen setups.

Users can now show the diffs from a branch or changeset, move the window to a second screen and the diffs will be updated once a different changeset or branch is selected. This is really useful to review changes.

The dynamic diff window will be updated every time a different branch or changeset is selected in any of the related views (Changesets view, Branches view, Branch Explorer view). It works for shelves too. Please have in mind that multiple selections will not update the dynamic diff window.

This behavior can be overriden by launching the diff operation while the shift key is pressed. Additionally, the dynamic diff window update will stop if there are multiple diff windows on display.

Windows GUI: The filter in the 'Code Reviews' view is not performing server calls anymore. This caused the GUI to appear unresponsive when working with a remote server and the view contained a large number of code reviews. As a result, the filter is immediately applied and the GUI no longer freezes.

TeamCity plugin: Changeset comments including international characters were incorrectly displayed if the TeamCity server ran on a Windows machine. Fixed.

Gluon: The checkin view had problems when it lost the focus while the checkin operation was performed. The two weird behaviors were:

Office plugins were not correctly installed. Now it's fixed.

Gluon: now, you can save a given revision of a file to your computer. To do so, after selecting an item (both in "workspace explorer" and "configuration mode"), right click on a revision on the details panel on the right, and click the "Save this revision as..." menu item.

Improvements in ActiveDirectory servers working in LDAP mode. Now it is possible to:

Configure the user using the UPN (userPrincipalName) or the name (samAccountName). Previously only the name was supported.

Configure the attribute to display the user and group names. Previously only samAccountName was supported.

To configure the attribute used to display the name just add this setting to server.conf file (inside the ServerConfigData section):

Jet backend: the performance of the 'list repositories' operation has been improved.

Jet backend: the locks (exclusive checkout) resolution performance has been improved.

Jet backend: using Jet backend with high-performance mode enabled, commit a locked file was failing with the error 'The process cannot access the file 'Z:\jet\transaction\0bc91799-41af-4397-a910-e78f13ae4a90\items.dat' because it is being used by another process.'. Fixed.

Gluon: now, "Checkin changes" is automatically refreshed each time the window gets the focus. This way manual refresh is no longer needed.

Many users requested this so we are going to test how well it goes, although we are not big fans of auto-refresh ourselves ;-). If everything goes fine, we will enable this in the Plastic GUIs too.

Windows GUI: the "Open with" and custom "Open with" menu items are now enabled for directories on disk. They are useful, for example, for opening a directory on software prepared to do so, such as some text editors.

You can add custom "Open with" options through the preferences dialog, under "Custom 'Open with...'".

Gluon and Windows GUI: now, the maximum file size to download generate the preview of a file when that file is not loaded in the workspace (configure mode in Gluon, "Repository browser" mode in Windows GUI) is configurable. To do that, add the following key to your client.conf file:

The default value is 1 MiB (1048576 bytes). It means that, if the selected, non-loaded file size is more than 1 MiB, it won't be downloaded to generate its preview (but you will still be able to see its icon, if any, its size, and its attributes)

Linux (GTK) GUI and Command Line Interface: The filesystem watcher has been re-enabled and tuned up so it doesn't prevent the applications from exiting.

Mac OS GUI: The application bundle has been renamed to PlasticSCM.app. The CLI scripts will be automatically updated accordingly.

Windows GUI: the changeset coloring by replication source on the Branch Explorer was working erratically. Fixed.

Windows GUI: Some icons couldn't be loaded if the computer is set to use the Turkish culture. Fixed.

Windows GUI: Fixed a bug that prevented that outlining nodes were collapsed on diff. Also some outline nodes, for example C# properties were not expanded although they had differences. Now it's fixed.

The repositories view was displaying duplicate repository entries if the same server was included both as an automatic profile and inside the plastic.servers file. This also caused the repositories view to show an error message if it was set to Tree mode. Fixed.

Gluon: now, the workspaces list on the "Switch workspace" window has the focus by default, so you can directly type in your keyboard to focus a workspace on the list.

Under some particular cases, the update operation could fail to update some files displaying the error message 'Destination array was not long enough'. Fixed

GitSync: errors occurred when updating the remote git references were not shown. Thus, the pushed commits could seem missing since the branch reference was not updated. Now, if a reference cannot be updated, the error message is correctly shown by the command line. Example of the new output:

Windows GUI: The branches view was displaying an inconsistent behavior when it was set to Tree mode and the sorting column contained duplicated entries. Fixed.

Windows GUI: We improved the way to switch workspaces. Now instead of tabs there is a button with the last N recently used workspaces (7 by default).

You can change this value by editing the "RecentWorkspacesCount" property in the guiclient.conf file, placed on ~/AppData/Local/plastic4 directory.

The overall performance of filters (ignored, cloaked...) has been improved. Manually edited rules were particularly affected, so a major increase in filter performance is expected for those cases. Several operations will take advantage of these improvements, such as 'status' (pending changes) or 'update'.

Linux (GTK) GUI and Mac OS GUI: The pending changes view could have a wrong content after a large merge operation if the time to calculate the pending changes view was slower than the merge process time. Fixed.

Gluon: The loading of the 'Explore workspace' view could fail on some corner cases if the workspace was not properly initialized. Fixed.

Gluon: The workspace configuration was failing when the workspace was not properly initialized and the server contents could not be loaded. Fixed

Gluon: The 'Update forced' operation in the update report dialog was failing in some particular cases. It applied to errors coming from update operations that could not be applied. The related update forced dialog messages suggested to modify the workspace configuration and retry the update operation, but doing so led to a failure. Fixed.

Jet: The last write time of the storage files wasn't guaranteed to be correct on server stop. Fixed.

TeamCity plugin: Building full patches in server checkout mode failed if checkout rules were set. Fixed.

Installer: Fixed an unexpected error when uninstalling the Visual Studio package.

Visual Studio integration: Added support for Visual Studio 2017.

GitServer: The checksum of the git pack files, which comes from a 'git push' operation, is verified before processing the package.

Windows GUI: The "differences" window now remembers the size of the columns, and the sort column.

CLI: The annotate command now accepts a new --dateformat=date_format_str argument. This enables users to explicitly set the desired output format for dates involved in the annotate command. The command will fall back to the OutputDateFormat value in the client.conf file if no --dateformat argument is found.

Plugin core: the undo checkout command was throwing a null pointer exception. Fixed.

Unity 3D plugin: A error is thrown when you try to save changed files and some of them are exclusively checked-out by someone else. Fixed.

Windows GUI: If you closed the diff window while calculating differences, you could get a "Cannot access a disposed object" error. Now it's fixed.

Windows, Linux (GTK) and Mac OS GUIs: Now, the Plastic SCM GUI will measure the performance while looking for pending changes on your workspace. If the GUI detects that the performance of the operation is not as good as expected, depending on the cause, it will give you advice on how to improve it.

CLI tools: Now, the cm CLI tool will measure the performance of the status operation. If it detects that the performance of the operation is not as good as expected, depending on the cause, it will give you advices about how to improve it (except if the --machinereadable or --xml flags are set).

Configuration files: the performance warnings can be enabled through the client.conf file, adding the following key:

Linux (GTK) and Mac OS GUIs: The changesets view context menu includes a new option: "Diff with another changeset". It enables users to select a changeset in a context dialog and diff its contents with the selected changeset. This menu option is also available in the Branch Explorer when a single changeset is selected.

Linux (GTK) and Mac OS GUIs: The branches view context menu includes a new option: "Diff with another branch". It enables users to select a branch in a context dialog and diff its contents with the selected branch. This menu option is also available in the Branch Explorer when a single branch is selected.

Linux (GTK) and Mac OS GUIs: Changing the display options or the date filter in the Branch Explorer view of a workspace window caused the rest of the workspace windows to load that configuration without notice or updating the GUI controls. Fixed.

Cloud and Jet: Checkin operation with 'added' items and 'keep items locked' preference enabled failed. Now it's fixed.

The P4 sync was failing with directories with the FileSystem permissions changed. Fixed.

Bamboo plugin: Queries for changes in the first builds of each new plan will return an empty set. The improvement in the build time of that particular case is specially remarkable when creating a new plan for an existing repository with a long history (thousands of changesets).

Linux: The GPG keys used to sign the repositories have been updated, as they reached their expiration date. If you use a Debian-based distro, please run the following command to update your local apt-key list:

Replace ${DIST_NAME} with the distro name that applies to your current system: Debian_6.0, Debian_8.1 or Ubuntu_14.04.

GoCD plugin: A new Plastic SCM plugin is available for GoCD. It allows Plastic SCM to be set up as a pipeline material.

Since BL808 (6.0) the listlocks command was complaining that the user didn't have view permissions. The server was checking view permissions on the server instead of the repo. Fixed.

Visual Studio integration: Fixed an error when open a project from Plastic SCM.

TeamCity plugin: The build patch operation of server-side checkouts was building incorrect patches when there were moved or deleted changes. Fixed.

Jet backend: When a checkin operation failed and couldn't be completed, the next checkin operations on the same branch failed with the error 'The object is currently locked. Try later...'. Fixed.

Windows GUI: dynamic diff window to help diffing code in multi-screen setups.

You can show the diffs from a branch or changeset, move the window to a second screen, and the diffs will be updated when you select a different changeset or branch. This is super useful to review changes.

The diff window will be updated if you select a different branch in Branch Explorer or the branches view, and same for changesets. It works for shelves too.

You can skip this behavior launching the diff window using Shift + DoubleClick. When there are more than one "dynamic" diff, the diffs won't be updated.

Mac OS GUI: When right clicking an item in any view (items, branches, changesets) the selection did not change. Some users requested to change this behavior.

Now, when you right click an item in a view, the selection is changed, and then its context menu is displayed.

Eclipse plugin: Added support to find locally moved, renamed and deleted files. You can find these options clicking the "options" buttons in the pending changes view.

Jenkins plugin: Each build will publish environment variables containing the data of the built changeset for each configured workspace. These are the exposed variables of the main workspace for the project:

Additional workspaces will include their position in the list, like this:

Command Line Interface: The checkin result will return the created changesets list as a comma-separated list when the --machinereadable parameter is present.

Bamboo plugin: Branch detection was only working for direct children of the main plan branch. This restriction has been removed.

Bamboo plugin: The silent merge (using the Plastic SCM MergeTool) wasn't working anymore. Fixed

Linux (GTK) GUI and Mac OS GUI: Performing a merge operation using the --nointeractiveresolution parameter didn't have any effect. Fixed.

Windows GUI: Clicking an object on the Branch explorer seldom displayed an error message regarding an index out of range error. Fixed.

Windows GUI: Dialogs with multi-line text areas didn't have text wrapping enabled. This affected the checkin comments text field, the create branch dialog, the new label/attribute dialog and the code review comments dialog. Fixed.

Windows GUI: The Branch Explorer filters where being applied after drawing the diagram, so they were not correctly shown until the Branch Explorer was refreshed. Fixed.

Cloud Server: When the encryption keys were incorrectly set, the decryption process was failing with the following misleading error message: 'Padding is invalid and cannot be removed'.

From now on, a more descriptive message will be shown: 'Data cannot be decrypted, please ensure your encryption key password is correct'.

Cloud Edition was incorrectly asking for credentials, when it already had the right ones configured.

Trying to delete or move the currently loaded changeset in the workspace with privates incorrectly warned of pending changes. Fixed.

Sync View: Under certain circumstances, the sync replication view could fail with the following error: 'An item with the same key has already been added'.

This error could happen since 5.4.16.809 on 5.4 versions and since 6.0.16.804 on 6.0 versions. Now it's fixed.

This is the seventh release of the new Plastic SCM 6.0 series. It includes important core improvements and features. It is published in the "labs" channel instead of the official one because there are some important design changes still to be delivered, although it is stable enough to be used in production.

Mac OS GUI: The 'Create'/'Rename' dialogs of the 'Workspaces' view and the 'Repositories' view allowed tabs to be inserted at the beginning or end of the text input fields. Fixed.

Windows Mergetool: code folding was wrongly enabled for the merge, causing drawing errors when code regions were folded. Fixed.

Server: An error message containing "The object is currently locked. Try later." was shown every time two users tried to perform an exclusive checkout on the same branch at the same time. Fixed.

This is the sixth release of the new Plastic SCM 6.0 series. It includes important core improvements and features. It is published in the "labs" channel instead of the official one because there are some important design changes still to be delivered, although it is stable enough to be used in production.

Windows GUI: Added links to the documentation in all views (items, branches, changesets, ...). When you click the "information" button in the toolbar, a new "learn more" links to the online documentation.

Windows GUI: Improved merge view performance with very big workspaces.

Office plugin: The Plastic SCM plugin for Office now supports Office 2016 (Word, Excel and PowerPoint)

Jenkins plugin: A retry mechanism was implemented so any failed command will be retried two times. This should solve any issues caused by network micro-cuts, for instance.

Mac OS GUI: Buttons re-designed. The actions in the views ('items', 'pending changes', etc.) were difficult to find because we used icons instead of native buttons.

Axosoft extension: The list of statuses considered as 'pending' (affecting the list of tasks displayed on the Create Branch dialog) is now editable as a comma-separated values string on the Axosoft configuration.

Linux (GTK) GUI and Mac OS GUI: Implemented "Create workspace from this repository" action. The action is available from the repository context menu. Additionally, when you type a server in the repositories view and press enter key, the view is now refreshed.

Experimental support for organizations in the server. Starting the server with 'plasticd --organizations=organizations.conf' allows you to have independent sets of repositories (organizations).

'organizations.conf' is a text file with an organization name on each (or empty line for empty (default) organization).

And org1, org2 and org3 (the 3 on organizations.conf) will be 3 independent organizations with different sets of repositories and independent permissions (repository server permissions will affect to each of the organizations independently of each other).

Branch Explorer global configuration: Now the Branch Explorer can be globally configured for all users adding a branchexplorer.conf file in the "global configuration files repository" (plastic-global-config) under the "allrepos" directory. More about global config here.

This feature closes the UserVoice request Create a master conditional format that can be pushed from the server to all users.

A global branchexplorer.conf file looks as follows:

While a local branchexplorer.conf contains user-specific information too:

The GUIs will combine the global and local filters. The resulting configuration for filters will be as follows:

As a result of the combined rules in the example above:

Users will NOT see branches which the 'status' attribute is set to 'RESOLVED' (because the rule type is 'exclusion_rule'). (Global config).

Use will see the branches that are not merged (type 'non_integrated_branches') colored blue (RGB 0,128,192). (Local config).

How to create a branchexplorer.conf global configuration file:

Then, find the generated configuration file at:

Windows: %USERPROFILE%/AppData/Local/plastic4/branchexplorer.cfg

Linux and macOS: $HOME/.plastic4/branchexplorer.conf

Copy the resulting file to the global configuration repository.

What can be globally configured?

Only the filters and conditional format rules can be globally configured.

The user-specific configuration, such as displaying full branch names, merge links, the start and end date, and so on, will always prevail from the local configuration file. If these settings are set globally, they will be ignored during the "merge" of global and local rules.

Windows GUI: The size position and size was not remembered between application restarts. Now it's fixed.

Widows GUI and Gluon: Fixed the following error diplaying the preview of image files (jpg, png, gif, etc.):

Windows GUI: Fixed a cut tag in the merge-needed dialog (the dialog that appears during a checkin, when a merge is needed).

Windows GUI: Branch Explorer lost focus after refresh. Fixed.

Windows GUI: Fixed an "Index out of bounds" exception in the annoatate view. This can happen while annotating a file that have a big history.

Axosoft extension: The New Branch dialog was incorrectly using the Defect prefix regardless of the actual issue type. Fixed.

Axosoft extension: The URL no longer needs to end with a slash ('/') to allow the extension to work.

Axosoft extension: The checkin result wasn't being logged in the Axosoft issue custom field. Fixed.

TeamCity plugin: TeamCity was unable to store the last affected changeset for each build when the VCS root was configured to use long repository/server names. Fixed.

Cloud Edition incorrectly prompted cloud credentials even when the default ones were set. Fixed.

Jenkins plugin: A failed polling operation caused builds to be launched. Fixed.

Bamboo plugin: The checkout directory in the Source Code Checkout task was being ignored. Fixed.

This is the fifth release of the new Plastic SCM 6.0 series. It includes important core improvements and features. It is published in the "labs" channel instead of the official one because there are some important design changes still to be delivered, although it is stable enough to be used in production.

Gluon: now, both file and directory sizes are displayed on the "configure workspace" mode. This way, you can know the size of the files and directories before downloading them from the server.

Jenkins plugin: Our plugin supports Pipelines now! You can either use the form included in the snippet generation or write the command yourself.

These are the supported parameters:

Gluon: the size of modified and checked out files was not correctly displayed in the workspace explorer. The size displayed was always the one from the last time the file was checked-in, instead of the real one from your disk. Fixed.

Windows GUI: The visual diff of the analyze refactors functionality from the diff window was broken. Fixed.

This is the fourth release of the new Plastic SCM 6.0 series. It includes important core improvements and features. It is published in the "labs" channel instead of the official one because there are some important design changes still to be delivered, although it is stable enough to be used in production.

Mac OS GUI and Mergetool: Plastic SCM for Mac OS now have embedded Semantic Diffs included!

Mac OS GUI: Differences are now editable in the 'Pending changes' and 'Diff branch/changeset' views. Differences between left/right contributor can be deleted/restored by using the two button bars attached to each difference.

(Editions can be saved when the right revision is the same as the loaded one in the workspace).

Windows GUI, Linux (GTK) GUI, and Mac OS GUI: Multiple improvements in the 'Branch Explorer' view:

Now, the first result for a search in the Branch Explorer is guaranteed to be the exact one (if it exists).

Additionally: the Branch Explorer multi-selection was improved back on release 5.4.16.791: when you searched for an object on the Branch Explorer, it did not affect your selection, but the properties panel was not being updated with the information from your search results. Now, it shows again the information of the current search result as well, and not only the information of the last selected object, without affecting the selection.

With these two improvements, it is easier to search for changesets, labels, and branches, correctly identifying the one you want, to perform actions like diffing them.

Linux (GTK) GUI and Mac OS GUI: Differences for big files are now calculated on demand. A new panel with a button to start calculating differences is shown when a big file is focused.

The default threshold to consider a big file is set to 2MB, but this threshold can be overriden by setting the following entry in the mergetool.conf config file:

Example (set threshold to 3MB):

REMARK: The diff control will still show regular embedded differences for non-big files.

Linux (GTK) GUI and Mac OS GUI: Two new context menu options have been added to the 'Pending Changes' view menu:

Apply local change: converts any local change to a controlled change. For instance, a locally changed file will become a checked-out file and private file will become an added file.

Search matches: applies locally moved files from a private/local delete pair when Plastic can't automatically detect them as such.

Mac OS GUI: Added Unity Smart Merge as a mergetool to the pre-configured tools. To configure it in Plastic SCM:

1 - Go to the "Merge tools" tab of the preferences window.

2 - Click on the "Add" button

3 - For the file type, select "Custom extension" and type ".unity".

4 - From the "External tool" dropdown list, select UnitySmartMerge.

Repeat steps 2 to 5, changing the ".unity" extension for ".prefab", to finish configuring Unity Smart Merge in Plastic SCM.

By default, if Unity Smart Merge finds any conflict that cannot be automatically solved, it will prompt you to manually solve it using macOS' FileMerge utility. You can configure Unity Smart Merge to use the mergetool shipped alongside Plastic SCM (a.k.a. macmergetool), instead of FileMerge. To do so:

Edit the file /Applications/Unity/Unity.app/Contents/Tools/mergespecfile.txt, adding these two lines to tell Unity Smart Merge to use macmergetool:

You can learn more about Unity Smart Merge here: https://docs.unity3d.com/Manual/SmartMerge.html

Linux (GTK) GUI and Mac OS GUI: while performing a merge with conflicts on a Xlinked repository, merging a single item from the main repository resulted in all the conflicts from the Xlinked repositories to be processed at the same time. Fixed.

Linux (GTK) GUI and Mac OS GUI: while performing a merge with conflicts inside a xlinked repository nested inside another xlinked repository, those conflicts were not being shown. Fixed.

Windows GUI: Push/pull operations were failing since version 6.0.16.804, displaying a timeout error message. This issue was related to a database query that could take several minutes in big repositories. It has been optimized down to a few milliseconds, so the push/pull error has been consequently fixed.

Since Release 6.0.16.808 the server threw an exception on startup:

This is the third release of the new Plastic SCM 6.0 series. It includes important core improvements and features. It is published in the "labs" channel instead of the official one because there are some important design changes still to be delivered, although it is stable enough to be used in production.

Windows GUI: the update operation doesn't lock the GUI since it is not modal anymore.

Linux (GTK) GUI: The merge view now includes a Merge Explanation diagram to display the requested merge on a filtered Branch Explorer.

Linux (GTK) GUI and Mac OS GUI: The 'selected branches' filter in the 'Branch Explorer' view will be remembered when the application is closed and reopened.

Mac OS GUI: The Merge Explanation diagram in the Merge view now allows users to switch between all repositories involved in the merge to preview the results.

Windows GUI: The 'find in files' search results were not visible in the diff window when the user moved the top splitter before performing the search. Now it's fixed.

Windows GUI: Showing annotate of a C# file in the diff view was too slow when a file have some methods/using's/regions collapsed. Now it performs good.

Gluon: The history view disappeared from the details panel after performing a check-in operation (and then closing the check-in view) from the Workspace Explorer. Now it's fixed.

This is the second public release of the new Plastic SCM 6.0 series. It includes important core improvements and features. It is published in the "labs" channel instead of the official one because there are some important design changes still to be delivered, although it is stable enough to be used in production.

Windows GUI: the checkin operation no longer locks the GUI. Now a panel with the progress information is displayed on the bottom of the window, so the user can continue using Plastic.

TeamCity plugin: The server-side checkout will now set up a workspace to download the first patch contents.

TeamCity plugin: The agent-side checkout failed if the previous build had left changed files in the workspace. Fixed.

Several fixes related to the client trying to contact the default server wrongly:

cm lrep was always trying to contact the default server if it was in LDAP mode, even when the specified server to list repos from was a different one. Fixed.

cm lrep was trying to solve the users even when they were not going to be printed. Fixed.

cm lrep tried to solve the users from the default server, which is wrong. Fixed. It now uses the specified server.

cm li didn't work if the default server was not reachable, even if the user specified a different one on the CLI. Fixed.

cm update tried to contact the default server wrongly. Fixed.

GitServer: The git fetch/pull operation failed in scenarios with certain latency between the git client & gitserver. The error showed by the git client was an 'early EOF index-pack failed' error. Fixed.

Windows GUI: replication progress didn't show MB during data transfer with PlasticProto. Fixed.

This is the first public release of the new Plastic SCM 6.0 series. It includes important core improvements and features. It is published in the "labs" channel instead of the official one because there are some important design changes still to be delivered, although it is stable enough to be used in production.

Jet - the super-fast repository storage.

We have designed a new storage for our repositories. It is super-fast and scalable and it has been designed specifically to deal with the way in which Plastic handles data and metadata read and writes. As a special purpose storage, it is hard to beat in terms of efficiency.

We still support SQL databases (MySQL, SQL Server, SQLite, Firebird and a few others) but the goal is to enable Jet as default backend replacing SQLite and eventually make it the default even for large teams.

We created support for 2 different workloads in Jet:

Small server workload support: perfect to handle local repository replicas on laptops and workstations and even small team servers. It focuses on performance and not scalability.

High-scalability workload support: a more complex alternative focused on scalability workloads.

Right now, Jet is not enabled by default but you can use the admin tool on Windows to migrate your repos to Jet.

To configure Jet from scratch, simply create a jet.conf file in the same place where your current db.conf is located, with the following content:

basepath=the path to a directory where you want you Jet repos to live.

In terms of performance Jet runs circles around all the other alternatives. It is about 10 to 40 times faster than SQLite and SQL Server in metadata reads and writes, which makes the server up to 3-5 times faster in operations like big checkins. Jet is so fast that we were able to find other hotspots once the data layer was no longer the slow part, and we continue optimizing the server thanks to it. We will share the results of the benchmarks we ran both on Windows and Linux to compare to the other databases and also Git, which we now consistently beat even on Linux.

Floating license system.

We have implemented a new system for companies who require floating licenses.

The traditional licenses so far are based on "named users". If you have 3 licenses, then John, Mike and Sara can access Plastic and consume the 3 licenses. If Sara leaves the company, then the admin will need to deactivate Sara to allow Paul to use the server.

With floating it is different. The server handles a number of free spots. On startup, all spots are free. And as soon as users access the server, spots are reserved. Spots stay reserved for a given time then can be renewed or taken by a different user. The floating licenses tend to reflect the number of active users in the system during the labor day. As such, the leased time is set to a minimum of 8 hours.

Consider the same scenario described above but this time with floating licenses. We have 3 spots. Then Sara accesses the server and one license spot is reserved and kept for a period of time. Later John does the same and then Mike. Suppose Paul wants to access immediately after: since you only have 3 licenses, his connection will be rejected. But as soon as Sara, Mike or John reserved spots expire, Paul will gain access, without administration intervention.

Floating licenses are great for teams with a central server and offices around the globe: if you have 20 users in Madrid and 20 in Seattle, you won’t need 40 licenses but only 20 floating ones.

Full backwards compatibility.

A 6.0 client can connect to a 5.4 server, and a 5.4 client can connect successfully to a 6.0 server. This greatly simplifies upgrades because a "big-bang" deployment is no longer required.

Our intention is to keep backward compatibility even between major versions from now on.

Optimization during connection creation.

Now connections are cached by server and not by full url. It means that whether you invoke the "branch handler" or the "item handler" you can still reuse the same connection.

Small performance improvements in Plastic servers URL parsing to avoid doing string operations again and again.

Windows GUI, Linux (GTK) GUI and Mac OS GUI: The 'Update report' dialog has been redesigned.

The error message for each update conflict has been moved to a text area on the right hand side of the dialog for better readability.

OS X: Merge Explanation diagram.

The merge view now includes a Merge Explanation diagram to display the requested merge on a filtered Branch Explorer.

OS X server icon now launches documentation.

Opening the server application bundle (by double-clicking on its icon or otherwise) will now open a descriptive website detailing the available administration/configuration actions on Mac.

Linux and OS X GUIs: save file from history.

[link]https://plasticscm.uservoice.com/forums/15467-general/suggestions/15555477-add-an-option-to-save-a-file-from-the-history-scre UserVoice: add an option to save a file from the history screen[\link]

Now, it is possible to save a given revision of a file from the History view. To do so, while browsing the history of a file:

Right click on the revision you want to save

Select the "Save this revision as..." menu item

Choose a destination for the revision and confirm the operation

Linux and OS X GUIs: open files in the file manager.

You can now directly open a file or directory in your default File Manager. To do that, right-click on an item on the "Items" view, or in the "Pending changes" view, and select "Reveal in Finder" if you use OS X, or "Open in explorer" if you use a GNU/Linux system.

Linux GUI Branch Explorer learns to filter.

A new "Branch explorer" submenu has been added to the Branch Explorer view context menu. It contains the previous "Go to branch base" menu item and three new options: 'Filter selected branches', 'Filter selected and related branches' and 'Filter pending merges for selected branches'. Each of them will refresh the Branch Explorer, showing only those branches affected by the selected filter. A new "Remove filter" button will appear. Clicking on it will clear the filter and refresh the Branch Explorer using the previous conditional filter settings (if present).

New after-checkin trigger environment variable: PLASTIC_CHANGESET.

The after-checkin client side trigger gains a new environment variable: 'PLASTIC_CHANGESET', which reflects the cset number of the changeset created after the checkin operation.

You can read more about the Plastic SCM triggers in the documentation [link]https://www.plasticscm.com/documentation/triggers/plastic-scm-version-control-triggers-guide.shtml[\link]

JIRA extension: custom field is now optional.

[link]https://plasticscm.uservoice.com/forums/15467-general/suggestions/14830797-jira-integration-make-custom-field-id-optional UserVoice: JIRA integration - make Custom Field ID optional[\link]

The custom field ID for Plastic SCM in JIRA is now optional. If it is not set in the configuration, Plastic SCM will not log any information concerning the checkin into JIRA's related issue. The user can still benefit from JIRA integration while creating branches from JIRA issues, or from browsing JIRA issues from the Branch Explorer.

Windows GUI: when the branch name was too long, the diff window displayed it overlapping the branch GUID in the header of the diff window. Fixed.

OS X GUI: The diff view in the pending changes view was collapsed (not visible) sometimes after closing and reopening the UI. Now it's fixed.

ImageDiff: The "differences" button was not correctly enabled sometimes when showing image differences in the pending changes view or the diff view.

Windows GUI: Version tree 2D was showing a null reference error when clicking on a branch and the differences panel was visible. Fixed.

Windows GUI: Fixed "an error occurred processing your request" when launching annotations from the diff view.

Linux and OS X GUI: fixed progress in replica.

The progress indicator for the current stage of a replica was being hidden after a try. Fixed: if the replica operation is retried, the progress indicator for the current operation is shown again.

GTKMergeTool: the application got stuck right before exit. Fixed.

**Examples:**

Example 1 (unknown):
```unknown
highperf=true|false
```

Example 2 (unknown):
```unknown
/
/src
/src/lib
/src/lib/foo.c
```

Example 3 (unknown):
```unknown
/
/src
/src/lib
/src/lib/foo.c
```

Example 4 (unknown):
```unknown
cm move /src/lib/foo.c /src/foo.c
cm rm /src/lib
mkdir /src/lib
cm add /src/lib
cm move/src/foo.c  /src/lib/foo.c
```

---

## Undo changes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/undo-changes

**Contents:**
- Undo changes#

If you’ve made changes in your project that you don’t want to keep, you can revert back to the latest checked-in version.

To revert changes to a file:

This removes the selected changes from both the Pending Changes tab and your project.

Note: If you have already checked in the changes you want to undo, you can revert to a previous changeset to remove changes.

---

## Find revisions

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-revisions

**Contents:**
- Find revisions#
- Filtering options#
- Output options#
- cm find revisions examples#
  - Find revisions made in a specific changeset#
  - Find revisions for a branch#

Find and filter revisions.

The following list displays the different filtering options (where) that are available to use with the cm find revisions command:

The following list displays the different output options (--format) available to use with the cm find revisions command:

You can use a custom format, for example if you only want to find the file and folder paths of the revisions in a specific changeset:

You can also use PowerShell or Bash to filter by folder:

The following example returns all the revisions for a specific changeset within a specified timespan:

You can also use PowerShell or Bash to filter the information:

**Examples:**

Example 1 (unknown):
```unknown
cm find revisions
```

Example 2 (unknown):
```unknown
replsrcdate
```

Example 3 (unknown):
```unknown
replsrcrepository
```

Example 4 (unknown):
```unknown
replsrcserver
```

---

## ATTRIBUTE UNSET

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/attribute-unset

**Contents:**
- ATTRIBUTE UNSET#
- Description#
  - Usage#
- Help#
  - Remarks#
  - Examples#

Unsets an object's attribute.

cm attribute | att unset <att_spec> <object_spec>

The command unsets an attribute that was previously set on an object. It does not delete the attribute object itself.

cm attribute unset att:status br:/main/SCM105

(Removes attribute realization 'status' from branch 'main/SCM105'.)

cm att unset att:integrated@reptest@localhost:8084 cs:25@reptest@localhost:8084

(Removes attribute realization 'integrated' from changeset 25, all in repository 'reptest'.)

**Examples:**

Example 1 (unknown):
```unknown
cm attribute | att unset <att_spec> <object_spec>
```

Example 2 (unknown):
```unknown
cm attribute unset att:status br:/main/SCM105
```

Example 3 (unknown):
```unknown
cm att unset att:integrated@reptest@localhost:8084 cs:25@reptest@localhost:8084
```

---

## Get started with Analytics

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/get-started

**Contents:**
- Get started with Analytics#
- Prerequisites#
- Install the Analytics package#
- Collect data#
  - Unity 6.2 and later with Analytics SDK 6.1 and later#
  - Unity 6.1 and earlier, or Analytics SDK 6.0 and earlier#
  - Change player consent status#
- Set up Analytics#
- Next steps#

To start using Analytics, perform the following actions:

Before you continue, make sure you meet the following requirements:

Note: Analytics is compatible with the following operating systems and platforms: iOS, Android, Windows, macOS, and WebGL.

To begin using the Analytics SDK, install the Analytics package:

You can now start using the Analytics SDK.

To enable the Analytics SDK to collect data:

The Developer Data framework controls Analytics SDK data collection:

To delete player data, deny consent using the EndUserConsent.SetConsentState(...) and then call the AnalyticsService.Instance.RequestDataDeletion() method. If you request data deletion while consent is still granted, the SDK throws an exception and does not make the request.

Note: For the SDK to collect data, you must confirm user consent for Analytics. To learn about managing privacy and obtaining player consent, refer to User consent.

Note: For the SDK to collect data, you must confirm that the user has consented to the use of Analytics. For more information about managing privacy and obtaining player consent, refer to Manage data privacy with the SDK.

You can change a player's consent status using the following methods:

Important: You must call StartDataCollection() at the start of each session to enable data collection. The SDK doesn’t track player consent status between sessions.

To set up and manage Analytics from the Unity Dashboard:

When you launch Analytics for the first time, it appears in the Shortcuts section on the sidebar and opens the Game Performance page.

Note: Only Organization Owners can sign up for Analytics.

When you've enabled data collection, the SDK begins collecting events and uploading them at a regular cadence of every 60 seconds while your game is running.

The SDK automatically records some events, enabling you to directly access Analytics in the Unity Dashboard for data analysis. For a list of events sent automatically versus those requiring manual configuration, refer to Standard Events.

Refer to the following tutorials to learn how to build and record your own events:

Note: To learn about how the SDK works, refer to SDK behavior.

**Examples:**

Example 1 (unknown):
```unknown
UnityServices.InitializeAsync()
```

Example 2 (unknown):
```unknown
EndUserConsent.SetConsentState(...)
```

Example 3 (unknown):
```unknown
AnalyticsIntent
```

Example 4 (unknown):
```unknown
EndUserConsent.SetConsentState(...)
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/authentication-service-accounts

---

## PARTIAL

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial

**Contents:**
- PARTIAL#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Runs commands in a partial workspace.

cm partial <command> [options]

cm partial <command> --usage

cm partial <command> --help

cm partial configure +/background-blue.png

cm partial update landscape-1024.png

cm partial checkin eyes-green.png eyes-black.png

**Examples:**

Example 1 (unknown):
```unknown
cm partial <command> [options]
```

Example 2 (unknown):
```unknown
cm partial <command> --usage
```

Example 3 (unknown):
```unknown
cm partial <command> --help
```

Example 4 (unknown):
```unknown
cm partial configure +/background-blue.png
```

---

## PROFILE DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/profile-delete

**Contents:**
- PROFILE DELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Example#

Deletes a server connection profile from the client's configuration.

cm profile delete | rm <index | name>

cm profile delete | rm --index=<index>

cm profile delete | rm --name=<name>

Deletes a server connection profile from the client's configuration. It works both with the profile index and the profile name. The 'cm profile list' command does not show profile names by default, check 'cm profile list --help' to check how to output profile's name.

(Removes the profile at index 1.)

cm profile delete 192.168.0.2:8087_UPWorkingMode

(Removes the profile with name '192.168.0.2:8087_UPWorkingMode'.)

cm profile delete --name=12

(Removes the profile with name '12'.)

**Examples:**

Example 1 (unknown):
```unknown
cm profile delete | rm <index | name>
```

Example 2 (unknown):
```unknown
cm profile delete | rm --index=<index>
```

Example 3 (unknown):
```unknown
cm profile delete | rm --name=<name>
```

Example 4 (unknown):
```unknown
cm profile delete 1
```

---

## Control access to services

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/server-access-control

**Contents:**
- Control access to services#
- Integration with UGS services#

To store a player’s information, you need an identifier for the player. Unity Gaming Services (UGS) requires players to authenticate to access most features for security and identification. The authentication process means that if the same player signs in to your game through the same provider on a new device, the player has the same playerId, which also allows you to synchronize their game data between devices.

By default, UGS allows player applications to call API endpoints directly, which you can use to test. Server authority principles recommend that you restrict direct player access and only allow updates through trusted server code. This means that the player client acts as a presentation layer while Cloud Code validates integrity and stores the accurate game state data.

To disable player API access at the endpoint level, you can use access control. You can use access control to only allow calls to backend services through Cloud Code functions. You can also use a project’s service credentials to grant access to a server.

A good place to start with access control is to disallow writes from the client, but allow reads. This means that updates will go through Cloud Code, but the client can get the latest state directly from the service, which will reduce Cloud Code costs. The following access control configuration will:

If there are other services you would like to block client access to, the URNs for each serivce are listed in the Access Control page.

For an example of how to use access control, refer to the page on how to Get started with Access Control and Cloud Code.

Cloud Code integrates seamlessly with other Unity Gaming Services (UGS), such as Remote Config, Cloud Save, and more, to build complete backends. Some UGS services generate trigger events sent to the Triggers service when specific actions occur.

If you have a server authoritative game, clients have no ability to create events. This means that events like triggers are always created on the server and you can trust the data.

For more information on how you can use triggers and other events in you game, refer to Triggers.

**Examples:**

Example 1 (unknown):
```unknown
{
  "$schema": "https://ugs-config-schemas.unity3d.com/v1/project-access-policy.schema.json",
  "Statements": [
    {
      "Sid": "deny_access_to_cloud_save_writes",
      "Action": [
        "Write"
      ],
      "Effect": "Deny",
      "Principal": "Player",
      "Resource": "urn:ugs:cloud-save:/**",
      "Version": "1.0.0"
    },
    {
      "Sid": "allow_access_to_cloud_save_queries",
      "Action": [
        "Write"
      ],
      "Effect": "Allow",
      "Principal": "Player",
      "Resource": "urn:ugs:cloud-save:/**/query",
      "Version": "1.0.1"
    },
    {
      "Sid": "deny_access_to_economy_writes",
      "Action": [
        "Write"
      ],
      "Effect": "Deny",
      "Principal": "Player",
      "Resource": "urn:ugs:economy:/**",
      "Version": "1.0.0"
    },
    {
      "Sid": "allow_access_to_economy_purchases",
      "Action": [
        "Write"
      ],
      "Effect": "Allow",
      "Principal": "Player",
      "Resource": "urn:ugs:economy:/**/purchases/*",
      "Version": "1.0.0"
    },
    {
      "Sid": "deny_access_to_leaderboards_add_score",
      "Action": [
        "Write"
      ],
      "Effect": "Deny",
      "Principal": "Player",
      "Resource": "urn:ugs:leaderboards:/v1/projects/*/leaderboards/*/scores/players/*",
      "Version": "1.0.0"
    },

    {
      "Sid": "deny_access_to_player_name_updates",
      "Action": [
        "Write"
      ],
      "Effect": "Deny",
      "Principal": "Player",
      "Resource": "urn:ugs:social:/v1/names/*",
      "Version": "1.0.0"
    }
  ]
}
```

Example 2 (unknown):
```unknown
{
  "$schema": "https://ugs-config-schemas.unity3d.com/v1/project-access-policy.schema.json",
  "Statements": [
    {
      "Sid": "deny_access_to_cloud_save_writes",
      "Action": [
        "Write"
      ],
      "Effect": "Deny",
      "Principal": "Player",
      "Resource": "urn:ugs:cloud-save:/**",
      "Version": "1.0.0"
    },
    {
      "Sid": "allow_access_to_cloud_save_queries",
      "Action": [
        "Write"
      ],
      "Effect": "Allow",
      "Principal": "Player",
      "Resource": "urn:ugs:cloud-save:/**/query",
      "Version": "1.0.1"
    },
    {
      "Sid": "deny_access_to_economy_writes",
      "Action": [
        "Write"
      ],
      "Effect": "Deny",
      "Principal": "Player",
      "Resource": "urn:ugs:economy:/**",
      "Version": "1.0.0"
    },
    {
      "Sid": "allow_access_to_economy_purchases",
      "Action": [
        "Write"
      ],
      "Effect": "Allow",
      "Principal": "Player",
      "Resource": "urn:ugs:economy:/**/purchases/*",
      "Version": "1.0.0"
    },
    {
      "Sid": "deny_access_to_leaderboards_add_score",
      "Action": [
        "Write"
      ],
      "Effect": "Deny",
      "Principal": "Player",
      "Resource": "urn:ugs:leaderboards:/v1/projects/*/leaderboards/*/scores/players/*",
      "Version": "1.0.0"
    },

    {
      "Sid": "deny_access_to_player_name_updates",
      "Action": [
        "Write"
      ],
      "Effect": "Deny",
      "Principal": "Player",
      "Resource": "urn:ugs:social:/v1/names/*",
      "Version": "1.0.0"
    }
  ]
}
```

---

## Scaling settings

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/scaling-settings

**Contents:**
- Scaling settings#
- Minimum available servers#
- Maximum servers#

You can manage how your fleet scales per region with scaling settings. There are two scaling settings available per region: the minimum available servers and the maximum servers. Together, these scaling settings control the size of the available servers buffer.

The minimum available servers scaling setting controls the minimum number of unallocated servers on online machines available in a region at a time.

Warning: Any number of available servers incurs costs, even without traffic. If you're in development or trying to limit costs in a low traffic environment, set the Minimum available scaling value to 0.

This setting controls the maximum number of allocated servers in a region at a time.

The total number of servers may exceed the maximum servers value to fully occupy all online machines. The number of servers per machine is defined by the fleet server density settings.

---

## Use Smart Locks

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/use-smart-locks

**Contents:**
- Use Smart Locks#
- Create lock rules#
- Lock a file#
- Access a locked file#
- Release a locked file#
- Remove a lock#
- View existing locks#

Use Smart Locks to avoid merge conflicts and simplify the version control process for non-mergeable files.

You can create lock rules in the Unity Dashboard, under the Version Control Settings menu. Items are under the lock rule if their file extension matches any of the extensions set up in the rule.

If a file has existing lock rules, these rules apply even if you select Checkout.

If there are no matching lock rules create a new one using the dialog. You must have permission to create lock rules; otherwise, ask your admin.

If you try to check out a locked file, the UI displays an error message which shows that the file is locked and who has locked the file.

Smart Locks also prevent you from checking out a revision that's not the latest. An error message informs you if you try to check out an older revision.

You should wait until the lock is released, or you can contact the lock owner or an admin to release or remove the lock.

Releasing a lock makes the file available to someone else to make changes in the latest revision. This sets the status to Retained, meaning it's the latest edit of a development line that started in your Destination branch.

To release a locked file, check-in your change:

Lock owners can manually release locks by following these steps:

This is only recommended as a last resort as it could enable merge conflicts.

Removing a lock means that your development is complete and the file has no current lock status. From this point, the last revision is considered to be the one in your Destination branch.

The latest version of the file is now available in the repository for other users to check out.

Lock owners or admins can manually remove locks by following these steps:

This is only recommended as a last resort as it could enable merge conflicts.

To view the locked files in the UVCS Desktop Client:

To view the locked files in the Unity Dashboard:

---

## Set global configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/issue-tracking/global-extension

**Contents:**
- Set global configuration#
- Create the global repository configuration#
- Set up the global configuration#

You can set a global configuration in the server so that all clients have the same default settings. The client downloads the server configuration when the UVCS desktop GUI starts. For example, you can set global parameters such as connection strings and let users specify their own credentials.

To set up global configuration, you need to create a repository with the name plastic-global-config. Use one of the following structures:

Global configuration for a specific repository: /<repname>/issuetrackers/<extension_configuration_file>.conf

Global configuration for all repositories: /allrepos/issuetrackers/<extension_configuration_file>.conf

The specific configuration for a repository loads first, and if there isn’t one, UVCS loads the allrepos configuration instead.

Note: For submodules, use the - character instead of /. For example, if plugins is the main repository, and 3dplugin is the submodule, use /plugins-3dplugin/issuetrackers/jira.conf.

You can find the issue trackers configuration example files in the <plasticscm_install_path>/client/extensions/config_samples folder. Include and update any parameters you need in your extension_configuration_file.conf file.

If you customize the issue tracker configuration with the credentials that every client uses, then when a user opens the Issue Tracking tab in the client, the common and global values load automatically. This means the user only has to enter the credentials information to be correctly logged in the issue tracking system.

The user credentials save in the user local directory:

For example, C:\Users<user>\AppData\Local\plastic4\issuetrackers<server_port><repname>\extension_configuration_file.conf.

**Examples:**

Example 1 (unknown):
```unknown
plastic-global-config
```

Example 2 (unknown):
```unknown
/<repname>/issuetrackers/<extension_configuration_file>.conf
```

Example 3 (unknown):
```unknown
/allrepos/issuetrackers/<extension_configuration_file>.conf
```

Example 4 (unknown):
```unknown
/plugins-3dplugin/issuetrackers/jira.conf
```

---

## Text evidence management

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/text-evidence/text-evidence-management

**Contents:**
- Text evidence management#

Text evidence management is an optional feature that helps moderators evaluate player reports with conversational evidence. To enable this feature, contact Unity Support or your Vivox representative.

With this server-to-server API, you can request text messages from player chat history to review instances of reported behavior. All versions are stored for review if a message was edited, deleted, or redacted by the Chat filter. The text evidence management feature contains a text-evidence-report endpoint and a player-evidence-report endpoint. The text-evidence-report endpoint returns a report for a given channel or direct message. The player-evidence-report endpoint returns a list of conversations a player participated in with optional time filters.

When active, Text Evidence Management has a storage limit of 30 days, extending the storage limit of Chat History.

The API leverages Unity Dashboard service accounts for authentication. After enablement, follow the admin authentication instructions (Unity Services Web API Docs) to create a service account and add the Text Evidence Management role.

**Examples:**

Example 1 (unknown):
```unknown
text-evidence-report
```

Example 2 (unknown):
```unknown
player-evidence-report
```

Example 3 (unknown):
```unknown
text-evidence-report
```

Example 4 (unknown):
```unknown
player-evidence-report
```

---

## Check out and lock files

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/check-out-and-lock

**Contents:**
- Check out and lock files#
- Checkout#
- Force a lock and checkout#
- Check out files recursively#

Check out a file to make sure that other users don’t simultaneously edit the same files as you. If you have lock rules set up, when you check out a file, you lock the file so that no one else can edit it until you check the file back in.

Note: A checkout only locks files if your server has lock rules set up.

To check out a file, right-click the file and select Checkout.

Note: To check out or lock a file with the command line, run the cm partial checkout command.

If you don’t have lock rules set up, or want to ensure that a file is locked, you can select Lock and checkout. If the server for the repository doesn’t have lock rules set up, a dialog displays for you to add your own lock rule.

If you need to lock all of the files in a folder, right-click the file and select Checkout recursively.

Note: To perform a recursive checkout in the command line, run the command: cm partial checkout -R.

**Examples:**

Example 1 (unknown):
```unknown
cm partial checkout
```

Example 2 (unknown):
```unknown
cm partial checkout -R
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/sdk-behaviour

---

## Create a Slack web trigger

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/tutorials/slack-webtrigger

**Contents:**
- Create a Slack web trigger#
- Configure Slack#
- Make the web trigger#
  - Example Slack web triggers#

You can create a web trigger to connect Unity Version Control with Slack to receive notifications. The notification includes the information available to the specific trigger that you use.

To configure Slack, you first need to make a Slack application with the correct scopes:

Once you install your app to your workspace, you can set it up and get the information you need in your Slack application:

To create the Slack web trigger, you need the Bot User OAuth Token from when you install your app into Slack, and the channel name of the channel you added the app to.

You need to use the webtrigger-slack string (instead of webtrigger) before the script path, followed by the Slack channel: webtrigger-slack https://slack.com/api/chat.postMessage/${channelOrUserId}/${slackBotToken}

The trigger below causes the server to post a message to Slack after every check in made in the server myPlasticServer. The message includes details such as the check in comment, the check in author, and the specification of the changeset the operation created.

**Examples:**

Example 1 (unknown):
```unknown
channels:read
```

Example 2 (unknown):
```unknown
groups:read
```

Example 3 (unknown):
```unknown
webtrigger-slack
```

Example 4 (unknown):
```unknown
webtrigger-slack https://slack.com/api/chat.postMessage/${channelOrUserId}/${slackBotToken}
```

---

## Editor tools

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/SDK-editor-tools

**Contents:**
- Editor tools#
- Scriptable objects#
  - Example workflow#
  - Player balances helper#
  - Player inventories helper#
  - Purchases helper#

The Economy package comes with some Editor tools that provide more ways to interact with your game's Economy.

You can interact with your economy directly through the Unity Editor using the scriptable objects provided by the Economy package.

There are scriptable objects for balances, inventories and virtual purchases.

For these objects to work you need to follow the usual Economy setup flows, including configuring your Economy through the Unity Dashboard and signing in via Authentication.

To create the objects, right-click in your project window, then Create > Economy Tools, and select the desired helper.

When you click the button, you will attempt to make that purchase.

This helper allows you to set, increment and decrement a player's balance. When configuring your event, trigger the InvokeAsync() method on this object.

This helper allows you to add and update player's inventory items. When configuring your event, trigger the InvokeAsync() method on this object.

This helper allows you to make purchases. When configuring your event, trigger the InvokeAsync() method on this object.

This helper does not support real money purchases.

**Examples:**

Example 1 (unknown):
```unknown
InvokeAsync()
```

Example 2 (unknown):
```unknown
InvokeAsync()
```

Example 3 (unknown):
```unknown
Currency ID
```

Example 4 (unknown):
```unknown
InvokeAsync()
```

---

## Game state management

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/game-state-management

**Contents:**
- Game state management#
- Chess example#

To implement server authority, you can model the full game state on a backend server. This means that each player client acts as a view port while the server enforces rules, validation and cheat prevention. You can store game state data in a Cloud Save to ensure that the game is persistent across clients and can resume from any point.

Server game state management is a robust way to build asynchronous multiplayer games as you leverage the cloud server as the source of truth while clients handle presentation. The client can focus on smooth UI and visualization, while the server manages game play, integrity, and synchronization.

For a game like chess, the server can maintain the authoritative board and piece positions in Cloud Code and Cloud Save. When a player makes a move, their client sends a request to a Cloud Code function with parameters such as:

The Cloud Code function for a chess game can do the following each turn:

---

## Gitserver

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gitserver/gitserver

**Contents:**
- Gitserver#

Every on-prem Unity Version Control (UVCS) server can use the Git protocol to pull content from UVCS.

Note: Gitserver is the server-side counterpart of GitSync, which allows UVCS clients to push and pull to a GitHub server, and closes the GitHub interoperability loop.

The main purpose for GitServer is to function as a universal connector for any GitHub software to connect to UVCS. For example, there are the following usage scenarios:

With GitServer, your UVCS server can behave like a GitHub server that's transparently accessed by Git clients. For example, you can have the following scenarios:

**Examples:**

Example 1 (unknown):
```unknown
mapping.interval
```

---

## Get scores for a certain tier from a leaderboard version

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-score-by-tier-version

**Contents:**
- Get scores for a certain tier from a leaderboard version#

This method fails when your leaderboard is not configured with tiers. When you retrieve scores by tier, the returned LeaderboardEntry response tiers are contextual to the rank. For example, if a rank named Silver starts at rank 100 and a player’s global rank is 101, their rank within the Silver tier is 1.

To get scores for a particular tier from a leaderboard version, use the GetVersionScoresByTierAsync method. By default this method returns the top 10 scores from the specified tier:

Paginated access to all scores within the tier is available by specifying the optional GetVersionScoresByTierOptions object with the optional Offset and Limit pagination arguments.

Offsetis the number of entries to skip when retrieving the leaderboard scores and defaults to 0.

Limit is the number of leaderboard scores to return and defaults to 10.

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetVersionScoresByTierOptions configuration object:

For details on how to get available leaderboard version IDs, visit Get available leaderboard version.

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
LeaderboardEntry
```

Example 2 (unknown):
```unknown
GetVersionScoresByTierAsync
```

Example 3 (unknown):
```unknown
public async void GetVersionScoresByTier(string leaderboardId, string versionId)
{
    var scoresResponse = await LeaderboardsService.Instance
        .GetVersionScoresByTierAsync(leaderboardId, versionId, "silver");
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 4 (unknown):
```unknown
public async void GetVersionScoresByTier(string leaderboardId, string versionId)
{
    var scoresResponse = await LeaderboardsService.Instance
        .GetVersionScoresByTierAsync(leaderboardId, versionId, "silver");
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

---

## Remote Config files

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/remote-config-files

**Contents:**
- Remote Config files#
- Creation#
- File Format#
  - Example#
- File Deployment#

For the files to be properly parsed they must respect the JSON schema.

The following example contains these keys:

When you've created your Remote Config files, you can deploy them to your chosen environment.

For more information on working with the Deployment window, refer to Deployment package.

**Examples:**

Example 1 (unknown):
```unknown
user_schema
```

Example 2 (unknown):
```unknown
{
  "$schema": "https://ugs-config-schemas.unity3d.com/v1/remote-config.schema.json",
  "entries": {
    "name": "example_name",
    "id": "10000000000",
    "user_schema": {
        "user_id_key": "user_id",
        "user_name_key": "user_name"
    }
  },
  "types": {
      "id": "LONG"
  }
}
```

Example 3 (unknown):
```unknown
{
  "$schema": "https://ugs-config-schemas.unity3d.com/v1/remote-config.schema.json",
  "entries": {
    "name": "example_name",
    "id": "10000000000",
    "user_schema": {
        "user_id_key": "user_id",
        "user_name_key": "user_name"
    }
  },
  "types": {
      "id": "LONG"
  }
}
```

---

## Switch to branch

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/switch-to-branch

**Contents:**
- Switch to branch#
- Switch with pending changes#
  - Shelve and Switch#
  - Leave changes#
  - Bring changes#

Use the Switch workspace to this branch feature to update your local workspace to a specific branch.

Switch to an existing branch in the Unity Version Control window:

When you switch to a different branch, you might have pending changes in your local workspace. To determine how Unity Version Control (UVCS) handles the switch, configure the Behavior when trying to switch/update the workspace with changed items setting.

The default behavior is Shelve, which shows you a dialog with two options to decide what to do with the pending changes:

Note: The Shelve and Switch behavior is also available when you switch to a changeset or label. When you switch to a label, only the Leave changes option is available because you can't check out a label.

Select this option to leave the pending changes on your current branch. This lets you switch to the new branch cleanly as if your workspace didn't have any changes. If you switch back to the original branch, you can re-apply the changes in your workspace and continue to work on them.

For example, this option is helpful if you're working on one branch but want to quickly check something on an unrelated branch, or a previous changeset on the same branch.

UVCS automatically creates a shelveset with your pending changes, and detects when you switch back to the branch to offer you the option to apply the changes.

Select this option to keep pending changes across the switch. Your local workspace switches to the new branch and brings the pending changes so you can check in the changes in the destination branch.

For example, this option is helpful if you accidentally make changes on a branch you didn't mean to, and want to bring the changes to the correct branch.

Note: If you select Bring changes, the destination of the switch might contain changes in the same files as your current workspace. You might need to manually resolve conflicts to proceed with the operation. In this case, UVCS performs the switch and you can either resolve the conflicts, or leave them in the shelveset to resolve them later.

---

## PARTIAL SHELVESET

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-shelveset

**Contents:**
- PARTIAL SHELVESET#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to manage partial shelvesets.

cm partial shelveset | shelve <command> [options]

cm partial shelveset <command> --usage

cm partial shelveset <command> --help

cm partial shelveset create -c="my comment"

cm partial shelveset apply sh:3

cm partial shelveset delete sh:5

**Examples:**

Example 1 (unknown):
```unknown
cm partial shelveset | shelve <command> [options]
```

Example 2 (unknown):
```unknown
cm partial shelveset <command> --usage
```

Example 3 (unknown):
```unknown
cm partial shelveset <command> --help
```

Example 4 (unknown):
```unknown
cm partial shelveset create -c="my comment"
```

---

## BRANCH CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/branch-create

**Contents:**
- BRANCH CREATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - You can specify a comment using either the '-c' or the '-m' switches#
  - Examples#

Creates a new branch.

cm branch | br [create | mk] <brspec> [--changeset=<csetspec> | --label=<lbspec>] [-c=<str_comment> | -commentsfile=<comments_file>]

To create a top-level branch, specify the name without any hierarchy. For example:

If no optional parameter '--changeset' is specified, the base of the new branch will be the last changeset on the parent branch. If the new branch is a top-level branch, the base changeset used will be cset 0.

cm branch /main/task001 -c="This is the comment"

cm branch /main/task001 -m "This is the comment"

Set the PLASTICEDITOR environment variable to specify an editor for entering comments. If the PLASTICEDITOR environment variable is set, and the comment is empty, the editor will be automatically launched to allow you to specify the comment.

cm branch create task001

(All of the examples above, create a top-level 'task001' branch in the repository of the current workspace.)

cm branch br:/task001/task002@

(Creates 'task002' branch as child of 'task001'.)

cm br /main/task001@myrep@myserver:8084 -c="my comment"

(Creates 'task001' branch as child of 'main' in repository 'myrep@myserver:8084' with comment 'my comment'.)

cm branch br:/main/task001 --changeset=2837 -commentsfile=commenttask001.txt

(Creates the 'task001' branch as child of 'main' with base 'changeset=2837', and applies the comment in 'commenttask001.txt' file.)

**Examples:**

Example 1 (unknown):
```unknown
cm branch | br [create | mk] <brspec> [--changeset=<csetspec> | --label=<lbspec>] [-c=<str_comment> | -commentsfile=<comments_file>]
```

Example 2 (unknown):
```unknown
cm branch /main/task001 -c="This is the comment"
```

Example 3 (unknown):
```unknown
cm branch /main/task001 -m "This is the comment"
```

Example 4 (unknown):
```unknown
cm branch task001
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/apple-privacy-survey

**Contents:**
- Apple privacy manifest#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

Note: The developer determines whether to collect Advertising data or Other data types.

The PrivacyInfo.xcprivacy manifest for Analytics is available in the SDK from version 5.1.1. You can also see its contents below, if you are not using the SDK:

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

Example 2 (unknown):
```unknown
Advertising data
```

Example 3 (unknown):
```unknown
Other data types
```

Example 4 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

---

## Google Play data safety section

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/google-play-data-safety

**Contents:**
- Google Play data safety section#
  - Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Unity Matchmaker. For your convenience, Unity Ads provides information on its data collection practices below.

Important: The data disclosures below are for this service only. You are also responsible for providing any additional disclosures for your app, including other third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

---

## Unity Dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/configuration/unity-dashboard

**Contents:**
- Unity Dashboard#
- Preview scripts#
- Create a leaderboard#
- Delete a leaderboard#

The Unity Dashboard is a simple way to get started as it allows you to take full control of your leaderboards through a graphical interface. This section covers how you can preview, create, edit, and delete your leaderboards.

You can access a list of all Leaderboards for an environment from the Unity Dashboard. To access it:

A list of all Leaderboards in the selected environment for the project appears. The table contains the name, ID, and last published date. You can sort the table by name or use the pagination to see the full range of leaderboards.

Create your first leaderboard in the Unity Dashboard to get started with Leaderboards.

Each leaderboard is linked to a specific environment.

The next screen is the Details page for your new leaderboard.

To delete leaderboards from the Unity Dashboard:

Deleting a leaderboard which a live game uses causes errors in the game client.

---

## Server configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/server-configuration

**Contents:**
- Server configuration#

After you install your Unity Version Control (UVCS) server, configure the server to your needs.

To configure the server, run the command line admin tool as an administrator:

Configure the required settings:

**Examples:**

Example 1 (unknown):
```unknown
plasticd configure
```

Example 2 (unknown):
```unknown
/opt/plasticscm5/server/plasticd configure
```

Example 3 (unknown):
```unknown
/Applications/PlasticSCMServer.app/Contents/MacOS/plasticd configure
```

---

## Game lobby sample

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/game-lobby-sample

**Contents:**
- Game lobby sample#
- Features#
- Service organization setup#
- Service overview#
  - Lobby#
  - Relay#
  - Vivox#
- Setup#
- Running the sample#
  - Lobby Join menu#

Important: For most users, the Serverless multiplayer game sample replaces this Game lobby sample. Starting with Unity 6, the Multiplayer Services package is the one-stop solution for adding multiplayer elements to your game.

Note: This sample was tested with Unity 2020.3 for PC and Mac.

The Game lobby sample demonstrates how to use the Lobby and Relay packages to create a typical game lobby experience. It also includes Vivox Voice chat. Players can host lobbies that other players can join using a public lobby list or lobby code, and then connect with Relay to use Unity Transport ("UTP") for basic real-time communication between them. Relay allows players to securely communicate with each other while maintaining connection anonymity. Connecting to the lobby will also connect to Vivox to enable voice chat as long as an audio input device is available.

Note: This is not a “drag-and-drop” solution; the Game Lobby Sample is not a minimal code sample intended to be completely copied into a full-scale project. Rather, it demonstrates how to use multiple services in a vertical slice with some basic game logic and infrastructure. Use it as a reference and starting point to learn how Lobby and Relay work together and how to integrate them into your project.

The following video demonstrates how to set up global matchmaking with Lobby and Relay : How to set up Relay and Lobby | Unity Gaming Services

To use Unity’s multiplayer services, you need a cloud organization ID for your project. If you do not currently have one, follow the How do I create a new Organization? article to set up your cloud organization.

Once you have an ID, link it to your project under Edit > Project Settings > Services and use the Unity Dashboard to manage your project’s services.

The Lobby service allows developers to create lobbies and share data between players before a real-time network connection is established. It simplifies the first step in connecting users to other services such as Relay and provides tools to allow players to find other lobbies.

This Lobby documentation contains code samples and additional information about the service. It includes comprehensive details for using Lobby along with additional code samples, and it might help you better understand the Game Lobby Sample.

Manage the Lobby service in the Unity Dashboard.

The Relay service connects players in a host-client model with an obfuscated host IP. This allows them to host networked experiences as though players connected directly while only sharing private information with Relay itself.

The Relay documentation contains code samples and additional information about the service. It includes comprehensive details for using Relay along with additional code samples, and it might help you better understand the Game Lobby Sample.

Manage the Relay service in the Unity Dashboard.

In this sample, once players are connected to a lobby, they are connected through Relay to set up real-time data transfer over UTP. Lobby and Relay both depend on Auth for credentials. This sample uses Auth’s anonymous login feature to create semi-permanent credentials that are unique to each player but do not require developers to maintain a persistent account for them.

The Vivox service provides player voice and text chat rooms for in-app communication. It also sports useful features like spatial audio and chat transcription.

The Vivox documentation contains comprehensive details for using Vivox, in addition to code samples, which might help you to better understand the Game Lobby sample.

Manage the Vivox service for your app in the Unity Dashboard.

The Lobby and Relay sections of the Unity Dashboard contain their own setup instructions. Select About > Get Started and follow the provided steps to integrate the services into your project.

With those services set up and your project linked to your cloud organization, open the mainScene scene in the Editor and begin using the Game Lobby Sample.

You will need two “players” to demonstrate the full sample functionality. Create a standalone build to run alongside the Editor in Play mode. Although Auth creates anonymous credentials using your machine’s registry, your Editor and your build have different credentials because they create different registry entries.

The Lobby Join menu contains the lobby list UI, which acts as a hub for players to connect to each other using the public lobby list or lobby code.

A. Public lobby list: Shows all lobbies not set to private. Lobbies contain developer-defined data which can be set to public and non-public visibility. The Lobby service cleans up any “zombie” rooms so they don’t appear in this list. For this sample, lobby names and player counts are shown, and lobbies in the “in-game” state are not shown. You can select a lobby and then select Join.

B. Refresh icon: Refreshes the Lobby List. The Lobby service imposes rate limits on all API requests to prevent spamming. Refresh attempts within the rate limit will do nothing (approximately every 1.5 seconds, see Rate limits for details).

C. Filters: Sets the Lobby List to only show servers of a certain color. The Lobby service can filter any queries by data set to public visibility. For this sample, players can optionally filter by color, which hosts set for their lobbies.

D. Quick Join button: Join the first available lobby in the list that matches your filters.

E. Lobby Code field: Enter a lobby code for an existing lobby. In addition to the public lobby list, all lobbies can be joined using their codes. This allows players to privately share access to lobbies.

F. Lobby password field: Enter a lobby password to join a password-protected lobby.

G. Join: Requests to join by public lobby list selection or lobby code. Failed requests are also rate limited to prevent spam, if the player presses the button repeatedly.

H. Create: Allows creation of a new lobby. Players select a lobby name and whether to make a private lobby, and they then connect to the new lobby as its host.

I. Player name: Displays the player name and allows renaming. By default, players are assigned a name based on their anonymous Auth credentials, but name changes follow their credentials so that all players see the new name.

The Lobby View UI displays information from Lobby and Relay for all players in a lobby. When a new player joins, they immediately begin connecting to the host, after which they synchronize emotes and state changes with the other lobby members.

A. Lobby name: Set when the lobby was created and cannot be changed.

B. Lobby Code: Shareable code generated by the Lobby service. This may be provided externally to other players to allow them to join this lobby.

C. Lobby user: A player in the lobby. The player’s name, state, and emote are displayed; this data is synchronized through Relay + UTP, so any changes that a player makes will appear immediately for all connected players. Incoming players will be sent the current data once they have connected.

D. Emotes: Shows the player’s Emote, as well as controls for voice chat if the user has a mic connected.

E. Vivox Voice Controls: Clicking the audio icon will mute/unmute that user.

F. Relay IP: The anonymous server IP that Relay generates. This does not need to be shown to players and is displayed here simply to indicate that Relay is functioning.

G. Relay Code: An internal join code generated by Relay that is used during Relay connection. This does not need to be shown to players and is displayed here simply to indicate that Relay is functioning.

H. Emote icons: Sets the player’s emote and is synchronized using UTP.

I. Lobby color: (Host only) Sets the lobby color for filtering in the Lobby List. This is synchronized through Lobby, so changes won’t appear immediately for all players because Lobby queries are rate limited. See Rate limits.

J. Ready: Sets a ready state on the player. When all players are ready, the host initiates a countdown to an “in-game” state, and the lobby becomes hidden from the public lobby list.

The Game Lobby Sample is designed as a vertical slice of a multiplayer lobby, so it has additional infrastructure that might be expected in full game production, as well as some components to allow multiple services to work together. As such, not all of the codebase will be relevant depending on your needs. Most contents are self-documenting, but some high-level points follow:

Logic for using the Auth, Lobby, and Relay services are encapsulated in their own directories. Much of the API usage is abstracted away for convenience.

The Game directory contains core “glue” classes for running the sample itself, representing a simple framework for a game.

The Infrastructure directory contains classes used for essential tasks related to overall function but not specifically to any service.

The UI directory strictly contains logic for the sample’s UI and observing relevant data. Viewing these files should not be necessary to understand how to use the services themselves, though they do demonstrate the use of the Observer pattern.

Multiple Tests directories are included to demonstrate core behavior and edge cases for some of the code. In particular, the Play mode tests for Lobby and Relay can be used to ensure your connection to the services is functioning correctly.

In the Editor, the project assets are broken into nested prefabs for convenience when making changes during sample development. Their details should not be considered vital, although there are UI elements that depend on event handlers that are serialized.

While the Game Lobby Sample represents more than just a minimal implementation of the Lobby and Relay services, it is not comprehensive and some design decisions were made for faster or more readable development.

All operations using Lobby and Relay rely on asynchronous API calls. The sample code has some logic for handling issues that can result from receiving the results at arbitrary times, but it doesn’t have logic for enqueuing calls that the user initiates during setup and cleanup. Rapid operations when entering and exiting lobbies can result in unexpected behavior.

Relay does not support host migration, but Lobby does. If a lobby host disconnects, the lobby might seem to clients to continue to operate until Lobby detects the disconnect. In practice, you might want to implement an additional periodic handshake between hosts and clients in cases where data could get out of sync quickly.

The sample sets up heartbeat pings with Lobby and Relay to keep the connections alive, but they do not impose any limitations on a lobby’s duration. Consider a maximum duration in actual use, such as a maximum game length.

HTTP errors will appear in the console. These are returned by Lobby and Relay API calls for various reasons. In general, they do not impact the sample’s execution, though they might result in unexpected behavior for a player since the sample doesn’t provide any explanatory UI when these errors occur.

404 (“Not Found”) errors might occur when the Lobby service handles multiple incoming API calls in an arbitrary order, usually when leaving a lobby. They will also occur if trying to join an invalid lobby, such as one that has been deleted but still appears in the lobby list before refreshing.

429 (“Too Many Requests”) errors occur if rate limited operations happen too quickly. In particular, refreshing the lobby list too quickly results in 429 errors from the QueryLobbiesAsync call. Consult Error codes for details.

401 (“Unauthorized”) errors occur if the user enters the lobby menu before Auth sign-in completes, since all Lobby and Relay operations require Auth credentials.

409 (“Conflict”) errors occur if a player tries to join a lobby using the same credentials as another player. In particular, this will happen if you are trying to test with multiple standalone builds, since they share the same registry entry on your machine. To test with three or more players on one machine:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/overview

---

## Use Push Notifications

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/use-push-notifications

**Contents:**
- Use Push Notifications#
- Environments#

The following sample image shows how text would appear on player devices:

Push Notifications can be sent either at a specified time in the future or as an automated notification, sending regularly as players enter the Audience you have chosen to target.

If you want to send a notification once, select Send Once then specify the Send Time. If Player Timezone is selected, players will be notified at the specified Send Time in their local timezone.

Note: When selecting the Player Timezone option, it might be useful to consider the Current Time and your notification's Send Time. Using a Send Time that is not at least 13 hours in the future of the current time (UTC), is not guaranteed to notify all timezones initially. This is due to the fact that the initial Send Date/Time might already be in the past locally.

If you want to set up an ongoing notification, select Ongoing. The Start Date and End Date defines the period in which the notification will be active. If Player Timezone is selected, players will be notified at the specified Send Time in their local timezone.

The Send Time will be the time that players receive the notification. For example, if you set a send time of 8th May at 2pm and the player becomes eligible on the 15th May they will receive the notification at 2pm.

The Cooldown Period is the time that must pass before a player can receive the notification again. With a period of seven days, for example, if a player receives the message on the 20th May they won’t be eligible for another until the 28th May.

You can see a list of your Push Notifications with their names, status, and Start Date.

An event is sent when the Push Notification is sent, and when the player interacts with it. The events are:

Push-specific reporting is available to help you measure the success of your campaign. You’ll also see reporting on dismissed messages.

Note: If setup is potentially incomplete due to setting the keys incorrectly, you can still create Push Notifications but they won’t send to devices.

You can switch between and manage your environments using the toggle on the top left of the dashboard.

Use environments in separate Push Notifications in your different development environments for safety and testing.

**Examples:**

Example 1 (unknown):
```unknown
outOfGameSend
```

Example 2 (unknown):
```unknown
notificationOpened
```

---

## Manage On-Prem licenses

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/on-prem-licenses

**Contents:**
- Manage On-Prem licenses#
- Monitor licenses#
- Reassign licenses#
- Manage read-only users#

Manage your user licenses for Unity Version Control (UVCS) On-Prem.

Note: Only server administrators can run commands to manage licenses. If you haven’t configured your administrator users, right-click a repository in the desktop application, select Repository server permissions, and select your user as the owner.

To find information about your license, run the cm licenseinfo command.

After you install and configure your UVCS server with a new license, by default there are no active users. If your license has available seats, the users activate the first time they perform a write operation on the server.

Reassign a license to a different user:

To check that you correctly assigned the license, run the cm licenseinfo command. The new user appears as INACTIVE until they perform a write operation on the server.

If you create a new user in UVCS and don’t assign them a license, the user can run read-only operations such as an update or diff. The user turns into an active user if they perform a write operation.

Note: After a user activates a license, you can deactivate the user, but the user loses both read and write access to the server.

The read-only function allows you to grant access to users who need to check the system but don’t need to check in changes. Similarly, you can use it to grant access to continuous integration (CI) systems that only need read-only operations.

**Examples:**

Example 1 (unknown):
```unknown
cm licenseinfo
```

Example 2 (unknown):
```unknown
cm deactivateuser
```

Example 3 (unknown):
```unknown
cm activateuser
```

Example 4 (unknown):
```unknown
cm licenseinfo
```

---

## REMOVE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/remove

**Contents:**
- REMOVE#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to delete files and directories.

cm remove | rm <command> [options]

cm remove <command> --usage

cm remove <command> --help

cm remove \path\controlled_file.txt

cm remove private \path\private_file.txt

**Examples:**

Example 1 (unknown):
```unknown
cm remove | rm <command> [options]
```

Example 2 (unknown):
```unknown
cm remove <command> --usage
```

Example 3 (unknown):
```unknown
cm remove <command> --help
```

Example 4 (unknown):
```unknown
cm remove \path\controlled_file.txt
```

---

## Import the Chat Channel Sample

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/chat-channel-sample/import-chat-channel-sample

**Contents:**
- Import the Chat Channel Sample#

To import the Chat Channel Sample, complete the following steps:

When this process is complete, the Chat Channel Sample is imported into your project's Assets folder.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/key-concepts

---

## Install Unity Version Control on Linux

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/install-uvcs-on-linux

**Contents:**
- Install Unity Version Control on Linux#
- Choose your installation type#
  - Cloud Edition#
  - Complete Installation (Server and Client)#
  - DVCS packages#
  - Proxy server#
  - Install a specific version#
- Debian#
  - Prerequisites#
  - Set up the repository#

This guide explains how to install Unity Version Control (formerly Plastic SCM) on Linux using packages for your distribution.

First, choose the installation type that you want to use. Then refer to the instructions for the following operating systems:

Select the Unity Version Control installation that matches your development needs. The following installation types are available:

Use Cloud Edition (package: plasticscm-cloud) to collaborate with your team using Unity's hosted infrastructure.

After you complete your distribution's repository setup, install the Cloud Edition package using your Package Manager.

When you first launch plasticgui, enter your Unity Version Control Cloud Edition credentials to connect with your organization and start collaborating.

Use the complete installation to get both server and client tools with full control over your version control setup. This setup is ideal for teams that use on-premises servers. The following packages provide different components:

Use DVCS packages (plasticscm-dvcs) for distributed development workflows when you want to work with local repositories that sync with your team's central server.

After installation, launch plasticgui to get started. You can connect to your on-premises server or use the default local setting to work with your personal local server.

Set up a Proxy Server (package: plasticscm-proxy-server) to improve performance when your team works across different network locations.

The proxy runs on port 8085 and automatically creates a plasticscm-proxy-server system service for reliable operation.

You can specify exact versions for each package in your installation command when you need a particular Unity Version Control version.

Note: We maintain recent versions of UVCS. Older versions might not be available through package installation.

You can also use the zip installer from the More installers section on our downloads page to downgrade if needed.

Set up and install UVCS on Debian.

Add Unity Version Control's stable repository to access our latest long-term support releases:

Replace 11.0.16.7608 with your desired version:

Set up and install UVCS on Ubuntu.

Add Unity Version Control's stable repository to access our latest long-term support releases:

Replace 11.0.16.7608 with your desired version:

Set up and install UVCS on Fedora.

Add Unity Version Control's stable repository:

Tip: Enable automatic startup by running systemctl enable plasticscm-server after installation. This ensures your Unity Version Control server starts automatically when your system boots.

Tip: Enable automatic startup for the proxy by running systemctl enable plasticscm-proxy-server after installation.

Important: If you want to upgrade from an older proxy and you have plasticscm-proxy-server-netcore installed, remove it first to avoid conflicts:

Your configuration and data is preserved during this upgrade.

Replace 11.0.16.7608 with your desired version:

Set up and install UVCS on Red Hat or CentOS.

Add Unity Version Control's stable repository:

Unity Version Control needs the lttng-ust package to function properly. Get it from the Extra Packages for Enterprise Linux:

Enable automatic startup by running systemctl enable plasticscm-server after installation. This ensures your Unity Version Control server starts automatically when your system boots.

Tip: To enable automatic startup for the proxy, run systemctl enable plasticscm-proxy-server after installation.

If you want to upgrade from an older proxy and have plasticscm-proxy-server-netcore installed, remove it first to avoid conflicts:

Your configuration and data will be preserved during this upgrade.

Replace 11.0.16.7608 with your desired version:

Set up and install UVCS on OpenSUSE.

Add Unity Version Control's stable repository:

Tip: Enable automatic startup by running systemctl enable plasticscm-server after installation. This ensures your Unity Version Control server starts automatically when your system boots.

Tip: To enable automatic startup for the proxy, run systemctl enable plasticscm-proxy-server after installation.

Important: If you want to upgrade from an older proxy and you have plasticscm-proxy-server-netcore installed, remove it first to avoid conflicts:

Your configuration and data is preserved during this upgrade.

Replace 11.0.16.7608 with your desired version:

To use Unity Version Control with Eclipse, follow these steps:

The -clean flag ensures Eclipse recognizes the new plug-in on startup.

Contact our support team if you need help with your Unity Version Control setup.

**Examples:**

Example 1 (unknown):
```unknown
plasticscm-cloud
```

Example 2 (unknown):
```unknown
plasticscm-complete
```

Example 3 (unknown):
```unknown
plasticscm-client-complete
```

Example 4 (unknown):
```unknown
plasticscm-client-core
```

---

## Allocations

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/allocations

**Contents:**
- Allocations#

An allocation is a request to the Allocations service from the host player to reserve space on a Relay server for the host plus the number of players the host is expecting to join their game (indicated with the max_players field in the /allocate request). After a player joins the host player’s allocation, they receive a unique allocation ID, and Relay considers the player allocated.

**Examples:**

Example 1 (unknown):
```unknown
max_players
```

Example 2 (unknown):
```unknown
/allocate request
```

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/privacy-overview

**Contents:**
- Privacy overview#
- Product overview#
- Personal Data Collected about App Users/ Game Players#
  - Developer Defines#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent (Opt-in) vs Opt-out#
- Data Subject Requests#
  - Access#
  - Deletion#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Cloud Diagnostics is a crash and error reporting tool that helps developers identify, investigate, and resolve the crashes and exceptions on client side devices that are hurting players’ experiences. Cloud Diagnostics is a combination of Crash Reporting & User Reporting.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected (always collected in order for the product to work)

While this product allows for the collection of developer defined data (via metadata), we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they must implement it client-side in a way determined by the developer.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by submitting the request here.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by submitting the request here.

Please note: this functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests.

This product has no dependencies on other Unity products.

By default, personal data is retained for 7 or 90 days, depending on which Unity plan a developer has.

This service is not intended to be used in applications with child users, unless you, the developer, have obtained Verified Parental Consent where required as outlined in Section 6.7 of the Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

Unity DPA applies to the transfer of data for this product.

---

## Unity SDK tutorial

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk

**Contents:**
- Unity SDK tutorial#

The Leaderboards SDK documentation describes how to use online multiplayer leaderboards in games created with Unity using examples. Learn how to get started with the SDK before using it.

---

## OBJECTSPEC

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/objectspec

**Contents:**
- OBJECTSPEC#
- Description#
  - Usage#
- Help#
  - Repository server spec (repserverspec)#
    - Examples#
    - Side note#
  - Repository spec (repspec)#
    - Examples#
  - Branch spec (brspec)#

Describes how to write object specs.

(To get all the information about how to build object specs.)

Several UVCS commands expect 'object specs' as input to refer to a given object (typically a branch, changeset, repository, etc).

This documentation describes the different "specs" available and how to build them.

Each spec type begins with a unique tag, for example "rep:" or "cs:". The tag must be specified for commands that take a general object spec, for example "cm setowner object_spec", but can often be omitted for commands that take only a single type of spec, for example, "cm getfile revision_spec".

cm repo list repserver:skull:8084

cm repo list skull:8084

We call it 'repository server spec', instead of just 'server spec' for historical reasons. Long ago, we had separate workspace and repository servers, and the naming survived.

rep:rep_name@[repserverspec]

cm showowner rep:codice@localhost:6060

(Here the "rep:" is required because showowner admits not only repos but also other types of objects. So it needs the user to indicate the object type.)

br:[/]br_name[@repspec]

cm switch br:/main@rep:plastic@repserver:skull:9095

(In this case "br:", "rep" and "repserver" are not needed, so the command admits a much shorter form: "cm switch main@plastic@skull:9095".)

cm find revisions "where branch='br:/main/task001'"

The initial '/' on the branch is not mandatory. We used to specify all our branches as /main, /main/task001, and so on. But now, we prefer the shorter form main, main/task001 which makes commands more compact.

cs:cs_number|cs_guid[@repspec]

The number or GUID of the changeset can be specified.

cm ls /code --tree=ae1390ed-7ce9-4ec3-a155-e5a61de0dc77@code@skull:7070

cm switch lb:RELEASE2.0

cm switch lb:RELEASE1.4@myrep@MYSERVER:8084

cm diff rev:readme.txt#cs:19 rev:readme.txt#cs:20

cm diff serverpath:/doc/readme.txt#cs:19@myrepo serverpath:/doc/readme.txt#br:/main@myrepo@localhost:8084

cm cat revid:1230@rep:myrep@repserver:myserver:8084

cm lock unlock item:audio.wav

cm lock unlock itemid:1234@rep:myrep@repserver:myserver:8084

att:att_name[@repspec]

cm attribute set att:merged@code@doe:8084 cs:25@code@doe:8084 done

sh:sh_number[@repspec]

wk:name@clientmachine

Rarely used, since they only apply to workspace related commands. Useful to specify the workspace by name and machine instead of path.

cm showselector wk:codebase@modok

These specs come from the old days of Plastic SCM 2.x where 'workspace servers' existed as a way to store workspace metadata in a centralized way. Were deprecated due to performance issues.

**Examples:**

Example 1 (unknown):
```unknown
cm objectspec
```

Example 2 (unknown):
```unknown
cm repo list repserver:skull:8084
```

Example 3 (unknown):
```unknown
cm repo list skull:8084
```

Example 4 (unknown):
```unknown
cm showowner rep:codice@localhost:6060
```

---

## Integrate using C++

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/sdk/unreal-engine-sdk/cpp-integration

**Contents:**
- Integrate using C++#
- Add the Multiplay Game Server SDK as a dependency#
- Multiplay Server Config Subsystem#
  - How to Access UMultiplayServerConfigSubsystem#
  - GetServerConfig#
- Multiplay Game Server Subsystem#
  - SubscribeToServerEvents#
  - OnAllocate#
  - ReadyServerForPlayers#
  - UnreadyServer#

The following section shows how to integrate with the Multiplay Game Server SDK using Unreal Engine Subsystems.

Three interfaces are available in the Multiplay Game Server SDK:

Refer to Programming Subsystems (Unreal Engine).

Before continuing, add MultiplayGameServerSDK as a public dependency of your module, then include the plug-in header files in your classes.

Add MultiplayGameServerSDK as a dependency of your module to your Unreal project build file:

Include the plug-in header files you wish to access in your own classes:

This subsystem that retrieves the server configuration for the current session.

This subsystem reads the server.json file and exposes its values via the MultiplayServerConfig struct.

MultiplayServerConfig has the following values:

MultiplayServerConfigSubsystem automatically reads the server.json file on subsystem initialization.

First, you must get a reference to the subsystem, MultiplayServerConfigSubsystem is a GameInstanceSubsystem. You can retrieve it from GameInstance.

After you have a reference to the subsystem, retrieve MultiplayServerConfig using MultiplayServerConfigSubsystem::GetServerConfig()).

The Multiplay Game Server Subsystem allows you to subscribe (and respond) to game server events, such as when a game server becomes allocated and when a game server is ready for players. Refer to Game server lifecycle and Server readiness.

You can access the Multiplay Game Server Subsystem by obtaining a reference to the MultiplayGameServerSubsystem subsystem. MultiplayGameServerSubsystem is a GameInstanceSubsystem that you can retrieve from GameInstance.

Use the SubscribeToServerEvents()) method to establish a connection between the game server instance and the SDK daemon.

The SDK daemon transmits events to the game server, including OnAllocate and OnDeallocate events. By subscribing to these events, the game server knows when your matchmaker (or another allocating service) allocates and deallocates Multiplay to game sessions.

The OnAllocate multicast delegate lets the game server know when the game server is allocated. Game server instances must subscribe to the OnAllocate callback to know when the instance has been allocated.

Use the OnAllocate callback to perform any setup logic necessary when the game server becomes allocated.

Use the ReadyServerForPlayers()) method to let Multiplay know that a game server is ready to accept players.

Use the UnreadyServer()) method to let Multiplay know that a game server is no longer ready to accept players.

Scenarios in which you might want to use UnreadyServer()) include:

A game match is almost complete

A game match is complete

The game server is full

Use the OnDeallocate callback to subscribe to deallocation events. You might want to perform any last-minute cleanup or bookkeeping in response to a deallocation event.

Last-minute cleanup might include collecting telemetry data from the server and beginning the shutdown process by disposing objects and calling RequestExit to quit the application.

The Multiplay Server Query Handler Subsystem allows you to set game server variables monitored by the game server query protocol.

The Multiplay Game Server SDK has a full implementation of Unity’s Server Query Protocol, so the game server only needs to populate the variables. Refer to Server Query Protocol to learn more.

Use the Multiplay Server Query Handler Subsystem to send the relevant information to the game server’s SQP protocol.

Before using the Multiplay Server Query Handler Subsystem, you must retrieve it as shown in the following code snippet.

After retrieving the subsystem, you can connect and disconnect to the game server and set and get the game server query values.

Use the set methods to configure all the game server query values:

Use the accessor methods to access the game server query values:

IncrementCurrentPlayers()) provides a means of atomically increasing the current number of players whenever a player joins the match:

DecrementCurrentPlayers()) provides a means of atomically decreasing the current number of players whenever a player leaves the match:

Use the SetCurrentPlayers()) method to set the number of players connected to the game server. The following example shows how to set the current number of players to 32.

Use the SetMaxPlayers()) method to set the maximum number of players allowed to connect to the game server. The following example shows how to set the maximum allowed number of players to 64.

Use the SetServerName()) method to set the game server name. The following example shows how to set the game server name to AwesomeServer.

Use the SetGameType()) method to set the game type the game server is running. The following example shows how to set the game type to SearchAndDestroy.

Use the SetBuildId()) method to set the game server build ID. The following example shows how to set the build ID to NewBuildId.123.0.1.

Use the SetMap()) method to set the game server map name. The following example shows how to set the game map to MAP_TD_Dusthill.

Use the SetPort()) method to set the game server port number. The following example shows how to set the game server port to 8080.

This is the port number from which the game client can connect to the game server. It's separate from the query port number.

It’s best to continuously update these values throughout the duration of the game. Keeping the values as up-to-date as possible ensures Multiplay collects and displays data while the server is running. After setting all the values, you can make a call to Connect().

Use the Connect()) method to connect to the game server.

Use the GetCurrentPlayers()) method to get the number of players connected to the game server.

Use the GetMaxPlayers()) method to get the maximum number of players allowed on the game server.

Use the GetServerName()) method to get the game server name.

Use the GetGameType()) method to get the game server type.

Use the GetBuildId()) method to get the ID of the build the game server is running.

Use the GetMap()) method to get the active map of the game server.

Use the GetPort()) method to get the port number of the game server.

This is the port number from which the game client can connect to the game server. It's separate from the query port number.

Use the Disconnect()) method to disconnect from game server updates. After you disconnect from the server, you no longer receive updates about the game server, such as allocation and deallocation events.

**Examples:**

Example 1 (unknown):
```unknown
MultiplayGameServerSDK
```

Example 2 (unknown):
```unknown
MultiplayGameServerSDK
```

Example 3 (unknown):
```unknown
PublicDependencyModuleNames.AddRange(new string[] { "Core", "CoreUObject", "Engine", "InputCore", "MultiplayGameServerSDK" });
```

Example 4 (unknown):
```unknown
PublicDependencyModuleNames.AddRange(new string[] { "Core", "CoreUObject", "Engine", "InputCore", "MultiplayGameServerSDK" });
```

---

## Party matchmaking

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/advanced-topics-parties

**Contents:**
- Party matchmaking#
- Using Unity Lobby#

Matchmaker supports party matchmaking where a group of players can request to be matched together in a game.

A matchmaking ticket can contain multiple players. The Matchmaker places all players from one ticket onto the same team. The maximum party size is 20 players per ticket.

The following code sample shows how to create party matchmaking:

Ticket containing two players with each their custom data

Party ticket creation with Unity SDK

Players on the same ticket will not be split into different teams if more than one team is defined in the matchmaking configuration.

Sharing player data like Quality of Service results with the party leader can be difficult. To simplify sharing data, it is possible to use the Unity Lobby service.

Players store the data that is be added on the ticket by the party leader. The party leader is responsible for creating the matchmaking ticket on behalf of the party.

Once the ticket is matched, the party leader can save the information about the server allocation in the Lobby data, and players can use them to connect the match.

**Examples:**

Example 1 (unknown):
```unknown
{
  "queueName": "4vs4",
  "attributes": {},
  "players": [
    {
      "id": "6cc5ac8d-dfab-4b50-9ede-c1d026d8dc81",
      "customData": {
        "Hero": "tank"
      },
      "qosResults": [
        {
          "regionId": "75721794-e9fd-4d8a-9879-aa853ed18885",
          "packetLoss": 0.8,
          "latency": 50
        },
        {
          "regionId": "1e29bd54-8acc-433a-ae7d-28ae5fc192a1",
          "packetLoss": 0.5,
          "latency": 20
        }
      ]
    },
    {
      "id": "ac35c771-291c-4e7e-9a0e-6351faf261c6",
      "customData": {
        "Hero": "support"
      },
      "qosResults": [
        {
          "regionId": "75721794-e9fd-4d8a-9879-aa853ed18885",
          "packetLoss": 0.2
          "latency": 75
        },
        {
          "regionId": "1e29bd54-8acc-433a-ae7d-28ae5fc192a1",
          "packetLoss": 0.5,
          "latency": 10
        }
      ]
    },
  ]
}
```

Example 2 (unknown):
```unknown
{
  "queueName": "4vs4",
  "attributes": {},
  "players": [
    {
      "id": "6cc5ac8d-dfab-4b50-9ede-c1d026d8dc81",
      "customData": {
        "Hero": "tank"
      },
      "qosResults": [
        {
          "regionId": "75721794-e9fd-4d8a-9879-aa853ed18885",
          "packetLoss": 0.8,
          "latency": 50
        },
        {
          "regionId": "1e29bd54-8acc-433a-ae7d-28ae5fc192a1",
          "packetLoss": 0.5,
          "latency": 20
        }
      ]
    },
    {
      "id": "ac35c771-291c-4e7e-9a0e-6351faf261c6",
      "customData": {
        "Hero": "support"
      },
      "qosResults": [
        {
          "regionId": "75721794-e9fd-4d8a-9879-aa853ed18885",
          "packetLoss": 0.2
          "latency": 75
        },
        {
          "regionId": "1e29bd54-8acc-433a-ae7d-28ae5fc192a1",
          "packetLoss": 0.5,
          "latency": 10
        }
      ]
    },
  ]
}
```

Example 3 (unknown):
```unknown
var player1 = new Player(
    "6cc5ac8d-dfab-4b50-9ede-c1d026d8dc81", 
    new Dictionary<string, object> { {"hero", "tank"} },
    new List<QoSResult>
    {
        new QoSResult("75721794-e9fd-4d8a-9879-aa853ed18885",0.8, 50),
        new QoSResult("1e29bd54-8acc-433a-ae7d-28ae5fc192a1",0.5, 20)
    });

var player2 = new Player(
    "ac35c771-291c-4e7e-9a0e-6351faf261c6", 
    new Dictionary<string, object> { {"hero", "support"} },
    new List<QoSResult>
    {
        new QoSResult("75721794-e9fd-4d8a-9879-aa853ed18885",0.2, 75),
        new QoSResult("1e29bd54-8acc-433a-ae7d-28ae5fc192a1",0.5, 10)
    });
var players = new List<Player>
{
    player1,
    player2
};


// Set options for matchmaking
var options = new CreateTicketOptions(
  "Default" // The name of the queue defined in the previous step, 
  new Dictionary<string, object>());

// Create ticket
var ticketResponse = await MatchmakerService.Instance.CreateTicketAsync(players, options);

// Print the created ticket id
Debug.Log(ticketResponse.Id);
```

Example 4 (unknown):
```unknown
var player1 = new Player(
    "6cc5ac8d-dfab-4b50-9ede-c1d026d8dc81", 
    new Dictionary<string, object> { {"hero", "tank"} },
    new List<QoSResult>
    {
        new QoSResult("75721794-e9fd-4d8a-9879-aa853ed18885",0.8, 50),
        new QoSResult("1e29bd54-8acc-433a-ae7d-28ae5fc192a1",0.5, 20)
    });

var player2 = new Player(
    "ac35c771-291c-4e7e-9a0e-6351faf261c6", 
    new Dictionary<string, object> { {"hero", "support"} },
    new List<QoSResult>
    {
        new QoSResult("75721794-e9fd-4d8a-9879-aa853ed18885",0.2, 75),
        new QoSResult("1e29bd54-8acc-433a-ae7d-28ae5fc192a1",0.5, 10)
    });
var players = new List<Player>
{
    player1,
    player2
};


// Set options for matchmaking
var options = new CreateTicketOptions(
  "Default" // The name of the queue defined in the previous step, 
  new Dictionary<string, object>());

// Create ticket
var ticketResponse = await MatchmakerService.Instance.CreateTicketAsync(players, options);

// Print the created ticket id
Debug.Log(ticketResponse.Id);
```

---

## Cloud Save in the Unity Dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/tutorials/dashboard

**Contents:**
- Cloud Save in the Unity Dashboard#
- View data in the Unity Dashboard#
- Edit data in the Unity Dashboard#
  - Editing data#
  - Deleting data#

You can use the Unity Dashboard to view and edit player data in Cloud Save.

From the Unity Dashboard, you can view data items belonging to particular players using the search functionality.

If the player has data stored with the Cloud Save service, the Dashboard returns a table of saved values. Select the < > next to the value to view the entire field if it's cut off.

From the Unity Dashboard, you can modify data items belonging to particular players using the edit functionality.

The Cloud Save editor accepts JSON Data Types. You must provide values that adhere to the formatting rules of JSON Data Types.

The removal of data is permanent and cannot be undone.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/privacy/apple-privacy-manifest

---

## Game server events

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-events

**Contents:**
- Game server events#
- Misbehavior#
- Crashes#
  - Allocation pre-recovery#
  - Crash back-off#

Game servers meet many events throughout their lifecycles. This section covers unusual and unexpected events, such as misbehavior and crashes. For other events, refer to the server lifecycle.

When a game server misbehaves, it means something unexpected (other than a crash) happened with the build executable process. Usually, this means the build executable process started using more resources (CPU and memory) than the server slot allows or stopped responding to queries for an extended period of time.

Multiplay Hosting checks for misbehaving servers using a series of game server checks that run every minute. These checks ensure that the build executable process is:

Note: Multiplay Hosting only checks if game servers respond to queries if you implement a query protocol in the build and specify it in the build configuration.

If Multiplay Hosting detects that a build executable process is misbehaving, it sends the process a SIGSEGV signal. By default, Multiplay Hosting only considers build executables as misbehaving if they fail the same check three times within a 30-minute period.

A crash refers to an unintentional termination of a build executable process with any exit code other than 0 (opposed to an intentional exit). The recommended best practice is to have a build executable exit with a non-zero exit code when it meets an issue from which is can't recover.

When Multiplay Hosting detects that a build executable crashed, it attempts to recover the game session by restarting it with the same allocation ID. However, if the build executable continues to crash, Multiplay Hosting backs off and stops trying to recover the game session.

The allocation pre-recovery process prevents Multiplay Hosting from automatically restarting game servers that were allocated when they crashed.

Note: Multiplay Hosting only detects crashes if you implement a query protocol in the build and specify it in the build configuration.

When Multiplay Hosting detects that a game server no longer responds to server state queries (using the implemented server query protocol), it checks if the game server was allocated during the crash by reading the allocation UUID.

If the game server doesn’t have an allocation UUID, Multiplay Hosting restarts the build executable process. If the game server continues to crash, Multiplay Hosting stops restarting the game server. Refer to crash backoff.

If the game server has an allocation UUID, Multiplay Hosting won’t restart the game server process. Instead, the game server remains stopped until it receives a new allocation. This prevents Multiplay Hosting from starting game servers with stale allocation information.

Multiplay Hosting backs off and stops trying to recover a game session by restarting the build executable if the build executable process crashes more than a specific number✝ of times within a 30-minute period.

Note: By default, Multiplay Hosting only tries to restart the build executable process once (if the servers are running on a cloud machine).

---

## Get started with Lobby

**URL:** https://docs.unity.com/lobby/en/manual/lobby-sdk-installation

**Contents:**
- Get started with Lobby#
- Prerequisites#
- Set up Lobby#
- Link your Lobby project in the Unity Editor#
- Install the latest Lobby package for Unity#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

Read the following sections to learn how to set up a Lobby project and how to use the Lobby Game sample project.

To get started with Lobby, you need to do the following:

You can set up and manage Lobby through the Unity Dashboard:

When you launch Lobby for the first time, this adds Lobby to the Shortcuts section on the sidebar and opens the Overview page.

Note: For most users, the unified Multiplayer Services package replaces the Lobby standalone package, which is deprecated in Unity 6. Consider migrating to the unified package to facilitate a smooth transition. Visit the migration guide for a step-by-step transition process.

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.multiplayer
```

Example 2 (unknown):
```unknown
com.unity.services.lobby
```

---

## Anonymous authentication & linking

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/anonymous-auth-and-linking

**Contents:**
- Anonymous authentication & linking#

The principle of using anonymous authentication with external linking later is only recomended if frictionless platform-specific providers are not viable for your app. It may also be relevant if you need to link additional providers at a later date. Please refer to the best practices decision diagram if you are unsure of your overall approach.

This page provides some recommendations and tips to help you with your implementation of anonymous authentication and linking.

Anonymous authentication introduces players to your game and provides a frictionless First Time User Experience. A First Time User Experience is the initial interaction with the application. A player can go through the first few levels using an anonymous account, so game servers can still track the progress while the player gets a chance to try out and explore your game.

Once a player becomes invested in your game, prompt the player to upgrade their anonymous account to sign in with a platform account. A benefit of signing in with a platform account makes a player’s game progress recoverable if they want to switch devices and continue playing, or access items gained or purchased in the game.

In other cases a frictionless First Time User Experience may not be necessary and platform-specific providers may not fulfil your requirements. In that case you can request the player to link a platform agnostic accounts with a game from the start.

---

## Xlinks

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/xlinks

**Contents:**
- Xlinks#
- Types of Xlink#
  - Read only Xlinks (Xlink)#
  - Writable Xlinks (wXlink)#
  - Partial Xlinks#
- Complex Xlink structures#
  - Versioning#
- Xlink expansion rules#
  - Xlinks in top level branches#
  - Xlinks in a second level branch#

Often, you have separate repositories for different projects. To share existing components from a different project, you can use Xlinks to mount the component in your project.

An Xlink is a directory entry in your repository that points to another directory in a different repository. The Xlink contains information on the specific version of the directory that it points to. You define an Xlink with these three following arguments:

For information on how to create an Xlink, refer to Create an Xlink.

A read only Xlink is ideal if you use an existing component but don’t influence the development of the component. This means you can use the linked component in your project, but can’t change it.

With a writable Xlink, you can make changes inside the Xlinked repository.

Partial Xlinks are Xlinks that point to a specific relative path in another repository instead of the default root of the repository. Partial Xlinks are read only because writable partial Xlinks overcomplicate merges. You can create partial Xlinks only in the command line.

For example, the following command creates a read only partial Xlink that mounts the path /includes/opengl in the Xlinked repository and ignores the rest of the repository:

For more information on how to create Xlinks in the command line, use the command cm xlink –help.

Warning: Don’t use partial read only Xlinks with Gluon as you’ll get an inconsistent workspace.

Since Xlinks can point to repositories that already contain Xlinks, component mounting can address complex development scenarios.

You can specify, for example, that version 1.1 of project X uses version 2.1 of library Y.

When the new version 1.2 of project X is labeled, you can update the code of the project to use a new version 2.2 of library Y.

Since Xlinks are versioned, the Xlink in the original project still points to the original version of the library, so you can rebuild that configuration without issues.

Xlink expansion rules define how branches are created on your Xlinked repositories, and how the branches in the parent repository relate to the branches in the Xlinked repository.

UVCS automatically creates branches in linked repositories when you make changes.

In the following example, you have two repositories, quake and zlib, and a writable Xlink (wXlink) between the main branch on quake to the main branch on zlib:

You then create a new branch, task001 in the quake repository and modify an Xlinked file. Since you can make changes to a wXlink, UVCS automatically creates a matching task001 branch in the zlib repository. To track the new branch connection, UVCS creates an expansion rule:

UVCS automatically creates new rules if more branches are automatically expanded through the branch hierarchy.

In the following example, you create a wXlink in a task branch, main/xlink-creation, instead of your main branch:

Because you likely want to merge the main/xlink-creation in to your main branch, you might not want to create an Xlink expansion rule from main/xlink-creation@quake -> main@zlib. Instead, you likely want to Xlink the main branches.

UVCS detects this situation and creates a rule that connects the main branches: main@quake -> main@zlib. To notify you, UVCS provides an information message to tell you that UVCS creates a new expansion rule to link the two main branches and that if you don't want that layout, you can edit the expansion rules manually.

Because UVCS automatically defines the wXlink between the main branches, if you then modify a file in the wXlink on main/xlink-creation, the branch expansion works correctly and creates a matching main/xlink-creation branch in the linked zlib repository:

Note: You can manually edit the expansion rules if you want a different layout to the above example.

Symmetric links follow the same branch names, while asymmetric links connect different branch names.

In the previous two examples, the wXlinks are symmetric: main linked to main and main/task001 linked to main/task001.

Expansion rules can be especially useful if you need asymmetric links. For example, if you need to link the branch main@quake to branch main/fix@zlib.

UVCS allows you to link repositories asymmetrically, and sets up expansion rules accordingly. These expansion rules let you manage more complex branching structures where the parent repository and the linked repository don’t follow the same branch naming conventions.

In the following xlink configuration example, a video game company has an engine that two different game studios use in different locations. You can use Xlinks to optimize this workflow and share the engine code with both studios and still continue individual development:

Each game studio’s repository has both an Xlinked engine folder that syncs with the remote main repository and a folder for their local game repository. Each game repository has an Xlink that points to the main Engine repository.

The main engine repository has a separate branch for each game. The separate branches allow you to handle any specifications related to each game, and allows each game studio to use and independently modify the engine code.

Note: Another advantage of separate branches is that you can cherry pick and merge any helpful changes or fixes into the main branch of the engine repository. You can propagate changes from one game to the other, and you don’t need to replicate the entire engine repository for each studio location, Just sync the desired branches and reduce disk and network usage. For example, studio A doesn’t need a copy of the studio B branch.

The Xlink for each game repository points to the game specific branch of the engine repository. Since both games are connected to the same engine repository, you need to set the branch auto expansion rules.

You also need to select the following options:

When you merge a branch, the merge also affects the auto expanded branches in the wXlinked repositories. You do the merge operation on the top level repository (where the workspace points to) and UVCS also considers the changes in those linked repositories.

You only need to merge the top level repository; UVCS automatically merges any changes in linked repositories and updates the wXlink. As in any merge, you might need to manually resolve some merge conflicts in the Xlinked files.

This process keeps your Xlinked repositories in sync and ensures that you don't need to manually merge changes in the linked repositories separately.

In the following example, you have a main repository called ProjectX and another repository called MyLibrary. ProjectX has a writable Xlink (wXlink) that points to MyLibrary.

If you have two branches, task002 and task003, and make changes to an Xlinked file, events.h, in both branches, the following happens when you merge:

When you replicate an Xlink, the Xlink still links to the original target repository. For example, if your Xlink originally pointed to a repository on mainserver.location1.com:8087, when you copy it to another server, otherserver.location2.com:8087, it still tries to access the original repository on mainserver.

If you want everything to be local on your new server instead of depending on the original server, you can use relative Xlinks. A relative Xlink points to the local copy of the target repository in the same server as your main repository.

Note: A relative Xlink uses the GUID to identify changesets, so the relative Xlink points to the correct changeset even if they are numbered differently.

To create a relative Xlink, add the -rs modifier. For example, cm xlink -rs component1 / 6@mylibrary.

**Examples:**

Example 1 (unknown):
```unknown
/includes/opengl
```

Example 2 (unknown):
```unknown
cm xlink opengl\include /includes/opengl 1627@includes@localhost:8087
```

Example 3 (unknown):
```unknown
cm xlink opengl\include /includes/opengl 1627@includes@localhost:8087
```

Example 4 (unknown):
```unknown
cm xlink –help
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/beta/debugging-logging

---

## REPOSITORY RENAME

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/repository-rename

**Contents:**
- REPOSITORY RENAME#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Renames a repository.

cm repository | repo rename [<repspec>] <new_name>

This command renames a repository. If no repspec is specified, current repository will be assumed.

cm repository rename development

(The current repository will be renamed to 'development'.)

cm repo rename rep:default@SERVER:8084 development

(The 'default' repository on 'SERVER' will be renamed to 'development'.)

**Examples:**

Example 1 (unknown):
```unknown
cm repository | repo rename [<repspec>] <new_name>
```

Example 2 (unknown):
```unknown
cm repository rename development
```

Example 3 (unknown):
```unknown
cm repo rename rep:default@SERVER:8084 development
```

---

## cm find

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/cm-find

**Contents:**
- cm find#

Use the cm find query system to get specific information about objects in your version control system, such as changesets, branches, labels, merges, and more. You can also use the find command to customize the views in the GUI. This query system is similar to SQL in terms of syntax, but it doesn't allow JOINs, so you have to use a custom string to select the attributes that you want to return per result.

For more information, refer to the Unity Version Control (UVCS) CLI reference documentation for cm find or run cm find --help. To get a complete list of objects you can find, run the cm showfindobjects command.

**Examples:**

Example 1 (unknown):
```unknown
cm find --help
```

Example 2 (unknown):
```unknown
cm showfindobjects
```

---

## Attributes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-attributes

**Contents:**
- Attributes#
- Filtering options#
- Output options#
- cm find attribute examples#
  - Get all attributes#
  - Get all objects with a specific attribute#

Find and filter objects by the value of object attributes.

Note: The cm find attribute command refers to generic attributes, not specific UVCS attributes.

The following list displays the different filtering options (where) that are available to use with the cm find attribute command:

Note: The condition date and type correspond to the Creation date and Name columns in the Attributes view of the UVCS desktop application.

The following list displays the different output options (--format) available to use with the cm find attribute command:

To find attributes, you need the object ID. For example, you can get the ID when you query for a branch:

When you have the object ID, you can get the attribute list for that ID:

In the previous example, the attribute name is status and the attribute value is PASSED.

You can use Powershell or Bash to combine the two commands:

Query for a specific attribute regardless of the type of object:

**Examples:**

Example 1 (unknown):
```unknown
cm find attribute
```

Example 2 (unknown):
```unknown
cm find attribute
```

Example 3 (unknown):
```unknown
cm find attribute
```

Example 4 (unknown):
```unknown
cm find attribute
```

---

## Manage linked external identities

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/identity-management

**Contents:**
- Manage linked external identities#
  - Retrieve a player's information#
  - Handle account linking conflicts#

Managing a player’s linked external identities is important to ensure your players can secure their accounts and use the access method of their choice. When offering account linking to your customers, it's important to properly handle every scenario.

A player can have multiple linked unique external identities (e.g. Apple, Facebook, Google). However, an external identity can only be linked to a single player (e.g. one player ID cannot be linked to multiple Google identities).

GetPlayerInfoAsync() can be used to load a player’s information which includes their linked identities.

The linking operations will throw an error if an identity is already linked to another player.

When there’s a conflict, it’s important to inform the player of the situation.

An optional parameter can be provided to force the link to be created. Using this option will remove the initial link which can make the initial account unrecoverable.

We recommend offering the following options in case of conflict:

**Examples:**

Example 1 (unknown):
```unknown
GetPlayerInfoAsync()
```

Example 2 (unknown):
```unknown
SignInWith*
```

---

## Reducing ad frequency for engaged players

**URL:** https://docs.unity.com/ugs/en-us/manual/game-overrides/manual/reduce-ad-frequency

**Contents:**
- Reducing ad frequency for engaged players#
- Scenario#
- Requirements#
- Instructions#
  - Install Analytics, Authentication and Remote Config packages#
  - Link your game#
  - Set up a Remote Config key#
  - Setting up your game#
  - Setting up an Override#

This topic describes how to use a sample game that illustrates:

This example uses a Unity project called Platformer Microgame, but you can apply this use case to any other game.

Note: This example doesn't cover Unity Ads. However, you can call the ShowAd function within your premade class.

Here's an overview of the steps. Each step is described in more detail below.

In the Unity Editor, install the Analytics, Authentication, and Remote Config packages.

In the Unity Editor, select Edit > Project Settings > Services. Choose the relevant project and link it. This will link your project to the Unity Dashboard.

You can set up a Remote Config key in the Unity Dashboard or in the Editor.

In the Unity Dashboard, open Remote Config.

To add the config key to change for engaged players:

Alternatively, you can update these config values in the Unity Editor. Click Window in the menu bar, then Remote Config: it has a similar editing panel as the Unity Dashboard.

Use the following code to fetch the adFrequency data from Remote Config. Attach this code to an empty object in the scene.

When the object loads, it initializes an anonymous user. You now have the config value of adFrequency from Remote Config. This defines how often your game displays an ad when a player dies or fails the level.

The death logic counts the number of times a player dies. If the death count is equal to the frequency, the ad is displayed. If not, the ad isn't displayed.

The initial setup is complete after following the above steps.

This example explains how to create an Override to target engaged players, lowering adFrequency to show an ad on every third death. Non-engaged players will continue seeing an ad every time they die.

In the Unity Dashboard, open Game Overrides.

Select Create Override.

Enter a name for your Override then select Next.

Select Audiences, select the pre-defined Audience Engaged Players, then select Next.

Select Choose Content Type, select Config Overrides, and select Done.

Select adFrequency from the Key Name dropdown, enter a value of 3, and select Next.

Schedule the Override to run immediately, indefinitely, with a medium priority, and select Finish. You can adjust the priority to manage potential conflicts between Overrides.

Check your changes and select Enable.

Your Override is now active and engaged players will receive an ad on every third death.

If you have any questions, open a support ticket.

**Examples:**

Example 1 (unknown):
```unknown
adFrequency
```

Example 2 (unknown):
```unknown
adFrequency
```

Example 3 (unknown):
```unknown
using Unity.RemoteConfig;
using Unity.Services.Authentication;
using Unity.Services.Core;
using UnityEngine;
public class UGS : MonoBehaviour
{
 
    public struct userAttributes { }
    public struct appAttributes { }
 
    public int adFrequency = 1; //Default is 1 ad on death
 
    async void Start()
    {
 
        await UnityServices.InitializeAsync();
        // remote config requires authentication for managing environment information
        if (!AuthenticationService.Instance.IsSignedIn)
        {
            await AuthenticationService.Instance.SignInAnonymouslyAsync();
        }
        ConfigManager.FetchCompleted += ConfigManager_FetchCompleted;
        ConfigManager.FetchConfigs(new userAttributes(), new appAttributes());
    }
   
    void ConfigManager_FetchCompleted(ConfigResponse configResponse)
    {
 
        switch (configResponse.requestOrigin)
        {
            case ConfigOrigin.Default:
                Debug.Log("Default values will be returned");
                break;
            case ConfigOrigin.Cached:
                Debug.Log("Cached values loaded");
                break;
            case ConfigOrigin.Remote:
                Debug.Log("Remote Values loaded");
                adFrequency = ConfigManager.appConfig.GetInt("adFrequency");
                break;
        }
    }
}
```

Example 4 (unknown):
```unknown
using Unity.RemoteConfig;
using Unity.Services.Authentication;
using Unity.Services.Core;
using UnityEngine;
public class UGS : MonoBehaviour
{
 
    public struct userAttributes { }
    public struct appAttributes { }
 
    public int adFrequency = 1; //Default is 1 ad on death
 
    async void Start()
    {
 
        await UnityServices.InitializeAsync();
        // remote config requires authentication for managing environment information
        if (!AuthenticationService.Instance.IsSignedIn)
        {
            await AuthenticationService.Instance.SignInAnonymouslyAsync();
        }
        ConfigManager.FetchCompleted += ConfigManager_FetchCompleted;
        ConfigManager.FetchConfigs(new userAttributes(), new appAttributes());
    }
   
    void ConfigManager_FetchCompleted(ConfigResponse configResponse)
    {
 
        switch (configResponse.requestOrigin)
        {
            case ConfigOrigin.Default:
                Debug.Log("Default values will be returned");
                break;
            case ConfigOrigin.Cached:
                Debug.Log("Cached values loaded");
                break;
            case ConfigOrigin.Remote:
                Debug.Log("Remote Values loaded");
                adFrequency = ConfigManager.appConfig.GetInt("adFrequency");
                break;
        }
    }
}
```

---

## Configure EOL conversion

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/eolconversion-conf

**Contents:**
- Configure EOL conversion#
- Edit the client.conf file#
- Create the eolconversion.conf file#

Enable an end of line (EOL) conversion mechanism to transform different end of lines of text into the right EOL type for your system.

If you enable EOL conversion, Unity Version Control (UVCS) uses EOL conversion during updates and each time you retrieve a file from the workspace. If you update an existing workspace, UVCS doesn’t rewrite unchanged files and converts only the new files that download.

EOL conversion only works when you download files. A check in always preserves the content you create.

There are two ways to enable EOL conversion, which is disabled by default:

Note: The recommended best practice is to start with a clean workspace before you enable EOL conversion.

Refer to more information on how to use value pattern configuration files.

Note: If you don’t set a conversion type, UVCS uses the general conversion type configured in your client.conf file.

**Examples:**

Example 1 (unknown):
```unknown
client.conf
```

Example 2 (unknown):
```unknown
eolconversion.conf
```

Example 3 (unknown):
```unknown
client.conf
```

Example 4 (unknown):
```unknown
AutoEolConversion key:
```

---

## Types of merge rules

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/merge-rules/rule-types

**Contents:**
- Types of merge rules#
- Only allow reviewed merges#
  - only_allow_merges_if_reviewed example#
- Restrict merges to a branch#
  - restrict_merges_to_branch example#
- Only allow merges from a parent branch#
  - only_allow_merges_from_parent example#
- Only allow merges from a child branch#
  - only_allow_merges_from_children example#

Learn what merge rules are available and refer to examples on how you can apply them. Find more information on how to set up merge rules.

To only allow users to merge branches if they have an approved code review, use the following rule:

The following example applies to all repositories and ensures that all branches that follow the naming pattern QUAK-* need an approved review before they merge to the main branch:

To ensure that merges to a specific branch can only come from a defined set of branches, use the following rule:

The following example applies to only the examplerepo repository. The merge rule ensures that only merges from source branches named fixes-* can merge to the destination branch /fix3.0:

To only allow merges to a given branch if the merge is from its parent branch, use the following rule:

The following example applies to repositories that match the name game*. This rule ensures that any branches that match the name task* can only receive merges from a parent branch:

To only allow merges to a given branch if the merge is from its child branches, use the following rule:

The following example applies to repositories that match the name game*. This rule ensures that any branches that match the name iteration* can only receive merges from their child branches.

**Examples:**

Example 1 (unknown):
```unknown
only_allow_merges_if_reviewed
```

Example 2 (unknown):
```unknown
only_allow_merges_if_reviewed
```

Example 3 (unknown):
```unknown
only_allow_merges_if_reviewed
```

Example 4 (unknown):
```unknown
[{

   "enabled": true,
   "repositories": "*",
   "rule": "only_allow_merges_if_reviewed",
   "to":
   {
      "branchNames": ["main"]
   },
   "from":
   {
      "branchNames": ["QUAK-*"],
   }
}]
```

---

## Unity Gaming Services SDK for the Unreal Engine

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/ugs-for-the-unreal-engine

**Contents:**
- Unity Gaming Services SDK for the Unreal Engine#
- Authentication SDK for Unreal Engine#
- Multiplay Hosting SDK for Unreal Engine#
- Matchmaker SDK for Unreal Engine#

The Unity Gaming Services SDK contains the following three Unity products to help you implement into the Unreal Engine.

Unity Authentication provides anonymous and platform-specific authentication solutions for its supported platforms, including mobile and PC.

The Multiplay Game Server SDK for Unreal Engine includes all the functionality necessary to leverage Multiplay scaling and game server services in your game.

The Matchmaker SDK for Unreal Engine contains all the functionality necessary to leverage the Unity Matchmaker service within your game.

---

## LICENSEINFO

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/licenseinfo

**Contents:**
- LICENSEINFO#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Displays license information and license usage.

cm licenseinfo | li [--server=<repserverspec>] [--inactive] [--active] [--sort=(name|status)]

The information displayed consists of expiration date, activated and deactivated users, etc.

cm licenseinfo --server=myserver:8084

cm licenseinfo --sort=name

**Examples:**

Example 1 (unknown):
```unknown
cm licenseinfo | li [--server=<repserverspec>] [--inactive] [--active] [--sort=(name|status)]
```

Example 2 (unknown):
```unknown
cm licenseinfo
```

Example 3 (unknown):
```unknown
cm licenseinfo --server=myserver:8084
```

Example 4 (unknown):
```unknown
cm licenseinfo --sort=name
```

---

## Integrate using C++

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/sdk/unreal-engine-sdk/cpp-integration

**Contents:**
- Integrate using C++#
- Add the Multiplay Game Server SDK as a dependency#
- Multiplay Server Config Subsystem#
  - How to Access UMultiplayServerConfigSubsystem#
  - GetServerConfig#
- Multiplay Game Server Subsystem#
  - SubscribeToServerEvents#
  - OnAllocate#
  - ReadyServerForPlayers#
  - UnreadyServer#

The following section shows how to integrate with the Multiplay Game Server SDK using Unreal Engine Subsystems.

Three interfaces are available in the Multiplay Game Server SDK:

Refer to Programming Subsystems (Unreal Engine).

Before continuing, add MultiplayGameServerSDK as a public dependency of your module, then include the plug-in header files in your classes.

Add MultiplayGameServerSDK as a dependency of your module to your Unreal project build file:

Include the plug-in header files you wish to access in your own classes:

This subsystem that retrieves the server configuration for the current session.

This subsystem reads the server.json file and exposes its values via the MultiplayServerConfig struct.

MultiplayServerConfig has the following values:

MultiplayServerConfigSubsystem automatically reads the server.json file on subsystem initialization.

First, you must get a reference to the subsystem, MultiplayServerConfigSubsystem is a GameInstanceSubsystem. You can retrieve it from GameInstance.

After you have a reference to the subsystem, retrieve MultiplayServerConfig using MultiplayServerConfigSubsystem::GetServerConfig()).

The Multiplay Game Server Subsystem allows you to subscribe (and respond) to game server events, such as when a game server becomes allocated and when a game server is ready for players. Refer to Game server lifecycle and Server readiness.

You can access the Multiplay Game Server Subsystem by obtaining a reference to the MultiplayGameServerSubsystem subsystem. MultiplayGameServerSubsystem is a GameInstanceSubsystem that you can retrieve from GameInstance.

Use the SubscribeToServerEvents()) method to establish a connection between the game server instance and the SDK daemon.

The SDK daemon transmits events to the game server, including OnAllocate and OnDeallocate events. By subscribing to these events, the game server knows when your matchmaker (or another allocating service) allocates and deallocates Multiplay to game sessions.

The OnAllocate multicast delegate lets the game server know when the game server is allocated. Game server instances must subscribe to the OnAllocate callback to know when the instance has been allocated.

Use the OnAllocate callback to perform any setup logic necessary when the game server becomes allocated.

Use the ReadyServerForPlayers()) method to let Multiplay know that a game server is ready to accept players.

Use the UnreadyServer()) method to let Multiplay know that a game server is no longer ready to accept players.

Scenarios in which you might want to use UnreadyServer()) include:

A game match is almost complete

A game match is complete

The game server is full

Use the OnDeallocate callback to subscribe to deallocation events. You might want to perform any last-minute cleanup or bookkeeping in response to a deallocation event.

Last-minute cleanup might include collecting telemetry data from the server and beginning the shutdown process by disposing objects and calling RequestExit to quit the application.

The Multiplay Server Query Handler Subsystem allows you to set game server variables monitored by the game server query protocol.

The Multiplay Game Server SDK has a full implementation of Unity’s Server Query Protocol, so the game server only needs to populate the variables. Refer to Server Query Protocol to learn more.

Use the Multiplay Server Query Handler Subsystem to send the relevant information to the game server’s SQP protocol.

Before using the Multiplay Server Query Handler Subsystem, you must retrieve it as shown in the following code snippet.

After retrieving the subsystem, you can connect and disconnect to the game server and set and get the game server query values.

Use the set methods to configure all the game server query values:

Use the accessor methods to access the game server query values:

IncrementCurrentPlayers()) provides a means of atomically increasing the current number of players whenever a player joins the match:

DecrementCurrentPlayers()) provides a means of atomically decreasing the current number of players whenever a player leaves the match:

Use the SetCurrentPlayers()) method to set the number of players connected to the game server. The following example shows how to set the current number of players to 32.

Use the SetMaxPlayers()) method to set the maximum number of players allowed to connect to the game server. The following example shows how to set the maximum allowed number of players to 64.

Use the SetServerName()) method to set the game server name. The following example shows how to set the game server name to AwesomeServer.

Use the SetGameType()) method to set the game type the game server is running. The following example shows how to set the game type to SearchAndDestroy.

Use the SetBuildId()) method to set the game server build ID. The following example shows how to set the build ID to NewBuildId.123.0.1.

Use the SetMap()) method to set the game server map name. The following example shows how to set the game map to MAP_TD_Dusthill.

Use the SetPort()) method to set the game server port number. The following example shows how to set the game server port to 8080.

This is the port number from which the game client can connect to the game server. It's separate from the query port number.

It’s best to continuously update these values throughout the duration of the game. Keeping the values as up-to-date as possible ensures Multiplay collects and displays data while the server is running. After setting all the values, you can make a call to Connect().

Use the Connect()) method to connect to the game server.

Use the GetCurrentPlayers()) method to get the number of players connected to the game server.

Use the GetMaxPlayers()) method to get the maximum number of players allowed on the game server.

Use the GetServerName()) method to get the game server name.

Use the GetGameType()) method to get the game server type.

Use the GetBuildId()) method to get the ID of the build the game server is running.

Use the GetMap()) method to get the active map of the game server.

Use the GetPort()) method to get the port number of the game server.

This is the port number from which the game client can connect to the game server. It's separate from the query port number.

Use the Disconnect()) method to disconnect from game server updates. After you disconnect from the server, you no longer receive updates about the game server, such as allocation and deallocation events.

**Examples:**

Example 1 (unknown):
```unknown
MultiplayGameServerSDK
```

Example 2 (unknown):
```unknown
MultiplayGameServerSDK
```

Example 3 (unknown):
```unknown
PublicDependencyModuleNames.AddRange(new string[] { "Core", "CoreUObject", "Engine", "InputCore", "MultiplayGameServerSDK" });
```

Example 4 (unknown):
```unknown
PublicDependencyModuleNames.AddRange(new string[] { "Core", "CoreUObject", "Engine", "InputCore", "MultiplayGameServerSDK" });
```

---

## Unity Mirror sample

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/mirror

**Contents:**
- Unity Mirror sample#
  - Requirements and limitations#
    - Limitations#
    - Prerequisites#
  - Sample architecture#
    - Game client#
    - Game server#
  - Guides#
    - Install the Mirror sample from the Asset Store#
    - Test the sample project#

Important: This sample is deprecated. This sample was tested on Unity 2020.3 and is not maintained for later versions.

Welcome to the Unity Mirror sample project! This project demonstrates using the Unity Transport Package (UTP) and Relay with the Mirror Networking API.

You can find the files for UTP in the Assets/UTPTransport directory and the files for Mirror in the Assets/Mirror directory.

Note: This sample project uses code and information from Shrine's Mirror Networking series on YouTube.

The Unity Mirror sample has the following requirements:

This sample doesn't work with Multiplay Hosting out of the box. However, it's possible to adapt the sample to work with Multiplay Hosting. If you want to adapt the sample to use GSH, remember that Relay is a peer-to-peer-mimicking solution that fills the same space as GSH. As a result, it wouldn't make sense to use Relay and GSH together.

Before continuing, make sure you have all the prerequisites for using the sample project:

The Unity Mirror Sample project has two distinct components:

The game client and game server components use Unity and the Mirror Networking API.

The game client is the executable that players run locally on their machine to connect to the game server and backend services. You can run the game client with Relay or without Relay.

The game server is the build executable that runs the game server process.

You can run the game server executable locally (for development) or host it with a service such as Multiplay Hosting for production.

Note: From the perspective of the Relay service, the game server is the game client of the host player.

The following sections cover how to interact with, test, and adapt the sample project:

Complete the following steps to install the UTP Transport implementation from the sample project into your project. You can also get the sample project code from the repository on GitHub.

Warning: Before testing the sample project, make sure you’ve enabled and set up Relay in the Unity Dashboard.

To launch two instances of the sample project for testing purposes, complete the following steps:

After you have authenticated both editor instances with UAS for Relay, you can test the sample project's UTP transport and Relay functionality.

Use the sample GUI to test the following functionality:

Note: Ensure that you are using the correct buttons when testing each component

You can cross-compile both the game client and game server executables for Linux through the Unity Editor:

After the Linux Build Support module finishes installing, select Linux as a build option within the Unity Editor:

You can run the game client component locally as a standalone application or through the Unity Editor.

To run the game client as a standalone application, select the game client executable through the file explorer or through a command-line interface.

To run the game client through the Unity Editor:

Note: When you first open the Unity Mirror sample project, it might take a couple of minutes for Unity to import all the files and packages.

You can run the game server component locally through a command-line interface with the -server argument.

You can run the game client and game server executables locally by running one as a standalone application and the other through the Unity Editor.

Note: Before running the game client and server, you must create both a server and client build.

For example, to run the game server as a standalone application and the game client through the Unity Editor:

Note: The default port for the game server is 7777. Use the -port argument to change the port number.

The Unity Mirror sample project provides sample code for performing the following tasks:

The NetworkManager class in Assets/Mirror/Runtime/NetworkManager.cs is a singleton instance of the Mirror Network Manager. Use the Mirror Network Manager component to manage the networking aspects of multiplayer games, such as game state management, spawn management, and scene management.

The RelayNetworkManager class in Assets/UTPTransport/RelayNetworkManager.cs extends the NetworkManager class with Relay capabilities. It demonstrates how to:

The UtpTransport class in Assets/UTPTransport/UtpTransport.cs is an instance of Mirror.Transport that's compatible with UTP and Relay. It demonstrates how to:

The MyNetworkManager class in Assets/Scripts/MyNetworkManager.cs is an instance of RelayNetworkManager that ties the functionality of the UTP transport for Mirror and the Relay service together.

The MenuUI class in Assets/Scripts/MenuUI.cs is responsible for displaying the UI that drives the sample. It interfaces with MyNetworkManager to launch servers and connect clients.

This sample has a Unity Transport Package (UTP) transport for Mirror. You can use the code from this sample in your own project by following the instructions in the following sections.

Note: See the Requirements and limitations section before continuing.

Complete the following steps if you are already using Mirror and want to migrate from one of the built-in Transports to the UTP Transport.

If you want to use Relay, you must use UTP.RelayNetworkManager instead of Mirror.NetworkManager. This is because UTP.RelayNetworkManager inherits from Mirror.NetworkManager and adds functionality for interacting with the Relay service.

Before you use Relay, you must authenticate with the Unity Authentication Service (UAS). The Relay service requires you to authenticate even if you use your own authentication service.

The following code snippet demonstrates how to authenticate with the Unity Authentication Service:

After you are authenticated, you can use UTP.RelayNetworkManager to allocate a Relay server or join a Relay server using a join code.

Having trouble getting started? We can help. Go to the Relay support portal and submit a ticket. Make sure to select Networking Package > Mirror for the ticket category.

**Examples:**

Example 1 (unknown):
```unknown
Assets/UTPTransport
```

Example 2 (unknown):
```unknown
Assets/Mirror
```

Example 3 (unknown):
```unknown
com.unity.services.multiplayer
```

Example 4 (unknown):
```unknown
com.unity.services.relay
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/get-started

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/apple-privacy-manifest-core

**Contents:**
- Apple privacy manifest#
- Add the PrivacyInfo.xcprivacy file to your project#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements. The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

Include Vivox's PrivacyInfo.xcprivacy file to your Xcode project by dragging and dropping the file directly into your Xcode project files. The file is at vivox-sdk/SDK/Libraries/PrivacyInfo.xcprivacy. Alternatively, you can use the code sample below these steps to create the PrivacyInfo.xcprivacy file yourself.

Once you're ready to submit your game to the App Store, generate an archive from Xcode using the Product > Archive menu option.

Once complete, right-click your application bundle in the popup window and generate the privacy report to answer Apple's privacy-related questions.

Follow Apple documentation to upload your build to App Store Connect (Apple documentation).

The following code sample contains the PrivacyInfo.xcprivacy manifest for the Vivox SDK:

**Examples:**

Example 1 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeOtherDataTypes</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeOtherDiagnosticData</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<false/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypePerformanceData</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeProductInteraction</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeDeviceID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeAudioData</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeOther</string>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeSensitiveInfo</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeOther</string>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

Example 2 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeOtherDataTypes</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeOtherDiagnosticData</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<false/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypePerformanceData</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeProductInteraction</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeDeviceID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeAudioData</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeOther</string>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeSensitiveInfo</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeOther</string>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## Quality of service (QoS)

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/qos

**Contents:**
- Quality of service (QoS)#

Note: QoS currently doesn't work if you're using Relay with WebSockets/WebGL.

Relay’s quality of service (QoS) feature allows you to select a region automatically based on quality of service data by starting the NetworkDriver as a host player without selecting a target region.

Note: Not all Unity Editor versions support QoS. Make sure you’re using one of the following versions if you plan to use QoS SDK:

Creating an allocation request without specifying a region triggers the Allocations service to use quality of service data to select the best available region based on the quality of the connection between each region and the host. Relay considers both latency and packet loss. Check out the sample code below.

The diagram below shows how Relay selects a region based on QoS data between the host player client and the available regions. If Relay can't locate QoS servers or collect measurements, it uses the client's location to pick the nearest region. If the client's location can't be determined, then it resolves to the default region, which is Central US.

**Examples:**

Example 1 (unknown):
```unknown
// Launch this method as a coroutine
private IEnumerator StartRelayServer()
{

  // Request an allocation to the Relay service without a target region
  var relayMaxPlayers = 5;
  var allocationTask = RelayService.Instance.CreateAllocationAsync(relayMaxPlayers);

  while(!allocationTask.IsCompleted)
  {
      yield return null;
  }

  if (allocationTask.IsFaulted)
  {
      Debug.LogError("Create allocation request failed");
      yield break;
  }

  var allocation = allocationTask.Result;

  // Request the join code to the Relay service
  var joinCodeTask = RelayService.Instance.GetJoinCodeAsync(allocation.AllocationId);

  while(!joinCodeTask.IsCompleted)
  {
      yield return null;
  }

  if (joinCodeTask.IsFaulted)
  {
      Debug.LogError("Create join code request failed");
      yield break;
  }

  // Get the Join Code, you can then share it with the clients so they can join
  var joinCode = joinCodeTask.Result;

  // Format the server data, based on desired connectionType
  var relayServerData = HostRelayData(allocation, "dtls");

  // Create the network parameters using the Relay server data
  var relayNetworkParameter = new RelayNetworkParameter{ ServerData = relayServerData };

  // Bind and listen to the Relay server
  yield return ServerBindAndListen(relayNetworkParameter);
}
```

Example 2 (unknown):
```unknown
// Launch this method as a coroutine
private IEnumerator StartRelayServer()
{

  // Request an allocation to the Relay service without a target region
  var relayMaxPlayers = 5;
  var allocationTask = RelayService.Instance.CreateAllocationAsync(relayMaxPlayers);

  while(!allocationTask.IsCompleted)
  {
      yield return null;
  }

  if (allocationTask.IsFaulted)
  {
      Debug.LogError("Create allocation request failed");
      yield break;
  }

  var allocation = allocationTask.Result;

  // Request the join code to the Relay service
  var joinCodeTask = RelayService.Instance.GetJoinCodeAsync(allocation.AllocationId);

  while(!joinCodeTask.IsCompleted)
  {
      yield return null;
  }

  if (joinCodeTask.IsFaulted)
  {
      Debug.LogError("Create join code request failed");
      yield break;
  }

  // Get the Join Code, you can then share it with the clients so they can join
  var joinCode = joinCodeTask.Result;

  // Format the server data, based on desired connectionType
  var relayServerData = HostRelayData(allocation, "dtls");

  // Create the network parameters using the Relay server data
  var relayNetworkParameter = new RelayNetworkParameter{ ServerData = relayServerData };

  // Bind and listen to the Relay server
  yield return ServerBindAndListen(relayNetworkParameter);
}
```

---

## Back up and restore your data

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/backups/backups

**Contents:**
- Back up and restore your data#

Back up and restore the data in your Unity Version Control (UVCS) server. The backup and restore procedures are closely related to the database back end you use in Unity Version Control (UVCS).

---

## Update strategies

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/concepts/update-strategies

**Contents:**
- Update strategies#
  - Best score#
  - Latest score#
  - Total score#

You can choose between best score, latest score or total score update strategies.

These are applied when a player score is saved to a leaderboard.

Use the best score update strategy to store a player's highest score when a leaderboard is configured to sort from from highest to lowest, or to store their lowest score when a leaderboard is configured to sort from lowest to highest.

Use the latest score update strategy to store the most recent score for a player, regardless of if it's higher or lower than their previous score.

Use the total score update strategy to add a player's score to their existing score - or create a new entry for the player on the leaderboard if they don't have one.

You might use this to track experience points accumulated, number of coins collected or the number of games a player has played/won/lost.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/find-differences

---

## Access the server administration console

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/access-webadmin

**Contents:**
- Access the server administration console#
- Launch the administration console#
- Set a password#
  - Configure required settings#

Access the server administration console to configure your Unity Version Control (UVCS) server settings.

When you install the Unity Version Control server, you install it with default configuration values and it is ready for your UVCS clients to connect to it and run. The UVCS On-Prem server administration console is a cross-platform server configuration tool UI that the administrator can use to configure the server settings to suit the organization's needs.

To launch the server administration console, you can use one of the following methods:

To open the administration console, you need to enter the required credentials.

If your server is newly installed, set a password to access the administration console.

If you’ve set the server up, but the administration console password isn’t set, use the plasticd admindpwd utility to configure a password:

Open the command line as an administrator.

Run the following command:

Navigate back to the administration console and select Refresh.

Enter the configured password and select Log in.

You can also access other relevant information:

Note: If you edit the server.conf, network.conf, db.conf, and lock.conf files, the UVCS server reloads the configuration immediately.

**Examples:**

Example 1 (unknown):
```unknown
http://localhost:7178
```

Example 2 (unknown):
```unknown
[https://ipserver:7179](https://ipserver:7179)
```

Example 3 (unknown):
```unknown
WebAdminToolSslPort
```

Example 4 (unknown):
```unknown
server.conf
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/symlink-support

---

## Privacy and consent for Relay

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/privacy-and-consent

**Contents:**
- Privacy and consent for Relay#
- Privacy overview#
- Apple privacy manifest#
- Google Play data safety#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## Message

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/message

**Contents:**
- Message#

The message feature allows a user to send a message to a friend. This is not intended to be a full-fledged chat feature but rather a simple way of sending a notification to a friend. For example, a developer could create and invite someone to a game by allowing a user to send an invite to a lobby, with the necessary information to join that lobby.

A message is only sent to users that have their availability as ONLINE, BUSY, or AWAY. The message must also be a serializable object.

---

## Proxy servers

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/proxy-server

**Contents:**
- Proxy servers#
- Proxy storage#
- Log file#

Use a proxy server with UVCS to help you balance traffic between two machines. For example, you can have a remote server and a local proxy machine. You can configure your proxy server as a daemon, Windows service, or start it manually from the command line.

There are multiple benefits if you use a proxy server with UVCS:

Note: proxy-data-path is the directory where the proxy is configured to store the cache. For existing Proxy installations, the new version rebuilds the cache on the fly.

The UVCS proxy monitors free space on your disk and cleans up the cache to avoid using up all of the space. For example, the log records something similar to the following when you run low on disk space:

If there is enough room on the disk (twice the size of the cache), then the log records something similar to the following:

**Examples:**

Example 1 (unknown):
```unknown
proxy-data-path/proxy-lru.dat
```

Example 2 (unknown):
```unknown
proxy-data-path/proxy-last-cache-walk.dat
```

Example 3 (unknown):
```unknown
proxy-data-path
```

Example 4 (unknown):
```unknown
INFO  Daemon - Disk is running out of space. 5.78 Gb available. Will delete 1.15 Gb from cache
INFO  Daemon - Cleaning up 1.15 Gb (9576 entries)
INFO  Daemon - Cleaned up 1.15 Gb (9576 entries) in 2578 ms
```

---

## 

**URL:** https://docs.unity.com/authentication/manual/approaches-to-authentication

---

## SQL Data Explorer queryable tables

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/sql-data-explorer-tables

**Contents:**
- SQL Data Explorer queryable tables#
- EVENTS#
- USERS#
- FACT_USER_SESSIONS_DAY#
- FACT_EVENT_TYPE_USERS_DAY#
- FACT_WAU_USERS#
- FACT_MAU_USERS#

Through the SQL Data Explorer you have access to a number of tables.

For examples of SQL queries that can be written to access data via these tables, see the [SQL Data Explorer Cookbook](https://github.com/Unity-Technologies/UGS-SQL-Cookbook/tree/main/SQL Data Explorer Queries#queries).

This table lists all of the events that have been sent in from your application. Event-specific parameters can be found in the EVENT_JSON column as a JSON object. As the parameters are stored as a JSON object, you'll need to parse the content in order to query it. Examples for parsing your parameters can be seen in the samples included in this repository. You can also retrieve the syntax to parse the parameters by typing in the parameter name and pressing TAB to auto-complete the syntax. This table is updated every 1-2 hours.

This table lists all the users who have sent in an event in the past. For each user, the columns contain a variety of useful metrics. This table is updated every 3-4 hours.

This table has a record for each user session. Each record contains a variety of user level aggregate KPIs for that session. If any of the dimensions excluding aggregate dimensions, are recorded in this table change during a session (for example, AGE_GROUP or GENDER), a new record will be created for that session. This table is updated every 1-2 hours.

This table lists all of the events a user has recorded in one day and how many times they have sent in each of those events. This table is updated every 1-2 hours.

This table lists all of the users that have sent in an event in the last seven days. This table is updated every 1-2 hours.

This table lists all of the users that have sent in an event in the last 30 days. This table is updated every 1-2 hours.

**Examples:**

Example 1 (unknown):
```unknown
UNITY_ENVIRONMENT_NAME
```

Example 2 (unknown):
```unknown
UNITY_APPLICATION_NAME
```

Example 3 (unknown):
```unknown
ACQUSITION_CHANNEL
```

Example 4 (unknown):
```unknown
MAIN_EVENT_ID
```

---

## PURGE UNREGISTER

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/purge-unregister

**Contents:**
- PURGE UNREGISTER#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Purge actions can be deleted from the registry if you decide to not run them. Remember that it is not possible to unregister purges that were already executed.

cm purge unregister <purge_guid> [--server=<server>]

cm purge unregister 545ec81b-23ea-462c-91f4-d7c62a6e8817

(purges that were not executed can be deleted from the registry)

cm purge unregister 545ec81b-23ea-462c-91f4-d7c62a6e8817 --server=myorg@cloud

(you can specify a different server to unregister the purge)

**Examples:**

Example 1 (unknown):
```unknown
cm purge unregister <purge_guid> [--server=<server>]
```

Example 2 (unknown):
```unknown
cm purge unregister 545ec81b-23ea-462c-91f4-d7c62a6e8817
```

Example 3 (unknown):
```unknown
cm purge unregister 545ec81b-23ea-462c-91f4-d7c62a6e8817 --server=myorg@cloud
```

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/privacy-and-consent

**Contents:**
- Privacy and consent#
- Privacy overview for Economy#
- Apple privacy survey for Economy#
- Google Play data safety for Economy#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## Configure GitServer

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gitserver/configure-gitserver

**Contents:**
- Configure GitServer#
- Prerequisites#
- Quickstart guide#
- gitserver.conf file#
- Configure http port on Windows#
- Configure HTTP authentication#

Set up Gitserver to work with your Unity Version Control (UVCS) server.

Enable GitServer so that you can push and pull from GitHub to UVCS. After you enable GitServer, you can edit the configuration file to customize how GitServer works with your repositories. You can also configure your http port on Windows, and set up HTTP authentication for security.

To enable GitServer on your UVCS server:

After you create this file, you can push and pull from GitHub to UVCS as follows:

This command pushes your GitHub repository to the Plastic repository named default.

The gitserver.conf file controls the GitServer configuration, and has the following format, where each line is optional:

If you run your UVCS server in a non-admin mode instead of as a Windows service, grant permissions that allow GitServer to use an HTTP port to the user who runs the process. To add the permissions, use the following command:

GitServer can use HTTP basic authentication to secure GitHub clients. This means that the GitHub client asks you to enter the username and password when you connect to GitServer. The UVCS server only checks if the user that authenticates has permissions in UVCS to access the specified repository.

Note: To authenticate users, the UVCS needs to be configured in LDAP, AD, or UP security modes so that the GitHub client can enter a valid user and password.

To set up HTTP authentication so that it works with GitServer:

Add the following entry to your gitserver.conf file to configure HTTP authentication:

Add the following entry to your gitserver.conf file to configure GitServer to listen in the HTTP protocol:

**Examples:**

Example 1 (unknown):
```unknown
gitserver.conf
```

Example 2 (unknown):
```unknown
plasticd.exe
```

Example 3 (unknown):
```unknown
git push --all git://localhost/default
```

Example 4 (unknown):
```unknown
git push --all git://localhost/default
```

---

## Unity In-App Purchasing

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/overview

**Contents:**
- Unity In-App Purchasing#
- Additional resources#

Unity In-App Purchasing (IAP) provides a unified system for implementing and managing in-app purchases across multiple stores.

Use the Unity IAP service to sell a variety of digital content from within your application. It provides a unified API to manage transactions across multiple digital distribution platforms, including the Apple App Store and Google Play Store. Unity IAP makes it easier to implement and manage purchases for different stores.

With Unity IAP, you can sell different types of content, such as consumable items that can be purchased multiple times, non-consumable entitlements that are purchased once, and recurring subscriptions. This documentation explains how to configure Unity IAP, define your products, and implement a secure purchasing workflow in your project.

---

## Access Control

**URL:** https://docs.unity.com/ugs/manual/overview/manual/access-control

**Contents:**
- Access Control#
- How Access Control works#
- How to use Access Control#
  - Example policies#
  - Error responses#
- Policy selection in Access Control#
- Resource URNs and Query Parameter Handling#
  - Rules for Query Parameter Handling in Resource URNs#
  - Backward Compatibility#
- Best practices#

Access Control for Unity Gaming Services (UGS) allows you to defend your game state and logic in UGS from cheaters and exploiters. Access Control (also known as API Authorization) is important as it lets you control who can access, modify, or delete game data and resources in order to protect the game from unauthorized access.

API authorization for UGS is the process of determining what actions a user is allowed to perform once they have been authenticated. Authentication verifies that a user is who they claim to be. Together, authentication and authorization provide a secure way to control access to APIs and access to resources. UGS provides an Authentication solution that works with API authorization described in this documentation.

Without authentication, anyone can access the API and potentially perform unauthorized actions. For example, if an API allows users to view sensitive information or make changes to data, and there is no authentication in place, anyone can access that information or make changes without permission.

Authentication establishes the identity of the user, and authorization controls what actions they are allowed to perform. Authentication provides the necessary foundation for authorization to work. It’s like a key that unlocks the door of the API, but the authorization decides if the user is allowed to enter, and what they can do once they are in.

Access Control in UGS is configured using resource policies. UGS services enforce rules for who can access those services and what actions they are allowed to perform.

When a user attempts to access a UGS service, the service checks the user's identity against the configured policies and either denies or allows an API request.

A resource policy is a collection of statements. The statements are defined in terms of the user’s identity (the Principal attribute), what actions (the Action attribute) are restricted or allowed (the Effect attribute), and the resource the policy applies to (the Resource attribute). A policy also contains a Sid attribute (Statement Identifier), a user-defined descriptive name for the given policy which can only contain alphanumeric characters and hyphens.

The resources in the policies are defined as Uniform Resource Names (URNs), which typically end in API paths that make up the component parts of the URN.

Resource policies are configured on a per-project or per-player basis. A project policy is evaluated for all Principals that call UGS services for that project. A player policy is only evaluated for an individual player within the scope of a project and environment.

Here is an example of a valid URN in the Economy service:

It uses a glob pattern to match a set of resources that share a common pattern. The following table describes the different components of this URN.

Because URN matching uses glob patterns, the above URN can also be defined as the following.

urn:ugs:economy:/**/currencies/gold

When no Access Control policies are created, Access Control defaults to allowing all authenticated API calls from authenticated players. That could be described using the following resource policy.

The following example shows how to create a valid policy to allow authenticated players to read, but not change (write), the gold currency in Economy via an API call.

Alternatively, to completely deny access to authenticated players to all APIs within Economy:

Use the REST API or the UGS CLI to create resource policies for UGS. These policies only need to be created once and are evaluated and enforced for each API call to UGS within the context of the authenticated caller.

Do not allow Players to execute any Cloud Code scripts:

This resource policy denies access to all actions on cloud code scripts in the project that a Player is authenticated for. Cloud Code only provides an execute API as a POST request to that API, which falls under the Write Action in the above policy statement.

Below is another example of what a resource policy for Cloud Save could be:

This resource policy denies write access to all the cloud save data for any authenticated player for the project, including all nested paths and subfolders under items for a user or group with a Player identity. This effectively prevents Players from directly writing data to Cloud Save. Combining this policy with the previous policy for Cloud Code, means a developer could write data to Cloud Save via Cloud Code and implement any additional game logic within Cloud Code.

Below are the different components that make up a policy and what they do.

When a player attempts to access a resource for which they don't have appropriate permissions, an error response is returned with a status code of 403 Forbidden. The exact format of the error response depends on the type of access control policy in place.

If a player is restricted from accessing a resource based on a project-based policy, the error response includes the following fields:

If a player is restricted from accessing a resource based on a player-based policy, the error response includes the following fields:

If the player is temporarily banned, the error response also includes an expiresAt field which indicates when the ban expires:

If the player is permanently banned, the error response doesn't include an expiresAt field. You should handle these error responses appropriately in your application code to ensure a smooth user experience.

When Access Control policies are evaluated, only the most specific rule wins and its effect is applied.

Below are three example policies.

If a request is made to */currencies/silver, the second rule, allow /currencies/*, is applied because it is more specific than the first rule.

If a request is made to */currencies/gold, the third rule, deny */currencies/gold, is applied because it is the most specific rule that matches the request.

If there are multiple policies that list the exact same Resource, then the Deny Effect always takes precedence.

Resource URNs support query parameter-specific matching for flexible policy definitions. The rules governing how query parameters are evaluated depend on the structure of resource URNs in policies.

Access Control policies evaluate resource URNs as follows:

1.URNs with Query Parameters

If the defined policy URN includes specific query parameters (?), such as:

The policy matches requests that contain the exact path and query parameters specified in the URN. This enables precise control over requests based on the path and query parameter values.

2.URNs with a Wildcard(*)

If the defined policy URN ends with a *, such as:

The policy matches requests with the specified path (up to the wildcard) and any query parameters attached to the request.

3. URNs Without Query Parameters or Wildcard (*)

If the defined policy URN does not contain a ? or end with a *, such as:

Query parameters from the request are stripped during evaluation. This ensures that the policy applies strictly to the path, preventing misuse of query parameters to bypass authorization policies.

Resource URN matching rules are designed to maintain backward compatibility with existing policies. Policies created before this update that do not define query parameters (or use wildcards * at the end) will continue to evaluate requests based only on the path, excluding query parameters.

This avoids unintended bypasses or behaviors while enabling query parameter matching for newly defined or updated policies.

Start with a default policy of denying all access and explicitly grant access to specific APIs or resources.

Grant only the minimum permissions required for an API or resource.

Create policies for specific API methods and resources, rather than for all APIs and resources.

The URNs for the services are listed below. Note that Friends are Player Name use the same URN prefix, so you may need to add the routes you want to block into the resource field.

Regularly review and update API policies to ensure they reflect the current state of the game and to remove unnecessary permissions.

The Access Control APIs are accessible via web endpoints, or REST APIs. REST APIs provide flexibility to automate your workflows using your favorite language and game development engine.

Refer to the Access Control REST API documentation for more information. Refer to the Service Account Authentication documentation for more information on how to authenticate your API calls.

The following example shows how to set a resource policy using the REST APIs with the cURL tool.

To apply your configuration, you must deploy the configuration to the Access Control service.

To deploy Access Control configurations in the Unity Editor you must first install the required packages and link your Unity Gaming Services project to the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

In the Unity Editor, select Edit > Project Settings > Services.

If your project doesn't have a Unity project ID:

If you have an existing Unity project ID:

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

To create Access Control configurations within the Editor, you must install the following packages:

Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

To install these packages and add them to your list of available packages:

Follow these steps to create an Access Control configuration:

The new configuration is now visible in the Project window, and in the Deployment window, accessible by selecting Window > Deployment.

There are two methods to edit an existing Access Control configuration:

Use the UGS Access Control CLI for simpler management and automation of your Access Control configuration.

To configure the UGS CLI:

Run the following command:

ugs deploy <path-to-access-control-file>

**Examples:**

Example 1 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/*/currencies/gold
```

Example 2 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/*/currencies/gold
```

Example 3 (unknown):
```unknown
urn:ugs:economy:/v2/project/
```

Example 4 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/
```

---

## Review text sessions

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/concepts/text-sessions

**Contents:**
- Review text sessions#
- Where to find text sessions#
  - Incidents#
  - Player details#

Text sessions are the collection of messages sent between players within a game session. Safe Text collects these sessions and connects them to incidents within player reports.

Note: Only Safety Moderators and Safety Admins have access to text sessions.

Text session reports contain:

When Context analysis is enabled, text messages that have inappropriate context are included. This analysis is found in session results and incident reports under Incidents.

The Incident section lists all the automatically detected text incidents in the session. Each incident has the following information:

The Player details section lists all the users who were in the text session along with:

---

## Migrating from Git

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/migrating-from-git

**Contents:**
- Migrating from Git#
- Intro#
- What is GitSync?#
- Feature list#
- How does it work?#
  - Initial scenario#
  - Creating a new commit in the Git repo#
  - Creating a new changeset in the UVCS repo#
  - Performing changes concurrently: conflicts#
- The gitsync.conf file#

Unity Version Control System (UVCS) is a full-featured DVCS (Distributed Version Control Software). And, UVCS also speaks the Git network protocol.

UVCS can push and pull changes directly to any remote Git server. This is because UVCS supports the https:// and git:// protocols for pushing and pulling changesets.

This feature immediately turns UVCS into a DVCS fully compatible with Git. The advantage of this is that you can use UVCS or Git on your workstation and still participate in Git projects (GitHub, CodePlex, and many more).

This can be a first approach: GitSync is a native Windows DVCS connected to GitHub. So, it virtually turns UVCS into a full-fledged Windows client for Git.

Note: GitSync is not technically a new Git client: You would be using UVCS on the client-side but can push/pull to Git servers (using https or Git protocols).

Imagine that you're a developer using GitHub (or Bitbucket, or maybe CodePlex). In any case, there are things you like: using a cloud-based repository for your code and Windows to develop. And things you don't like: being forced to use the CLI and lacking really awesome GUI tools.

So, you wish you had everything: Cloud repositories, the DVCS power, and awesome tools for Windows.

That's what you get with GitSync.

The capabilities of GitSync are:

An entire push and pull process will show you GitSync works.

You have a Git repo, and you pull it on UVCS. As a result, you get an exact clone with the branches and commits you had in Git now converted to UVCS, and what's best about this is UVCS is able to render those branches and commits in the Branch Explorer:

The following image shows what happens when a new commit is created on the Git side and how the pull from UVCS retrieves it.

Instead of just performing a simple change, the figure shows a merge from big_feature branch into master. The result in UVCS mimics what happened at the Git side, adding the merge link (which is rendered as a green line) on the UVCS Branch Explorer:

The next step is performing a change in UVCS and pushing the change to Git. To create a more complete example, a merge will also be made instead of just creating a new changeset.

The changesets 6 and 7 are created on the UVCS side, then they're pushed to Git. As you can see in the figure below, the merge information (multiple parents on the Git repo) is also sent from UVCS to Git.

So far, the changes were done at one side or the other, but not at the two sides concurrently.

The following picture shows what happens when developers work on the same branch at the same time. A new commit is created in Git (on green) and another in UVCS (orange):

If the UVCS developer tries to push to Git, an error will show up since there are conflicting changes (which would happen on a similar scenario on a pure UVCS or pure Git setup). The steps to follow are:

First, pull the changes from Git.

A new "subbranch" will be created, placing the 88ffa changeset correctly.

The next steps will be resolving the merge conflict at the UVCS side and then completing the push:

Both repositories will look the same at the end of the interaction and let developers work together on both sides.

Note: Since UVCS is a full DVCS (like Git), it can clone a Git repository and later push changes to it... entirely! We do not restrict to a single branch. You can create branches on UVCS and push them to Git and create branches on Git and pull them to UVCS.

The GitSync configuration file (gitsync.conf) lets you include information automatically used during the GitSync operations.

This information is related to the mapping between two UVCS and Git objects:

Important! The gitsync.conf file must be located in:

In the gitsync.conf file, we can define a mapping between UVCS and Git (emails). This information will be used as author and committer when committing to Git.

This info is added on the email-mapping section in the following format:

An example of gitsync.conf file:

A Git submodule is just a pointer to a commit in a different repository. It doesn't propagate operations between submodules or handle the branching between the repositories, so this very basic information is enough for the submodules work.

A UVCS Xlink object is more complex than the Git submodule: the Xlinks allow the user to set relative servers, set rules for the branch expansion, and define whether the Xlink is writable or not.

In general terms, we can say that Git submodules and UVCS Xlinks have the same mission: pointing to a commit in a different repository. So a direct mapping can be established between:

GitSync lets you create UVCS Xlinks from Git submodules and vice versa. The Git submodules and the UVCS Xlinks can be synchronized using GitSync:

Before synchronizing a repository with Xlinks/Submodules, the target repositories must be synchronized.

To synchronize a repository with Xlinks/Submodules, the mapping information must be added on the gitsync.conf file. This info is added on the submodules section with the following format:

This would be a valid configuration example:

Two Git operations are restricted when using GitSync:

These Git commands don't take into account the history of your changes. Although the user can work in a parallel way, Git talks about history like something linear. But UVCS prioritizes keeping the changes history.

UVCS takes into account the whole history of the changes you make. This means that UVCS doesn't rewrite history (a design decision).

The changes history is reflected when working on branches and merging. Because UVCS can solve and show how the history is, we recommend you avoid using those Git commands when working with GitSync.

Rebasing is a subtle topic in Git - You can only do it before you push (in fact, many recommend that you never use it). Most of the time, it is used to understand the history without going crazy with all the merging:

Note: We don't handle rebases in Git fashion.

The Git fast-forward merge command does something similar, linearly solving the merge:

Note: Use the merge --no-ff command to keep the history.

UVCS has the Branch Explorer, which lets you understand what is going on graphically. This way, you are not distracted and you don't miss rebasing.

When you diff a branch with several merges, it is hard to see what you really changed on the branch and what comes from the merge... this is also solved in UVCS:

Important! We recommend not using the Git rebase and merge (fast-forward) command to avoid issues when synchronizing your UVCS-Git repositories.

In general, do not use those commands that rewrite the history of the repository. For example, delete or move changeset, delete or move labels.

As we've seen previously, UVCS can push and pull directly to remote Git servers using both native Git and HTTPS protocols, including well-known sites such as GitHub, BitKeeper, CodePlex, and many more.

When we started developing the Git-bidirectional synchronization with UVCS, we had the following scenarios in mind:

We went the hard way for a solution: we didn't come up with some sort of intermediate script to convert changes from one system to the other or do fast-import/export, imposing a ton of limitations. But we actually implemented was the Git network protocols in UVCS as a layer able to directly pull and push to Git.

UVCS starts a negotiation phase with the remote Git server, as a Git command would do, speaking the Git protocol. It is a core feature, not an add-on script.

As we've said, GitSync implements the smart-protocol and:

Let's start by connecting to a GitHub repository.

If you go to GitHub and browse the repos, you'll probably find a list of "trendy" repos. The corefx repository is used in the example below:

Now, to pull it to UVCS, a repo is created to "host it" (called corefx too) and in the initially empty Branch Explorer, the context menu option to launch Sync with Git:

Then you launch the Sync dialog (which is very similar to the replication dialog to push/pull changes between UVCS servers) and enter the URL of the Git repo:

No need for credentials now since we're just pulling (cloning) from a public repo. You'll need to specify them if you need to push, and the server requires you to be an authenticated user.

Note: If you use Github and need authentication, you must use a token and not a password. For more information, see Creating a personal access token

Press Sync, and the process (pull) will start up as follows:

Note: This operation can be done by using the command line in the following way: cm sync corefx git https://github.com/corefx/corefx.git

Assuming the local corefx repo is empty, it will calculate the changesets and branches it needs to pull from the remote GitHub repo and will pull them:

To pull new changes done on the GitHub side, simply re-run the same command:

cm sync corefx git https://github.com/corefx/corefx.git

And it will now calculate and pull only the new changes made on the Git side if any.

You're currently pulling Git changesets and branches directly to your local UVCS repository:

Once the replication is complete, go back to the workspace explorer and update the workspace to download the source files.

Refresh the Branch Explorer and you'll be able to render the just imported Git changesets in a typical UVCS way:

And now, right-clicking any changeset (commit in Git jargon), you'll be able to check differences with our built-in diff system:

Now you're ready to do more changes in UVCS, whether branches, merges, anything. Then repeat the same process to sync to Git (which will in turn push or pull changes and even ask you to solve merges before pushing back to Git if concurrent changes were done on the same branches).

We're going to push one of our UVCS repositories to GitHub. This process is similar to the previous one.

Create a new GitHub repository to export your UVCS repository to GitHub:

In this example, the dokancode UVCS repo is used. In the Branch Explorer view, right-click one of its branches and select the Sync with Git menu option:

The Sync dialog will be launched.

Enter the GitHub repository URL and the credentials if needed:

Click the Sync button to start the synchronization. In this case, you're pushing (or exporting) your UVCS repository:

We're currently pushing UVCS changesets and branches directly to my GitHub repository.

Note: This operation can be done by using the command line in the following way: cm sync dokancode git https://github.com/mbctesting/dokancode.git

Assuming the GitHub dokancode repo is empty, GitSync will calculate the changesets and branches it needs to push from the UVCS repo, and will push them:

Once the push operation is finished, you can see a summary of the objects that have been exporting:

If you go back to GitHub and refresh the dokancode repository, you'll see the exported objects from UVCS:

Now you're ready to work with the repository in both sides: UVCS and GitHub. You'll be able to create branches, do changes, and synchronize again by pulling/pushing.

This section explains how to work with the dokancode repo, in the GitHub and UVCS sides, applying some basic operations.

Important! Before performing any changes at either of the sides, you must synchronize your repo (using the Sync with Git action) to avoid conflicts.

As an example, some operations will be run on the master branch:

Delete the license.txt file:

Edit the dokan-net-0.6.0\readme_dokan.txt file:

And move it to dokan-net-0.6.0\DokanNet folder:

And then, create a new branch (scm007).

And edit one of those files:

The commits are done, and you can see them on the UVCS side.

GitSync can calculate what's new on the other side, negotiate with the remote server, and push the changes.

Go to synchronize the UVCS repo with the GitHub one by running Sync with Git:

By clicking Sync, the synchronization will begin and will pull to the UVCS repo the changes you performed on the GitHub side:

Once the synchronization is complete:

You can see a summary with the imported objects:

If you go back to the Branch Explorer and refresh the view, you'll see the changes done on GitHub that have been imported to UVCS:

You can open the Changesets view to see these GitHub changes:

And, if you want to go deeper, you can confirm the changes done with the readme_dokan.txt file on GitHub. You can see the history of that file to check that those changes have been applied with the synchronization:

Now you can continue performing changes on UVCS.

As an example, changes are made to the scm005 branch. At this point, both the Git and UVCS have the same content. You can check it on both sides:

Edit the DokanOperation.cs file:

These are the new changes:

Once the changes are done, synchronize the GitHub repository by running Sync with Git:

Once the synchronization is done, you can see the summary:

The summary tells you that the synchronization has sent two changesets involved in one branch:

If you go to GitHub, you can see these new changes that were done on UVCS:

Note that the UVCS main branch is mapped to the Git master branch. This mapping is also considered for the children branches of main on UVCS. This means that the UVCS branches are converted into Git branches by removing the hierarchy and replacing the / with -. And this rule is also valid when a Git branch is converted into a UVCS branch: the - character is used to recreate the hierarchy in UVCS.

In the examples before, the UVCS branch /main/scm005 is converted to master-scm005. And the Git branch scm007 under master is converted to /main/scm007:

The - character is also allowed as part of the branch name like the following examples:

Since UVCS handles the same concepts as Git (DAG, commits, merge links, and so on), it is straightforward to share the merge tracking. You do a merge in Git, you can get it back to UVCS. If you do a merge in UVCS, you can even push the merge link back to Git.

The most difficult feature for us to handle is the "precise item tracking"; we do (and Git doesn't). UVCS has an internal id associated with each file and directory. It means we can easily handle tons of merge conflicts that are hard to track for Git (like a divergent move, something trivial for UVCS).

In the following examples, you'll see how the merge tracking works when using GitSync.

In the following example, two branches are created:

Branch scm008 - The DokanResetTimeout method is edited in the DokanNet.cs file, moved, and a new field is added:

Branch scm009 - The DokanNet.cs file is moved to another folder, then the method DokanResetTimeout is moved to another class and edited:

Once the changes are done on different branches, they'll be merged to the main branch:

Now the repositories will be synchronized on both sides using the Sync with Git. This will push the merges on the Git side.

The new branches have been pushed and the merge tracking looks like this on Git:

Now we're going to see how a merge in Git is tracked on UVCS.

Create new branch in Git, create a new file and edit another one:

Once the commits are done, perform a merge from the branch (in this case, scm010) to the master branch:

Note: The merge is done using the --no-ff option as we've seen in the GitSync restrictions section.

The merge is complete, and these changes have to be pulled to the remote Git repo:

Once the local Git changes have been pulled to the remote Git repo, synchronize your repos. This means that the latest changes will be pulled to the UVCS repo. Run Sync with Git:

Refresh the Branch Explorer once the synchronization is finished. You'll see how the changes and merge done on Git have been pulled into UVCS:

As seen in the How it works section, you can make changes concurrently both in UVCS and Git. This means that you can work on the same branch on the two systems and reconcile changes (as you do when using a pure UVCS or Git environment).

In the Changes on the Git side section, some changes were made on GitHub:

Now, to perform some changes in UVCS:

In the main branch, edit the DokanNet.cs file:

Once the changes are done, synchronize both repos using Sync with Git:

When the synchronization is finished, a message will pop up saying a merge is needed.

This is because we made some changes in the same branch in Git and UVCS.

In the summary, you'll see that the main (or master) branch is the one that requires a merge operation:

Changes were made in the master branch in Git, and some other changes in the main branch on the UVCS side. Remember, that main and master is the same branch but using different names (see the Git-UVCS Dictionary for further information).

As seen in the How it works section, you have to resolve the merge conflict at the UVCS side.

If you update the Branch Explorer, you'll see that:

To solve this conflict, run a merge from the "GitHub" head (the head of the subbranch):

The changes that are going to be merged:

Click the Process all merges button to automatically merge all items.

The last step is to checkin (confirm) the changes in the Pending changes view:

Once you click the Checkin button, you'll see that the two "heads" are merged into only one head, the one from the main branch:

The merge conflict is now solved. Complete the synchronization by pushing in the Git side the changes done in the UVCS one. This is done by using Sync with Git.

Once this operation is finished, both repos are fully synchronized. This means that you have the same content on both sides.

GitSync supports sync with Git repositories using the SSH protocol.

The SSH protocol lets you connect and authenticate to remote servers and services.

You must have the command line SSH client ssh in your PATH environment variable.

You must add your private SSH key to your ssh-agent. Follow these instructions to add your SSH key to the ssh-agent.

The SSH agent now manages your SSH keys and remembers your passphrase.

You can use GitSync the same way as you usually do with HTTP protocol, by using the UVCS GUI or the CLI.

Let's see an example. If you use the command line, you have to specify the URL accordingly for the SSH protocol:

$ cm sync rep2 git git@github.com:PlasticSCM/Myrepo.git

instead of the HTTPS one:

$ cm sync rep2 git https://github.com/PlasticSCM/Myrepo.git

**Examples:**

Example 1 (unknown):
```unknown
gitsync.conf
```

Example 2 (unknown):
```unknown
gitsync.conf
```

Example 3 (unknown):
```unknown
$HOME/.plastic4
```

Example 4 (unknown):
```unknown
C:\Users\_user_\AppData\Local\plastic4
```

---

## Unity Version Control Extension for Visual Studio

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/vs-extension

**Contents:**
- Unity Version Control Extension for Visual Studio#
- Prerequisites#
- Install the UVCS Extension#
- Select UVCS as your Source Control#
- Open a solution#
- Version Control options#
- UVCS Changes panel#
  - Check-in#
  - Shelve#
  - Undo#

Warning: Unity DevOps is discontinuing support of the Visual Studio extension on the January 9th, 2025. UVCS versions and patches after January 9th don't include support for this plugin. For more information, submit a ticket or send an email to devops-vcs-support@unity3d.com.

Note: If you still use the deprecated Visual Studio Source Control Package, you can refer to the deprecated MS Visual Studio integration documentation.

The Unity Version Control (UVCS) extension works to enhance Visual Studio and allow you to connect and work with your Unity Dashboard repositories. The extension uses your CLI credentials to add UVCS features and built-in controls to effectively manage your version control workflow:

For information on version control concepts in UVCS, refer to the Concepts documentation.

You can install the UVCS Visual Studio extension from your Visual Studio application:

For the extension to install, you need to close any open Visual Studio windows you have open, and select Modify in the resulting pop up window.

You can also view the Unity Version Control Extension for Visual Studio in the Visual Studio Marketplace.

You need to configure Visual Studio to use Unity Version Control as the source control plug-in:

For the UVCS extension to work, you need to open a solution from an existing UVCS workspace. You can create a workspace in the UVCS Unity Dashboard.

To open the UVCS extension specific option menu, you can right-click on a file and select Unity Version Control.

The UVCS Changes window displays new and changed files in your local version of the project. Use this tab to check in your files to the UVCS workspace, exclude files from version control, and compare changed files with the previously checked-in version.

To view more information about the repository, you can hover over a file in the pending changes list. To view more information about the specific changeset and location, you can hover over the branch icon.

To include file modifications in your workspace and allow your collaborators to access them, you need to check them in.

When you check in your files, the UVCS Changes window refreshes and no longer lists the files you have checked in. The files that you check in compile into a changeset, which you can view in the UVCS Workspaces window.

If you don’t want to add your changes to your workspace, but you do want to keep them, you can shelve the changes and return to them later:

To view your shelved changes, select Shelves at the bottom of the window. This tab shows any shelves that you own. If you right-click a shelved change, you have the following options:

Note: If you apply shelved changes, you still need to check the changes in.

If you’ve made changes in your project that you don’t want to keep, you can revert back to the latest checked-in version.

To revert changes to a file:

This removes the selected changes from both the pending changes list and your project.

The UVCS Workspaces window lists the changesets in your workspace. This window shows the following information about each changeset:

To view changesets from a specific branch, you can select a branch from the sidebar.

To view the options, right-click on the changeset:

---

## Custom ID sign-in

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-custom-id

**Contents:**
- Custom ID sign-in#
- Set up a Custom ID Sign In#
- Client-side setup#
- Server-side setup#
- Linking an existing player#

Minimum SDK version: 3.1.0

If you already have an existing player management system that creates player IDs, you can use the Custom ID provider to link the identities.

The Custom ID providers works by having game clients make requests to your game backend. Your backend uses Service Account credentials to generate tokens for the players with custom IDs and returns it to them for use with UGS services.

Since the Unity Authentication service is not in control of the provided player IDs, it needs to rely on a server-authoritative backend and cannot allow game clients to request their own tokens.

This article guides you through the following scenarios to set up authentication for players in your game with a Custom ID provider:

Add Custom ID as an ID provider for Unity:

Create a Service Account and add project role Player Authentication Token Issuer. These credentials will be used by your backend to make requests to the Unity Authentication service.

Together with the server side sign in set up further below, an access token has to be retrieved from your backend and processed with the AuthenticationService:

ProcessAuthenticationTokens is used to process Unity Authentication Service Tokens and makes them available to other UGS SDKs integrated into the game that require the player to be authenticated. This results in the player being effectively signed in using the tokens provided.

You should call ProcessAuthenticationTokens with both the access token and the session token. The Unity Authentication SDK refreshes the access token before it expires to keep the player's session active. Refer to the page on session management for more details.

Alternatively you can call ProcessAuthenticationTokens with only the access token. However since access tokens expire after 1 hour you must manually refresh the access token and call ProcessAuthenticationTokens with the new access token.

Note that the sample code is a method only, not a class.

The access and session tokens need to be retrieved from your backend. Refer to the Server-side setup below for more information on that.

During the player sign-in process on your backend, each player is signed up with Unity Authentication service using their custom ID and granted a accessToken and sessionToken. Your backend uses the Service Account credentials to perform the requests to sign up the players with Unity Authentication.

The response of this request will contain an idToken and a sessionToken that you have to return to the game client for initializing the AuthenticationService. The idToken can be used as the accessToken in this context.

If the player already has a Unity Authentication account, they can be linked by providing the existing access token to the Custom ID sign-in request. The access token will need to be provided either by the player in their request to your backend, or requested by your backend if it knows which existng Unity player ID they want to be linked to:

**Examples:**

Example 1 (unknown):
```unknown
AuthenticationService
```

Example 2 (unknown):
```unknown
ProcessAuthenticationTokens
```

Example 3 (unknown):
```unknown
ProcessAuthenticationTokens
```

Example 4 (unknown):
```unknown
ProcessAuthenticationTokens
```

---

## WHOAMI

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/whoami

**Contents:**
- WHOAMI#
- Description#
  - Usage#
- Help#

Shows the current UVCS user.

Shows the current UVCS user.

---

## Client configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/client-configuration

**Contents:**
- Client configuration#
- Configure in the GUI#
- Configure in the CLI#

Use the client configuration wizard to connect the client to a UVCS server when you install the Unity Version Control (UVCS) client onto a machine.

You can run the client configuration wizard from the UVCS startup menu. To open the wizard manually, enter the following command in the CLI:

In the UVCS configuration window, you can configure the following settings:

After you select Connect, UVCS detects the authentication mode set on the server you connect to. Enter any authentication details the server requires and select Sign in.

To configure your client in the command line, use the command cm configure. In the client configuration wizard, you can configure the following settings:

**Examples:**

Example 1 (unknown):
```unknown
plastic --configure
```

Example 2 (unknown):
```unknown
plasticgui --configure
```

Example 3 (unknown):
```unknown
server:port
```

Example 4 (unknown):
```unknown
cm configure
```

---

## Sample app design overview

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unreal/manual/Unreal/vivox-unreal-sample-app/sample-app-design-overview

**Contents:**
- Sample app design overview#

The Unreal Shooter Game sample app is designed to demonstrate a variety of Vivox features in the context of a first-person shooter game.

For example, various communication features that are typically included in modern first-person shooter games are available in the Unreal Shooter Game sample app, including squad chat, positional chat, push-to-talk, and a roster with speaking indicators.

---

## Get started with the Moderation Platform

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/get-started

**Contents:**
- Get started with the Moderation Platform#
- Ensure Moderation endpoints on the allowlist#
- Import the Moderation SDK#
- Initialize Unity services#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

Before you get started with Unity Moderation, make sure you meet all the requirements.

If you have Safe Text enabled in your project, you have access to the Moderation Platform within the Unity Dashboard.

You can follow the steps in the Safe Text documentation to activate the product in your project.

Once Safe Text is in your project, follow these steps:

Once Moderation is working in your project, assign User roles of Safety Admin and Safety Moderator to other members of your project to begin reviewing reports.

If you're using Access Control in your project, you might be applying a Deny by Default strategy.

If so, to allow the Moderation SDK to send reports to the Moderation service, you need to give players the ability to send reports.

Add the following policy to your project to grant players the ability to send reports:

Once you have linked your project to the Unity Dashboard, you can install the latest version of the Moderation package.

Use the Unity Package Manager to import the Moderation package in the Unity Editor.

Note: The Moderation SDK is available in the following version of Unity in the Package Manager:

The Moderation SDK exposes a singleton instance of a class you can use to report players. To use it, initialize Unity Services and authenticate your players with Unity Authentication Service (UAS).

The following code is an example of how to authenticate a user using UAS:

**Examples:**

Example 1 (unknown):
```unknown
{
  "Sid": "allow-moderation-report",
  "Action": ["*"],
  "Effect": "Allow",
  "Principal": "Player",
  "Resource": "urn:ugs:moderation-report:/*"
}
```

Example 2 (unknown):
```unknown
{
  "Sid": "allow-moderation-report",
  "Action": ["*"],
  "Effect": "Allow",
  "Principal": "Player",
  "Resource": "urn:ugs:moderation-report:/*"
}
```

Example 3 (unknown):
```unknown
using Unity.Services.Core;
using Unity.Services.Authentication;
async void Start()
{
    await UnityServices.InitializeAsync();
    await AuthenticationService.Instance.SignInAnonymouslyAsync();
    if (AuthenticationService.Instance.IsSignedIn)
    {
        // game code.
    }
    else
    {
        Debug.Log("Player was not signed in successfully?");
    }
}
```

Example 4 (unknown):
```unknown
using Unity.Services.Core;
using Unity.Services.Authentication;
async void Start()
{
    await UnityServices.InitializeAsync();
    await AuthenticationService.Instance.SignInAnonymouslyAsync();
    if (AuthenticationService.Instance.IsSignedIn)
    {
        // game code.
    }
    else
    {
        Debug.Log("Player was not signed in successfully?");
    }
}
```

---

## SHOWPERMISSIONS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/showpermissions

**Contents:**
- SHOWPERMISSIONS#
- Description#
  - Usage#
- Help#
  - Examples#

Lists the available permissions.

cm showpermissions | sp

**Examples:**

Example 1 (unknown):
```unknown
cm showpermissions | sp
```

Example 2 (unknown):
```unknown
cm showpermissions
```

---

## Get the player’s score

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-player-score

**Contents:**
- Get the player’s score#

Get the entry for the player in the specified leaderboard with the GetPlayerScoreAsync method:

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetPlayerScoreOptions configuration object:

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
GetPlayerScoreAsync
```

Example 2 (unknown):
```unknown
public async void GetPlayerScore(string leaderboardId)
{
    var scoreResponse = await LeaderboardsService.Instance
        .GetPlayerScoreAsync(leaderboardId);
    Debug.Log(JsonConvert.SerializeObject(scoreResponse));
}
```

Example 3 (unknown):
```unknown
public async void GetPlayerScore(string leaderboardId)
{
    var scoreResponse = await LeaderboardsService.Instance
        .GetPlayerScoreAsync(leaderboardId);
    Debug.Log(JsonConvert.SerializeObject(scoreResponse));
}
```

Example 4 (unknown):
```unknown
IncludeMetadata
```

---

## Glossary of terms

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/glossary

**Contents:**
- Glossary of terms#
    - A2S#
    - access key#
    - allocate#
    - allocated game server#
    - allocated server#
    - allocated server capacity#
    - allocated ID#
    - allocation#
    - allocation ID#

A2S is a popular UDP-based game server query protocol that Valve Software keeps as a part of the Steam SDK.

An access key is a unique identifier that points to your account. It’s tied to a secret key. Refer to Authentication.

Allocating is the process of a matchmaker allocating a game server for a game session.

Refer to allocated server.

An allocated server is a server that's in use by an allocation. Allocated servers have a populated allocatedID field in their server.json file.

Allocated server capacity is the number of allocated game servers within a fleet or fleet region. Multiplay Hosting keeps a buffer between the total server capacity and the allocated server capacity to allow the fleet or fleet region to accommodate sudden spikes in allocated servers.

Refer to allocation ID.

An allocation is a request for the best possible game server for a game match. Refer to Allocations.

An allocation ID is an identifier that you (or a matchmaker) assign to an allocation upon creation.

Allocation spread is the maximum number of machines that the reactive scaling system spreads allocations across machines in a fleet or fleet region.

The allocation timeout is a value that determines the amount of time that the reactive scaling system waits before force-deallocating allocated game servers, even if players are on the server. This value serves as a hard limit on the amount of time that an allocation can exist.

An available game server is a game server that's ready for a matchmaker to use to fulfill an allocation. Refer to Available servers.

An available server is a server that's ready for a matchmaker to use to fulfill an allocation.

The available server pool is a group of game servers in a fleet that's online and ready to fulfill an allocation request.

The best available server is an available game server that best meets the requirements for an allocation request.

A server buffer is a collection of servers kept in an available state, ready to fulfill an allocation. Refer to Availability buffer.

A build has the files necessary to run your game or application on a server. Refer to Builds.

A build configuration manages how a build runs by dictating the query protocol, the application executable path, the configuration variables, and the launch parameters. Refer to Build configurations.

A build executable is the executable file within a build.

The build executable path is the file system location of the build executable. It's relative to the structure of the build files you upload.

A number that identifies a specific build within the current Unity project.

A build install is a job triggered when you roll out a new build release to the servers in your fleet. Refer to Install lifecycle.

A dedicated machine for deploying and testing configuration changes, game images, and game image updates. Scaling configurations and fleet settings don't apply to build machines because they exist outside of any fleet. You receive your build machine’s hostname, IP address, and machine ID during the proof-of-concept onboarding stage.

A build process is the process running on a server after launching a build executable.

Capacity refers to the number of game servers within a fleet (game server capacity) or the number of machines within a fleet (machine capacity).

Concurrently connected users (CCU) is the number of players simultaneously connected to a fleet, region, or server at a time.

Refer to concurrent users.

A configuration variable is a variable you define on a build configuration. Multiplay Hosting passes these variables to servers using the build configuration. Refer to Configuration variables.

A containerized version of a build that lives on the Multiplay Hosting container registry. Refer to Container builds.

The Multiplay Hosting container registry is a custom registry for hosting containerized builds.

The CPU core count defines how many CPU cores each server has access to.

The CPU frequency defines the amount of CPU frequency in megahertz (MHz) each server instance has access to.

Credentials allow you to authenticate with Multiplay's API. Each account has an access key and a secret key that make up the credentials.

Deallocating is the process of removing an allocation.

A disabled machine is a machine that you can't use to fulfill allocations or reservations.

Draining is the process of players leaving a game server after a game session ends.

Refer to excess servers.

Excess servers refers to any running game server over the target buffer.

A fleet is a collection of servers that host a game or application in specific regions. Accounts can have one or more fleets, each with its own regions, builds, build configurations, and settings. Refer to Fleets.

Refer to force-deallocate.

Force deallocating is the process of deallocating a game server regardless of the state of the game session.

A forced rollout is a less graceful method of deploying a build update where you force servers to update even if there are players connected. If players are connected when you start a forced rollout, Multiplay Hosting kicks the players from the server.

A game client is software that an end-user, or player, interacts with to join a match on a game server.

Game map is a broad term that refers to a playable set of content for a game. The content can be anything from a level to a play area for a game session.

A game mode is a variation of a game with some configuration altered, such as the number of players allowed per session, the game objective, or the points system.

A game session is a temporary match that players can join to play a game together.

A game server is an instance of a game running on a machine that players can connect to. Each game server instance has a unique server ID, a unique port, a server ID directory, a log file, and a server.json file. Refer to Servers.

Refer to game server.

A game server query protocol is a protocol that facilitates querying information from a game server instance. Multiplay Hosting uses the information supplied by the game server query protocol to detect unresponsive game servers and to create live dashboards of advanced analytic data. Refer to Query protocols.

A game server slot is a reserved percentage of machine resources on which a game server can run.

Game server usages is the average resource consumption per game server, including CPU power, network bandwidth, and memory. Refer to Server density.

A session of multiple players connected to the same game server to play a game together.

A game title is the name of a specific game.

A specific release version of an image of a game server binary.

Refer to machine specifications.

A launch parameter is a variable sent to a build process as a startup flag when launching the executable on a server. Refer to Launch parameters.

Refer to local mirror machine.

A machine in Multiplay's mirror network that hosts game images for the fleet machines in the same location.

A game server that's disabled for maintenance. You can't use a locked game server to fulfill an allocation or reservation. Refer to Server statuses.

A machine is a physical or virtual computer with a set amount of compute resources that runs servers.

Server density is the number of servers a single machine can fit. The usage settings of the current build configuration determines this number.

Machine specifications include a set of hardware requirements for fleet machines. The requirements might include a minimum processor clock speed, a minimum amount of RAM, and processor configuration options. The machine specifications might vary between bare-metal and cloud machines.

The state of a machine. A machine can be offline, online and allocated (or reserved), online and available, or online and disabled.

A multiplayer networking feature in games that groups players into a game session.

The process of grouping players together into a game session.

The maximum servers scaling setting controls the maximum number of servers that can run in a region at a time.

The memory defines the amount of RAM (random access memory) in megabytes (MB) each server has access to.

The minimum available servers scaling setting controls the minimum number of servers that are available in a region at a time. Refer to Scaling settings.

The absolute minimum number of game servers that the reactive scaling system keeps in a fleet or fleet region at any time. Refer to Scaling settings.

The number of game servers within a fleet or fleet region that are offline. Standby game servers serve as a form of warm capacity that Multiplay Hosting can use to host game servers in case of a sharp influx in currently connected users (CCU).

A game server from the available server pool that best fits the allocation requirements.

A game server that Multiplay Hosting has shut down in response to a decrease in the number of total concurrently connected players.

Refer to offline game server.

An online game server is a game server that's running and accessible to players on a remote game client.

Refer to online game server.

An individual connected to a game client that has the intention to connect to a game server to join a game session.

Player density is the number of players within a region at a given time.

Players per session is the maximum number of players that can join a game session.

The process of running a game session on a game server to test a game build, gather feedback from users participating in the playtest, or collect data about the resources the game server uses while hosting a game session. Multiplay Hosting uses playtests to calculate game server resource usages to find the optimal server density for the game build.

A progressive rollout is a graceful method of deploying a build update where you update servers only when they're empty. If there are any players connected to a server, Multiplay Hosting waits for your matchmaker to deallocate the server.

The proxy payload is a locally available proxy on game server machines at port 8086 that you can use to retrieve payloads uploaded with the Allocate V2 endpoint

An acronym for quality of service. In the context of Multiplay, it describes the network connection quality between a game server and a game client.

A machine in a specific location that game clients use to retrieve quality of service information. The game client then uses the quality of service information—along with the quality of service information from other QoS servers—to find the best location to join a game session.

The QoS service allows game clients to gather quality of service (QoS) data to supply to a matchmaker.

QStat is an open-source command-line tool that interacts with game server query protocols to gather statistics about game servers.

A query protocol is a protocol that facilitates querying information from a game server instance. All builds must support a query protocol.

The reactive scaling system is a system that allows fleets to respond dynamically to player demand by scaling the number of game servers in a region.

A region is a geographic locations in which a fleet can host servers. Each fleet can have access to one or more regions and each region within a fleet has independent scaling settings. Refer to Regions.

A release is a version of your build that’s ready to release to servers to run your game.

The process of "rolling out" an updated build to all the server in a fleet or fleet region.

A rollout mode is a mode where you deploy a build update. There are two rollout modes: progressive and forced.

Scaling is the process of adjusting the number of servers in a region in response to demand. Refer to Scaling.

Scaling down is the process of shutting down and eventually deleting server capacity in response to decreases in allocated servers. Refer to Scaling.

Scaling settings allow you to manage how your fleet scales per region. There are two scaling settings available per region: the minimum available servers and the maximum servers. Refer to Scaling settings.

Scaling up is the process of creating more server capacity within a fleet or a fleet region in response to increases in allocated servers. Refer to Scaling.

A secret key is akin to a password and is only visible when you first generate your credentials. You use the secret key along with the corresponding access key to authenticate with the Multiplay Hosting API. Refer to Authentication.

A server, also known as a game server, is an instance of a build executable running on a machine within a fleet. Refer to Servers

A server action is an action (such as start, stop, allocate, and unallocate) performed on a server. Multiplay Hosting can perform these actions automatically or you can perform them manually.

Refer to machine capacity.

A server event is an event that occurred on a server, such as a server action, failure, or build update. Refer to Server analytics.

A server failure happens when a server crashes, fails to start, or becomes unreachable. Refer to Server analytics.

Each server instance has a directory on the host machine that has data specific to the server instance. The directory name matches the server's ID.

A server log is an application-level log produced by a build executable. Refer to Server files.

A server file is an application-level file produced by a build executable. Refer to Server files.

Server usage is the analytic information about the compute resources a server uses.

The server.json file has variable data, such as the current allocation ID, for each server instance. It’s automatically generated and populated for each server. Refer to Server.json file.

The shutdown TTL determines the amount of time that the reactive scaling system waits before shutting down a cloud machine with no allocated game server instances. Refer to Scaling settings.

SQP is a query protocol that allows you to retrieve information about a running game server.

A game server that exists on a machine that's in a shutdown state. The reactive scaler doesn't include such game servers in the available server pool.

Refer to launch parameter.

The number of game servers that a fleet or fleet region should have online and available for new players to join at any time.

The total number of game servers within a fleet or a fleet region.

A transient state is any machine state that's transitionary, such as when a machine is booting up or shutting down.

A game server that's available to fulfill an allocation request.

An unallocated server is a server that's not in use by an active allocation. The allocatedID field in its server.json file should be an empty string.

A game server that has repeatedly failed to respond to the implemented game server query protocol.

**Examples:**

Example 1 (unknown):
```unknown
allocatedID
```

Example 2 (unknown):
```unknown
server.json
```

Example 3 (unknown):
```unknown
server.json
```

Example 4 (unknown):
```unknown
server.json
```

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/privacy-and-consent

**Contents:**
- Privacy and consent#
- Privacy overview for Multiplay Hosting#
- Apple privacy manifest for Multiplay Hosting#
- Google Play data safety for Multiplay Hosting#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## Templates

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/templates

**Contents:**
- Templates#
- Getting Started#
  - Top tip#
- Adding a file to a template#
- Use cases#
- Examples#
  - Required properties and types for an array of missions#
  - String formatting for in-game messages#
  - Number formatting for level difficulty#
  - Using an enumerated list for a seasonal event reward#

Templates can be used in Remote Config to define a shape for JSON keys. This enables validation for the data within your game configuration and ensures that any updates made are in the shape that your game client expects.

To define a Template, you create a JSON schema to define the constraints of the data and attach it to one or more keys. Any future updates made against those keys in Remote Config, Game Overrides or the Remote Config API must meet the constraints of the schema defined in the Template.

Templates provide another layer of safety to the live updates made in your game. For example, developers can configure Templates with constraints as part of their initial implementation, and then hand them over to their live operations team to make updates safely.

To create a Template and add it to an existing Remote Config key, complete the following steps:

You can use an online schema generator (such as JSON to JSON schema) to take an existing key’s JSON and create a new schema as a starting point.

With an active Cloud Content Delivery subscription, you can include files in Templates and upload them via Remote Config.

To add a file to your Template, add a new property to the definition with type object and subtype file:

Once the file field is added and the template is applied to Remote Config keys, you can select a file on your local device to upload to CCD. The CDN link, file name and size are added to the value. You can use the CDN link in your game client to fetch assets at runtime. Files served to the game client count towards your total CCD usage and billing.

Note: Before the first file upload, you'll be prompted to set up the CCD bucket when editing the selected value in Remote Config.

For added safety, you can add required fields for your object:

You can use Templates to achieve various use cases by using the constraints provided by JSON Schema revision 7. The following table provides some example use cases and links to the relevant reference.

You can use Templates to define a shape for any change to your game. The following examples provide suggestions to help you get started that you can edit to meet your needs.

Below is a schema for a single-level key that configures a number of missions where each must have a name string and a number ID.

Setting the maximum length for a string, a date format and using a regular expression to check the format of a string.

Setting a minimum and maximum number for a level difficulty field, as well as ensuring it’s always a multiple of 5.

This schema ensures that the mission details object is required whenever a mission type is defined - and the same for rewards.

This schema contains the image file and the related information for an in-game promotional popup.

**Examples:**

Example 1 (unknown):
```unknown
description
```

Example 2 (unknown):
```unknown
...
"properties": {
  "myImage": {
    "type": "object",
    "subtype": "file"
  }
}
...
```

Example 3 (unknown):
```unknown
...
"properties": {
  "myImage": {
    "type": "object",
    "subtype": "file"
  }
}
...
```

Example 4 (unknown):
```unknown
...
"properties": {
  "myImage": {
    "type": "object",
    "subtype": "file",
    "properties": {
      "name": {
        "type": "string"
      },
      "size": {
        "type": "number"
      },
      "url": {
        "type": "string"
      }
    },
    "required": [
      "name",
      "size",
      "url"
    ]
  }
}
...
```

---

## Reporting

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/Reporting

**Contents:**
- Reporting#

Use Reporting to see the performance of your Push Notifications. To access specific information about your Push Notification, choose between metrics like Application Opens and Purchases. Select the time frame since the send date, from 24 hours to 30 days.

To see a report, select a Push Notification and select the Reporting tab.

The available metrics are:

---

## Google Play Data safety section for Push Notifications

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/google-data-safety

**Contents:**
- Google Play Data safety section for Push Notifications#
- Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Analytics. Push Notifications collects information through the Analytics SDK. For your convenience, Analytics provides information on its data collection practices below.

Important: The data disclosures below are for the Analytics SDK only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

* Analytics offers an SDK for customers to add into their game allowing them to track their players action. The events being tracked can then be analyzed in a variety of tools in the Unity Dashboard. There are standard events that the SDK automatically collects such as gameStarted, gameEnded, etc., and users can also create their own custom events to track additional events that are specific to their game. When Analytics is used with Campaigns users are able to use analytics data to segment their playerbase being targeted by a particular campaign and in order to do this analytics compares the user profile (composed of installationID and other metrics collected) against a set criteria to determine if they would be a member of the audience.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

** A randomly generated installation ID (or developer-generated ID) is used to identify the player.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

** The IAP plugin forwards transaction events for users to be able to analyze their transactions.

*** Required but developers can disable IAP plugin and the transaction events will no longer be sent.

* Developers can record whatever data they desire, we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Installation ID, IDFV, and IDFA.

Unity Analytics collects data specified and controlled by the developer, and can include any of the data designated with an asterisk (*). The developer should make a determination for whether they collect and/or share those data types, and whether that data is processed ephemerally, is required to be collected, and why that data is collected.

**Examples:**

Example 1 (unknown):
```unknown
gameStarted
```

Example 2 (unknown):
```unknown
installationID
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/check-out

---

## Analytics access

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/analytics-access

**Contents:**
- Analytics access#

When you launch Analytics, it can take up to one hour before you start to see data in your Analytics dashboards. However, you immediately have access to the UI (such as Dashboards).

Important: If you cancel UGS, you immediately lose access to the UI, and lose access to the APIs 30 days later. Historical data (such as events or player information) is deleted 120 days after cancellation and cannot be retrieved.

If you return to UGS, any Analytics events that you sent after cancelling might be processed, but access to the ingestion pipeline is lost after you cancel.

---

## Tiers

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/concepts/tiers

**Contents:**
- Tiers#

Create tiers to organize a leaderboard based on player score thresholds. For example, you can use tiers to only allow players access to a leaderboard once the player attains a specific score, rank, or a specific percentage of the best score. These tiers act as leagues and ranks, and can give your players a better sense of progression.

You can also define thresholds for tiers as absolute values (for example, a score above 100, or scores above 90%).

---

## Analytics User Roles

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/user-roles

**Contents:**
- Analytics User Roles#
- Available roles#
  - Read-only actions by role#
  - Manage feature actions#
    - By base roles#
    - By add-on roles#

Analytics uses a role-based access control system that provides granular control over which users have access to which features. You can toggle these roles for each user at the organization level and at the project level. Roles are inherited, so a user with a role at the organization level also has that role at the project level. Refer to assigning member roles for information on how to assign these roles.

Warning: If you are a user with the User role prior to November 8th, 2023, you should have automatically been assigned the Analytics Manager role to maintain the existing level of access held at that time. Any users with the User role whose account was created after this date only have read-only access to features, and must contact their organization owner to grant them the add-on roles for features they require.

All roles below are both organization and project level roles.

All roles below are assignable at both the organization and project level.

All add-on roles below are assignable at both the organization and project level, except for the Manage Data Access role. This role is only assignable at the organization level.

Note: the ability to manage data access configurations is accessible to the organization level Analytics Manager role only.

**Examples:**

Example 1 (unknown):
```unknown
Analytics Manager
```

---

## Third-party license information

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/third-party-license-information

**Contents:**
- Third-party license information#

The Vivox SDK uses various open-source packages. The following table lists the open-source software that's distributed with the Vivox SDK.

https://www.nuget.org/packages/expat

Expat XML Parser - BSD license

BSD 3-clause "New" or "Revised" License

https://www.nuget.org/packages/expat

Language Technologies Institute Carnegie Mellon University License (BSD-like)

https://github.com/festvox/flite/

getopt.c by Gregory Pietsch

License for getopt.c by Gregory Pietsch

https://github.com/eblot/newlib/blob/master/newlib/libc/stdlib/getopt.c

File + Dynamic Library

https://github.com/gradle/gradle/

BSD 3-clause "New" or "Revised" License

https://sourceforge.net/projects/kissfft/

Creative Commons Public Domain Dedication License

https://sourceforge.net/projects/libb64/

https://github.com/strophe/libstrophe/

MD5 - Command Line Message Digest Utility

MD5 CommandLine License (Public Domain)

http://www.fourmilab.ch/md5/

BSD 3-clause "New" or "Revised" License

https://opus-codec.org/

RSA Data Security-MD5 Message

RSA Message-Digest License

http://www.efgh.com/software/md5.htm

BSD 3-clause "New" or "Revised" License

https://www.speex.org/

BSD 3-clause "New" or "Revised" License

https://www.speex.org/

https://sourceforge.net/projects/tinyxml/

https://github.com/mattconte/tlsf

BSD 3-clause "New" or "Revised" License

https://webrtc.googlesource.com/src

---

## Integrations with other UGS services

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/integrations

**Contents:**
- Integrations with other UGS services#
- Server Authoritative Data#
- Game Overrides#

Matchmaker integrates with different UGS services, including Leaderboard and Game Overrides to provide a complete suite of features.

Matchmaker integrates with Leaderboard to enable game developers to attach a score, a rank, and a tier to a player. Leaderboard seamlessly integrates this data into a matchmaking ticket and creates matchmaking rules based on the data.

Matchmaker integrates with Game Overrides to offer the possibility to A/B Test matchmaking configurations. To learn more, refer to A/B testing.

---

## Check in files

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/check-in-files

**Contents:**
- Check in files#

The Pending Changes tab of the Unity Version Control (UVCS) window displays all your existing project files as Added and private. To include these files in the workspace and allow your collaborators to access them, you need to check them in.

When you check in your files, the Pending Changes tab refreshes and no longer lists the files you have checked in. The files that you check in compile into a changeset, which you can view in the Changesets tab.

Note: If you install the VCS desktop app, the app displays a dialogue to notify you if you forget to add a comment before you check in the files.

---

## Events

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/concepts/events

**Contents:**
- Events#
- Emitted events#
- Delivery semantics#
- Event structure#
- Payload versioning#
  - Scheduled event payload#
- Scheduled events#
  - One-time schedule#
  - Recurring schedule#
- Overlap with Triggers#

The Scheduler service and Unity Gaming Services produce events. The events are then sent over to the Triggers service, which matches the events to a configuration, then executes the corresponding Cloud Code script or module.

The Scheduler service and Unity Gaming Services emit events that you can wire triggers to.

By default, events have at-least-once delivery semantics. This means that all events are guaranteed to be processed once, but could potentially be processed multiple times in the event of a network issue. To avoid this, the recommended best practice is to create idempotent Cloud Code scripts and modules.

All events contain an event type, payload version and carry a payload.

The event type differs slightly depending on whether it is emitted by the Scheduler service or by UGS.

You can customize the events emitted by the Scheduler service by defining the event name, payload version and payload in the schedule configuration. The UGS emitted events have a different payload structure depending on the event type and cannot be customized.

Refer to Supported UGS events for more information on what each event type returns.

Payload versioning helps to avoid breaking changes. Every event includes payload versioning for the event payload.

For example, com.unity.services.player-auth.signed-up.v1 is an event type emitted by the Authentication service with a payload version of 1. This allows different triggers to be set up for different payload versions of the same event.

Note: Payload versioning is supported for both scheduled events and events emitted by UGS. However, while you can customize the payload version and content for scheduled events, you cannot customize events emitted by UGS.

Events emitted by the Scheduler service have a customizable payload. The payload is defined in the schedule configuration.

For example, if you want to add a new field to the scheduled event payload, you can create a new version of the payload, and create a trigger to use the new version of the payload.

A schedule configuration may look like this:

The sample above results in an event type of com.unity.services.scheduler.example-event.v1.

You can set up a trigger for this event type:

If you want to add a new field to the event payload, you can create a new version of the payload, and create a trigger to use the new version of the payload.

Which results in an event type of com.unity.services.scheduler.example-event.v2. This allows you wire a new trigger to the new event type.

To emit a scheduled event, you must create a schedule configuration. Refer to Schedule events for more information.

By deploying schedule configurations, you can create events that are emitted at a set or recurring moment in time.

The following is a sample schedule configuration:

Note: Limits apply. Refer to Limits for more information.

A one-time schedule is a single event that is executed at a specific time. It may look like this:

The schedule field is a RFC3339 timestamp that defines when the event is triggered.

Note: The timestamp must be declared in the future.

A recurring schedule is a series of events that is executed at a specific time interval. It may look like this:

The schedule field is a cron expression that defines when the event is triggered.

Refer to Triggers structure to check how events are tied to triggers.

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.scheduler.example-event.v1
```

Example 2 (unknown):
```unknown
payloadVersion
```

Example 3 (unknown):
```unknown
"{\"someBoolean\": true, \"someString\": \"something\"}"
```

Example 4 (unknown):
```unknown
com.unity.services.scheduler.example-event.v1
```

---

## Callback server

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/server-side-recording/callback-server

**Contents:**
- Callback server#
- Set up a callback server#
- Callback payload#
- Error codes#

SSR provides a callback mechanism to notify you when a recording job is complete. This allows you to take action on the recording once it is complete.

The payload of the callback contains the following fields:

**Examples:**

Example 1 (unknown):
```unknown
callbackUri
```

Example 2 (unknown):
```unknown
callbackKey
```

Example 3 (unknown):
```unknown
Authorization
```

Example 4 (unknown):
```unknown
{
    "job_status": "string",
    "job_id": "string",
    "code": "string",
    "metadata": "object"
}
```

---

## Join codes

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/join-codes

**Contents:**
- Join codes#
- Generate a join code#
- Use a join code to join a game#

Join codes are player-shared codes that allow players to group together into a logical game session. Players can share these codes anyway they want, such as through a Lobby, in-game chat, or an outside method such as chat service.

The join codes are case insensitive, simple, and short. This makes them easy to share, such as in situations where copy and pasting isn't available.

After a host player creates a game session, they then request a join code from the Allocations service to send to their friends. Their friends can then use the join code to join the host player's game session with their game client. The Relay service handles the networking and authentication behind the scenes.

Allocations and join codes are valid for as long as the host player is connected to the Relay server. If the host player disconnects from the Relay server, or if the connection times out, the allocation and join code become invalid. There is no way to explicitly invalidate a join code.

Join codes are scoped to the Unity project ID of the player who created it. This player is typically the host player. Because join codes are designed for players to share them out-of-band, any player with the join code can join the game, even if they're anonymous.

Note: Check out Allocating, binding, and joining.

You can generate a join code as the host player either with the Relay SDK or directly via the Relay API.

If you’re using Relay with Netcode for GameObjects (NGO), check out Configure the transport and start NGO as a host player.

If you’re using Relay with UTP, check out Create an allocation and request a join code.

You can use a join code to join a Relay server as a joining player with the Relay SDK or the Relay API.

If you’re using Relay with Netcode for GameObjects (NGO), check out Join an allocation (NGO).

If you’re using Relay with UTP, check out Join an allocation (UTP).

---

## Unity Lobby

**URL:** https://docs.unity.com/lobby/en/manual/unity-lobby-service

**Contents:**
- Unity Lobby#

The Lobby service provides a way for players to discover and connect to each other to accomplish a variety of multiplayer gaming scenarios. Some common examples of this are:

The Lobby can persist for the duration of the game session to provide a mechanism for users to re-join an existing game session or facilitate host-migration after an unexpected disconnect.

Visit the Support page to learn how to contact the Unity Lobby support team.

---

## GETFILE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/getfile

**Contents:**
- GETFILE#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Downloads the content of a given revision.

cm getfile | cat <revspec> [--file=<output_file>] [--debug] [--symlink] [--raw]

cm cat myfile.txt#br:/main

(Obtains the last revision in branch 'br:/main' of 'myfile.txt'.)

cm getfile myfile.txt#cs:3 --file=tmp.txt

(Obtains the changeset 3 of 'myfile.txt' and write it to file 'tmp.txt'.)

cm cat serverpath:/src/foo.c#br:/main/task003@myrepo

(Obtains the contents of '/src/foo.c' at the last changeset of branch '/main/task003' in repository 'myrepo'.)

cm cat revid:1230@rep:myrep@repserver:myserver:8084

(Obtains the revision with id 1230.)

cm getfile rev:info\ --debug

(Obtains all revisions in the 'info' directory.)

**Examples:**

Example 1 (unknown):
```unknown
cm getfile | cat <revspec> [--file=<output_file>] [--debug] [--symlink] [--raw]
```

Example 2 (unknown):
```unknown
cm cat myfile.txt#br:/main
```

Example 3 (unknown):
```unknown
cm getfile myfile.txt#cs:3 --file=tmp.txt
```

Example 4 (unknown):
```unknown
cm cat serverpath:/src/foo.c#br:/main/task003@myrepo
```

---

## LINKTASK

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/linktask

**Contents:**
- LINKTASK#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Links a changeset to a task.

cm linktask | lt <csetspec> <ext_prefix> <task_name>

cm lt cs:8@rep:default@repserver:localhost:8084 jira PRJ-1

**Examples:**

Example 1 (unknown):
```unknown
cm linktask | lt <csetspec> <ext_prefix> <task_name>
```

Example 2 (unknown):
```unknown
cm lt cs:8@rep:default@repserver:localhost:8084 jira PRJ-1
```

---

## Economy Game Overrides with Cloud Code

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/game-overrides-CC

**Contents:**
- Economy Game Overrides with Cloud Code#
- How Game Overrides and config caching work with Economy#
- Using Economy Game Overrides with Cloud Code#
  - Cloud Code setup#
  - Editor setup#
  - Full example#
  - Pitfalls#

With Game Overrides you can personalize your in-game Economy. For example, providing seasonal sales that only exist for a short time, or giving veteran players more rewards in a purchase.

Please read Config caching for more information on how to use Config assignment hash with Cloud code and the Economy SDK.

For Economy to know which Overrides to apply for a player, it has to know which Overrides are on the client device. Economy returns configAssignmentHash as part of the configuration. Passing the configAssignmentHash to Economy ensures that Economy uses the same configuration that’s on the device and provides a consistent user experience for the player.

Economy SDK 2.0.0 and above passes configAssignmentHash to Economy automatically when interacting with the Economy API. To learn how to use Game Overrides in the Economy SDK, see the Economy SDK guide’s Game Overrides.

Economy SDK 1.0.0 and Economy SDK in Cloud Code do not pass configAssignmentHash to Economy automatically. If Economy does not receive a configAssignmentHash as a parameter, it has a way to ensure consistency with the client device configuration, but in some unusual cases, this configuration can be inconsistent with what is on the client device.

Another way to use Cloud Code to move your game logic away from the client device is to use it to interact with your game economy. When interacting with Economy from Cloud Code, you need to pass configAssignmentHash to your Cloud Code script and then pass it onto Economy. The SDK has a method of getting configAssignmentHash on the client device. The full steps are as follows:

Set up Cloud Code script with configAssignmentHash as a parameter.

Add a script calling Economy in Cloud Code with Economy SDK 2.2 or later.

Get a configuration from Economy SDK 2.0.0 or above.

from the Economy SDK.

Pass configAssignmentHash from step 2 into Cloud Code.

See Config Caching Pitfalls

**Examples:**

Example 1 (unknown):
```unknown
configAssignmentHash
```

Example 2 (unknown):
```unknown
configAssignmentHash
```

Example 3 (unknown):
```unknown
configAssignmentHash
```

Example 4 (unknown):
```unknown
configAssignmentHash
```

---

## Retention schemas

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/retention-schemas

**Contents:**
- Retention schemas#
- Retain forever#
- System initiated user content deletion#
  - For free accounts#
  - For paid accounts#

Unity is committed to responsible management of user content. Users own their user content and are accountable for its management. To help you manage this content, we have the following retention schema available. We plan to add additional configurability and retention schemas in the future.

User content refers to data stored in UVCS, UBA, or Asset Manager on behalf of users.

DevOps stores your data indefinitely until you choose to delete the data.

You must maintain a free account that is active or a paid account with no overdue payments for the retain forever retention schema to be valid.

System initiated deletion of user content depends on the type of account you have:

Note: For user initiated deletions, user content is inaccessible immediately and fully deleted from DevOps systems within 7 days in accordance with Unity’s Terms of Service.

DevOps retains free user content for a maximum of 90 days after we detect that an organization has become inactive. Any member of an organization can log into the Unity Dashboard to reset their retention period.

DevOps retains the user content of paying users indefinitely according to the retention schema, unless your account is not in compliance with our Terms of Service. For example, if you fail to pay outstanding balances for more than 90 days, Unity reserves the right to delete your content.

---

## Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/concepts/authentication

**Contents:**
- Authentication#
- Authenticate players#
- Authenticating trusted clients (Basic authentication)#

Both Scheduling and Triggers Admin APIs only accept authenticated requests. Only Service Account Authentication can authenticate these services.

The Scheduler and Trigger APIs currently do not support player authentication.

You can use the Scheduler and Trigger APIs with Service Account Authentication.

To access the Triggers Admin API and the Scheduler Admin API, use Basic authentication. You can use the Service Account credentials directly by base64 encoding the <KEY_ID>:<SECRET_KEY>.

Grant the appropriate permissions to Service Account before use.

Refer to the table below for available roles for Triggers.

Refer to the table below for available roles for the Scheduler.

Check Service Account Authentication for more information.

**Examples:**

Example 1 (unknown):
```unknown
<KEY_ID>:<SECRET_KEY>
```

---

## Start, stop, or restart your server

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/start-stop-restart-server

**Contents:**
- Start, stop, or restart your server#
- Windows#
  - Use the Windows Service Manager#
  - Use the command line#
- Linux#
  - Example commands#
- macOS#
  - Start your UVCS server#
  - Stop your UVCS server#

Manually stop, start, or restart your server.

The Unity Version Control (UVCS) server starts automatically on server boot, and when the installation process finishes.

Manage your server on the following systems:

To start and stop the Plastic SCM service on Linux systems, use the plasticsd script as sudo. Find the script in the following locations:

The plasticsd script has the following options:

Note: The status option returns the running process ID of the server.

To start or stop the UVCS server daemon, you need to use the launchctl macOS command as sudo.

To start the UVCS server, run the following command:

To stop the UVCS server, run the following command:

**Examples:**

Example 1 (unknown):
```unknown
services.msc
```

Example 2 (unknown):
```unknown
plasticd {--start |--stop | --restart}
```

Example 3 (unknown):
```unknown
plasticd {--start |--stop | --restart}
```

Example 4 (unknown):
```unknown
/etc/init.d
```

---

## C++ integration

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/unreal-engine-sdk/cpp-integration

**Contents:**
- C++ integration#
- Add the Authentication SDK as a dependency#
- Authentication Subsystem#
  - SignInAnonymously#
  - GetUserInfo#
  - DeleteUser#
  - RegisterStateChangedCallback#
  - SignOut#
  - SwitchProfile#
  - ProfileExists#

The following section shows how to integrate with the Authentication SDK using Unreal Engine Subsystems. The Blueprint API provides the Authentication Subsystem to expose this functionality.

Before continuing, add Authentication as a public dependency of your module, then include the plugin header files in your classes.

Add Authentication as a dependency of your module to your Unreal project build file:

Include the plugin header files you wish to access in your own classes:

The Authentication Subsystem contains the interface to communicate with Unity Authentication servers, hold player profile information, and load/unload player preferences from local storage. It’s responsible for handling the authentication lifecycle and storing important authentication information for your project.

You can access the Authentication Subsystem by obtaining a reference from a UGameInstance.

Use the SignInAnonymously()) method to anonymously authenticate. This is a quick way to authenticate without any user information, and requires no interaction with external providers. If successful, this populates the current player profile with the retrieved credentials returned from the Unity Authentication servers.

SignInAnonymously()) takes an FAuthenticationSignInOptions struct as a parameter that changes the way a sign-in is performed. See the Unity API services documentation page for more information about these parameters.

The response from the SDK can be handled in a response handler which needs to take in an FAuthenticationResponse.

Use the GetUserInfo() method to retrieve information about the currently authenticated user. This includes their user Id, authentication timestamps, and any external Identity providers that are linked to their session.

The response from the SDK can be handled in a response handler which needs to take in an FAuthenticationUserResponse.

Use the DeleteUser() method to delete all information related to the currently authenticated player. This method also signs out the player, and deletes all player preferences and profiles connected to the player.

Note: If DeleteUser() Is called while using the default profile, then the profile information is cleared and the profile stays intact.

The response from the SDK can be handled in a response handler which needs to take in a bool: its value is true in case of successful deletion and false otherwise.

Use the RegisterStateChangedCallback() method to assign a callback function that invokes upon the state of the subsystem changing. For instance, the assigned function executes when a player has successfully authenticated and the subsystem state has changed to Authorized.

The response from the SDK can be handled in a response handler which needs to take in an AuthenticationStateChangedResponse.

Use the SignOut() method to sign-out of the currently authenticated player profile. This removes the current player profile and switches to the default profile. This method also has an optional parameter to remove any stored credentials associated with this player.

Note: If SignOut() is called while using the default profile, then the profile information is cleared and the profile stays intact.

Use the SwitchProfile() method to switch to or create a player profile.

Note: SwitchProfile() can only be called while signed-out. If a profile switch is invoked while authenticated, a warning is logged and nothing happens.

Use the ProfileExists() method to check if a given profile exists in the current session.

Note: ProfileExists() cannot detect profiles from previous sessions that have not been re-created in the current session.

Use the GetCurrentProfileName() method to retrieve the name of the current player profile.

Use the GetCurrentProfileName() method to retrieve a list of all player profile names being used in the current session.

Use the RegisterProfileChangedCallback() method to assign a callback function that invokes upon the player profile changing. For instance, the assigned function executes when SwitchProfile has executed successfully.

The response from the SDK can be handled in a response handler which needs to take in an AuthenticationPlayerProfileChangedResponse.

Use the RegisterProfileChangedCallback()) method to assign a callback function that invokes upon a player profile getting removed from the current session. For instance, the assigned function executes when SignOut has executed successfully.

The response from the SDK can be handled in a response handler which needs to take in an AuthenticationPlayerProfileChangedResponse.

Use the IsSignedIn() method to check whether the current player profile is signed-in. Being “Signed-In” is defined as being either Authorized or Expired.

Use the IsAnonymous()) method to check whether the current player profile is signed-in anonymously. This should return true after executing SignInAnonymously successfully.

Use the IsAuthorized() method to check whether the current player profile is signed-in and currently authorized. This should return true after executing any sign-in method successfully while the expiration time has not yet passed.

Use the IsExpired()) method to check whether the current player profile’s session has expired. This should return true when the expiry time returned from a successful sign-in response has passed.

Use the SessionTokenExists() method to check whether a session token exists in player preferences for the current player profile.

Use the GetUnityProjectId() method to retrieve the Unity Project Id associated with the current authentication session.

Use the GetUnityEnvironmentName() method to retrieve the name of the Unity Environment Id associated with the current authentication session.

Use the GetAccessToken() method to retrieve the access token for the current session. If none exists, this returns an empty string.

Use the GetSessionToken() method to retrieve the session token for the current session. If none exists, this returns an empty string.

Use the GetUserId()) method to retrieve the user Id for the current session. If none exists, this returns an empty string.

Note: This is different from the player profile name. The user Id is the unique user identifier returned from the Unity Authentication System.

Use the GetState()) method to retrieve the current state of the authentication session.

Use the SetUnityProjectId() method to set the Unity Project Id for the current authentication session. This overrides the Unity Project Id configured in Project Settings.

Use the SetUnityEnvironmentName() method to set the Unity Environment name for the current authentication session. This overrides the Unity Environment name configured in Project Settings.

**Examples:**

Example 1 (unknown):
```unknown
Authentication
```

Example 2 (unknown):
```unknown
Authentication
```

Example 3 (unknown):
```unknown
PublicDependencyModuleNames.AddRange(new string[] { "Core", "CoreUObject", "Engine", "InputCore", "Authentication" });
```

Example 4 (unknown):
```unknown
PublicDependencyModuleNames.AddRange(new string[] { "Core", "CoreUObject", "Engine", "InputCore", "Authentication" });
```

---

## ATTRIBUTE SET

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/attribute-set

**Contents:**
- ATTRIBUTE SET#
- Description#
  - Usage#
- Help#
  - Remarks#
  - Examples#

Sets an attribute on a given object.

cm attribute | att set <att_spec> <object_spec> <att_value>

An attribute can be set on an object to save additional information for this object. Attributes can be set on the following objects: branches, changesets, shelvesets, labels, items, and revisions.

cm attribute set att:status br:/main/SCM105 open

(Sets attribute 'status' to branch 'SCM105' with value 'open'.)

cm att set att:integrated@reptest@server2:8084 lb:LB008@reptest@server2:8084 yes

(Sets attribute 'integrated' to label 'LB008' in repository 'reptest' with value 'yes'.)

**Examples:**

Example 1 (unknown):
```unknown
cm attribute | att set <att_spec> <object_spec> <att_value>
```

Example 2 (unknown):
```unknown
cm attribute set att:status br:/main/SCM105 open
```

Example 3 (unknown):
```unknown
cm att set att:integrated@reptest@server2:8084 lb:LB008@reptest@server2:8084 yes
```

---

## Configuration variables

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/configuration-variables

**Contents:**
- Configuration variables#
- Built-in Configuration variables#

Configuration variables are variables defined on build configurations that Multiplay Hosting uses to generate a server.json file for each server. Each build configuration has a set of built-in variables, but you can create any number of custom configuration variables to track data that’s important to your build. You might want to track a difficulty modifier, the game mode, or the game map.

You can define configuration variables per build configuration. These custom configuration variables allow you to track data, such as a difficulty modifier, the game mode, or the game map.

Multiplay Hosting uses your custom variables and the built-in variables to generate a server.json for each game server.

Note: Multiplay Hosting loads configuration variables into the server.json file after the build executable starts. If you need to pass configuration to your server as it starts, consider using launch parameters instead.

Each build configuration has the following built-in configuration variables:

**Examples:**

Example 1 (unknown):
```unknown
server.json
```

Example 2 (unknown):
```unknown
server.json
```

Example 3 (unknown):
```unknown
server.json
```

Example 4 (unknown):
```unknown
allocatedUUID
```

---

## SHELVESET APPLY

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/shelveset-apply

**Contents:**
- SHELVESET APPLY#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Comparison methods#
  - Examples#

Applies a stored shelveset.

cm shelveset apply <sh_spec> [<change_path>[ ...]] [--preview] [--mount] [--encoding=<name>] [--comparisonmethod=(ignoreeol | ignorewhitespaces| ignoreeolandwhitespaces | recognizeall)]

The 'shelveset apply' command restores the contents of a stored shelveset.

cm shelveset apply sh:3

(Applies a stored shelve.)

cm shelveset apply sh:3 /src/foo.c

(Applies only the /src/foo.c change stored on the shelve.)

**Examples:**

Example 1 (unknown):
```unknown
cm shelveset apply <sh_spec> [<change_path>[ ...]] [--preview] [--mount] [--encoding=<name>] [--comparisonmethod=(ignoreeol | ignorewhitespaces| ignoreeolandwhitespaces | recognizeall)]
```

Example 2 (unknown):
```unknown
cm shelveset apply sh:3
```

Example 3 (unknown):
```unknown
cm shelveset apply sh:3 /src/foo.c
```

---

## Unity Gaming Services CLI

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/schedule-events/cli

**Contents:**
- Unity Gaming Services CLI#
- Prerequisites#
- Using the CLI#
  - Deploy schedules#
  - Retrieve schedules#
  - Delete schedules#

You can use the Unity Gaming Services CLI to interact with schedules. The CLI allows you to manage schedule configurations from the command line.

For more comprehensive information on the CLI, follow the steps in the Unity Gaming Services CLI Get Started guide.

To follow this guide, you first need to complete the following actions:

Use the following to configure your Project ID and Environment:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Configure a service account with the required roles for Scheduler and environments management. For more information, refer to Get Authenticated.

For a full reference of all commands and options, refer to the Schedules Command Line documentation.

Note: The ugs scheduler command is also available as ugs sched.

Run the new-file command to create a schedule configuration locally:

The configuration file contents can look like the following:

You can also separate the schedule configurations into multiple files if you need to.

You can use the Deploy command to promote your local schedule configuration files to the remote environment.

You need to deploy the configuration files for them to become active schedules.

To list all currently active schedules, run the following command:

You can use the Fetch command to retrieve multiple schedules from remote at once.

The provided path is the directory that schedules are saved to:

You can delete a schedule by running the deploy command with a --reconcile flag.

Warning: Reconcile is a destructive operation. It deletes all schedules that are not present in the provided path. You can check the output of the command with the --dry-run flag before running the command without it.

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
ugs scheduler
```

Example 4 (unknown):
```unknown
ugs scheduler new-file <file-name>
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/upgrade-to-iap-v5

---

## Receipt validation

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/receipt-validation

**Contents:**
- Receipt validation#
- Receipt structure#
- Transaction verification#
- Validation methods#

The Receipt validation page explains how Unity IAP handles purchase receipts, their structure, and the secure transaction verification methods to prevent fraud.

A purchase receipt is a secure, digital record from an app store that serves as proof of a successful transaction. After a user completes a purchase, your application receives this receipt.

Unity IAP provides a unified receipt structure, which includes a store-specific payload with detailed transaction data. After receiving a receipt, you should verify its authenticity to prevent fraud. This process is known as transaction verification.

Unity IAP formats the receipt into a JSON object with a consistent structure across different stores.

The following are the key fields:

Transaction verification is critical to prevent users from accessing content they haven't legitimately purchased. Without it, you can't reliably trust that a purchase is legitimate.

Verification protects your application from the following common forms of fraud:

By verifying the receipt with the original app store, you can confirm that the transaction is authentic and associated with the correct user and product before granting access to content.

You can validate a receipt either on the user's device (local validation) or on a secure server you control (remote validation).

Important: Local validation is less secure because a malicious user can more easily tamper with code on their own device to bypass the check.

Remote (server-side) validation

Note: Unity IAP doesn't provide a built-in remote validation service, but you can implement your own or use third-party solutions.

**Examples:**

Example 1 (unknown):
```unknown
AppleAppStore
```

Example 2 (unknown):
```unknown
TransactionID
```

Example 3 (unknown):
```unknown
OrderInfo.Apple.jwsRepresentation
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/setowner

---

## Force client upgrades

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/upgrade-version

**Contents:**
- Force client upgrades#

Ensure that users upgrade their Unity Version Control (UVCS) clients correctly.

The UVCS server can reject clients that are older than the current version of the server.

To force a given build number, add the ForceBuildNumberMatch key to your server.conf file. This key admits the following values:

**Examples:**

Example 1 (unknown):
```unknown
ForceBuildNumberMatch
```

Example 2 (unknown):
```unknown
server.conf
```

Example 3 (unknown):
```unknown
<ForceBuildNumberMatch>800</ForceBuildNumberMatch>
```

---

## Delete a lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/delete-a-lobby

**Contents:**
- Delete a lobby#
- Best practices#

Lobby hosts can delete their lobbies. Deleted lobbies are no longer accessible; deleted lobbies do not appear in queries and all APIs targeting a deleted lobby (for example, Get and Update) fail.

Note: The lobby is automatically deleted when the last player leaves the lobby.

Clients should expect that they can be removed from a lobby at any time. This could be due to the lobby being deleted, the player being removed from a lobby by the host, the player being removed from the lobby due to a relay disconnect (see Relay integration), or a service outage. Clients should expect that all API calls targeting a specific lobby can fail, and should handle them accordingly.

**Examples:**

Example 1 (unknown):
```unknown
try
{
    await LobbyService.Instance.DeleteLobbyAsync("lobbyId");
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

Example 2 (unknown):
```unknown
try
{
    await LobbyService.Instance.DeleteLobbyAsync("lobbyId");
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

---

## Mergebots

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/mergebots

**Contents:**
- Mergebots#
- Mergebot configuration#
  - Branch configuration#
  - Types of mergebot#
  - Status parameters#
  - Trunk bot options#
- Advanced settings#
    - CI integration#
    - Notifier integration#

A mergebot is a tool that you can use to automate parts of your merge process. Mergebots check that a merge request meets specified conditions before it merges into your destination branch. This automation can help you can work faster and reduce room for errors.

For example, you can set up a mergebot to automate the following tasks:

For information on how to set up a mergebot, refer to Create a mergebot. For a full tutorial on how to create a Trunk bot, refer to the Create a mergebot Unity Learn tutorial.

The Destination branch that you select is the branch that a trunk bot merges task branches into, and the branch that a conflicts bot checks for merge conflicts. The destination branch is usually your main branch.

You can enter a specific Branch prefix to further filter the branches that your mergebot processes.

Mergebots use a branch's status attribute to detect which branches the mergebot should process. You can edit the attribute name according to your workflow.

The following configuration options are only available for a trunk bot.

You can set up Continuous Integration (CI integration) so that your trunk mergebot triggers a build when it merges changes. The mergebot integrates with Jenkins, Bamboo, and TeamCity.

To set up a CI integration, you need the base URL of your system server, and your username and password to connect to the platform system.

Note: CI integration is only available for trunk bots.

You can add a Notifier integration to both conflict and trunk mergebots so that the mergebot can send users status notifications. You can send notifications through either Slack or email.

To use Slack, you need your Slack Token to connect to the Slack API. To use Email, you need the sender email address and password. You also server URL and port of the SMTP server that you want to use to send the emails.

**Examples:**

Example 1 (unknown):
```unknown
LABEL.${AUTO_INCREMENT_NUMBER}_${BUILD_DATE_FORMATTED, yyyy-MM-dd}
```

Example 2 (unknown):
```unknown
LABEL.128.2018-10-23
```

---

## Friend requests

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/friend-requests

**Contents:**
- Friend requests#

A friend request is a request from one user to another user to create a friendship relationship. From the current user's perspective, there are two types of friend requests: incoming friend requests and outgoing friend requests.

An incoming friend request is a friend request the current user receives from another user. These requests go into the current user's incoming friend requests list until they respond to the request.

An outgoing friend request is a friend request the current user sends to another user. These requests go into the incoming friend requests list of the receiving user until they respond to the request.

When a user receives a friend request, they can respond to the request in the following ways:

---

## Review incidents

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/incidents

**Contents:**
- Review incidents#
- Incident status#
- Incident details#

Incidents are player reports of other players breaking the rules of your online community or otherwise committing offensive behavior (committing an offense). Each incident has:

If Safe Text is enabled, incidents can be automated detections captured by those services. Incidents will include the scoring of each services.

For more information about the different incident types, refer to Incident types

Safety Moderators and Admins can view, evaluate, and respond to all moderation reports from the dashboard. To access the incident reports from the Unity Dashboard, go to Vivox > Safe Text > Moderation queue.

The Moderation dashboard separates incidents into two groups based on their status:

When resolving an incident, moderators can choose to:

Refer to Resolving incidents for the steps to resolve an incident.

Note: Moderators can apply different actions, and durations, to the offender and the reporter. They don't need to be the same.

Each incident report, whether it’s unresolved or resolved, has the following information:

Tip: You can control the number of incidents displayed per page by changing the Rows per page setting.

Note that Resolved incidents have a field for Actions that have been taken.

For more details on what's contained within an incident, refer to Incident details

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/privacy-overview

**Contents:**
- Privacy overview#
- Product Overview#
- Personal Data Collected about App Users/Game Players#
  - Developer Defines#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent (Opt in) vs Opt out#
- Data Subject Requests#
  - Access#
  - Deletion#

Cloud Code offers serverless computing to RT3D backend developers. In parallel, it acts as the conductor in the Unity ecosystem, allowing developers to put in place a Server Authoritative Game Logic with UGS Services.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected

Optional Personal Data Collected (personal data which may be collected at action of the Developer)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business Provider.

As we are a Processor, we do not determine the legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they must implement it client-side in a way determined by the developer.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by filing a ticket in the Help and Support section of the Unity Dashboard.

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. You can action them by filing a ticket in the Help and Support section of the Unity Dashboard.

Depending on how you enable it, this product may be on the Authentication product. By enabling this product, you will also be enabling the Authentication product and you should refer to Unity Authentication SDK for more information.

Personal data collected by Unity is stored for up to 30 days.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

Unity DPA applies to the transfer of data for this product.

---

## Google Play data safety section for Vivox

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/google-data-safety

**Contents:**
- Google Play data safety section for Vivox#
- Data collection survey#
- Data types#

Starting April 2022, Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs. For your convenience, this topic provides information on Vivox data collection practices.

Important: The following data disclosures are only for the Vivox SDK. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

* Voice data is collected only in the context of server-side recording (SSR), and is used for performance monitoring and product improvement purposes. Today, data is processed ephemerally. This stands to change in coming months when we will begin storing it for analysis and model training. Today, users (where SSR is deployed) have no choice but to allow the integrating developer to collect their audio data. The SDK also collects performance data, which users cannot opt out of.

** Voice data is not encrypted, but the signaling is. Voice data is encoded (not encrypted), and gets decoded by the SDK/client side. The purpose of this is for app functionality and analytics.

*** We do not store user data, and thus have little to remove in the event of such requests.

****** No if using server-side recording (SSR), otherwise yes.

---

## 

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/welcome/

---

## 

**URL:** https://docs.unity.com/authentication/en/manual/player-name-management

---

## Config Caching

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/config-caching

**Contents:**
- Config Caching#
- Config assignment hash#
    - What does the Config assignment hash represent?#
  - Config caching with Cloud code and Economy SDK#
  - Accessing the configuration assignment hash#
    - GetConfigAssignmentHash#
    - SyncConfigurationAsync#
  - Pitfalls#
    - Economy changes not being reflected due to a cached Config Assignment Hash#
  - Exceptions#

Remote Config & Game Overrides utilize Config assignment hashes to cache player config. Economy services cache the Config assignment hash for many hours to avoid unnecessary network calls.

The ConfigAssignmentHash is a unique identifier for a snapshot of a player's data in Remote Config, Game Overrides and Economy project config.

For Economy specifically, the snapshot is only for the Economy project config (Item definitions, currency definitions, etc) and not for the player's balances or inventory.

Please read Game Overrides - Cloud code and Game Overrides - Economy for more information on how to use Config assignment hash caching with the Economy Cloud Code SDK and C# SDK.

At some point, you may want to retrieve the player's current configuration assignment hash to use it with other Unity services. You can get the hash from the Configuration namespace.

Retrieves the players current configuration assignment hash as a string. Returns null if none present.

Fetches the latest config for the authenticated player and saves the Config Assignment Hash locally for future Economy API calls. It's a good practice to call this method before making other Economy calls to ensure the right Config Assignment Hash is used.

When you make changes to the Economy project config or Game Overrides, both Cloud code executions and Economy SDK calls will continue using their latest cached Config Assignment Hash.

You can circumvent this issue by making sure that you fetch the latest Config Assignment Hash before making any API calls.

For Cloud Code, you might want to pass the latest Config Assignment Hash as a parameter to your script and to your API calls inside the script.

You can also fetch the latest Config Assignment Hash at the start of your Cloud code script and pass it to your API calls inside the script.

Cloud code JS Example

You may run into an EconomyException that tells you the configuration assignment hash was not found.

This exception has a Reason of EconomyExceptionReason.ConfigAssignmentHashInvalid.

To resolve this, fetch your Economy configuration again using one of the Configuration methods, for example, GetCurrenciesAsync(). This causes the SDK to get a refreshed configuration assignment hash, and you are then able to make calls as normal.

**Examples:**

Example 1 (unknown):
```unknown
EconomyService.Instance.Configuration.GetConfigAssignmentHash();
```

Example 2 (unknown):
```unknown
EconomyService.Instance.Configuration.GetConfigAssignmentHash();
```

Example 3 (unknown):
```unknown
EconomyService.Instance.Configuration.SyncConfigurationAsync();
```

Example 4 (unknown):
```unknown
EconomyService.Instance.Configuration.SyncConfigurationAsync();
```

---

## Third-party license information

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/third-party-license-information

**Contents:**
- Third-party license information#

The Vivox SDK uses various open-source packages. The following table lists the open-source software that's distributed with the Vivox SDK.

https://www.nuget.org/packages/expat

Expat XML Parser - BSD license

BSD 3-clause "New" or "Revised" License

https://www.nuget.org/packages/expat

Language Technologies Institute Carnegie Mellon University License (BSD-like)

https://github.com/festvox/flite/

getopt.c by Gregory Pietsch

License for getopt.c by Gregory Pietsch

https://github.com/eblot/newlib/blob/master/newlib/libc/stdlib/getopt.c

File + Dynamic Library

https://github.com/gradle/gradle/

BSD 3-clause "New" or "Revised" License

https://sourceforge.net/projects/kissfft/

Creative Commons Public Domain Dedication License

https://sourceforge.net/projects/libb64/

https://github.com/strophe/libstrophe/

MD5 - Command Line Message Digest Utility

MD5 CommandLine License (Public Domain)

http://www.fourmilab.ch/md5/

BSD 3-clause "New" or "Revised" License

https://opus-codec.org/

RSA Data Security-MD5 Message

RSA Message-Digest License

http://www.efgh.com/software/md5.htm

BSD 3-clause "New" or "Revised" License

https://www.speex.org/

BSD 3-clause "New" or "Revised" License

https://www.speex.org/

https://sourceforge.net/projects/tinyxml/

https://github.com/mattconte/tlsf

BSD 3-clause "New" or "Revised" License

https://webrtc.googlesource.com/src

---

## Find branches

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-branches

**Contents:**
- Find branches#
- Filtering options#
- Output options#
- cm find branches example#

Find and filter branches.

The following list displays the different filtering options (where) that are available to use with the cm find branch command:

The following list displays the different output options (--format) available to use with the cm find branch command:

The following example filters branches by the following requirements:

The example also formats the results to show the name of the branch and the creation date, with consistent 30 character spacing.

**Examples:**

Example 1 (unknown):
```unknown
cm find branch
```

Example 2 (unknown):
```unknown
replsrcdate
```

Example 3 (unknown):
```unknown
replsrcrepository
```

Example 4 (unknown):
```unknown
replsrcserver
```

---

## Fleet lifecycle

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/fleet-lifecycle

**Contents:**
- Fleet lifecycle#
  - Region lifecycle#

The fleet lifecycle is the series of states or statuses a fleet can transition through. There are three possible fleet statuses: online, draining, and offline.

The state flow of a fleet is offline → online → draining → offline.

Multiplay Hosting uses the highest status of the regions in a fleet as the status. For example, if a single region within a fleet is online, the fleet is online. Likewise, if a single region within a fleet is draining and the remaining are offline, the fleet is draining. Multiplay Hosting only considers a fleet offline if all the regions within it are offline.

The region lifecycle is the series of states or statuses a region can transition through. There are three possible region statuses: online, draining, and offline.

The state flow of a region is offline → online → draining → offline.

Multiplay Hosting uses the highest status of the regions within a fleet to decide the fleet's status. For example, if a single region within a fleet is online, the fleet is online. Likewise, if a single region within a fleet is draining and the remaining are offline, the fleet is draining. Multiplay Hosting only considers a fleet offline if all the regions within it are offline.

---

## View local changes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/checkin-changes-tab

**Contents:**
- View local changes#
- Options#

Use the Checkin changes tab to view all of the changes you've made to files locally. You can select which files you want to check in to your source control.

The Checkin changes tab also displays the diffs for any files that you select.

Use the Options dialog in the Checkin changes tab to configure the following:

Below each option in these tabs is an explanation of what the option does.

---

## LABEL DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/label-delete

**Contents:**
- LABEL DELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Deletes one or more labels.

cm label delete <lbspec>[ ...]

This command deletes one or more labels.

cm label delete lb:BL001

(Deletes the label 'BL001'.)

cm label delete lb:BL001 lb:BL002@reptest@server2:8084

(Deletes the labels 'BL001' and 'BL002'.)

**Examples:**

Example 1 (unknown):
```unknown
cm label delete <lbspec>[ ...]
```

Example 2 (unknown):
```unknown
cm label delete lb:BL001
```

Example 3 (unknown):
```unknown
cm label delete lb:BL001 lb:BL002@reptest@server2:8084
```

---

## Unity Authentication use cases

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/use-cases

**Contents:**
- Unity Authentication use cases#
    - Keep up with a player across multiple devices#
    - Host your multiplayer game in a P2P network#
    - Form compatible parties and lobbies in your multiplayer game#
    - Protect your game economy#
    - Implement data migration scripts for authenticated players#
    - Reward players for in-game milestones#

Unity Authentication easily integrates with the following Unity gaming services:

Unity Authentication also supports multiple cross-platform use cases.

Here are a few examples of how to leverage Unity Authentication with other Unity products.

Many apps are cross-platform. As a result, a player might end up using their mobile device, a laptop, or tablet to use your app, switching it up as they wish.

You can find out the following scenarios:

Use Cloud Save with Unity Authentication to set up sign-ins with platform accounts so the same player can sign in from Google, Facebook, Apple, or Steam and start playing again from where they left off from any device.

Game development takes time and effort, and finding the tools to create and test it shouldn’t be time-consuming for a multiplayer game if you’re able to integrate and take advantage of Unity solutions.

You can find out the following scenarios:

Use the Relay with Unity Authentication to identify individuals who are good game server hosts in a P2P environment, to implement peer-to-peer networking using authentication to build, test, and operate your multiplayer game without needing a third-party solution or a dedicated game server.

Consider how multiplay features should be implemented to encourage people to connect, be social, and play together safely and enjoyably.

You can find out the following scenarios:

Use the Lobby and Matchmaker with Unity Authentication to securely allow players to anonymously authenticate, connect, communicate, and group up to play your game in a party.

Some players will try to reap in-game rewards or in-app purchases by cheating or impersonating other players. Actions like these compromise your game economy as well as players' identities.

You can find out the following scenarios:

Use Economy with Unity Authentication to set up authenticated sign-in in your game to associate unique tokens and an ID for each player which can’t be manipulated by anyone else.

Live updates, bug fixes, and other administrative actions need planning to service in your game and often affect your players depending on the nature of the update, a player’s game client version, event triggers, and other backend factors.

You can find out the following scenarios:

Use Cloud Code with Unity Authentication to target state updates or data migration through scripts to an authenticated player based on their game play, play frequency, and other behaviors.

The reward strategies you employ in your game to celebrate key accomplishments can impact your player behavior and how they perceive and play your game. Milestone rewards can tie a greater purpose and intention to a player’s gaming and encourage them to keep playing.

You can find out the following scenarios:

Use Cloud Code, Cloud Save, and Economy with Unity Authentication to trigger a reward check script after a milestone (if a player finishes a level or match), store the last time the player received a reward, store the reward itself in the player’s inventory, and understand the player across services, respectively.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/undocheckoutunchanged

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/admin

---

## Branches

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/branches

**Contents:**
- Branches#
- Branch data#
- Branches in the Unity Dashboard#

A branch acts as a parallel line of development. You can make changes on a branch instead of your main repository to isolate your changes so developers can work simultaneously, until you’re ready to merge your changes into the main repository.

When you create a new branch, the branch is a child of the branch that you create it from. A branch isn’t a copy of the entity repository structure, or a special directory; each branch points to its parent branch. This means the branch inherits data and only stores and adds the changes that you make.

Each repository that you make in Unity Version Control (UVCS) has a default branch called main. UVCS creates the main branch with an empty changeset, cs:0, which contains your root directory.

Each changeset you make belongs to a branch in your repository.

In UVCS, a branch is a complete entity, and has its own metadata:

The Branches tab shows you a list of branches in the repository. On this page, you can do the following tasks:

---

## Trigger use case samples

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/use-cases/overview

**Contents:**
- Trigger use case samples#

You can use this set of samples to use Cloud Code triggers to automate functionality from other services such as Authentication, Cloud Save, Leaderboards, and Economy.

Note: For more advanced sample projects, you can refer to the UGS use cases sample project.

---

## Privacy Overview

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/privacy/privacy-overview

**Contents:**
- Privacy Overview#
- Personal Data Collected about App Users/Game Players#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent#
- Data Subject Requests#
- Dependencies#
- Data Retention#
- Child Privacy#
- Privacy Policy Requirements#

Vivox Voice and Text Chat (also known as Vivox).

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected (always collected in order for product to work)

Optional Data Collected (data which may be collected at the action of the end user)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

Privacy and wiretapping laws may require consent depending on the region in which your end-users.

To provide the user a method to opt-in, it must be implemented client-side in a way determined by the developer.

To provide the user a method to opt-out, it must be implemented client-side in a way determined by the developer.

Two of the most common data subject requests based in law are: (i)the request for access to personal data and (ii) the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Vivox support team with the Player ID of the end user that requested access.

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Vivox support team with the Player ID of the end user that requested data deletion.

This product has no dependencies on other Unity products.

By default, the below personal data is retained for up to 30 days:

The following is ephemeral:

By default, the following is available for 7 days and can be configured to be available for up to 6 months at the Developer’s choice:

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

Unity DPA applies to the transfer of data for this product.

---

## Disconnection

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/disconnection

**Contents:**
- Disconnection#
- Close the connection to the Relay server#

Disconnection is what happens when a joining player sends a DISCONNECT message to the host player. This only disconnects the player from the host player in the game session. It doesn't remove the player’s allocation from the Relay server.

For a player to deallocate from a Relay server (remove their allocation from the Relay server), they must send a CLOSE message to the Relay server. As a result, players must rebind to the Relay server through the connection flow after closing their connection.

In a typical game session, every player closes their own connection, with the host closing their connection last. Because the host player is the one who created the join code, closing their connection triggers Relay to:

When a player closes a connection, the Relay server updates all connected players to remove the disconnected player. This also frees up a connection slot on the Relay server.

Relay servers also disconnect players if the connection times out. You can prevent timeouts by keeping the connection alive.

Note: Relay doesn't have any method to migrate the host when a host player disconnects from the Relay server through a CLOSE message. However, you can add custom logic to place the remaining players in a lobby and select a new host. Check out Host migration.

---

## Query for lobbies

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/query-for-lobbies

**Contents:**
- Query for lobbies#
- Sorting lobbies#
- Filtering lobbies#
- Filtering with custom data#
- Randomized query results#
- Pagination#

Players can use the query API to discover public lobbies they might want to join. They can browse through the lobbies and view their public information. Every lobby has its own metadata, which includes the lobby name, project ID, maximum number of players, and a list of players. Game developers can also add custom metadata to add specific types of data that are unique to the game, such as the map ID. Only custom data which is set to public visibility is visible by players who have not joined a lobby.

Players can specify the sort order of the lobbies that are returned by the query API. For example, if players want to only view the most recently created lobbies, then they can sort by lobby creation time.

Players can specify one or more filters when using the query API to view only the lobbies that fit their parameters. For example, players can filter by lobby name, maximum lobby size, available player slots, and creation date, or by using custom data such as game type, map, or level requirements. You can only filter within your own project and environment.

The following code sample shows how to filter lobbies:

Lobbies have five custom string fields (S1-S5) and five custom number fields (N1-N5) that you can use for querying. This is helpful for customizing lobby browsing experiences for players. For example, a game can enable players to filter by mode, map, region, and skill.

The following code sample shows how to filter with custom data:

When multiple players with the same query filter want to query for lobbies at the same time and there are more results available than requested, the lobby service uses randomized sampling to return different query results. This helps to minimize contention and to distribute players evenly between lobbies so they can start their games as soon as possible. This alleviates the load time and facilitates connection to games when multiple players are looking to connect to similar games.

Randomized sampling ensures that players with the same search criteria are not shown the same query result, which could lead to players trying to join lobbies that have filled up since the query was performed. However, there is always a potential race condition where players might attempt to join a lobby that has already filled up; client logic should expect this to happen and should plan to gracefully handle lobby join failures.

Clients can also choose not to randomize their query results, in which case results can be paginated. When querying for non-randomized results, a continuation token is returned in the response. This token can be provided to a subsequent query to fetch the next page of results. Note that even if the next page has 0 lobbies, a continuation token will still be provided.

The following code sample shows the basic pattern for using continuation tokens:

**Examples:**

Example 1 (unknown):
```unknown
try
{
    QueryLobbiesOptions options = new QueryLobbiesOptions();
    options.Count = 25;

    // Filter for open lobbies only
    options.Filters = new List<QueryFilter>()
    {
        new QueryFilter(
            field: QueryFilter.FieldOptions.AvailableSlots,
            op: QueryFilter.OpOptions.GT,
            value: "0")
    };

    // Order by newest lobbies first
    options.Order = new List<QueryOrder>()
    {
        new QueryOrder(
            asc: false,
            field: QueryOrder.FieldOptions.Created)
    };

    QueryResponse lobbies = await LobbyService.Instance.QueryLobbiesAsync(options);

    //...
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

Example 2 (unknown):
```unknown
try
{
    QueryLobbiesOptions options = new QueryLobbiesOptions();
    options.Count = 25;

    // Filter for open lobbies only
    options.Filters = new List<QueryFilter>()
    {
        new QueryFilter(
            field: QueryFilter.FieldOptions.AvailableSlots,
            op: QueryFilter.OpOptions.GT,
            value: "0")
    };

    // Order by newest lobbies first
    options.Order = new List<QueryOrder>()
    {
        new QueryOrder(
            asc: false,
            field: QueryOrder.FieldOptions.Created)
    };

    QueryResponse lobbies = await LobbyService.Instance.QueryLobbiesAsync(options);

    //...
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

Example 3 (unknown):
```unknown
// Creating a custom indexed string property to be used as lobby data
var lobbyData = new Dictionary<string, DataObject>
{
    {
        "GameMode", new DataObject(
            visibility: DataObject.VisibilityOptions.Public,
            value: "Conquest",
            index: DataObject.IndexOptions.S1)
    }
};

// ... set the lobby data ...

// Create query filter for the custom data that was set above
var queryFilter = new List<QueryFilter>()
{
    new QueryFilter(
        field: QueryFilter.FieldOptions.S1,
        op: QueryFilter.OpOptions.EQ,
        value: "Conquest")
};
```

Example 4 (unknown):
```unknown
// Creating a custom indexed string property to be used as lobby data
var lobbyData = new Dictionary<string, DataObject>
{
    {
        "GameMode", new DataObject(
            visibility: DataObject.VisibilityOptions.Public,
            value: "Conquest",
            index: DataObject.IndexOptions.S1)
    }
};

// ... set the lobby data ...

// Create query filter for the custom data that was set above
var queryFilter = new List<QueryFilter>()
{
    new QueryFilter(
        field: QueryFilter.FieldOptions.S1,
        op: QueryFilter.OpOptions.EQ,
        value: "Conquest")
};
```

---

## Matchmaker Overview

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/matchmaker-overview

**Contents:**
- Matchmaker Overview#
- Features#
- Get started#

Matchmaker is part of Unity's growing suite of multiplayer services that are designed to help you create and operate multiplayer games no matter what engine you're using.

Note: Unity Matchmaker is offered free of charge when you're using Multiplay Hosting or a client-hosted solution provided by Unity (Relay and Distributed Authority).

With almost limitless customizability, Matchmaker is ready to grow and adapt with your game.

Visit the Support page to learn how to contact the Unity Matchmaker support team.

Use the Get started guide to learn how to start leveraging Matchmaker in your project.

Check out the following samples to help you get started:

---

## Configuring your project for Unity Remote Config

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/configuring-your-project

**Contents:**
- Configuring your project for Unity Remote Config#
- Requirements#
- Installing the Remote Config package#
  - Verified release#
  - Preview release#
  - Beta customers#
- Remote Config environments#
- Assembly Definition References#

See documentation on packages for more information on working with packages in a project. These steps may vary depending on which version of the Unity Editor you’re using.

Upon receiving the Remote Config package from your account manager, follow these steps:

To get started, create an environment and give it a name.

Note environment names are immutable.

The first environment you create is set as the default environment. This is the environment which is requested unless otherwise specified by the client. You can assign the default environment to an EnvironmentID in the Unity Dashboard, or via the REST API.

Once you’ve configured your project, configure your rules and settings in the Unity Dashboard

The Remote Config package depends on Unity's authentication and core services. These dependencies require a small amount of user code for proper configuration.

To use Remote Config, you will need to include the following references:

Prior to using Remote Config, you will then need to:

**Examples:**

Example 1 (unknown):
```unknown
UnityServices.InitializeAsync()
```

Example 2 (unknown):
```unknown
AuthenticationService.Instance.SignInAnonymously()
```

Example 3 (unknown):
```unknown
AuthenticationService.Instance.SignInWithAppleAsync()
```

Example 4 (unknown):
```unknown
AuthenticationService.Instance.SignInWithFacebookAsync()
```

---

## Environment support

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/environment-support

**Contents:**
- Environment support#

Analytics fully supports UGS environments. For more information about initializing UGS SDKs against a specific environment, see the environments page.

Once the SDK has been initialized for an environment, all events uploaded during the session will be sent there.

Note: Events do not remember which environment they were recorded against, so a change in environment will see any events that were cached or buffered against a previous environment uploaded to the current one. For example, if you play offline against a dev environment and close the game to cache some events do disk, and then restart the game against the production environment instead, those cached events will be uploaded to production.

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/Privacy/apple-privacy

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The following code sample contains the PrivacyInfo.xcprivacy manifest for Cloud Diagnostics and User Reporting. This file is also available in the SDKs.

To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
  <dict>
    <key>NSPrivacyTracking</key>
    <false />
    <key>NSPrivacyTrackingDomains</key>
    <array />
    <key>NSPrivacyCollectedDataTypes</key>
    <array>
      <dict>
        <key>NSPrivacyCollectedDataType</key>
        <string>NSPrivacyCollectedDataTypeCrashData</string>
        <key>NSPrivacyCollectedDataTypeLinked</key>
        <false />
        <key>NSPrivacyCollectedDataTypeTracking</key>
        <false />
        <key>NSPrivacyCollectedDataTypePurposes</key>
        <array>
          <string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
          <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
        </array>
      </dict>
      <dict>
        <key>NSPrivacyCollectedDataType</key>
        <string>NSPrivacyCollectedDataTypePerformanceData</string>
        <key>NSPrivacyCollectedDataTypeLinked</key>
        <false />
        <key>NSPrivacyCollectedDataTypeTracking</key>
        <false />
        <key>NSPrivacyCollectedDataTypePurposes</key>
        <array>
          <string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
          <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
        </array>
      </dict>
      <dict>
        <key>NSPrivacyCollectedDataType</key>
        <string>NSPrivacyCollectedDataTypeOtherDiagnosticData</string>
        <key>NSPrivacyCollectedDataTypeLinked</key>
        <false />
        <key>NSPrivacyCollectedDataTypeTracking</key>
        <false />
        <key>NSPrivacyCollectedDataTypePurposes</key>
        <array>
          <string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
          <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
        </array>
      </dict>
      <dict>
        <key>NSPrivacyCollectedDataType</key>
        <string>NSPrivacyCollectedDataTypeUserID</string>
        <key>NSPrivacyCollectedDataTypeLinked</key>
        <false />
        <key>NSPrivacyCollectedDataTypeTracking</key>
        <false />
        <key>NSPrivacyCollectedDataTypePurposes</key>
        <array>
          <string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
          <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
        </array>
      </dict>
    </array>
    <key>NSPrivacyAccessedAPITypes</key>
    <array />
  </dict>
</plist>
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
  <dict>
    <key>NSPrivacyTracking</key>
    <false />
    <key>NSPrivacyTrackingDomains</key>
    <array />
    <key>NSPrivacyCollectedDataTypes</key>
    <array>
      <dict>
        <key>NSPrivacyCollectedDataType</key>
        <string>NSPrivacyCollectedDataTypeCrashData</string>
        <key>NSPrivacyCollectedDataTypeLinked</key>
        <false />
        <key>NSPrivacyCollectedDataTypeTracking</key>
        <false />
        <key>NSPrivacyCollectedDataTypePurposes</key>
        <array>
          <string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
          <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
        </array>
      </dict>
      <dict>
        <key>NSPrivacyCollectedDataType</key>
        <string>NSPrivacyCollectedDataTypePerformanceData</string>
        <key>NSPrivacyCollectedDataTypeLinked</key>
        <false />
        <key>NSPrivacyCollectedDataTypeTracking</key>
        <false />
        <key>NSPrivacyCollectedDataTypePurposes</key>
        <array>
          <string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
          <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
        </array>
      </dict>
      <dict>
        <key>NSPrivacyCollectedDataType</key>
        <string>NSPrivacyCollectedDataTypeOtherDiagnosticData</string>
        <key>NSPrivacyCollectedDataTypeLinked</key>
        <false />
        <key>NSPrivacyCollectedDataTypeTracking</key>
        <false />
        <key>NSPrivacyCollectedDataTypePurposes</key>
        <array>
          <string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
          <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
        </array>
      </dict>
      <dict>
        <key>NSPrivacyCollectedDataType</key>
        <string>NSPrivacyCollectedDataTypeUserID</string>
        <key>NSPrivacyCollectedDataTypeLinked</key>
        <false />
        <key>NSPrivacyCollectedDataTypeTracking</key>
        <false />
        <key>NSPrivacyCollectedDataTypePurposes</key>
        <array>
          <string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
          <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
        </array>
      </dict>
    </array>
    <key>NSPrivacyAccessedAPITypes</key>
    <array />
  </dict>
</plist>
```

---

## Polarion integration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/issue-tracking/polarion

**Contents:**
- Polarion integration#
- Configure Polarion#
  - Add the UVCS plugin to Polarion#
  - Create a new repository#
- Configure the client for Polarion#
  - Configure the client on Windows#
  - Configure the client on Linux and macOS#
  - Polarion parameters#
- Use the Polarion integration#
  - Task on branch workflow#

Learn how to configure and use the Polarion extension with Unity Version Control (UVCS).

Configure Polarion to work with Unity Version Control (UVCS).

Add the plugin so that you can link UVCS changesets to Polarion workitems:

Create a repository in Polarion to link to a UVCS repository:

There are different methods to configure the client depending on your operating system:

Regardless of your operating system, you need to configure the Polarion parameters.

Set a local Polarion configuration on a Linux or macOS machine:

Note: You can also set a global extension configuration on the server.

Use the following parameters to further configure your Polarion integration:

Use one of the following working modes for your Polarion integration:

Task on branch is the default working mode. Each Polarion task links to a branch in Unity Version Control (UVCS).

The branch name connects the branch to a Polarion issue:

The task on changeset working mode allows you to link multiple changesets to multiple branches

Use the UVCS desktop application to link changesets to Polarion issues:

To log the checkin information in the related Polarion issue, enter a comment in the Checkin comments field, start the comment with the # character followed by the issue key.

**Examples:**

Example 1 (unknown):
```unknown
com.codicesoftware.platform.repository.external.plasticscm
```

Example 2 (unknown):
```unknown
client/polarion
```

Example 3 (unknown):
```unknown
[Polarion installation]/polarion/extensions
```

Example 4 (unknown):
```unknown
client.conf
```

---

## SWITCH

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/switch

**Contents:**
- SWITCH#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Switches the workspace to a branch, changeset, label, or shelveset.

cm switch (<brspec> | <csetspec> | <lbspec> | <shspec>) [--workspace=<path>] [--repository=<name>] [--forcedetailedprogress] [--silent] [--verbose] [--xml[=<output_file>]] [--encoding=<name>] [--forcedetailedprogress] [--noinput]

This command allows users to update the workspace tree to the contents of the specified object (branch, label, shelveset, or changeset).

cm switch br:/main/scm002 --repository=rep2

**Examples:**

Example 1 (unknown):
```unknown
cm switch (<brspec> | <csetspec> | <lbspec> | <shspec>) [--workspace=<path>] [--repository=<name>] [--forcedetailedprogress] [--silent] [--verbose] [--xml[=<output_file>]] [--encoding=<name>] [--forcedetailedprogress] [--noinput]
```

Example 2 (unknown):
```unknown
cm switch br:/main
```

Example 3 (unknown):
```unknown
cm switch lb:Rel1.1
```

Example 4 (unknown):
```unknown
cm switch br:/main/scm002 --repository=rep2
```

---

## Backfill

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/advanced-topics-backfill

**Contents:**
- Backfill#
- Optimize matchmaking configuration for backfill use cases#
  - Example#
- Backfill flow#
- Create a backfill ticket#
- Approve a backfill ticket#
- Update a backfill ticket#
- Delete a backfill ticket#

Backfill is a flow that allows players to join a game that has already started.

Backfill can have different goals:

Even if a configuration has the property backfill set to false, backfill will still work when a backfill ticket is created.

For backfilling, it is not recommended to set the minimum number of players to create a match to one (1). This might result in the creation of a large number of matches which can prevent backfilling from working efficiently. This is especially true when there is a low number of servers backfilling at the same time.

Instead, the recommended best practice is to set the minimum number of players to a large number, or equal to the maximum number of players in a match, and to relax that minimum number of player to a lower number after a little while (at least four seconds).

The following example shows that the first match is created if there are 60 players in the match, and then after five seconds, the subsequent match is created if at least one player is in the match.

The following diagram shows the backfill flow

A Game Server is responsible for keeping a backfill ticket up-to-date. For example, if a player leaves or joins the server outside of Matchmaker, the Game Server needs to inform the Matchmaker service by updating the backfill ticket.

When a game server needs to backfill players who have left the game and there aren't any backfill tickets, the Game Server creates a new backfill ticket.

If a backfill ticket is not approved regularly by the Game Server, then the Matchmaker service automatically deletes the ticket. This prevents backfill tickets from Game Servers that are not running from holding player tickets for no reason.

If a backfill ticket is deleted, either timed out by the Matchmaker service or by the game server, the tickets that were not assigned are put back into the pool of tickets.

The following code sample demonstrates how to create a backfill ticket from a Game Server:

When approving a backfill ticket, the game server informs the Matchmaker that the game server is still running and expecting new tickets from the Matchmaker. Unity suggests approving a backfill ticket every second. If there isn’t a call to approve the backfill ticket after a while, the Matchmaker service automatically deletes the ticket.

The following code sample demonstrates how to approve a backfill ticket:

Backfill tickets should be updated when a new player joins the match from outside Matchmaker, or when a player leaves the match. Updating backfill tickets enables the game server to inform Matchmaker that the match composition has changed.

The following code sample demonstrates how to update a pre-existing backfill ticket:

When a backfill ticket is updated by the Game Server, all unassigned tickets are released into the pool of tickets.

A backfill ticket should be deleted when:

The following code sample demonstrates how to delete a backfill ticket:

**Examples:**

Example 1 (unknown):
```unknown
{
  "Name": "60 Players",
  "MatchDefinition": {
    "Teams": [
      {
        "Name": "Team",
        "TeamCount": {
          "Min": 1,
          "Max": 1
        },
        "PlayerCount": {
          "Min": 60,
          "Max": 60,
          "Relaxations": [
            {
              "Type": "RangeControl.ReplaceMin",
              "AgeType": "Oldest",
              "Value": 1,
              "AtSeconds": 5
            }
          ]
        },
        "TeamRules": []
      }
    ],
    "MatchRules": []
  },
  "BackfillEnabled": true
}
```

Example 2 (unknown):
```unknown
{
  "Name": "60 Players",
  "MatchDefinition": {
    "Teams": [
      {
        "Name": "Team",
        "TeamCount": {
          "Min": 1,
          "Max": 1
        },
        "PlayerCount": {
          "Min": 60,
          "Max": 60,
          "Relaxations": [
            {
              "Type": "RangeControl.ReplaceMin",
              "AgeType": "Oldest",
              "Value": 1,
              "AtSeconds": 5
            }
          ]
        },
        "TeamRules": []
      }
    ],
    "MatchRules": []
  },
  "BackfillEnabled": true
}
```

Example 3 (unknown):
```unknown
// Set the Match Properties. These properties can also be found in the Allocation Payload (cf Allocation Payload)

var teams = new List<Team>{
                    new Team( "Red", "9c8e302e-9cf3-4ad6-a005-b2604e6851e3", new List<string>{ "c9e6857b-a810-488f-bacc-08d18d253b0a"  } ),
                    new Team( "Blue", "e2d8f4fd-5db8-4153-bca7-72dfc9b2ac09", new List<string>{ "fe1a52cd-535a-4e34-bd24-d6db489eaa19"  } ),
                };

// Define the Players of the match with their data.
var players = new List<Unity.Services.Matchmaker.Models.Player>
{
   new (
       "c9e6857b-a810-488f-bacc-08d18d253b0a",
       new Dictionary<string, object>
       {
           { "Team", "Red" }
       }),
   new (
       "fe1a52cd-535a-4e34-bd24-d6db489eaa19",
       new Dictionary<string, object>
       {
           { "Team", "Blue" }
       })
};

var matchProperties = new MatchProperties(teams, players);


var backfillTicketProperties = new BackfillTicketProperties(matchProperties);

// Set options for matchmaking
var options = new CreateBackfillTicketOptions("queue", "127.0.0.1:8080", new Dictionary<string, object>(), backfillTicketProperties);


// Create backfill ticket
string ticketId = await MatchmakerService.Instance.CreateBackfillTicketAsync
(options);

// Print the created ticket id
Debug.Log(ticketId);
```

Example 4 (unknown):
```unknown
// Set the Match Properties. These properties can also be found in the Allocation Payload (cf Allocation Payload)

var teams = new List<Team>{
                    new Team( "Red", "9c8e302e-9cf3-4ad6-a005-b2604e6851e3", new List<string>{ "c9e6857b-a810-488f-bacc-08d18d253b0a"  } ),
                    new Team( "Blue", "e2d8f4fd-5db8-4153-bca7-72dfc9b2ac09", new List<string>{ "fe1a52cd-535a-4e34-bd24-d6db489eaa19"  } ),
                };

// Define the Players of the match with their data.
var players = new List<Unity.Services.Matchmaker.Models.Player>
{
   new (
       "c9e6857b-a810-488f-bacc-08d18d253b0a",
       new Dictionary<string, object>
       {
           { "Team", "Red" }
       }),
   new (
       "fe1a52cd-535a-4e34-bd24-d6db489eaa19",
       new Dictionary<string, object>
       {
           { "Team", "Blue" }
       })
};

var matchProperties = new MatchProperties(teams, players);


var backfillTicketProperties = new BackfillTicketProperties(matchProperties);

// Set options for matchmaking
var options = new CreateBackfillTicketOptions("queue", "127.0.0.1:8080", new Dictionary<string, object>(), backfillTicketProperties);


// Create backfill ticket
string ticketId = await MatchmakerService.Instance.CreateBackfillTicketAsync
(options);

// Print the created ticket id
Debug.Log(ticketId);
```

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/privacy-and-consent

**Contents:**
- Privacy and consent#
- Privacy overview for Unity IAP#
- Apple privacy survey for IAP#
- Google Play data safety for IAP#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/annotate

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/allocations-payload

---

## A/B testing

**URL:** https://docs.unity.com/ugs/en-us/manual/game-overrides/manual/ab-testing

**Contents:**
- A/B testing#
- Define the Override as an A/B test with statistical significance tracking#
- Configure the test#
- Target#
- Configuring the content#
- Schedule the test#
- Viewing the results and reporting#
- Make a decision and end the Override#
- Best practices#

Game Overrides can be split into multiple variants to compare the impact they have on your game. For example, you might believe starting players are given too many coins and are progressing through your game too quickly or stop playing too early, missing IAP (in-app purchases) opportunities. To test this, you’d set multiple starting balances: the control and the variants.

Statistical significance tracking increases the confidence that the effects observed during an A/B test are not due to chance. This option allows you to configure A/B tests to run for long enough and receive the required participation before they display results.

To set up a multi-variant test using Game Overrides without enabling statistical significance tracking, refer to Get started.

The result displayed after calculation represents how many players need to fall in each of the variants so the experiment is statistically significant.

A/B tests with statistical significance tracking target all players; you can't choose a specific Audience or use JEXL for targeting. To limit the number of players who get an alternate configuration, set a lower weight for the variants and a higher weight for the control.

Audiences and JEXL are still available for targeting within Game Overrides that do not use statistical significance tracking.

On the Content page, under Variant 1, select Add Keys. Choose your Key name and Value. Variant 1 is the control and matches the default value of your configuration. Add a new variant group using the tab at the top and repeat the same steps, with a different value you want to test. Select Add a variant group to add variants. A best practice would be to test a single change to know whether the variable you’re testing impacts your metrics.

By default, your players are allocated equally between the control and variant group. Select Split Manually if you want to control the individual weightings of a group. We recommend splitting the variants to a level you are comfortable with.

You can change the percentage of players that will fall into each group. The values must add up to 100%. Select Next to continue.

Schedule your Override with a Start Date.

Make sure you are not running overlapping Overrides against the same variables to maintain the integrity of the configuration served to players as part of the test. Select a higher priority for the test so it has precedence over other Overrides.

Set the priority for the Override and select Continue to create the Override.

Once the A/B test has been running for 7 days and the required number of participants has been met, select Load experiment results from the reporting tab.

You can then interpret the result and see how the change introduced to a subset of players as part of the A/B test impact the chosen metric.

You can also view the corresponding Game Overrides reporting through Analytics events. In your Game Overrides list, select the Override name, then select the Reporting tab.

You can filter by metrics and adjust the time window to view results for today, the last seven days, the last 14 days, the last 30 days, and the last quarter.

Once the results of the A/B test have been loaded to review, the associated Game Override will stay active until you make a decision.

Select End Override at the top right of the Override's page select one of the two main options:

To confirm and apply this choice check the reminder checkbox at the bottom of the prompt and select End Override.

---

## Insights usage

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/ccd-insights-usage

**Contents:**
- Insights usage#
- Total downloads#
- Total errors#
- Top 50 errors#

Use the Insights tool to access download and error metrics for your game.

To find this feature, In the Unity Dashboard, open Cloud Content Delivery and select Insights.

The following metrics are available:

Total downloads checks the total number of downloads per bucket in your game for the selected environment.

Insights only displays up to the first 10 releases to avoid overpopulating the graph. You can select a release listed under the resulting graph to toggle its downloads from appearing.

Total errors accesses statistics concerning how many errors occurred for one or more specified buckets.

Insights only displays up to the first 10 buckets to avoid overpopulating the graph. You can select a bucket listed under the resulting graph to toggle its errors from appearing.

Top 50 errors displays up to fifty of the most common errors occurring in your game.

---

## Server administration console

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/overview

**Contents:**
- Server administration console#

Use the Unity Version Control (UVCS) server administration console, a web-based, cross-platform server configuration tool UI, to configure your server settings. The server administration console covers the following topics and settings:

---

## Welcome to Cloud Content Delivery (CCD)

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCD

**Contents:**
- Welcome to Cloud Content Delivery (CCD)#
- CCD interfaces#
- CCD organization#
  - Environments#
  - Buckets#
  - Entry#
  - Release#
  - Badge#

Cloud Content Delivery (CCD) is Unity's managed cloud service that hosts and delivers content to your application’s users worldwide without having to reinstall a new version of the application. The service is fully integrated into the Unity development platform, saving you months of building and maintaining your own similar service. CCD is most valuable for content-rich, live games or applications that require content updates on a regular basis.

There are multiple ways to integrate your application content with Cloud Content Delivery (CCD):

In CCD, you organize your content into buckets per environment to create a clear workflow for your project. A typical workflow example could be having separate buckets per platform (for example, an iOS bucket and an Android bucket), across multiple environments. You start with a production environment, but you can add other environments such as development and staging.

Within a given bucket, you group specific versions of each asset to create a release. As these versions change, or you add and remove entries, you designate new releases as required.

A release can also have a unique identifier associated with it, called a badge. Give this badge a meaningful name, then use it to query content, and move it between releases to add flexibility to your workflow.

You can create environments in the Unity Dashboard. A project can contain multiple environments (such as production, staging and development), but only one of them is the default one. By default, every project has a production environment.

Using Cloud Content Delivery, you organize your content into buckets to create a clear workflow for your project. A bucket is a single context for publishing content. A typical workflow example could be having separate buckets for different platforms, with names such as ios and android. The buckets could be in different environments, such as the production and development environments. A bucket can be private or public. Private buckets protect read access to buckets with an access token, so only those users with that access token can retrieve content from that bucket. You can also mark a bucket as "promotion only" to restrict write access to that bucket and prevent mistakes such as uploading incorrect content to the wrong bucket. The image below shows a sample bucket as it appears in CCD, including its bucket ID, Promotion Only setting, Privacy setting, description, and the details for a release within the bucket.

You can create and edit buckets either through CCD in the Unity Dashboard or through the CLI.

An entry is a single unit of content within a bucket. Entries support labels and metadata. Creating a release captures the current state of all the entries in the bucket, similar to a versioning process.

Uploading entries to a bucket pushes a local folder’s contents to the remote bucket, which automatically adds, updates, and deletes contents in the bucket, as necessary. CCD supports entries of many file types, the most popular being .gzip, .txt and .bundle (AssetBundles).

Each entry has the following information:

When you create a release, CCD takes a snapshot of all the entries (at their current versions) contained in a bucket at that specific point in time. To remove, update, or add entries, you must create a new release in order to deliver the new or changed entries. You can move releases between buckets by a process called promotion.

Creating or promoting a new release does not create copies of the entries in a bucket.

Badges enable you to select which release your application uses. You can assign a unique badge to a release, and request the badged content using that badge’s name. The image below shows how badges appear in CCD.

You can move this badge between releases, adding more flexibility to content workflows. Moving a badge removes it from the previous release that it was associated with. You can only assign a badge to a single release at a time, but you can associate multiple different badges to a release.

By default, an automatically generated badge named latest is assigned to the latest release.

---

## Code-Link

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/platform-signin-code-link

**Contents:**
- Code-Link#
- Set up Code-Link#
- Sign in using Code-Link#

Minimum SDK version: 3.0.0

See the following scenarios in setting up authentication for players in your game with Code-Link:

Sign in as a player using these Code-Link functions:

Note: Step 4 can be skipped if device B polls the service until the Code is either confirmed or expired.

To sign in using Code-Link, follow these steps:

Use the GenerateSignInCodeAsync method (passing an identifier is optional but recommended to identify the device that generated the sign in code) from the unauthenticated device that wants to authenticate to generate a Sign In Code.

Show the generated SignInCode and expiration to the player.

Note: The identifier has a maximum length of 128 characters.

Give player access to input the SignInCode, in a second already authenticated device.

(Optional) Use the player-provided SignInCode to fetch the SignInCode information, using GetSignInCodeInfoAsync, and display it to the player to confirm they're authorizing the correct device by comparing the identifier on both devices.

Authorize the Code-Link sign in using ConfirmCodeAsync.

Note: The ConfirmCodeAsync method also supports optional parameters in idProvider and externalToken. These parameters should only be used on consoles. Using them on other platforms will return an error.

Call SignInWithCodeAsync to sign in the player on the same device that generated the SignInCode. (The credentials to validate the Code-Link sign in are stored in memory so make sure to call GenerateSignInCodeAsync before calling SignInWithCodeAsync or it will throw an exception). If the code has yet to be authorized, this method is successful, but the player won't be signed in; look for the SignedIn event to see if the sign in was successful.

Note: The SignInWithCodeAsync method also allows for automatic polling (every five seconds), so the device automatically signs the player in after the code has been authorized, or throws an exception if the code has expired. This method also accepts a CancellationToken to cancel the polling.

**Examples:**

Example 1 (unknown):
```unknown
GenerateSignInCodeAsync
```

Example 2 (unknown):
```unknown
async Task GenerateCodeAsync(string identifier)
{
    try
    {
        var codeInfo = await AuthenticationService.Instance.GenerateSignInCodeAsync(identifier);
        // Display code, and expiration and identifier to the player
    }
    catch (Exception e)
    {
        // Notify the client something went wrong generating the code
    }
}
```

Example 3 (unknown):
```unknown
async Task GenerateCodeAsync(string identifier)
{
    try
    {
        var codeInfo = await AuthenticationService.Instance.GenerateSignInCodeAsync(identifier);
        // Display code, and expiration and identifier to the player
    }
    catch (Exception e)
    {
        // Notify the client something went wrong generating the code
    }
}
```

Example 4 (unknown):
```unknown
GetSignInCodeInfoAsync
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/5

---

## CCD and Addressables walkthrough

**URL:** https://docs.unity.com/ccd/en/manual/UnityCCDWalkthrough

**Contents:**
- CCD and Addressables walkthrough#
- Prerequisites#
  - Download and test the project#
  - Install the Addressable Assets package#
- Configure Addressables in the Editor#
  - Configure game assets as addressable#
  - Configure an Addressables profile#
- Connect your project to CCD#
  - The Command-line interface (optional)#
- Create buckets#

You can use the Addressable Asset system in Unity with CCD to effectively serve content to your users. This page demonstrates how to set up an actual Unity game project with Cloud Content Delivery (CCD) and Addressables, which allows you to easily integrate a pipeline of assets from Unity Editor into CCD.

Note: The Addressables Asset System isn’t required for using CCD.

This workflow gives you instructions on how to do the following tasks with the Loady Dungeons sample project in Unity:

Note: This walkthrough uses Unity 2023.18f.

For this workflow, you need to install the Loady Dungeon sample project. This project comes with the Addressables Assets package pre-installed, but you can also install the package from the Asset Manager.

The first thing you need to do to follow along with this walkthrough is to download the latest version of our sample game from GitHub, Loady Dungeons.

You can then test the project in the Unity Editor:

Note: When you play the game in its initial state, you can't load the first level. As you progress through this workflow, you associate the required assets to use CCD with Addressables to fix this limitation.

In order to mark assets as addressable, you need to install the Addressables package directly in Unity Editor.

This project already has an Addressables package pre-installed, but if you are following along with a custom project or want to upgrade to a newer verified version, install the Addressables package through the Package Manager:

Addressable assets provide an easy way to handle asset management overload by loading assets by address. To load game assets by address, you need to mark them as Addressable:

Open the Scenes folder in the Project window.

Select the following assets:

In the Inspector window, select Addressable for each asset.

Select Window > Asset Management > Addressables > Groups to open the Addressables Groups window.

Select Create > Group > Packed Assets and create the following new groups:

Drag the Scenes assets from the default group into their corresponding groups. For example, drag the Level_01 scene from the default group into the new Level 01 group you created.

In the Project window (Prefabs > Hats), drag the entire contents from the Hats folder (not the folder itself) into the Hats group.

Select each of the assets from the Addressables Groups window, and rename their lengthy Addressable field to something simpler in the Inspector window.

Note: To automatically rename them, select all the assets, right-click, and select Simplify Addressable Names.

To save all of the associated settings related to development of the game, you can create a new Addressables profile:

After you set up your Addressables in the Unity Editor, you can connect the game project to the Cloud Content Delivery (CCD) service, ultimately leveraging the Addressables and AssetBundles. CCD is managed cloud service that hosts and delivers content to your application’s users worldwide without the need to reinstall a new version of the application.

To get started with CCD:

Sign in to the Unity Dashboard with your Unity ID.

From the projects page, select New button.

Open your new Loady Dungeons Workshop project and take note of the Project ID.

Select the Environments tab. If you don't already have a development environment, create one.

From the Products page in the dashboard, locate and open Cloud Content Delivery.

Note: If you haven't used CCD before, you can refer to CCD in the Unity Dashboard for more information about how to set it up.

You can also use the optional command-line interface (CLI) to manage your project:

For more information, refer to CCD Command-line interface (CLI).

You can create buckets to assist in the different stages of creation for this project.

From the CCD landing page, select Buckets on the left.

Select Loady Dungeons Workshop from the projects dropdown (if not already selected).

Select Create Bucket to create a new bucket.

Name the bucket Loady Dungeons Sample and give the bucket an optional description.

Select the permissions for this bucket from the following:

To restrict read access to this bucket, select Enable Bucket Privacy. Private buckets only allow users with an access token to read the content.

Note: You cannot change the bucket privacy settings after you create the bucket.

Select Next and make sure both production and development environments are selected.

When you create the Loady Dungeons Sample bucket. it appears on the Cloud Content Delivery Buckets page in the Unity Dashboard, for both development and production environments. You can use the environments dropdown to switch between environments at the top of the page. Take note of the Bucket IDs of the buckets in both environments because you need to use them later in your remote load path.

If you want to read the data from private buckets, you need to have a valid Bucket Access Token.

As of Addressables 1.19.4, you can use the WebRequestOverride feature to add a Bucket Access Token as a header to the request, which the following example demonstrates:

In this example, token is the base64 encoded Bucket Access Token value.

Note: If you want to use the CCD Management package instead, skip to the Generate AssetBundles and upload content with CCD Management package section.

An AssetBundle is an archive file that contains platform-specific non-code assets that Unity can load at run time.

To generate AssetBundles:

In your Unity Editor project, select Window > Asset Management > Addressables > Groups.

In the Profile dropdown, make sure that Development Profile is selected. If it isn’t, select it now.

In the Profile dropdown, select Manage Profiles.

With Development Profile selected, set the following:

RemoteBuildPath: AssetBundles/[BuildTarget], where [BuildTarget] is the default subfolder.

RemoteLoadPath: https://PROJECT_ID.client-api.unity3dusercontent.com/client_api/v1/buckets/BUCKET_ID/release_by_badge/latest/entry_by_path/content/?path=

Return to the Addressables Groups window and select Hats.

In the Inspector panel, set the build path and load paths for these four sets of assets to the paths we specified for the Development Profile:

In the Groups window, select the Build dropdown, then select New Build > Default Build Script. This saves the AssetBundles at the RemoteBuildPath location.

To use the build you made as the basis for a play test, select Play Mode Script > Use Existing Build.

Select the Play button in Unity Editor to test the game. Press Start in the game. Notice how the game is now stuck.

At this point, you can upload this content into the Development bucket you set up in CCD earlier.

CCD automatically applies the automatically created latest badge to this release, which marks it as the newest release created in this bucket.

Note: You can also use the CLI to upload content.

The CCD Management package with Addressables 1.19.15+ allows you to build, upload and release Addressable content.

Note: You need to upgrade the Addressables versions and install the CCD Management package through the Package Manager.

Note: At this point if you don't already have the CCD Management package installed, Unity Editor prompts you to add it. Select the Install CCD Management SDK Package button to install it.

When you select Start in the game, the game is now stuck.

To generate, upload, and release this content into the Loady Dungeons Sample bucket we set up in CCD earlier:

The CCD Management package uses the default build script behavior to generate the Addressable bundles. Then, the management package uploads all groups associated with the path pair that is connected to the Loady Dungeons Sample bucket and latest badge that we set up earlier to those remote targets. Finally, the management package creates a release for those remote targets and updates their badge to latest.

After you upload your assets to the Loady Dungeons Sample bucket in your development environment and you tie those assets into a release, you can put these latest changes out for public consumption. That’s why we also created the bucket in your production environment. The buckets in your production environment contain releases ready for your players. This means moving the release from the bucket in your development environment to the one in your production environment by a process called promotion.

To promote the release from the bucket in your development environment to the one in your production environment:

Again, CCD automatically applies the automatically created latest badge to this release, which marks it as the newest release created in this bucket.

Before you test the game, you need to modify the profile variables to point to the correct bucket. There are two ways to do this:

In this workflow, you successfully move the release and all its assets from Development to Production, ready to deploy to your users as a functional game.

**Examples:**

Example 1 (unknown):
```unknown
Development Profile
```

Example 2 (unknown):
```unknown
Loady Dungeons Workshop
```

Example 3 (unknown):
```unknown
Loady Dungeons Sample
```

Example 4 (javascript):
```javascript
void Start()
{
	textComponent = GetComponent<Text>();
	Addressables.WebRequestOverride = webRequest =>
	{
		webRequest.SetRequestHeader("Authorization", "Basic "+token);
		//  Debug.Log($"Fetching: {webRequest.url}");
	};
	Addressables.LoadAssetAsync<TextAsset>("Assets/one.txt").Completed += handle =>
	{
		textComponent.text = handle.Result.text;
		// Debug.Log($"Text is now: {handle.Result.text}");
	};
}
```

---

## Offenses

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/offenses

**Contents:**
- Offenses#
- Cheat/Tampering#
- Disruption#
- Inappropriate communications#
- Inappropriate content#

An offense is a violation of a community’s rule or an otherwise offensive action performed by a player in the community. Unity Moderation categorizes offenses by offense type. The player reporting the incident (the reporter) selects the type of offense before reporting the incident.

Unity Moderation has the following types of offenses.

---

## Change authentication mode

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/change-authentication-mode

**Contents:**
- Change authentication mode#

Change the authentication mode for your Unity Version Control (UVCS) clients. For more information about authentication modes, refer to Authentication configuration.

To change your authentication mode, sign in to the server administration console:

---

## Limitations

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/limitations

**Contents:**
- Limitations#

Relay has the following limitations:

Relay is engine agnostic. If you use Relay with Unity, the recommended best practice is to use the Relay SDK, which is coupled with Unity Transport Package (UTP). Relay works with Unity Transport (UTP), giving it the ability to connect clients that might otherwise be unable to communicate because of routing restrictions such as restrictive firewalls.

Players can only connect with other players within the same game session. Check out Connection flow.

Currently, there is no region-locking functionality; anyone can request an allocation in any region if the region has enough capacity to support the request.

The Relay service routes all communication through a single region selected by the host. As a result, cross-region communication might not offer optimal latency.

A maximum of 150 players can join the host in the same game session. Not all game types will scale to that high amount of players without the use of a dedicated game server. Carefully consider the impact on the host player when attempting high player count sessions with Relay. This limit's aligned with the maximum number of players allowed in a Lobby.

---

## Game server signals

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-signals

**Contents:**
- Game server signals#
  - SIGTERM#
  - SIGKILL#
  - SIGSEGV#

A signal is a way to report an occurrence of an exceptional event to the host operating system. The signal type tells the host operating system how to handle the event. This section provides guidance around using common signals and how Multiplay Hosting responds to them.

Warning: The following signals are only for games running on Linux-based operating systems.

SIGTERM is a generic signal that triggers process termination. It’s similar to SIGKILL, except that the process can block, handle, or ignore it. You can think of SIGTERM as a way to politely request a process to end (terminate).

Multiplay Hosting sends the build executable process a SIGTERM signal when stopping the server. Build executables must respond to SIGTERM signals by exiting. If a build executable process doesn’t respond to a SIGTERM signal within 20 seconds, it receives a SIGKILL command.

Note: There’s no Windows equal to SIGTERM.

SIGKILL is a generic signal that causes a process to immediately end (terminate). It’s similar to SIGTERM, but the process can’t block, ignore, or handle it. A SIGKILL always terminates the process.

Multiplay Hosting uses a SIGKILL signal to terminate build executable processes if they fail to respond to a SIGTERM signal within 20 seconds.

Note: The Windows equal of SIGKILL is PROCESS_TERMINATE.

SIGSEGV is a signal sent to a process trying to access an inaccessible memory location, resulting in a segmentation error. Some more common triggers of SIGSEGV signals include de-referencing null pointers, buffer overflows, and invalid permissions.

Multiplay Hosting sends a SIGSEGV signal to build executable processes when it detects that the process is misbehaving. Usually, this means the process is using too much memory (or CPU) or is attempting to access memory it doesn’t have access to.

Note: Multiplay Hosting uses SIGSEGV signals instead of other interrupt signals (like SIGSTOP) because other signals either don’t trigger a core dump or cause issues with the game engine.

Note: The Windows equivalents of SIGSEGV are PROCESS_QUERY_INFORMATION and PROCESS_VM_READ.

---

## Available servers

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/available-servers

**Contents:**
- Available servers#

Available servers are servers in a region in a ready state that can fulfill an allocation request quickly. Having these “ready to go” servers ensures there’s always a server available to fulfill an allocation request, which prevents players from having to wait for you to scale up more servers.

Multiplay Hosting keeps a collection of available servers for each region. This collection is the availability buffer. The region’s scaling settings decides the number of available servers per region.

For example, if you have a region with a minimum of one server and a maximum of five servers, you can have, at most, five servers in that region. With that in mind, the minimum and maximum available servers scaling settings control the size of the available servers buffer. Effectively, these settings decide the number of servers you want to keep online, available to allocate, in case of an increase in allocations.

---

## Vivox Core SDK documentation

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/overview

**Contents:**
- Vivox Core SDK documentation#
- Introduction#
- Vivox versions#
- Additional resources#

Note: If you're looking for the documentation for the Vivox Unity SDK for the Unity Engine, refer to Unity Vivox.

The Vivox Core SDK is an engine-agnostic voice and text chat system that brings in-app communications to your project.

Vivox SDK provides the following core capabilities:

Game developers can integrate these capabilities directly into game clients and companion applications by using the Vivox SDK.

Vivox offers additional features for speech-to-text transcriptions and text-to-speech for better accessibility for users. As well as server-side recording to help reduce in-game toxicity.

Optionally, game developers can provide additional capabilities by integrating their game server with Vivox servers through the Vivox Server to Server Web API, which is a simple XML over HTTP protocol that you can access by using a variety of server technologies.

---

## Using CCD via the UGS CLI

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDCLIWalkthrough

**Contents:**
- Using CCD via the UGS CLI#
- Authentication#
  - Logging In Using the CLI#
    - Using Environment Variables for Authentication#
      - For Unix-based systems (Linux, macOS)#
      - For Windows#
- Configuration#
  - Set Project ID#
  - Set Environment Name#
  - Set Bucket Name#

Note: The CCD UCD CLI and its walkthrough are officially deprecated and no longer receive updates. You can transition to use the UGS CLI and this UGS CLI walkthrough instead.

To authenticate with the service, you need to use a service account. Ensure that your service account has the appropriate roles assigned for the required access levels:

If you don't have a service account or need to manage your existing accounts, visit the Service Account Authentication Documentation for detailed instructions on how to create or manage your service account.

Once you have your service account set up and the appropriate roles assigned, you can log into the service using the command-line interface. If you encounter any issues or need additional guidance, refer to the Getting Started section for help.

To log in, simply enter the following command and follow the interactive prompts:

As an alternative to interactive login, you can also set your credentials as environment variables. This method is particularly useful for scripting or automated workflows. To do this, set the UGS_CLI_SERVICE_KEY_ID and UGS_CLI_SERVICE_SECRET_KEY environment variables with your service account's Key ID and Secret Key respectively. Example of setting environment variables (use the appropriate method for your operating system):

After setting these environment variables, the CLI will automatically use them for authentication, eliminating the need for interactive login during your session.

Configure the UGS CLI to target your specific project, environment, and bucket.

Link the CLI to your Unity project by setting the Project ID. Replace <project-id> with your actual Project ID:

See the Getting started section if you need help locating your Project ID.

To find a list of environments for your project, run this command:

Specify the environment you want to use (e.g., development, staging, production) for your CLI operations. For example, to set it to production:

The list of environment is also available from the Unity Dashboard by selecting Projects, open your project, and then selecting the Environments tab.

If you have a bucket ready, link it to your CLI session for asset management. Replace with your actual Bucket name:

These configurations ensure your CLI commands target the correct project, environment, and bucket.

Create your first bucket. Buckets are associated with a single project.

List the buckets (which should be empty at this point) for this project:

Create a bucket called example_bucket for this project:

You can only edit the bucket name via the CDD Dashboard.

Bucket and entry names are case sensitive.

To see the newly-created buckets, list the buckets again for this project:

To make it easier to work with creating entries and releases, save the newly-created bucket to the local configuration (don’t provide it as a parameter to the CLI for every operation).

CCD will automatically performs any commands relating to entries and releases on the bucket you specified.

List entries in this newly-created bucket (it should be empty):

No Entries found for current bucket.

Synchronize all the files in a local folder. In this example, the local folder contains generated AssetBundles as the content:

This adds the files as entries to the bucket. You can list the bucket’s contents and see some basic information about each entry:

List bucket's contents

There should be 22 entries in the bucket.

To get more detailed information about a specific entry, use the entries info command with the path of the entry:

Get entry information

Your game client can now request content for an individual file in the bucket using the path associated with the entry. Make all game client requests to your project-specific subdomain at <project_guid>.client-api.unity3dusercontent.com. The URLs all begin with /client_api/v1/ in the request path. None of these client requests require authentication.

To get the content of an entry, such as spaceshooterdata_starfield.bundle, by path, enter:

https://<project_guid>.client-api.unity3dusercontent.com/client_api/v1/buckets/00000000-0000-0000-0000-000000000000/entry_by_path/content/?path=spaceshooterdata_starfield.bundle

Or to get the content of an entry by Entry ID, enter:

https://<project_guid>.client-api.unity3dusercontent.com/client_api/v1/buckets/00000000-0000-0000-0000-000000000000/entries/00000000-0000-0000-0000-000000000000/content/

Create a release from the current state of your entries:

This allows you to use these exact versions of those entries when requesting content, even if you update or remove those entries later.

While you can add a note during the creation of a release by using the -n flag, you can only edit it afterward through the CDD Dashboard.

To get more detailed information about a release, use the releases info command and provide the ID of the release that you just created:

Get release information

To get a list of all releases you generated in this bucket, enter:

List releases in bucket

You can now directly reference the content contained within this release. This ensures you get the exact set of content that CCD uses to generate the release even if you change the entries later in the bucket.

To get the content of an entry, such as spaceshooterdata_starfield.bundle, by path, enter:

https://<project_guid>.client-api.unity3dusercontent.com/client_api/v1/buckets/00000000-0000-0000-0000-000000000000/releases/00000000-0000-0000-0000-000000000000/entry_by_path/content/?path=spaceshooterdata_starfield.bundle

Or to get the content of an entry by Entry ID, enter:

https://<project_guid>.client-api.unity3dusercontent.com/client_api/v1/buckets/00000000-0000-0000-0000-000000000000/releases/00000000-0000-0000-0000-000000000000/entries/00000000-0000-0000-0000-000000000000/content/

You can also request the content that corresponds to the latest release in the bucket, so the client does not need to change each time CCD generates a new release. To do this, update the request to use the release_by_badge route and specify a badge name of latest (see Managing badges). For example:

https://<project_guid>.client-api.unity3dusercontent.com/client_api/v1/buckets/00000000-0000-0000-0000-000000000000/release_by_badge/latest/entry_by_path/content/?path=spaceshooterdata_starfield.bundle

After generating a release, you can apply a badge that uniquely identifies the release. A badge can only ever point to a single release within a bucket, but you can move badges between releases. At runtime, you can query content using the badge name rather than a specific release ID, allowing for more flexibility in workflows.

For example, you might apply a badge called qa_latest to the latest release for your QA team to use, and move that badge to each new release as part of a process (manual or automated).

To add a badge named my_first_badge to the release you generated in Creating a release, enter, using the release_num and badge_name as arguments:

To list all the badges you applied in this bucket:

List badges in bucket

The content associated with the release that the badge references is ready for download. You can do this in a similar way to downloading content directly by Entry ID.

To get the content for an entry, such as spaceshooterdata_starfield.bundle, by path, enter:

https://<project_guid>.client-api.unity3dusercontent.com/client_api/v1/buckets/00000000-0000-0000-0000-000000000000/release_by_badge/my_first_badge/entry_by_path/content/?path=spaceshooterdata_starfield.bundle

Or to get the content of an entry by Entry ID, enter:

https://<project_guid>.client-api.unity3dusercontent.com/client_api/v1/buckets/00000000-0000-0000-0000-000000000000/release_by_badge/my_first_badge/entries/00000000-0000-0000-0000-000000000000/content/

Releases can be copied from one bucket to another, a process referred to as promotion. This is especially useful when you want to move a release to a different bucket and environment or a more restricted bucket.

Create a second bucket and update its permission to be a promotion only bucket. This means the bucket will only accept promoted releases and won't allow direct creation, update, or deletion of entries from service accounts with the user type "user".

Finally, promote your release to the target bucket by specifying the release number, the target bucket's name and target environment:

This section demonstrates how to set up an actual Unity game project with Cloud Content Delivery (CCD) and Addressables, allowing you to easily integrate a pipeline of assets from Unity Editor into CCD.

The Addressables Asset System isn’t required for using CCD.

Using a very simple mobile game called Loady Dungeons, you will learn how to:

After reading this walkthrough, you will know how to effectively serve content to your users, and how to use the Addressable Asset system in Unity with CCD.

This walkthrough uses Unity 2021.3.18f1.

The first thing you need to do to follow along with this walkthrough is to download the latest version of our sample game from GitHub, Loady Dungeons.

Open the Loady Dungeons project.

Open the MainMenu scene.

Click on the Game tab.

In the Aspect dropdown, click +.

Create a new aspect of Type "Aspect Ratio", with a Width and Height of 9 and 16, respectively. This makes the game preview look more like it's running on a phone.

Deselect Low Resolution Aspect Ratios.

Press the Editor's Play button to try the game.

Playing the game in its initial state means you can't load the first level. Progressing through this walkthrough fixes this limitation by associating the required assets to use CCD with Addressables.

In order to mark assets as addressable, you need to install the Addressables package directly in Unity Editor.

This project already has an Addressables package pre-installed, but if you are following along with a custom project or want to upgrade to a newer verified version, install the Addressables package through the Package Manager.

Addressable assets provide an easy way to handle asset management overload by loading assets by address. Now that you have the Addressables package installed, it’s time to mark your game assets as addressable.

Open the Scenes folder in the Project window.

Select the following assets:

In the Inspector window, select Addressable for each.

Open the Addressables Groups window from Window > Asset Management > Addressables > Groups.

Create the following new groups using Create > Group > Packed Assets:

Drag the Scenes assets from the default group into their corresponding groups. For example, drag the Level_01 scene from the default group into the new Level 01 group you created.

Drag the entire contents from the Hats folder (not the folder itself) in the Project window (Prefabs > Hats) into the Hats group.

Select each of the assets from the Addressables Groups window, and rename their lengthy Addressable field to something simpler in the Inspector window. You can select all the assets, right-click > Simplify Addressable Names to automatically rename them.

For the scene asset Level_00, rename its Addressable field from Assets/Scenes/Level_00.unity to Level_00.

At this stage, create a new Addressables profile to save all the associated settings related to development of the game to this development profile:

Click Window > Asset Management > Addressables > Groups.

Select Profile > Manage Profiles from the dropdown.

In the resulting Addressables Profiles window, select Create > Profile.

A profile named New Profile appears. Right-click it and select Rename Profile. Name it “Development Profile”.

Right-click Development Profile > Set Active. This sets the Development Profile as the current profile in use.

Now, build your AssetBundle, which is an archive file that contains non-code assets for your game. This is so that the Editor’s play mode uses our AssetBundles instead of local assets.

Click Window > Asset Management > Addressables > Groups.

Select Build > New Build > Default Build Script from the dropdown.

Select Play Mode Script > Use Existing Build from the dropdown.

Now you are ready to hook this game into the Cloud Content Delivery (CCD) service, ultimately leveraging Addressables and AssetBundles. The benefit of CCD is that it is a managed cloud service that hosts and delivers content to your application’s users worldwide without having to reinstall a new version of the application.

To get started with CCD:

Go to the Unity Dashboard.

Sign in using your Unity ID.

From the projects dropdown, click Create Project.

Name it “Loady Dungeons Workshop”.

Click Create project.

Open the Loady Dungeons Workshop project and take note of the Project ID.

Select the Environments tab.

If you don't already have a development environment, create one.

From the Dashboard landing page, locate and select Cloud Content Delivery.

If you prefer to use the optional command-line interface (CLI) to manage your project:

See CCD Command-line interface (CLI).

At this point, it is time to create buckets to assist in the different stages of creation for this project.

From the CCD landing page, click Buckets on the left.

Select Loady Dungeons Workshop from the projects dropdown (if not already selected).

Name the bucket “Loady Dungeons Sample”.

Give the bucket an optional description.

Choose whether this bucket is:

To restrict read access to this bucket, select Enable Bucket Privacy. Private buckets only allow users with an access token to read the content.\

You cannot change the bucket privacy settings after you create the bucket.

Make sure both production and development environments are checked.

The Loady Dungeons Sample bucket should now appear on the Cloud Content Delivery Buckets page in the Unity Dashboard, for both development and production environments. You can switch between environments using the environments dropdown at the top of the page. Take note of the buckets’ Bucket ID in both environments because you need to use them later in your remote load path.

An AssetBundle is an archive file that contains platform-specific non-code assets that Unity can load at run time.

To generate AssetBundles:

In your Unity Editor project, click Window > Asset Management > Addressables > Groups.

In the Profile dropdown, make sure that Development Profile is selected. If it isn’t, select it now.

In the Profile dropdown, select Manage Profiles.

With Development Profile selected, set the following:

RemoteBuildPath: AssetBundles/[BuildTarget], where [BuildTarget] is the default subfolder.

RemoteLoadPath: https://PROJECT_ID.client-api.unity3dusercontent.com/client_api/v1/buckets/BUCKET_ID/release_by_badge/latest/entry_by_path/content/?path=

Replace PROJECT_ID with the ID of your project. If you didn’t take note of your Project ID earlier, find it by clicking on your user name in the corner of the Unity Dashboard, then Account > Project Management > Loady Dungeons Workshop.

Replace BUCKET_ID in the path with the ID of the bucket you want to use, the Loady Dungeons Sample bucket created in your development environment in this example. If you didn’t take note of its BUCKET_ID earlier, find it in your list of buckets in the Unity Dashboard.

The latest in the path refers to the badge called Latest, an automatically generated badge assigned to the most recent release.

Return to the Addressables Groups window.

In the Inspector panel, set:

Build Path: RemoteBuildPath

Load Path: RemoteLoadPath

Repeat for Level 00, Level 01, Level 02, and Level 03

This sets the build path and load paths for these four sets of assets to the paths we specified for the Development Profile.

Still in the Groups window, click on the Build dropdown, then select New Build > Default Build Script. This saves the AssetBundles at the RemoteBuildPath location.

To use the build we just made as the basis for a playtest, click on the Play Mode Script > Use Existing Build.

Click the Play button in Unity Editor to test the game.

At this point, we want to upload this content into the Development bucket we set up in CCD earlier.

Notice that CCD automatically applies the automatically created latest badge to this release, marking it as the newest release created in this bucket.

You can also upload content using the CLI.

The CCD Management package with Addressables 1.19.15+ facilitates building, uploading and releasing Addressable content.

You need to upgrade the Addressables versions and install the CCD Management package through the Package Manager.

In your Unity Editor project, click Window > Asset Management > Addressables > Groups.

In the Profile dropdown, make sure that Development Profile is selected.

In the Profile dropdown, select Manage Profiles.

In the Profiles window, select Development Profile, then change the Remote dropdown to use Cloud Content Delivery.

At this point if you don't already have the CCD Management package installed, Unity Editor prompts you to add it. Click on the Install CCD Management SDK Package button to install it.

In the next list of options, choose the Loady Dungeons Sample bucket created earlier.

In the subsequent list, choose the Latest badge.

Return to the Addressables Groups window.

In the Inspector panel, under Content Packaging & Loading:

Set Build and Load Paths: Remote

Repeat for Level 00, Level 01, Level 02, and Level 03

This sets the build path and load paths for these four sets of assets to the paths pairs specified for the Development Profile. See Profile for more information on path pairs.

In the Groups window, click on the Build dropdown, then select New Build > Default Build Script. This saves the AssetBundles at the RemoteBuildPath location.

To use the build we made as the basis for a playtest, click on the Play Mode Script > Use Existing Build.

Select the Play button in Unity Editor to test the game.

Select Start in the game. Notice how the game is now stuck.

To generate, upload, and release this content into the Loady Dungeons Sample bucket we set up in CCD earlier:

The CCD Management package uses the default build script behavior to generate the Addressable bundles. Then, the management package uploads all groups associated with the path pair that is connected to the Loady Dungeons Sample bucket and latest badge that we set up earlier to those remote targets. Finally, the management package creates a release for those remote targets and updates their badge to latest.

After you’ve uploaded your assets to the Loady Dungeons Sample bucket in your development environment and you tie those assets into a release, you can put these latest changes out for public consumption. That’s why we also created the bucket in your production environment. The buckets in your production environment contain releases ready for your players. This means moving the release from the bucket in your development environment to the one in your production environment by a process called promotion.

To promote the release from the bucket in your development environment to the one in your production environment:

Again, notice that CCD automatically applies the automatically created latest badge to this release, marking it as the newest release created in this bucket.

Before you test the game, you need to modify the profile variables to point to the correct bucket. There are two ways to do this:

You’ve now successfully moved the release and all its assets from Development to Production, ready to deploy to your users.

To read the data from private buckets, you need to have a valid Bucket Access Token.

As of Addressables 1.19.4, you can use the WebRequestOverride feature to add Bucket Access Token as a header to the request, which the following example demonstrates.

In this example, token is the base64 encoded Bucket Access Token value.

**Examples:**

Example 1 (unknown):
```unknown
$ ugs login
```

Example 2 (unknown):
```unknown
$ ugs login
```

Example 3 (unknown):
```unknown
export UGS_CLI_SERVICE_KEY_ID="your_key_id"
export UGS_CLI_SERVICE_SECRET_KEY="your_secret_key"
```

Example 4 (unknown):
```unknown
export UGS_CLI_SERVICE_KEY_ID="your_key_id"
export UGS_CLI_SERVICE_SECRET_KEY="your_secret_key"
```

---

## SUPPORT BUNDLE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/support-bundle

**Contents:**
- SUPPORT BUNDLE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Creates a "support bundle" package with relevant logs. You can attach the file while requesting help, asking for extra info, or submitting a bug.

cm support bundle [<outputfile>]

This command allows users to create a "support bundle" package which can be attached when requesting help, asking for extra info, or submitting a bug. The user can optionally specify a location for the output file; otherwise, the output file will be written to the temp directory.

(Creates "support bundle" in temp directory.)

cm support bundle c:\outputfile.zip

(Creates "support bundle" at the specified location.)

**Examples:**

Example 1 (unknown):
```unknown
cm support bundle [<outputfile>]
```

Example 2 (unknown):
```unknown
cm support bundle
```

Example 3 (unknown):
```unknown
cm support bundle c:\outputfile.zip
```

---

## Unity Version Control 10.x Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/10

**Contents:**
- Unity Version Control 10.x Release Notes#
- 10.0.16.6656#
  - New#
    - Show semantic information in CodeLens#
    - Show semantic history in CodeLens#
    - Pagination/sorting added to 'cm find' command.#
    - Added '--gitpushchunk' parameter to export Plasti…#
  - Bug#
    - fixed Browse Repository view on case insensitive…#
    - trigger environment variables are now properly se…#

This document contains all release notes for Unity Version Control major version 10.x, organized from newest to oldest.

Windows - Visual Studio 2022 plugin: Show semantic information in CodeLens

This new release enhances the plugin for Visual Studio 2022 showing semantic information above every class, method or property in your Plastic SCM projects!

The CodeLens annotations above every class, method or property in files controlled by Plastic SCM will show semantic information about its last change. This includes the change type, user who modified it, and change date.

Keep in mind that this feature will only show up in semantic-available files (C#, C, C++) that are in a Plastic SCM Workspace.

This new feature will be installed as part of the Visual Studio 2022 Plastic SCM extension if you select the option during the Plastic SCM installation process. Once installed, the Plastic SCM CodeLens provider can be enable/disable from Tools > Options > Text Editor - All Languages - CodeLens > Show Plastic SCM

Windows - Visual Studio 2022 plugin: Show semantic history in CodeLens

This new release takes the CodeLens information in the plugin for Visual Studio 2022 a step further. When you create the Plastic SCM data point above a method, property or type, it will display a list of up to 10 of the last changes in that element. This leverages the semantic technologies in Plastic SCM, showing only changes in the file that affect the annotated element.

Keep in mind that this feature will only show up in semantic-available files (C#, C, C++) that are in a Plastic SCM Workspace.

This new feature will be installed as part of the Visual Studio 2022 Plastic SCM extension if you select the option during the Plastic SCM installation process. Once installed, the Plastic SCM CodeLens provider can be enable/disable from Tools > Options > Text Editor - All Languages - CodeLens > Show Plastic SCM

Command-line client: Pagination/sorting added to 'cm find' command.

Every find object now complies with pagination, defining a 'limit' and an 'offset' to manage the result size and starting point. In addition, some objects (branch, changeset, label, review) will comply with 'order by' clause. Please, kindly refer to the 'cm find --help' and 'cm help showfindobjects' for further details.

For instance, the following command:

Displays the 10 labels starting from the 21st where I am the owner.

Another example could be:

Displays the first 10 branches I created, sorted by name in descendant order.

GitSync: Added '--gitpushchunk' parameter to export Plastic repositories to Git in smaller chunks.

This parameter allows to process the push operation (exporting changes from Plastic to Git) in chunks of a certain number of changesets instead of sending all the changes in one single package.

This is only useful for huge repos to avoid network or package size related issues or just for debugging purposes. It uses chunks of 1000 changesets if no value is specified.

Windows - Plastic: fixed Browse Repository view on case insensitive filesystems

Browsing the repository was not working correctly because we were failing to distinguish items where the name differed only in case. E.g., "FILE" and "file". This is because we were using the local filesystem path comparison rules, which on Windows meant we were doing a case insensitive comparison.

We fixed it to do a case sensitive comparison.

All clients: trigger environment variables are now properly set.

For before/after update triggers, PLASTIC_INITIAL_CHANGESET and PLASTIC_FINAL_CHANGESET environment variables were swapped, considering the final changeset as the origin and vice versa when using cm ci --update command. It was also noticeable when clicking the "Update workspace" button on the Incoming Changes view.

All platforms - Plastic, PlasticX, Gluon: fixed exception thrown when parsing help panel markup

Malformed release note markup was causing the GUI to throw an exception when showing the help panel. We protected against that.

All platforms - Plastic: Changed Plastic alpha version notification text

The notification text to try the new GUI has been improved.

Windows - PlasticFS: Fix 'The file is being used by another process' error.

We improved the ability of PlasticFS to work with antimalware software. Before, PlasticFS were unable to access some files from time to time, showing an error message like the following one:

Cloud Server: Fixed deadlock requesting branches of a deleted repo.

The cloud server uses file & memory locks to handle concurrent access to the Jet files. If the file lock failed because the repository was deleted from disk, then the memory lock was acquired forever a no other thread could acquire it.

This was a corner scenario since it's very uncommon to run calls against a repo that was deleted from disk.

All platforms - PlasticX: fixed the recycling in the pending changes tree

We fixed the recycling in the tree for the pending changes view. Now, each time you refresh the view, the cell controls for the expander column in the tree are recycled instead of creating them again.

All platforms - PlasticX: Home icon now drawn on switch to branch with new changesets

We fixed the switch to branch functionality on the Branch Explorer view so that it correctly updates the Home icon in the case where changes were made on the target branch since the last time the view was refreshed.

All platforms - PlasticX: Branch explorer search didn't focus branches properly.

There was an issue in the way branches rectangles were calculated, so when you search for a branch in the Branch Explorer, and the zoom level was big, the branch was not focused properly. Now it's fixed and the search was as expected.

All platforms - PlasticX: Changed Switch workspace shortcut

The Switch workspace context menu shortcut has been changed from:

Windows & Linux: Ctrl+W to Shift+Ctrl+W

Mac: Cmd+W to Shift+Cmd+W

Windows - PlasticX: Don't clear query history when using old GUI

We had a compatibility issue between the classic Plastic GUI and the new PlasticX GUI (alpha): when running a query from one of the GUIs, all the query history from the other GUI was removed. Now both applications are compatible, and the query history is kept when changing between them.

All platforms - PlasticX: Fixed a memory leak in pending changes view.

Fixed a bug that caused the memory to grow every time the Pending Changes view was refreshed.

macOS - PlasticX: Fix missing keyboard shortcut in the main menu

Actions -> "Switch To" keyboard shortcut was missing, this is now fixed

All platforms - PlasticX: Fix keyboard shortcut not working in changesets view

We fixed a keyboard shortcut in changesets view: when trying to diff several changesets, keyboard shortcut was not working

All platforms - PlasticX: New GUI Announcement

You're invited to check out the new Plastic GUI - a sneak peek at the work we've been doing to continuously improve the Plastic experience for all users, regardless of experience level. The new Plastic GUI is now the default GUI for MacOS and Linux. It is also discoverable in the bottom left corner of the Windows GUI.

This new GUI is cross-platform, includes a dark theme and provides better syntax highlighting. Many more improvements are coming soon, including Gluon support! Try out the new experience and switch back to the Legacy GUI at any time.

To try out the new GUI simply click on the "Switch to new GUI" text near the bottom of the side panel, as shown in these screenshots:

Switch to new GUI button Linux:

Switch to new GUI button macOS:

Switch to new GUI button Windows:

You can switch back to the legacy GUI at any time by selecting the option shown here:

Switch to legacy GUI:

Command-line client: Updated the Spanish command-line help for several commands.

We keep on updating the Spanish documentation of the command-line help. These are the commands whose Spanish documentation has been completely updated on this round:

All clients: The performance of the status operation was improved again!

The overall time of the status operation is a 60% faster. This is only super-noticeable with huge workspaces (>4M of files), when the watcher is enabled and after the first status runs. Otherwise, the time spent in disk operations makes the improvement less noticeable.

After all the improvements done, the status time goes from 7.1s to 2.7s!

using a workspace of 4011530 files, 264143 directories and 264 GB.

in an e2-standard-8 (Google Cloud) instance with a debian-10 image and a SSD persistent disk.

Command-line client: Changelist info is displayed along with the controlled changes in status command

When using --changelist options in status command, now it shows at the top of every grouped section of changes the information regarding the changelist owning these changes. The "--machinereadable status" option now works along with --changelist.

For instance: considering a workspace with two files (BoxCollider.cpp, and StartGameBtn.cpp), each one added to its corresponding changelist (Physics, GUI), the following command:

Will display something similar to this as far as there is a controlled change in BoxCollider.cpp file:

And the following command...

.. will display something similar to this as far as there is a controlled change in BoxCollider.cpp file:

Command-line client: Allow creating multi-line comments

Allows the use of the escape sequences 'n' and 'rn' to be used in checkin comments to generate line returns. Previously these would not be interpreted as escape sequences and would be included literally in the comment.

Command-line client: Allow the '--xml=output_file' parameter in the 'cm find' command.

Before, you needed to specify '--xml --file=output_file' to print the find result to a file. Now, you can just use '--xml=output_file' like other commands do.

All platforms - DevOps: Trunkbot auto enqueue branches when new changes in dst branch.

Before this version, if new changesets reach your trunk branch (i.e., '/main' branch) while a merge changeset -changes of your own branch and the trunk branch- is being built & tested, it won't be possible to merge the branch.

Now you can set up your Trunkbot configuration to queue the affected branch again automatically, and hence repeating all the branch processing, including the last changes from trunk branch in the merge changeset.

You can enable this feature in the mergebot configuration:

Windows - Plastic: Improved usage with external data (archived revisions).

Before, the first update run with archived revisions asked for the storage location with multiple GUI dialog windows at the same time. Moreover, this dialog was shown once per file which was annoying when you just wanted to skip downloading those files.

Now, it only shows one dialog window at a time. If you enter the right storage location in the first dialog, you are not bothered with more dialogs, and everything is downloaded as expected. On the contrary, if you cancel it, you are not asked again for other revisions archived during the same operation.

Plastic Drive - Error mounting this changeset

Before, the 'Mount this changeset in Plastic Drive' option failed showing the following error message: Unable to load DLL 'dokan1.dll'.

Now, Plastic Drive has been upgraded to use a newer version of Dokan, fixing the issue. You can download it from here:

https://github.com/dokan-dev/dokany/releases/download/v1.4.1.1000/DokanSetup.exe

All platforms - PlasticX: Enterprise configuration dialog has no margins

Margins added to enterprise configuration dialog.

All platforms - PlasticX: Launch Gluon enabled in onboarding

We have enabled the Launch Gluon button in the onboarding dialogs for PlasticX. Currently it launches the official Gluon release. In the future it will launch GluonX of course!

Al platforms - PlasticX: save revision enabled for History and Browse Repository views

You can now save a revision to disk from the History and Browse Repository views by selecting the context menu item.

All platforms, PlasticX: Fixed miscellaneous issues in Branch Explorer view.

When searching, with the "Only relevant" option enabled, the highlighted branch lost the changeset parent link draws. Now it's fixed.

Clicking on the changeset parent link draws fired an unwanted "changeset selected" event. Now it's fixed.

A user reported in the forum that using the "Only relevant" button moved the branch explorer away from the selection. Now it's fixed. The following rules are used to determine how to maintain the relative position:

** If the "home" changeset is visible on the screen it maintains its relative position.

** If there is a selected changeset, it maintains its relative position. If the selected changeset is not relevant, its relevant parent is used.

** Otherwise, the most right visible changeset is used to maintain the relative position.

When navigating changesets with keys in the branch explorer, sometimes a changeset that is not visible (but it's near the clip edges) is not made visible. Now it's fixed.

The attributes view was recalculated when clicking an object, even if it was already the selected object. Now it's fixed.

All platforms - PlasticX: fixed diff window files panel

Diff window panel files panel was not filling the available space, this is now fixed.

All platforms - PlasticX: Fix filter not working properly in Branch Explorer

After filtering a branch in the branch explorer, if you changed to another workplace the previous filter remained in the next workplace

We fixed this issue, and now the branch explorer filter works properly

All platforms - PlasticX: Fixed default focus selection in some dialogs

When a dialog is displayed the first TextBox must be selected with proper focus.

All platforms - PlasticX: Other Options in preferences give an index out of range error

Fixed issue caused by missing tag on client.conf.

Reported on Other Options in preferences give an index out of range error

All platforms - PlasticX: Transparent buttons issue

Fixed issue in which buttons from incoming changes notification appears transparent when hovering or clicking it.

All platforms - PlasticX: fixed exception when selecting empty search result

We fixed an exception that was thrown if you clicked on an empty search result on the Workspace Explorer view.

All platforms - PlasticX: Files overlay misaligned on 4k displays

Fixed an issue that causes the files overlay on workspace explorer to be misaligned when the display has a to be scaled, a common case for 4k displays.

Server: Added a new before-merge variable for the destination branch

The environment variable PLASTIC_MERGE_DESTINATION_BRANCH has been added to the "before-merge" trigger. It contains the name of the destination branch for the merge.

Server: Support Okta LDAP server for authentication.

The Plastic server didn't support an Okta LDAP server. All the user credentials (email + password) were rejected when you configure the server to use an Okta LDAP server. Now it works.

All Platforms - Server: Socket error code platform-independent

There were some logs writing different socket error codes depending on the platform. Now they will display the same code regardless of the platform where they were triggered from.

Server: Fixed branch creation from a deleted parent branch.

The server could create branches using a parent branch that was previously deleted. This led to "The specified branch xxx can't be found." errors when listing the repository branches of showing the branch explorer.

This code is properly protected now, and it will fail when trying to create a new branch using a parent branch that doesn't exist anymore.

All platforms - PlasticX: upgraded to .NET 6.0

We now build PlasticX on .NET 6.0. Previously it was built on .NET 5.0.

In addition to general improvements to stability and performance, this upgrade improves a specific stability issue when applying syntax highlighting in the text editor.

All platforms - PlasticX: Icons upgraded for 4k screens

Icons have been updated to better support 4k or higher resolution screens

All platforms - PlasticX: Improved the status bar UI

Changed the status bar background color.

Now the status bar is able to notify, info, success, warning, error, and progress messages.

All platforms - PlasticX: made version number selectable in About window

You can now select and copy the version number in the PlasticX About window.

All platforms - PlasticX: Preferences dialog redesign

The preferences dialog has been redesigned to a vertical layout as it provides a cleaner look.

All platforms - PlasticX: Tab navigation fixed for all app views

All app views and windows were reviewed to follow the proper order of the elements tab navigation, from top to bottom and left to right.

macOS - PlasticX: Fixed an issue when diffing C files

There was an issue that caused a 'libclang can't be loaded' error when launching a semantic diff for C language. We fixed this issue, and now the semantic diff is available for C files on macOS.

All platforms - Plastic, PlasticX: support environment variables in custom tool configuration

You can now include environment variables when defining custom actions that can be launched from the context menu.

See the documentation about configuring external tools.

In the configuration file 'externaltools.conf':

This will create a menu item "My custom tool" under the "Open" menu of the Workspace Explorer which will open the selected path using the executable pointed to by the environment variable "PATH_TO_TOOL_EXE".

You can add multiple external tools - just add a line to the config file for each one.

All platforms - Plastic, Gluon: Unity files considered as text by default

We added the following extensions to our list of known text extensions, and now they will be considered as text files by default:

Also, the following file will be considered as a binary file by default:

Remember that you can override this behavior, adding your custom extensions, by modifying your filetypes.conf file. Learn more about it here: Custom file types

All platforms - All clients: The status operation performance has been improved by changing how the stats times are tracked (again :).

This is only noticeable in super-huge workspaces (> 4M of files).

The overall time of the status operation is a 10% faster, but this is only noticeable when the watcher is enabled and after the first status run.

In this particular case the 'cm status' went from 6s to 5.4s.

Command-line client: Updated the Spanish command-line help for several commands.

We keep on updating the Spanish documentation of the command-line help. These are the commands whose Spanish documentation has been completely updated on this round:

All Platforms - Server: Improved the plasticd shell start up time

plasticd shell uses communication files to interact with the server. The problem came when these files became too big (> 1GB). It could take more than 10 min to connect with the server.

Now, it does a smart reading starting from the end of the communication file, so it doesn't depend on the size of the file. It always takes around 1-2 seconds to connect.

macOS - Server: the server in macos was not gracefully shutting down when pressing the intro key.

In other OS it was allowed to stop the server in console mode (plasticd --console) when inputing an empty command (by pressing intro with no text input) but in macos it was displaying an error detailing "Socket is not connected". Now it is fixed and working the same as in Windows and Ubuntu platforms.

Visual Studio plugin: Ignored files are no longer processed when adding to source control

We detected the "Add to source control" operation wasn't respecting ignored files. In addition, this operation will now perform an auto-checkin depending on the below user preference.

Tools -> Options... -> Source Control -> Plastic SCM settings -> Preferences -> Other options

"Checkin files and directories when adding to source control"

Windows - Wwise plugin: Improved performance for status

We noticed an issue in the Wwise plugin that caused 'cm shell' commands to perform poorly when their output was long (>8 KB).

It's fixed now, so these long commands -particularly the 'status' command- will run as fast as if you'd run them in a terminal.

All Platforms - GitSync: Fixed localization errors during GitSync operation.

The operation could show messages that didn't make sense because it used the wrong localization keys.

Windows - VSPlugin: Removed deprecated option 'Change Source Control...' from File menu.

Windows - Plasticfs: Fixed the ISPC compilation in dynamic workspaces.

It seems the ISCP compiler uses the FileInfo.IndexNumber field but plasticfs didn't fill this field when returning the file FileInfo fields.

Now, this field is properly assigned (it's just a reference number for the file) and ISCP can complete the build without issues.

All platforms, PlasticX: Improve the button look and feel.

We improved the button style across the application. Now the buttons always have a border and they are lighter in the light theme. This is how they looks now:

We additionally made the Checkin Button more noticeable (using primary blue color) in the pending changes view, to remark that it's the main action.

All platforms, PlasticX: UI boosts.

Reduced the width of the pipe in the sidebar.

Choose a better icon for sorting in the trees/lists.

Improve scrollbar style.

Redesign the incoming-changes notification.

The following screenshot shows most of the changes.

Improved the tooltip style reducing padding.

Unify all dropdown controls to have the same margins.

Convert text-based "Close" buttons to icon-based buttons in side-views.

All platforms - PlasticX: Tab navigation has been fixed for some dialogs

Tab navigation were not following the custom UI elements order in some dialogs. The custom navigation order is defined as from left to right and from top to bottom, so when users use tab key to navigate in any app dialog this order has to be followed.

All platforms - PlasticX: Fixed application of branch attributes

When a branch attribute was selected from the Name combobox the first default value was not loaded in Values combobox:

This fix updates the Values combobox selection with the first element found in the list.

Command-line client: Updated the help for the cm archive command.

We removed the --comment option from the help of the cm archive command because it's not available.

If you want to assign a comment to the 'archive' operation, please use the -c option.

All Platforms - GitSync: Protected some null errors when synchronizing with git repositories.

All Platforms - Client: Fixed a "repository mounted twice" error during checkin.

This error was only reproduced if there were multiple Xlinks pointing to the same repository in the workspace.

It also only happened if before-clientcheckin triggers existed for that repo. Otherwise, it was not reproduced at all.

All Platforms - CLI: status was not filtering properly by changelist

The option to group and filter controlled changes by changelists was not displaying only those changes under the changelist. Now it is fixed.

Having two controlled files in your workspace (file1.txt and file2.txt), each one under a different changelist (chlist1 and chlist2).

"cm status --changelists" will show something similar to the following:

while "cm status --changelist=chlist1" will display something like

All platforms - PlasticX: Improved exception handling

We detected some situations in which an exception could cause the application to crash. We fixed these scenarios to catch the errors and show them in a message box, and then continue with the application, instead of unexpectedly closing it

All platforms - PlasticX: Fixed 10% CPU usage in the Attributes panel

Displaying the Branch Explorer view caused Plastic X to report a constant 10% CPU usage in the Task Manager. This CPU consumption was caused by an animated progress bar placed in the Attributes panel. Although that progress bar was hidden, it continued invalidating the panel, causing that CPU consumption. Now it's fixed.

All platforms - PlasticX: Fixed an issue when creating dynamic workspaces

When creating a workspace, if the user selected the "Create workspace from this repository..." option from the repositories view, the dynamic workspace checkbox was being ignored, and we were always creating normal workspaces. We fixed this issue, and now the checkbox works as expected

All platforms - PlasticX: draw Home icon after switch to branch

Fixed an issue where the Home icon wasn't being drawn after switching to a branch or label.

Windows - Command line client: netcore-compiled command line client for Windows!

From now on, the command line client (cm) will be a netcore-based application, replacing the netframework-based command line client.

This also unlocks new cm subcommands that were just available for netcore flavor, like cm api subcommand (see release note below).

Windows - Plastic SCM API: The Plastic SCM API is now embedded in the CLI!

We created a new cm api command that starts the Plastic SCM API. It allows the same arguments as the old plasticapi.exe application (we removed this deprecated executable from the installer).

The previous versions (10.0.16.6419, 10.0.16.6443) already had this cm api command, but just for Linux and macOS. From now on, Windows will have also this command available.

Find more info about it via the command help:

And see more usage details at: https://www.plasticscm.com/documentation/restapi/plastic-scm-version-control-rest-api-guide

All platforms - Plastic SCM API: The Checkin endpoint now supports partial workspaces

We extended the Checkin endpoint in the Plastic SCM API to support partial workspaces. You will now be able to perform checkin operations in a partial workspace using this client-side REST API.

Just launch the cm api command and perform a POST request to endpoint /api/v1/wkspaces/{wkName}/checkin with a JSON body like this:

All platforms - Plastic SCM API: New endpoint to retrieve file info is now available

We created a new endpoint in the Plastic SCM REST API to retrieve information from a file. You will now be able to perform fileinfo operations in your workspace, using this client-side REST API.

Just launch the cm api command and perform a GET request to endpoint /api/v1/wkspaces/{wkName}/fileinfo/path-to-the-file-to-get-info.

All platforms - Plastic SCM API: The Update endpoint now supports partial workspaces

We extended the Update endpoint in the Plastic SCM API to support partial workspaces. You will now be able to perform update operations in a partial workspace using this client-side REST API.

Just launch the cm api command and perform a POST request to endpoint /api/v1/wkspaces/{wkName}/update.

All platforms - Plastic SCM API: The Switch endpoint now supports partial workspaces

We extended the Switch endpoint in the Plastic SCM API to support partial workspaces. You will now be able to perform switch operations to branch or changeset in a partial workspace using this client-side REST API.

Just launch the cm api command and perform a POST request to endpoint /api/v1/wkspaces/{wkName}/switch with a JSON body like this:

All platforms - Plastic SCM API: New revert endpoint for regular and partial workspaces

We created a new Revert endpoint in the Plastic SCM API. You will now be able to perform revert operations in your workspace, partial or otherwise, using this client-side REST API.

Just launch the cm api command and perform a POST request to endpoint /api/v1/wkspaces/{wkName}/revert/{my_item_to_revert} with a JSON body like this:

All platforms - Plastic SCM API: New partial configure endpoint for partial workspaces

A new Partial Configure endpoint has been added to the Plastic SCM API. Using this client-side REST API you will now be able to perform partial configure operations in your partial workspace.

Just launch the cm api command and perform a POST request to endpoint /api/v1/wkspaces/{wkName}/partialconfigure with a JSON body like this:

All platforms - Plastic SCM API: New merge endpoint for regular workspaces

We created a new Merge endpoint in the Plastic SCM REST API. You will now be able to perform merge operations in your workspace, using this client-side REST API. This operation doesn't support conflict resolution at the moment.

Just launch the cm api command and perform a POST request to endpoint /api/v1/wkspaces/{wkName}/merge with a JSON body like this:

All platforms - Plastic SCM API: New endpoint to undelete removed elements is now available

We created a new undelete endpoint in the Plastic SCM REST API. You will now be able to perform undelete operations in your workspace, using this client-side REST API.

Just launch the cm api command and perform a POST request to endpoint /api/v1/wkspaces/{wkName}/undelete with a JSON body like this:

All platforms - Plastic SCM API: New create shelve endpoint for regular workspaces

We created a new Create Shelve endpoint in the Plastic SCM API. You will now be able to create a new shelve from changes in your workspace, using this client-side REST API.

Just launch the cm api command and perform a POST request to endpoint /api/v1/wkspaces/{wkName}/shelvesets with a JSON body like this:

All platforms - Plastic SCM API: New endpoint to apply shelvesets is now available

We created a new Apply Shelve endpoint in the Plastic SCM API. You will now be able to apply a shelve in your workspace, using this client-side REST API.

Just launch the cm api command and perform a PATCH request to endpoint /api/v1/wkspaces/{wkName}/shelvesets/31 to apply shelve 31.

All platforms - GitSync: main branch support improvements

Now cm sync autodetects if your Git repository uses "main" or "master" as the main branch.

You can explicitly tell it to use any branch as main branch with --mainbranch:

All platforms - Client: cm update now supports a machine readable format

To obtain an easily parseable output, just use the --machinereadable option:

Remember you can override the default separators by using formatting options. You might need to double quote them depending on your shell:

All platforms - Client: cm partial update now supports a machine readable format

To obtain an easily parseable output, just use the --machinereadable option:

Remember you can override the default separators by using formatting options. You might need to double quote them depending on your shell:

All platforms - All clients: The status operation performance has been improved by changing how the stats times are tracked (again :).

This is only noticeable in super-huge workspaces (> 4M of files).

The overall time of the status operation is a 15% faster, but this is only noticeable when the watcher is enabled and after the first status run.

In this case, the 'cm status' went from 7.1s to 6s.

All platforms - GitSync: The 'cm sync' command (using ssh protocol) returned a wrong exit code (0) when it couldn't connect to the Git server/provider.

The command should return 1 (failed) as exit code when it failed due to any connection issue. This only affected to the ssh protocol.

This could be dangerous when automating stuff because the caller was not aware that something went wrong.

macOS - Plastic: Fixed onboarding error in Philippines time zone

Previously on Macs if the time zone was set to either Quezon City or Davao City in the Philippines, an error message "Offset must be within plus or minus 14 hours" was shown when creating a workspace during on-boarding.

All platforms - Server: Fixed how the server accounts for sent traffic.

If you ever open the ChannelCall server log file, you will see complete stats for the methods the clients execute on the server. In these stats, you can find the method name, how many bytes were sent and received, how much time did the writing and reading operations take…

We were accounting for sent bytes (column 'sentb') wrong when sending chunks over 500KB. This is now fixed.

All platforms - Cloud Server: Fixed a deadlock condition while querying a branch and renaming another branch in the same repo.

We had a race condition that could lead to a deadlock when the calls 'GetBranchInfoByName' & 'RenameBranch' happened at the same time in the same repo with a very specific race condition. The problem got worse because any requests that needed to access to any branch of that repo got infinitely stuck too.

Linux - Command line client: update operation failing with very old servers

We fixed an incompatibility when issuing a cm update operation with the current cm command line client with a server older than 6.0.16.1311.

Before this version, the cm update operation coud fail with a "Connection reset by peer" error with such an old server.

Now the issue is fixed.

All platforms - PlasticX: smoother panel closing animation

Improved the close animation for the Branch Explorer Options panel and the query views' Properties panel.

All platforms - PlasticX: Improve diff viewer editing performance.

We heavily improved the diff viewer editing performance. See a demo handling a file of 133.442 lines.

All platforms - PlasticX: Use Cascadia Mono as the default font for the source code viewers in Windows platforms.

If the font Cascadia Mono is installed on the machine, it's used as the default font for the source code viewers (diff, annotate, etc ...). Cascadia is a new, modern, monospaced font family that provides better flexibility for text editor experiences. Cascadia Mono was designed for optimal legibility and accessibility. When the font it's not available, Consolas font is used as a fallback. The following image shows the difference between Consolas and Cascadia fonts.

All platforms - PlasticX: fixed display of servers with underscores in the name

In the server selector combo box in the Repositories view, underscores in server names were not being displayed. We fixed that.

All platforms - PlasticX: filter/search views after refresh

Fixed an issue where the filter or search wasn't being taken into account after refreshing the view. Now if you type a filter or search while the view is refreshing, the correct items appear when the refresh finishes.

In addition, we fixed a null reference exception that was thrown when you type a filter in the diff window before it's loaded.

All platforms - PlasticX: Fixed syntax highlight tokens that were transparent.

Using some syntax highlight languages, such as Razor, Markdown ... displayed transparent tokens, so they were not visible. It only happened in the light theme. Now it's fixed.

All platforms - PlasticX: Greyed items on pending changes side bar

When adding a file or directory through the context menu 'Add to source control' or 'Add directory tree to source control' it was not possible to edit the selection of files or directories on the 'pending changes' side sheet. A side effect is that if a check-in is performed, then no further changes can be included or excluded from the list of pending changes unless the side sheet is closed and reopened.

This issue is now fixed by allowing files or directories to be included or excluded from the 'pending changes' side sheet.

All platforms - PlasticX: Fix crash creating directory with same name as existing file

When trying to create a file, if the given name already exists as a directory, plastic closed unexpectedly.

The same happens when trying to create a directory with a name that already exists for a file.

For example, if you have a file named Readme.txt, and you create a directory named Readme.txt, it failed.

We fixed this issue, and now you will see a clear error when trying to perform this operation

All platforms - Client: cm partial ci now supports machine readable format

To obtain an easily parseable output, just use the --machinereadable option:

Remember you can override the default separators by using formatting options. You might need to double-quote them depending on your shell:

All platforms - all clients: corrected pluralization of time span strings

We changed "1 days/hours/minutes ago" to "1 day/hour/minute ago" throughout all the clients.

All Platforms - Server: htop application was crashing when displaying View -> Method Stats.

Now it properly displays and updates each available method call.

Linux - PlasticX: enabled FileSystemWatcher for better performance finding pending changes

We enabled the .NET Core FileSystemWatcher in 'PlasticX' Desktop app and cm command line client on Linux. It was already enabled on Windows and MacOS, but now Linux users will benefit from this improvement too.

You should see a significant speed up in detecting changes in the Pending Changes view or using the cm status command.

The speed up will depend on the particular configuration. As an example, with 2000 items in the pending changes view, we saw the search time shrinks from 650ms to 350ms.

All platforms - PlasticX: Items search result panel is now bigger

We made search results panel of the items view wider, to show more of long paths, and taller, to show more items. In fact, the results panel is over 100% bigger than before!

All platforms - PlasticX: UX improvements to Query views.

We made some improvements to the views that have advanced query functionality: the changesets, branches, attributes, labels, shelvesets and code reviews views.

We changed the style of the Execute button to make it clearer.

Pressing Enter in the query entry field now executes the query.

Refreshing the view uses the currently query (rather than the last executed query).

All platforms - PlasticX: File size column now right-aligned

We right-aligned the text in the file size column throughout the application.

Windows - PlasticX: launch PlasticX after auto-upgrade

When a new version of Plastic is available, a notification panel will appear giving you the option of downloading and installing the new version.

Previously, after installing the new version, the official Plastic release would be launched even if you initiated the upgrade from PlasticX. Now, PlasticX will be launched in this case.

All platforms - PlasticX: Added merge explanation view

When applying a merge, now there is a "Merge diagram" button that shows the merge explanation. Here's how it looks:

All platforms - PlasticX: textmate integration is 450% faster.

We reworked AvaloniaEdit's TextMate integration and now is much faster when handling mid/big files and it reduces CPU by 50% when tokenizing files.

All platforms - PlasticX: Sometimes the diff viewer didn't display the first difference correctly.

Sometimes, when opening a differences window or a code review, the diff viewer didn't navigate to the first difference correctly. Now it's fixed.

All platforms - PlasticX: Fixed double click event on tables

When double-clicking on a table, we were executing the double-click event even if the user didn't click on a table row. For example, if the user double-clicked on the header of the table, or in the free space at the bottom of it, the selected row would be expanded (or whatever the double-click behavior is expected on that table). This also happened with the right-click.

Now this issue is fixed and the action will only be performed if the user clicked on a row of the table

All platforms - PlasticX: Fixed unexpected behavior when selecting items on a table

When selecting an item on a table for the first time, we were not managing the table properties correctly, and this was causing issues, such as the inability to execute a shortcut over the selected item, or open the context menu with a right-click.

We fixed this issue, and now the first selection of the table will work as expected

All platforms - PlasticX: Disable "Open" button in the switcher window when needed

The "Open" button in the switcher window was always enabled when the workspaces tab was selected, even when the workspaces list was empty. We fixed this issue, and now the button is only enabled when there is a workspace selected.

All platforms - PlasticX: corrected Date modified for Added items in Workspace Explorer

Added items were appearing in the Workspace Explorer with an invalid Date modified (1/1/1001) when they should have no date displayed.

All platforms - PlasticX: fixed exception opening context menu in a directory's History

An exception was thrown if you right-clicked in the History view for a directory. We fixed this. There is no context menu to show in this scenario.

All platforms - PlasticX: fixed text clipping on Code Review window

The text of the code review summary was being clipped by a couple of pixels at the bottom. Fixed.

Windows - Visual Studio Plugin: Plastic SCM now supports new Visual Studio 2022!!!

Installer now shows a new plugin for Visual Studio 2022 and above. As the IDE turned 64 bits, it required a new version of our plugin, which by the way can coexist with the old one, just in case you want to keep both Visual Studio 2019 and 2022 installed in your system.

As usual, if Visual Studio 2022 is present in the system, the extension will be suggested to be installed by default.

macOS, Linux - Plastic SCM API: The Plastic SCM API is now embedded in the CLI!

We created a new cm api command that starts the Plastic SCM API. It allows the same arguments as the old plasticapi.exe application. See more usage details here

Warning: this command is only available in macOS and Linux, as those platforms run our new .NET Core CLI client. We removed plasticapi.exe from all installers, so the Plastic SCM API is temporarily unsupported in Windows. It will be back as soon as we distribute our .NET Core CLI client in the Windows installers.

All platforms - Server: The Jet storage backend is now faster when reading files.

We changed the way we access the Jet backend files for reading. This change decreases the time needed for just reading content, making the overall time of reading calls to the server lower.

All platforms - All clients: The status operation performance has been improved by changing how the stats times are tracked.

This is only noticeable in super-huge workspaces.

The overall time of the status operation is a 17% faster in a workspace with 1M of directories and 5M of files.

All platforms - server: more detailed information in the relevant log and shell's 'htop' regarding internal and Web UI method calls.

Previously, every internal method call was tagged as "Internal", both for the server stats (relevant log) and shell's htop command. Now these calls are more qualified displaying the name of the method in execution. It has been also fixed on "ChannelCall" log where these calls are no longer tagged as "WebUI" but as "webui-Method'sName"

For example: on shell's htop, after executing a long-enough-lasting task (for instance a huge merge to) it should display "MergeTo" under Active requests or "webui-MergeTo", relying on the source of the method call. Remember that if the call is executed too fast, htop might not be updated in between and therefore not displaying any method at all.

All platforms - CLI: Checkout CLI command (co) now supports --machinereadable

We added the possibility of using --machinereadable parameter to the checkout command. Now it will be possible to specify --machinereadable argument to configure special chars which will be inserted where needed:

"--machinereadable" -> Outputs the result in an easy-to-parse format.

"--startlineseparator" -> Used with the '--machinereadable' flag, specifies how the lines should start.

"--endlineseparator" -> Used with the '--machinereadable' flag, specifies how the lines should end.

"--fieldseparator" -> Used with the '--machinereadable' flag, specifies how the fields should be separated.

(Checkouts the current directory, and prints the result in a simplified, easier-to-parse format, starting the lines with the specified strings.)

All platforms - Client: cm partial configure now supports a machine readable format

To obtain an easily parseable output, just use the "--machinereadable" option:

Remember you can override the default separators by using formatting options. You might need to double quote them depending on your shell:

All platforms - Plastic: Alpha new and Alpha bug release notes in help panels

We added two new categories to the release notes: Alpha new, and Alpha bug. They already appeared in the web (https://www.plasticscm.com/download/releasenotes), but now you will also see them in the plastic client, inside the new version notification. Check it out:

All Platforms - Command line client: PLASTIC_INITIAL_CHANGESET and PLASTIC_FINAL_CHANGESET environment variables are now properly set.

For before/after update triggers, PLASTIC_INITIAL_CHANGESET and PLASTIC_FINAL_CHANGESET environment variables were swapped, considering the final changeset as the origin and vice versa.

Windows - Plastic, Gluon: Fixed preview of unsupported image formats

There are some image formats that cannot be directly previewed or diffed inside Plastic. To diff two PSD images, for example, you need an external tool like ImageMagick to convert the images, and then perform the diff.

Although you could diff these kinds of images on a separate window by clicking "Diff with previous revision", the preview that appears in the pending changes view was not working:

We fixed this issue, and now you can diff these kinds of images without opening any external programs.

Windows - SemanticMerge tool: body method call wrongly renamed on edge case.

The problematic scenario is explained better with the following snapshot:

There is a "changed+renamed - changed" conflict on Upload method. And, there is also a method call to DirectoryUploader.Upload in the body (enclosed in a red rectangle), altough it wasn't modified by any contributor.

But the declaration "renamer" mechanism of SemanticMerge is not handling fine this edge case where the method call name in the body matches with the conflicting method (Upload in this case),

and it's applying the rename of the conflicting method to the method call in the body too (from Upload to UploadForClientTests) in the resulting file (also enclosed in a red rectangle).

Now it's fixed, and the method call in the body remains untouched, since it wasn't modified by any contributor at all.

macOS - Gluon: Fixed a performance issue opening a workspace with lots of files

The GUI hanged trying to open a workspace, when the root item has lots of children (>20000 items). Now it's fixed.

Windows - Installers: removed linux binary from the windows installer

The windows installers erroneously included a 120 MB binary file, "linplasticx", which is only required on linux. We removed it. Enjoy the extra disk space! (Note, you can safely delete this file from your current windows client install directly should you wish to do so).

All platforms - PlasticX: Try our new Plastic SCM cross-platform GUI!

We invite you to try our new Plastic SCM cross-platform GUI, code-named PlasticX (alpha)! This will also give you access to our new dark theme!How to get started with PlasticX (alpha)

PlasticX is packaged silently with every Plastic SCM release moving forward.

Download and install the latest Plastic SCM release.

Windows: Run this command from the Windows console: C:\Program Files\PlasticSCM5\client\winplasticx.exe

macOS: Open a terminal and run the following command: /Applications/PlasticSCM.app/Contents/Applications/plasticxscm.app

Linux: Run this command from the terminal: /opt/plasticscm5/client/linplasticx

How to provide feedback:

All platforms - PlasticX: launch internal image diff by default

If you have the default binary diff tool configured (or have no binary diff tool configured), image diffs will launch in a new PlasticX window.

All platforms - PlasticX: Save the last used workspace.

When switching the workspace from the top-left workspace selector, now the last used workspace is remembered when you close and reopen PlasticX.

All platforms - PlasticX: Support lines longer than 10.000 characters in diff and annotate views.

Prior to this fix, AvaloniaEdit (the text editor we use to display differences and annotate), didn't support displaying lines longer than 10.000 characters. We created this PR to fix it https://github.com/AvaloniaUI/AvaloniaEdit/pull/172

All platforms - PlasticX: Added scroll bar to the annotate view

Before this change, the annotate view was scrollable, but the scroll bar was not visible. We changed this and now you can see a vertical scroll bar when the file is long enough

All platforms - PlasticX: Added color picker control

Added the color picker control to be able to set custom colors to branches and changesets in the branch explorer using the rules and filters panel. This is how it looks:

All platforms - PlasticX: Added support for diff and code review Plastic Links

Plastic Links are a great way to share content from your plastic repositories with your colleagues. You can easily share diffs, links to files and links to code reviews using Plastic Links.

plastic://test.cloud/repos/NikkiTest1/changesets/50/diff

Just click on the link in the normal way and Plastic or Gluon will launch (if not already running) automatically and show you the content specified in the link.

Note: On Windows and MacOS, while PlasticX is in alpha, you will be asked whether you want to open links in Plastic (official release) or in PlasticX (alpha). You can change this setting at any time in Preferences -> Other options. On Linux, plastic links will always be opened in PlasticX.

From within Plastic, you can share diffs from any diff view by clicking on the Plastic Link icon in the top right corner. This copies the link into your clipboard, ready to paste into a message. You can also share code reviews by clicking the Plastic Link icon in the top right of the code review window.

From within Gluon, you can get links to specific files by clicking the Copy button in the Details panel:

All platforms - PlasticX: The "home" icon sometimes was not drawn on a newly created branch.

In certain machines under some concurrency scenarios, when creating a new branch and selecting the "Switch workspace to this branch" caused that the new branch is created but the home icon is not in the right place. Now it's fixed.

All platforms - PlasticX: Removed separator from the notification bar

In the bottom status bar, we sometimes show notification messages. To separate those messages we use a vertical line, which should only be visible when there is more than one message. We were always showing this line, even when there were no notifications to show:

Linux - PlasticX: Fixed hang when closing application

Sometimes when closing the workspace window in Linux, the application got frozen and it never ended. We fixed this issue

All platforms - PlasticX: Fixed an error that appeared after opening and closing the preferences window.

When opening and closing the preferences window, PlasticX displayed an exception. Now it's fixed.

All platforms - PlasticX: Removed latency when toggling "Only relevant" button

When clicking on the "Only relevant" button in the branch explorer, there was a latency that made the GUI freeze for some seconds. This was because of an operation that should be running in the background but instead was blocking the whole application. We fixed this call and now the branch explorer updates immediately

Also, now after refreshing the branch explorer view, if there are new branches or changesets that match the text in the search box, they will be highlighted

Command-line client: We keep on updating the Spanish documentation of the command-line help.

Now, it was time for the following commands to be completely updated and match the English version of the command-line help:

changeset editcomment

We're still working on the rest of the commands, so stay tuned!

All platforms - PlasticX: New Workspace switcher

We got a lot of user feedback telling us that the "Switch workspace..." button at the bottom of the GUI was a bit confusing.

So, we've replaced it with a more useful and intuitive workspace selector. It allows you to quickly switch between your recent workspaces, open the workspaces view to create new workspaces, or open the repositories view.

We also improved how we display the details of the current branch, changeset or label.

All platforms - PlasticX: Fixed refreshing issue in the update report dialog

We had an issue in the table of the update report dialog, that prevented it from refreshing after clicking "Update forced" or "Retry".

Now the issue is fixed, and the table gets correctly updated

macOS - Plastic: Fixed column sorting for query views

Sorting columns on some views on macOS was not working as expected. This was broken in 10.0.16.6223

We fixed the issue and now all tables can be sorted without issues.

These are the affected views:

All platforms - Client: Allow closing additional change requested editing the comment

You can close a change requested in review by editing the comment of the changeset and adding the change to close (e.g. [apply-change:384d716f]).

But if you tried to edit the comment again to close an additional one ([apply-change:94857d35]), it would fail with the error "The following review change requests (specified in the checkin comment) cannot be found or are already applied in a previous changeset: - 384d716f".

Now it's fixed and you can edit the comment to close as many additional changes as you need.

All platforms - PlasticX: New cross-platform GUI available!

We are happy to announce that we are currently working on a new cross-platform GUI for Plastic SCM, code-named PlasticX!

At this stage in development, we are looking for early adopters who would be willing to try the new GUI and give us some feedback. All you need to do is sign up and we will contact you with instructions on how to get started, provide feedback and report issues.

There is no commitment - you will be able to easily switch back to the GUI you are using today if needed.

PlasticX is available for our developer GUI at this time. It will eventually replace the existing GUI, so this is a wonderful opportunity for you to influence the direction of Plastic SCM!

The latest alpha version also provides significant macOS stability improvements that you can benefit from right away. And we are almost at feature parity! The missing features will be available in the coming weeks.

You will also be able to try out our new dark theme which is now an option in the new GUI!

Find some eye opening screenshots below! :-)

macOS running light theme:

And now the same Branch Explorer in dark theme full glory:

Continuing with macOS, see how great diffs look in both light and dark themes:

Now compare to the very same Branch Explorer screenshots in Linux and Windows:

And now Linux dark theme:

The Plastic SCM Team @ Unity!

All platforms - PlasticX: Show progress while saving code review comments

When you create a new code review comment, or modify an existing one, saving the comment may take some time (especially if you have configured a trigger to run after the operation). We weren't showing any feedback during this operation. Now we have added a progress control next to the save button, to let the user know that the comment is being saved.

All platforms - PlasticX: image diff viewer completed

Completed the image diff viewer with the following new modes:

Onion skin: places one image over the other, with a slider to control transparency.

Differences: displays the differences between two images, calculated pixel by pixel.

Swipe: overlays the two images and allows you to transition between them using a slider.

This updated image diff viewer also allows you to:

View the differences between images of different sizes.

Zoom with a smooth animation.

Navigate around an image by clicking and dragging.

All platforms - PlasticX: Improvements in the create workspace dialog

We added a checkbox in the create workspace dialog that lets you create workspaces in dynamic mode. Check it out:

For now this feature is only available on Windows. To see it, you need to enable it manually by adding the following line in your guiclient.conf file:

You can learn more about dynamic workspaces here: [https://blog.plasticscm.com/2021/07/dynamic-workspaces-alpha-for-windows.html Dynamic Workspaces (alpha) for Windows: A new way to interact with version control]

In addition, we added a "New" button, next to the repository label, that lets you create a new repository right from that dialog

All platforms - PlasticX: Fixed null exception when navigating the items tree

There was an issue when navigating the workspace explorer tree with the arrow keys: up and down keys should change the selection to the node above or below, and right and left keys should expand or collapse directories. When pressing the right key when a file is selected, we were throwing a null exception, because it couldn't be expanded. We fixed this issue

Command-line client: We're updating the Spanish version of the command-line help.

The documentation of these commands is now completely updated and match the English version of the command-line help:

We're still working on the rest of the commands, so stay tuned!

All platforms - WebAdmin: On the License configuration area, the button that takes you to sign up in plasticscm.com when you don't have a license in place now takes you to your licenses. Before it just took you to the sign up form.

All platforms - Plastic: Triggers no longer wait if parent process has exited and a child process is invoked.

Previously, triggers that launched a child process would wait for it to exit before returning. Now they allow the child process to run in the background while the trigger returns.

Command line client: cm archive command help improvements

Added more information and examples about the required use of the externaldata.conf file when unarchiving (restoring) an archived revision.

Command-line client: Updated the cm partial add documentation to include the formatting arguments.

Now, the cm partial add help includes the --format and --errorformat arguments. The help shows you how to use these arguments to retrieve the output in a specific format when adding items to a partial workspace.

Command-line client: Updated the cm lock list documentation to include the "machine readable" arguments.

Now, the cm lock list help includes the --machinereadable , --startlineseparator, --endlineseparator, and --fieldseparator arguments. The help shows you how to use these arguments to output the result in an easy-to-parse format.

All platforms Server: New ThreadPool boosting system to avoid long waiting requests

The server allows creating new threads to attend to the requests and goes beyond the max thread limit if needed.

Before this task, the boosting mechanism handles the slow requests (calls running for too long) and the too many requests waiting.

Now it also handles when the request is waiting for too long. It's helpful on the following scenario:

The server receives a high number of requests for a while. It's able to attend almost all of them with the current threads but not all, so the request queue starts growing little by little.

The old mechanism detects it when the queue grows too much. But this new mechanism detects it much earlier, improving the server responsiveness.

All platforms - WebAdmin: Fixed the Lock Rules page

The Lock Rules page in the Plastic server WebAdmin displayed an error. We fixed it, so now you can review/set the lock rules in your on-premises server again.

All platforms - Cloud: Fixed download data operations (update) waiting for other operations to complete.

In the detected case, the download data calls waited for a delete data operation (like removing a changeset) to finish.

This happened because we had a common throttle to limit the number of concurrent operations against the blob storage. Now, each operation type has its own throttle.

All platforms - client: Parallel download for big files now available!

Big files are stored in blocks, and now each block can be downloaded in parallel, achieving an incredible speed up.

We tested downloading a 560 MB file from Plastic Cloud using a 600mbps connection and now the speed is 2.5 times faster.

All platforms - Command line client: cm find branch allows formatting using the branch guid.

Previously running "cm find branch --format={guid}" returned an error since the guid was unsupported as a format field, it now prints the branch guid.

All platforms: Client: 27% less memory during the update operation

We worked on saving memory allocations on the client core, and finally, we were able to reduce up to 27% of the total allocations during an update operation.

Find some numbers here: We ran a 'cm update' to download 8GB of data and:

Before: cm allocated 636MB

After: cm allocated only 460MB (27% less)

All platforms - Cloud: Archiving revisions is now available in Cloud!

You can reduce the size (and the costs :)) of your cloud repositories by archiving revisions to an external storage.

Check the whole archive documentation here.

In summary, we can simply archive one revision as follows:

After executing the command, we can see the archived revision in the specified output path:

To unarchive the revision, firstly, we need to add the output archive folder to the externaldata.conf file:

and run the command to unarchive the revision:

Now, let's answer some questions:

How can I archive all the revisions bigger than 10 MB?

Very easy! Just find for the revisions bigger than 10MB in the repo and pass them to the 'cm archive' command as follows:

Remark: the 'cm archive' command also supports pipe to receive arguments from the standard input as follows:

How can I archive all the revisions of the file '/arch.zip' file? Guess what?

Very easy too! Just find for all the revisions of that item and pass them to the 'cm archive' command as follows:

How can I archive all the revisions except the last one loaded in br:/main?

It's exactly like the previous command but adding a condition to the find to skip the revision loaded in br:/main.

The possibilities are infinite using find conditions with the ls command to resolve revision and item ids. The 'cm archive' command only needs a list of revisions that we can filter as we prefer.

All platforms - Web UI: Added alpha version to the logo

We added the "Alpha" label to the logo to show that WebUI is a pre-release early version.

All platforms - Plastic, Gluon: Fixed displayed user name on Active Directory servers

When working with a repository on a server configured with Active Directory, if the server was not your default one, we were displaying the user ID in the Active Directory instead of the user name. This issue was fixed, and now you will always see the user name

All platforms - Plastic, Gluon: Fix help panel in repositories view

We had an issue with the help panel in the repositories view and cloud view: we were always showing it, even when the user checked the "Don't show again" checkbox. Now we only show it when it's needed

All platforms - Server: Fixed null error from the log

The server was logging a null error when a not-used connection was finished. This error didn't have any impact apart from being logged. Now it's fixed.

All platforms - Plastic, Gluon: Added SSO login method names

We are getting ready to support new SSO login methods, in addition to the existing "Unity ID" and "Email". We are adapting the GUIs to render the actual method name in the SSO buttons:

All platforms - CLI: Undo operation from outside the workspace.

Added a new example to the cm undo command in the command-line help to let you know that you can specify an absolute path to undo the changes in any workspace:

Server: Added configuration key for the webUI config files.

WebUI configuration files can now be placed on a different location through a setting placed in server.conf config file.

To set this custom path, add an entry to that file like the following below:

And copy there the webUI config files, such as webui.secret.conf, webui.tokens.conf, webui.userid.conf, and webui.users.conf

All platforms - Client: Fixed the parsing of the cloud tokens when they ended with '='. This could make a replica fail with a "The auth token expired." error.

This only applied to the email/password authentication and usually with short passwords.

A replica operation (pull/push) could work properly for some time until it needed to renew the token because the current one had expired. Since the renew token was not properly parsed in the client side, the renew operation failed and the operation was aborted.

All platforms - Web UI: Code review switching comments

Fixed an issue while switching comments: if the current file was changing, it was displaying the first diff instead of displaying the selected comment.

All platforms - CLI: Now you can specify tokens and cloud region configuration for every command

We added new global parameters to the CLI. They allow you to tune the configuration tokens and cloudregions files to use for command execution. So you don't need to have them configured on the machine. It's useful for integrations where there is no previous configuration.

The new parameters are:

--tokenconf=[token_conf_path] - allows specifying the token file to use for the command execution.

--cloudregionsconf=[cloud_region_conf_file] - allows specifying the cloudregion file to use for the command execution

All platforms: Change password in User/Pass auth mode is now instant.

Prior to this version, changing user's password in User & Pass authentication mode required up to 5 mins to be updated in the server.

From now on, changing a password is immediate. If the password is changed in the server, just open the "Preferences" > "General" window in your Plastic SCM client and enter the new password.

REMARK: A credentials prompt could be shown in the Plastic SCM client under the following conditions:

Your client is configured/connected to a server in User/Password mode.

Your client has also a persistent server profile to connect to the same server.

Then, your password is changed in the server.

This could happen because credentials of persistent profiles have preference over the client configuration. To avoid this prompt dialog showing up again and again, we encourage to enable the "Remember credentials as a connection profile" checkbox on that dialog, so the credentials of the stored profile are properly updated.

All platforms - Server: The warmup of a server under heavy load has been improved by x20 when using the UP authentication mode for groups.

This is valid when using the UP authentication mode or the mixed LDAP + UP groups mode (in both, the groups are read from the groups.conf file).

The bigger is the number of groups and users/groups inside these groups, the more noticeable is the performance improvement. The x20 improvement has been measured using 12000 group entries.

Linux - Proxy: the "plasticscm-proxy-server" is now the default proxy package, netcore-based.

We renamed the "plasticscm-proxy-server-netcore" to just "plasticscm-proxy-server", and we removed any plastic proxy compilation based on mono stack.

So, to install the proxy, use this package name from now on: "plasticscm-proxy-server".

REMARK: some distros (centos, opensuse, fedora) could require the removal of legacy "plasticscm-proxy-server-netcore" package before installing the new one. If so, please remove the "plasticscm-proxy-server-netcore" on your package manager before installing the new "plasticscm-proxy-server" (the legacy configuration is kept during the upgrade)

Windows - plasticfs: Updating a workspace to the head of the branch with changes in the workspace discarded said changes.

This scenario is more likely to happen when you are working on a branch with a colleague. They do a change, check it in, and then you update your workspace to grab the change. In a static workspace, you get to keep your workspace changes (both local and controlled), and even merge your changes with the incoming ones if needed! In a dynamic workspace, we were overriding your workspace changes. Not anymore, now both static and dynamic workspaces behave the same way.

All platforms - Web UI: Fixed a bug where if you had an assigned review you'd see an empty list when going to the code reviews page.

Linux - Installers: Aesthetic fix: removed confusing warning message while installing the client

The package installer in the supported Linux distributions printed this message when it processed the dependency package 'plasticscm-certtools-mono4':

The package post-install script pre-populates the Mono certificate store from Plastic SCM trusted domains. One of those was 'cloud.plasticscm.com', which is now deprecated.

This error didn't prevent the package from completing the installation, but it could alarm users. Now the message won't appear anymore, and the package imports the certificates from the proper domain (plasticscm.com).

All platforms - Plastic, Gluon: Fixed 'Selector can't locate a revision for the item xxx' error when checking-in local changes (changes done outside Plastic).

The problem was related to moving a controlled file into a private folder. The issue could be reproduced as follows:

In Windows Explorer, move the folder /Assets/Folder1/Folder2/Folder3 to /Assets/MoveTo.

Edit the content of the file/Assets/MoveTo/Folder3/New Material.mat.meta.

Try to checkin the current pending changes from the Plastic GUI.

Windows - plasticfs: Updating a workspace to the head of the branch with changes in the workspace discarded said changes.

This scenario is more likely to happen when you are working on a branch with a colleague. They do a change, check it in, and then you update your workspace to grab the change. In a static workspace, you get to keep your workspace changes (both local and controlled), and even merge your changes with the incoming ones if needed! In a dynamic workspace, we were overriding your workspace changes. Not anymore, now both static and dynamic workspaces behave the same way.

All platforms - Web UI: Fixed the following issues

Not seeing the repository name in the breadcrumb navigation

The menu not being selected when clicking on an item in a list e.g., when viewing the code review details.

macOS - Plastic: Fixed the revisions displayed in the code review

Under some circumstances in the code review, when you switch between the review modes or changesets the revisions displayed for the selected file in the diff viewer were not the correct ones. We fixed it, and now you will see the correct differences.

All platforms - GitSync: Fixed the parsing of LFS pointers that don't end with '\n'.

If (somehow) you have a LFS pointer in a wrong format (without the ending '\n') in your repo, now, we support it too!

This link shows the specification of the LFS pointers and how every entry has to end with '\n'.

All platforms - Web UI: Fixed image preview being stretched in code reviews

All platforms - Plastic: Triggers can now run from Global Config

One of the challenges when you need to run client-side triggers is to deploy them.

We have helped fix this problem by allowing triggers to be run from Global Config, which is a special repository that is deployed to all client workstations (or laptops :P). This way you just place your trigger in your Global Config repo, and every user will have it available.

To run the trigger, we introduced a new variable @GLOBAL_CONFIG_PATH, that will point to the global config directory of the server you're using.

So now you can create a trigger using a command like the following:

You can learn more about triggers here: https://www.plasticscm.com/documentation/triggers/plastic-scm-version-control-triggers-guide

All platforms - Server: Fixed checking free space on database path when a relative path was specified in the config.

Server failed to ensure a minimal storage when jet directory was set up using a relative path in jet.conf base path. Now it is fixed.

All platforms - CLI: Now you can specify working mode, user and password for every command

We added new global parameters to the CLI. They allow you to fine tune the credentials that will be used to run the command. Additionally, the command will be able to run without a client.conf file if you specify the working mode and credentials.

The new parameters are:

--server=[server] - override the default server defined in client.conf

--workingmode=[mode] - specify the working mode to use. Valid values are: nameworkingmode, adworkingmode, upworkingmode or ldapworkingmode.

--username=[username] - specify the username to use in client connections. Required for 'upworkingmode' or 'ldapworkingmode'.

--password=[password] - specify the password to use in client connections. Required for 'upworkingmode' or 'ldapworkingmode'.

All platforms - Server: Security upgrade on LDAP user authentication mode.

We upgraded the LDAP authentication mode for security reasons.

After upgrading the server to this version, users running Plastic SCM client versions older than 9.0.16.4272 could show an informative window asking for an application restart of the Plastic SCM client.

After this restart, the client will automatically use the upgraded authentication mode.

Remark: The client might also prompt a credentials window to retype user's credentials.

All platforms - All clients: The clients are now more resilient over unstable networks.

We improved our method call retry mechanism. With these changes, the client can handle slow networks and connectivity loss in a more reliable way, reducing the number of times an operation gets abandoned because of issues when contacting the server.

All platforms - Web UI: Copy comment GUID

Linux: Added support to install Plastic SCM in Debian 11

Prior to this relase, installing Plastic SCM with the package manager failed due an unmet dependency to a third-party library (libicu). Now it is fixed, the dependency is met, and installing Plastic in Debian 11 is now possible.

All platforms - Server: Fixed an AccessViolationException error

The server failed with an access violation exception in very rare concurrency circumstances. It happened when the TCP connection was killed while the server was writing the response on it.

Most of the time, it was totally possible end the client connection when the operation was still running without any problem. This is indeed a very common scenario that happens all the time and without major issues.

But if you saw your server process gone with no reason, you could be facing this issue.

Windows - Shell Extension: View History is now shown in folder background context menu

View history was visible when showing the context menu of a file or folder. Now it is also shown when displaying the context menu of a folder's empty space.

All platforms - Server: The 'showmethodlist' and 'htop' plasticd shell commands show more detailed information regarding trigger execution.

Now, when a server call enters the phase in which it runs a trigger, the status of the underlying connection will reflect so. This way, if the server is stuck running a trigger, you can easily debug it using the 'plasticd shell' debug tool.

You can see an example here: I created a before-mkbranch trigger that got stuck! Using the plasticd shell command I could connect to my server. Then I run showmethodlist and I could see that the method call was in Status=Trigger

All platforms - Server: Configurable timeout for server-side triggers.

A timeout can now be set for server-side triggers (it is set to 2 minutes by default).

You can change the timeout by adding this to the server.conf config file:

Or entirely disable the timeout:

All platforms - Web UI: Fixed the following issues

After commenting on a code review with the whole branch selected, the comment doesn't show on the file if newly changesets were added to the branch;

Fixed the list of comments cutting the last comment when the list scrolls;

Disallow users to add comments on files outside code reviews;

Fixed error popup in the desktop client when opening code reviews with conversations.

All platforms - Plastic: Use relative date in the default changesets query

When using a custom query in the changesets view to filter the results, by default we were using a query like the following:

This is a fixed date, that will not automatically change on future queries.

We changed this to a relative query, that will produce different results depending on when it's executed:

To see the updated default query you may need to delete your queries.conf file in your Plastic config folder

All platforms - Plastic, Gluon: fixed New Version Notification in Japanese

When a new version of the client is available, the "Help Owl" will pop up a help panel to let you know and provide you with a link to download the latest version.

Sadly, the Japanese Help Owl had gotten a little confused and his/her panel was incorrectly formatted. We re-educated the owl, and now the panel looks good:

All platforms - Web UI: Code reviews improvements

Added changesets select box to the changed files panel for easier changeset selection.

Removed the whole branch switch from the changesets panel since it was redundant.

Added badges for comments and conversations to easily spot how many are present.

All Platforms - GitSync: Added LFS support for GitLab & Bitbucket when pushing changes over SSH.

LFS was previously supported for GitLab & Bitbucket over https. However, the push operation (pushing changes from Plastic to Git) failed over SSH. Fixed.

All platforms - Web UI: File history improvements:

We removed the previous branch/label filter since it doesn't work correctly with the context of the history list and implemented individual filters for branches and types instead. We also added a button to go back to the file and individual download buttons for each entry in the history.

All platforms - Plastic, Gluon: Dockerfiles considered as txt files

Before this change, we were considering Dockerfiles as binary files by default, and users had to manually add the following line in filetypes.conf to consider them as text files:

Now they are considered as text by default

All platforms - Server: User reload users and groups time configurable

The server reloads the needed users and groups from the authentication provider every 5 minutes.

Now you can configure this time on the server.conf. Adding the setting "ReloadUsersRefreshTimeSpan" with the refresh time on the following format [d.]hh:mm:ss.

For example, if you want to do the refresh every hour, you should add the following to the server.conf.

All platforms - Web UI: Various fixes and improvements:

Repositories list: fixed breadcrumbs not showing;

File explorer: when switching branches/labels it redirects to the root of the branch/label if the current displayed file/folder doesn’t exist;

Code Reviews, Branch view, etc.: if the navigation is collapsed and changing the comment or trying to view the reviewers list it now expands it, before it wasn't doing anything;

Code Reviews, Branch view, etc.: Fixed portrait images being cut;

Code reviews: Hide changesets panel for changeset reviews;

Improved the order of breadcrumb items so when clicking on the repository name it goes to the File explorer instead of going to the Repositories list and when clicking on the organization it goes to the Repositories list instead of going to the dashboard;

Update login page text colors, font sizes and elements spacing;

Removed the page content fixed width for screens above 1920px;

All platforms - Web UI: Fixed xlink content not being shown correctly in code reviews.

Linux - Command line client: All the Linux client packages will now bundle a netcore-compiled command line client!

From now on, the command line client ("cm") will be a netcore-based application, replacing the mono-based command line client, that had several stability glitches, it lacked some features (latest SSL protocols) ... but now we use the netcore-based "cm" application compiled to target Linux-x64 archs specifically.

Find below some performance improvements:

A) Update operation test: Workspace of 110K items sizing 545MB. Instance: CentOS 7 rackspace instance of 15GB I/O v1

Time downloading the full workspace ('cm update' operation) with version 10.0.16.6001 (cm mono): 310s

Time downloading the full workspace ('cm update' operation) with version 10.0.16.6023 (cm mono): 256s (21% faster)

B) Checkout test: Workspace of 16K items, 137MB

Time performing a checkout recursive operation on the full workspace with version 10.0.16.6001 (cm mono): 5.4s

Time performing a checkout recursive operation on the full workspace with version 10.0.16.6023 (cm netcore): 3.2s (68% faster)

All Platforms - Cloud Server: Fixed an error that sometimes caused the server to fail when trying to use Google storage blobs

There was a race condition present when setting authorization headers that would sometimes cause an error alike to "Error getting data of ... - Value cannot be null." This should no longer happen.

All platforms - Web UI: Code review conversations

Cloud - Web UI: Fixed CORS issue when loading static assets like images or files

All platforms - Web UI: fixed an error when viewing binary metadata

All platforms - Web UI: Fixed an instance where an error wasn't displayed correctly if the file was too large

All platforms - Web UI: Fixed error when loading text files that are not encoded in UTF8

All platforms - Web UI: Various fixes & improvements:

Added missing support for multiple reviewers to the code review list;

Updated code review navigation icons to match the overall icons styling;

Replaced branch icon;

Creating a code review now appends the branch or changeset comment to the title, to match the same behavior as the desktop client.

All platforms - GitSync: It now supports LFS when syncing from Github Enterprise servers, GitLab and Bitbucket!

Before this, it only supported GitHub (cloud).

No extra configuration is needed to take advantage of this. Just try it!

All Platforms - Server: Fixed the server command line option --websocketport to use the right port.

Also, the websocket port is only started when the configuration setting EnableDevOps (located in server.conf) is enabled.

All platforms - Server: Fixed exception not allowing to leave TCP port unset while having a SSL port set

All Platforms - Server: Saving organizations.conf is now written out atomically

macOS - IntelliJ IDEA/Rider plugin: Fixed the client configuration action

The "Configure client" button in the Plastic SCM preferences panel produced an error. This happened because the plugin looked for an outdated installation path. We changed it to run /usr/local/bin/macplastic instead. Now, if you click that button, you'll see the Plastic SCM configuration window.

All platforms - Web Triggers: Added more information when an attribute changed its value

Now when the value of an attribute changed its value the name of the branch or the changeset where it belongs appears at the description of the message in Slack, Discord ...

All platforms - Web UI: Authentication token was moved to sessionStorage

This change was done to allow users to log in to multiple organizations at the same time in the same browser.

The authentication token will be stored until the user closes the browser tab.

Opening WebUI in a new tab will require the user to authenticate again.

Windows - Plastic: fixed issue where delete dialog was too big

When you delete files or other objects in Plastic it helpfully lists them in the confirmation dialog so you can confirm you're deleting the correct things. However, if you tried to delete a lot of things at the same time, this would become substantially less helpful, because the OK / Cancel buttons could end up pushed down off the bottom of the screen.

We fixed this by limiting the list to show at most 10 items.

All Platforms - Server: Replicating a repository using "cm clone" will no longer fail if that repository has shelves

All platforms - Web UI: Global Code Review comments

Added the ability to add comments for the entire code review

Updated the comments list to reflect which comment is assigned to a file and which one is assigned to the whole code review

Enabled the comments panel even if there are no comments available

All platforms - Web UI: 404 Not Found page

Updated the 404 Not Found page look & feel

Updated various views to redirect to the 404 Not Found page if the resource doesn't exist

All platforms - Web UI: Fixed File Explorer Readme.txt preview not rendering new lines

All platforms - Web UI: Fixed code review comments appearing and being added on the wrong line

Cloud - Web UI: Images were not properly shown and files could not be downloaded. Fixed.

All platforms - Web UI: Fixed error when opening a code review comment on a file when the whole branch is toggled on.

macOS - Plastic: Editing changesets to retroactively link to a code review will now mark the change requests referenced as done

For example, lets say you are fixing issues from a code review. You solve the problem brought up in the change request b78993b but forget to include it in your comment when checking in the changes:

To fix this, you can edit the comment in the properties panel, comparison view or via the command line to add the correct annotation:

Previously this would do nothing but now it will mark the change request as done.

Windows - Plasticfs: Enabled mounting plasticfs workspaces under network share paths

Sometimes running commands under a plasticfs mount can fail with the message 'The volume does not contain a recognized file system.' This is because plasticfs by default do not use the Windows Mount Manager. In order to work around this it's now possible to create workspaces with network paths such as '\workspace\path' (or any other path in the form ' \____') which will use the Windows Mount Manager and therefore doesn't have this problem.

For example, lets say you have a repository called 'Test Repo' that you want to run a python script in but keep encountering an error similar to the one above. To work around this you can create a new workspace for 'Test Repo' with the path '\test\repo' that will work for running your python script in.

Creating the workspace in this way has these minor usage issues:

The 'Open in Windows Explorer' menu option (in Plastic & Gluon) doesn't open the selected folder/file. It just opens a new Windows Explorer window.

The thumbnail preview doesn't work in Gluon.

The workspace cannot be moved (using the 'cm workspace move' command).

All Platforms - JetBrains IDE Plugin: Fixed UI lag after opening files

We detected that some files caused the UI to freeze after opening them. This happened for files that were modified after applying a shelveset in the current workspace. The annotate operation that the IDE runs after open took a long time until it failed.

We modified this so the UI doesn't get stuck anymore. The annotate operation is now safely running in the background and doesn't block any other underlying Plastic SCM operations.

All platforms - All clients: Wake On Lan support added to clients.

If your personal server runs on a different computer and it goes to sleep but supports WOL, the Plastic clients will send a magic Wake On Lan packet to try to wake it up.

We added support for Linux, Windows and macOS, but the feature is still kinda experimental, so do not hesitate to contact us with suggestions.

macOS - Command line client: .NET Core 'cm' is here!

All the macOS installers will now bundle a netcore-compiled command line client!

From now on, the command line client ("cm") will be a netcore-based application, replacing the mono-based command line client, that had several stability glitches, it lacked of some features (latest SSL protocols)... but now we use the netcore-based "cm" application compiled to target macOS specifically.

1- This new CLI client doesn't support issue tracker extensions yet. If you're using them, you might detect that checkins aren't logged in the configured issue tracker. We'll add support for that feature again in the future.

2- The cm sync git feature is not yet available, due to a compatibility issue with native libraries and this new compilation of "cm" in .NET Core. We will enable this feature really soon (next release). So, if you're using this feature in macOS, we recommend NOT TO UPGRADE to this version.

Windows - Plastic: Editing changesets to retroactively link to a code review will now mark the change requests referenced as done.

For example, let's say you are fixing issues from a code review. You solve the problem brought up in the change request b78993b but forget to include it in your comment when checking in the changes:

To fix this, you can edit the comment in the properties panel, comparison view or via the command line to add the correct annotation:

Previously this would do nothing but now it will mark the change request as done.

Windows - Plastic: Added support for FoxPro syntax highlight.

Now Plastic SCM displays syntax coloring for .prg source code files in the Diff Viewer (Windows only).

All Platforms - Command line client: The command "cm changeset edit" now correctly handles GUIDs

Previously this command only worked with changeset numbers. It now works if you refer to a changeset by its GUID.

All platforms - Plastic: Improved explanation text for directory conflicts

We add the words "Yours" and "Theirs" to the source and destination of a merge conflict to make it really clear where each conflicting change is coming from.

All Platforms - Server: Added the 'authtoken' command for generating authentication tokens.

This is useful if your Plastic SCM server is using LDAP or Active Directory authentication. In this case, we strongly encourage you to enable auth tokens for security reasons.

You can enable it by editing your server.conf and add the following key:

Where NEW-KEY-GENERATED will be actually the output of the 'plastic authtoken' command.

Windows - Gluon: switch to changeset

This change is part of a set of changes mainly aimed at improving the workflow for Artists working in Unreal, but it is available to all users.

Artists working in Unreal often run into problems because of the coupled nature of game engine code and assets. It is not clear to the Artist which changeset to work on, and if they choose incorrectly then checkins can overwrite game code.

We have added a menu option to the Changesets view that allows you to switch the workspace to a specified changeset. This allows Artists to ensure their entire workspace is consistent and in the correct changeset.

Here is where you'll find the new option:

Windows - Gluon: Custom actions for Changesets

You can now configure custom actions that can be launched from the Changesets view context menu.

This feature has been available in Plastic for some time, and now we've made it available to Gluon users too.

Check out this blog post about [https://blog.plasticscm.com/2017/12/introducing-plastic-scm-external-tools-actions.html configuring external tools].

Add a new configuration file 'externaltools.conf'.

It allows you to specify external applications and arguments to pass to them. This is the syntax:

toolName: The name of the tool to be displayed in the context menu

pathToExecutable: Absolute path to the targeted application

args: The arguments to be passed to the targeted application. There are three currently supported placeholders: @object (replaced with the object name), @repository (replaced with the repository of the object) and @wkpath (replaced with the current workspace path). Please note that the replaced values might contain blank spaces, so they'll probably need to be surrounded with quotes.

This will create a menu item "Label changeset" under "External Tools" which applies the label "MyLabel" to the selected changeset.

It should look like this:

You can add multiple external tools - just add a line to the config file for each one.

Plastic, Gluon - Linux: Release notes link not working

The release notes link in the About window on Linux didn't open the browser when clicking it. We fixed this behavior

macOS - Plastic, Mergetool: Fixed exception restoring differences in certain scenarios.

In macOS, when trying to restore a difference was placed in the last line on the right editor, it failed with an "Index out of bounds" exception. Now it's fixed.

Windows, Plastic: Fixed low contrast texts in Windows GUI for dark themes.

This is just an aesthetic issue. Using some themes (montana-dark, i3), the progress panels that appeared in the bottom when performing and "Update" or "Checkin" operation contrasted bad with the background. Now it's fixed.

Windows - Plastic: fixed error when deleting multiple branches

We corrected an unexpected error when deleting multiple branches at the same time. Note, the branches were deleted correctly, but an error was produced when updating the view after the delete.

Windows - Plastic: Fixed problems with Jira bound to Plastic changesets

When you link a changeset to a Jira task there was an error that showed that the specific repository wasn't found. Now this is fixed, and you can select a changeset at the branch explorer view and click on any changeset without getting this error.

All platforms - Server: Fixed server issue using security triggers.

Having a security trigger configured, the server could fail and terminate when an unauthorized user tried to get info from a repository. Now, it's fixed

All platforms - Client and server: Improved Active Directory security and performance

Now companies using Active Directory with Plastic server and clients running on Windows will benefit from extra performance (token based security) and security (we now use the underlying Negotiate protocol).

To take advantage of it:

Upgrade clients and servers to this version.

Set LdapTokenPrivateKey in server.conf. Check how to configure this value with support.

All platforms - Web UI: Fixed xlink navigation on cloud

All platforms - Web UI: Update the assigned reviewers menu badge when deleting the last one

All platforms - Web UI: Image display

Enabled image visualization on all pages;

Removed the size limit for images on File explorer;

Zooming is not currently supported but will be added in the future.

All platforms - Web UI: Fixed xlink navigation in file explorer for cloud or enabled organization

All platforms - Plastic: Better error handling when trying to show user profile in a cloud server

When opening the user profile tab in the preferences panel, we were showing a connection error every time the user selected a cloud server. This is because cloud servers don't support user profiles, and the connection always fails.

Now we handle this error, and show a proper error message when selecting a cloud server:

All platforms - Web UI: Fix file download and image display on cloud

All platforms - Web UI: Fixed the following issues

not being able to order lists when some data was empty;

enabled file history details for all types of entries;

restricting the display of the title of a code reviews to two lines for long titles (the plastic desktop client appends the branch description to the title);

showing 0 reviewers in the code review details header if there are no reviewers added;

when showing an alert the focus moves to it;

allow to see the comments list when clicking on the comments button when viewing the details of a comment or have the new conversation form opened;

closing the file explorer branch/label filter when selecting an item and preventing it from closing when clicking on the pagination.

Command line client: fixed exception during check-in when console window is narrow

We fixed a bug in building the animated check-in progress bar that caused an exception when the console window was too narrow to display the progress.

All platforms - GitSync: The character '|' is allowed in the repository name.

Before, the sync could not start if the character '|' was included in the repository name. It failed with the error "The git sync repository attribute cannot be properly parsed".

All platforms - Web UI: File history UI update

Consolidated the look & feel of the file history page.

Extended the capabilities of search and filtering.

All platforms - CLI: Undo operation from outside the workspace

The undo operation of the Plastic CLI could only be performed from inside the workspace where the changes were to be applied. We changed this behavior, and now you can specify an absolute path to undo the changes in any workspace.

All platforms - Web UI: Individual views UI refresh

All platforms - CLI: Add SSO working mode in clconfigureclient

Now you can configure your Plastic client from the command line using SSO. You need to specify the user, server, and SSO token. Like this:

All platforms - Web UI: Code review assigned to me filter now works with multiple reviewers

Previously the filter would only check the first reviewer in the list. Now, we check every user for a match.

All platforms - Plastic, Gluon: Fixed issue when obtaining user profiles

In the "User profile" tab inside the preferences panel, sometimes there was an issue retrieving the profile from the server:

Cannot retrieve the profile from localhost:7178. Details: Error: ConnectFailure (Connection refused)

We fix this issue - now we check if the server is listening before asking for the profile.

All platforms - Web UI: Fixed the following issues

Redirecting the user to the repos list if it doesn't have permissions for the current repo;

Fixed spacing issues between file list and readme contents;

Fixed navigation to the label diff from the labels list.

All platforms - Command line: Replica progress showed weird messages.

If you ever seen a weird message like this in your replica:

All platforms - Web UI: Code review file list fixes

Changes to file system permissions are no longer hidden from the file list.

Merge groups are now displayed and include the spec of the merge source.

Overall, the file list in Web UI should now closely match the layout and format of the desktop client.

All platforms - Web UI: Fixed the following issues

Fixed editing the title of a code review

Clearing alerts when navigating to another url

All platforms - Plastic, Gluon: Makefiles considered as txt files

Before this change, we were considering Makefiles as binary files by default, and users had to manually add the following lines in filetypes.conf to consider them as text files:

Now they are considered as text by default

Windows - Visual Studio Plugin: The plugin doesn't modify the .csproj anymore

Our VS plugin used to write some properties in the project file (.csproj) to know whether the project is under Plastic version control.

Now, the plugin will automatically detect whether you're using Plastic as Source control directly, without any need to use those properties.

All platforms - Plastic, Gluon, Command line client: Checkin operation performance improved: 2x faster!

We tweaked the default thread pools the checkin operation uses to upload data to the plastic server.

With these new default settings, we expect the checkin operation to be 2x faster than older default settings (since we doubled these default thread pool values).

We used the following setup to compare the old default values:

Hardware: bare Intel Xeon E5 1620 @3.6GHZ, 8GB RAM, 8 cores, Windows 10

Networking: 1gbps wired network

Plastic workspace: 20000 files, 2000 directories, 1.25GB total workspace size

checkin the whole workspace to a plastic cloud repository by using command line:

With old default settings, the checkin took 174 seconds.

With new default settings, the checkin took 72 seconds (2.4x faster)

All platforms - Web UI: Branches list UI update

Consolidated the look & feel of the branches list.

Extended the capabilities of search and filtering.

All Platforms - Server: Fixed multiple repositories with same name in concurrency scenarios.

If users attempted to create repositories with the same name at exactly the same time, sometimes the system would allow it. This has been fixed so you can no longer have duplicate repositories.

All platforms - Web UI: Labels list UI update

Consolidated the look & feel of the labels list.

Extended the capabilities of search and filtering.

All platforms - Web UI: Changesets list UI update

Consolidated the look & feel of the changesets list.

Extended the capabilities of search and filtering.

Windows - Plastic: Fixed unexpected error in the branch explorer

Sometimes, when clicking on the branch explorer before it finished launching, Plastic may throw an unexpected error. We protected this scenario and now it won't happen

All platforms - Web UI: Fixed file explorer performance issues when viewing large files

All platforms - All clients: The LDAP/auth token expired wrongly displayed.

Two error messages were potentially displayed wrongly:

The LDAP token expired. User: xxx

The auth token expired: User: xx

You were using Unity ID (SSO)

And you changed your password in unity.com

And your client.conf was pointing to your_org@cloud instead of "local" which is the default

Under these circumstances, instead of asking you for creds, a bug in the code just complained about the situation without providing a solution.

Windows, macOS - Plastic: Added warning to Code Review when item cannot be shown

We improved the user experience for two scenarios:

Previously in this case, clicking on the comment did nothing at all. This is because we can't show the deleted item. We improved this scenario by showing a warning to the user.

Previously in this case we would fail to show the file because it is not visible due to the filter. On Mac, we now show a warning in this case. On Windows, we clear the filter (and warn the user) so that the item can be shown.

All platforms - Web UI: Code review changesets change

Fixed a bug where, in code reviews, when changing changesets, it wasn't selecting the first file in the list.

All platforms - Plastic, CLI: Allow checkin pending changes under an out of date Xlink

The incoming changes said the message "There's nothing to download :-)" when you tried to checkin pending changes under a Xlink that was out of date. As a result, the checkin could not be completed.

This happened when someone else worked directly against the repository of the Xlink and created a new changeset on it. Thus, the parent repository (the one that contains the Xlink) points to the branch head although there are new changes on the branch of the Xlink repo that needs to be merged.

Now the checkin requires a merge on the Xlink. After running the merge, the checking can be completed.

Windows - Plastic: Auto-update!

Now you can update Plastic on Windows to the latest version from within the application itself.

When Plastic detects that a new version is available, the help panel will display a notification telling you which version is available. On the help panel is a link to download the latest version.

Here is the new version notification:

Simply click the link to download the update. You'll see progress in the notification bar at the bottom of the screen.

Once downloaded, you can click the button in the notification bar to launch the updater and restart Plastic.

All platforms - Web UI: File annotations

Added support for file annotations (blame).

All platforms - Web UI: Fixed the following issues

Corrected the code review reviewed button selected color

Added missing latest changeset description to the file view

All platforms - Web UI: File annotations

Fix annotations starting one line earlier.

Fix failing navigation from annotations to the branch.

Added default comment when there isn't one.

Windows - Visual Studio Plugin: The plugin doesn't modify the .sln anymore

Our VS plugin used to write some properties in the solution file (.sln) to know whether the solution has Plastic configured as version control.

Now, the plugin will automatically detect whether you're using Plastic as Source control directly, without any need to use those properties.

All platforms - Web UI: Code review semantic diff fixes

Semantic diff has been reenabled after being fixed. You'll now be able to use semantic diff on code reviews for all supported file types.

Windows - Visual Studio Plugin: Fixed null reference opening the workspaces dialog

Using the Plastic plugin for Visual Studio, you would run into a null reference exception if you clicked the "Change current workspace" button in the "Workspace working info" panel and you don't have any workspace registered. This unlikely scenario could happen if you have a valid workspace on disk but an empty list of registered workspaces for your client in that machine.

All platforms - Plastic onboarding: Cannot create an organization from the signup flow

Few releases back (10.0.16.5473) the possibility of creating an organization after signup got broken. Fixed.

All platforms - All GUIs: Improvements to Korean translations

We changed the translations of attribute and property based on user feedback. Thanks!

All platforms - Cloud Server: Jet repository backup could misplace Jet metadata files under rare conditions.

This could lead to issues accessing the affected repository until an administrator manually solved the issue. This is now fixed!

All platforms - Command line: Can't replicate with fresh Cloud Edition.

We had a bug that made fresh Cloud Editions not using profiles (just using the default config) unable to replicate from its local server to cloud (or clone, pull) because the credentials were not sent correctly to the local server to connect to cloud.

It only happened using command line if no replica from GUI happened first.

All platforms - WebAdmin: We fixed a critical security issue in WebAdmin.

If you're running an on-prem Enterprise server, you should update immediately to ensure the security of your Plastic installation. It fixes some security issues we found in our WebAdmin server management interface.

All platforms - All clients: The workspace tree (plastic.wktree) file format has been changed to read/save it in a much faster way!

We have tested the new format with different workspace sizes (with 80000 and 400000 files/directories) and in different machines. The improvements are the following:

The time reading the tree is x2, x4 or even x10 times faster (depending on the machine tested).

The time writing the tree is almost x2 times faster on average.

Reading an workspace tree of 77000 items took 490 ms. Now, it takes 109 ms.

Writing an workspace tree of 77000 items took 142 ms. Now, it takes 79 ms.

By default, the old format will still use. You can enable this format by adding the following setting on your client.conf. But this new format is not compatible with the Unity plugin yet. So, if you are a Unity user, please don't do it.

This format was originally published in release 10.0.16.5574 but we unpublish it because of the Unity plugin incompatibility.

If you don't enable the new format, this version will revert the workspace tree to the previous format. This will allow you to use the workspace with the Unity plugin again.

Some extra background about the file: The workspace tree metadata is stored in the plastic.wtree file inside the workspace metadata folder (wks/.plastic). This file is read every time use a workspace in the GUIs for first time or when running a cm command for a workspace. It is written every time we do a changes in the workspace (switch to a different branch/changeset, run an update, do a checkout, undo some changes, etc). Its size depends on the number of items loaded in the workspace, so for big workspaces the time reading (or saving it) can affect to the performance of the clients.

All platforms - Web UI: File Explorer README.md support

Added support for README files in the File Explorer.

All platforms - Web UI: Various improvements

If there are assigned code reviews, when visiting the code review list for the first time, it shows the assigned reviews, otherwise, it shows all reviews.

Avoiding resetting data when navigating from one list to another.

Lowered the minimum loading transition animation

All platforms - TeamCity plugin: Versioned settings is now supported!

We extended our plugin to support the Versioned settings feature in TeamCity. You can now enable it in any TeamCity project that consumes a Plastic SCM VCS root.

More info about Versioned Settings here.

Plastic Triggers: Wildcard support in repository filtering.

Triggers can now use wildcards to their repository filters, so they apply to either a single repository or a selected group of them.

Now, when you add a repository filter to your trigger, you can specify the exact repository name or use * as a wildcard. This would affect multiple repositories that share part of the name.

For all your repositories rep:*

For your website_intranet repository rep:website_intranet

For all your website repositories rep:website*

Try more! rep:web o rep:*intranet...

More info about Plastic triggers https://www.plasticscm.com/documentation/triggers/plastic-scm-version-control-triggers-guide

All platforms - Web UI: prevent duplicate code reviews

All platforms - Mergetool: Fixed MarkAsUnresolvedButton key

There was a missing key in one of the buttons in MergeTool, so the text wasn't being translated to the chosen localization

All platforms - Mergebot plugin for TeamCity: Fixed systematic failures after a single build failure

The Mergebot plugin started failing systematically from the moment a build failed. This happened because the first thing the plugin does is to undo all changes in the build workspace. Since the mergebots use temporary shelvesets that get deleted if the build fails, the 'undo' command failed in the agent workspace. All following builds would fail to checkout their sources.

We fixed that by protecting that initial 'undo' against errors.

All platforms - Web UI: branch/changeset/label owners are no longer the current user and now show the correct owner

All platforms - Web UI: Fixed the app not starting on Safari

All platforms - Web UI: Fix alerts not showing on some areas of the application

All platforms - Plastic, Gluon: Fixed sign in with email in Enterprise Edition

When signing in to a cloud server in the Enterprise Edition of Plastic or Gluon, if using the email and password method, sometimes the sign in operation could never end, showing a progress icon forever.

We fixed this, and now the operation either completes successfully or shows an error

All platforms - Server: Fixed an issue related to the calculation of the changesets to pull when it involved moved changesets.

Now the pull preview doesn't show the moved changesets as pending to replicate. Previously, the pull preview ('cm pull br:/main@repoA repoB --preview') showed the moved changesets as pending to replicate (incoming changes or outgoing changes). Those changesets were proposed again and again, as the replication skip them as they were already replicated.

All platforms - Server: The branch head was not properly set after moving a changeset that was in a 'subbranch'. Fixed.

After moving a subbranch changeset like the selected ones (in pink) in the image, the branch head was not properly updated. Now it's fixed.

All platforms - Web UI: Various fixes

Hide reply text area until the reply button is pressed

Added tooltips for conversation's icon buttons

All platforms - Web UI: Removed semantic diff on code reviews until it's fully implemented.

All platforms - Plastic: Error when deleting private files has been fixed.

There was thrown an error when trying to delete multiple private files at the same time. It was broken in prevoius version 10.0.16.5533. Now it is fixed.

All platforms - Web UI: Fixed Code reviews diffs navigation

All platforms - Web UI: Clear API error when refreshing the authentication token

All platforms - Web UI: Reversed code reviews changesets list order to match Plastic desktop

All platforms - All clients: The workspace tree (plastic.wktree) file format has changed to read & save it much faster!

We tested the new format with different workspace sizes (with 80000 and 400000 files/directories) in different machines:

The time reading the workspace tree metadata is 2x, 4x or even 10x times faster than previous release.

The average time writing the workspace tree metadata is up to 2x times faster than previous release.

Reading a workspace tree of 77000 items took 490 ms. Now it takes 109 ms.

Writing a workspace tree of 77000 items took 142 ms. Now it takes 79 ms.

Some extra background about the plastic.wktree file: The workspace tree metadata is stored in the plastic.wktree file inside the workspace metadata folder ($YOUR_WORKSPACE/.plastic).

This file is read every time a desktop application (Plastic, Gluon) opens a workspace for first time, or when running a command line operation for a workspace.

It is written every time we perform any change to the workspace (switch to a different branch/changeset/label, run an 'update workspace', checkout a file, undo pending changes, etc.).

Its size depends on the number of items loaded in the workspace. So, for big workspaces, the time reading (or saving) it can affect to the performance of the clients.

All platforms - Web UI: File Explorer README.md support

Added support for README files in the File Explorer.

All platforms - Web UI: Various improvements

If there are assigned code reviews, when visiting the code review list for the first time, it shows the assigned reviews, otherwise, it shows all reviews.

Avoiding resetting data when navigating from one list to another.

Lowered the minimum loading transition animation

All platforms - TeamCity plugin: Versioned settings is now supported!

We extended our plugin to support the Versioned settings feature in TeamCity. You can now enable it in any TeamCity project that consumes a Plastic SCM VCS root.

More info about Versioned Settings here.

All platforms - Web UI: prevent duplicate code reviews

All platforms - Mergetool: Fixed MarkAsUnresolvedButton key

There was a missing key in one of the buttons in the MergeTool, so the text wasn't being translated to the chosen localization

All platforms - Web UI: Loading states

All the new views like the repository list, file explorer and code review have new loading states to avoid displaying wrong states before the content is loaded.

All Platforms - Plastic: confirm deletion messages for labels and branches have been improved!

Now when trying to delete one or multiple labels/branches from both the Branch Explorer and the Labels/Branches View, a more specific message about what you are about to delete is shown.

Check the following screenshots for labels:

And screenshot for branches:

Deletion message for code reviews was also improved:

All platforms - Web UI: fixed xlinks in file explorer

Clicking an xlink in the file explorer no longer causes an error to occur and instead correctly displays the file or directory selected.

All platforms - Web UI: Repository list now correctly shows when a repository was last updated instead of the name of the creator

The last modified is calculated from the date of the most recent changeset for a repository. This'll help you quickly determine which repositories are active and whether there has been changes since you last looked.

All platforms - Web UI: Code Review: Fixed switching changesets not changing the changeset date

All platforms - Web UI: Fix File Explorer not showing files when organization and repository have the same name

All platforms - Command line client: encoding set to UFT-8

We now automatically set the console input and output encoding to UTF-8 so that East Asian languages can be displayed correctly. Note: you must select a font containing glyphs for your language for the output to display correctly.

All platforms - Server: The max number of worker threads is now limited to MaxWorkerThreads * 10.

This value can be defined in the server.conf file.

The default value used is the number of processors * 4 (when the value is not defined in the server.conf).

All platforms - Web UI: File explorer UI refresh

Refreshed the UI of the main File Explorer list. Individual file/history views will be refreshed in the next update.

All platforms - Web UI: File Explorer updates

On the roadmap to unify the design we updated the following in the File Explorer section:

Updated the File View design and fixed page double scroll

Tweaked the File History design, a full update is pending

Set the file name as the default ordering for the File list, folders and xlinks are grouped and take priority

All platforms - Web UI: Code review list comment count fix

The comment count is now correctly displayed for each code review in the code review list.

All platforms - Gluon: Fixed Enterprise Edition onboarding when using a Cloud server.

When connecting to a Cloud server from the Enterprise Edition Gluon onboarding, there was an error that prevented the user from listing the repositories in the server. We fixed this issue, and now you can connect to any kind of server from the onboarding

All platforms - Cloud Server: Client calls could get stuck in the server side while other (and unrelated) organization was loading its users. Fixed.

The cloud servers use a lock to handle the security of each organization. The problem was that the load of the organization's users were done inside this common lock, so if the users loading for one organization was very slow, other organizations were hit by this. Now, the loading of the organization users is done outside this lock.

We suffered issues in the US East region due to this issue from 2021-May-14 to 2021-May-16 leading to tons of calls stuck due to this.

All platforms - Web UI: Code review list redesign

We've just launched the redesign of the code review list and we are working hard towards refreshing all the other pages soon!

All platforms - Web UI: Breadcrumb navigation

Added repositories top menu item & removed the link from the logo

Added breadcrumb navigation to Code reviews section and File explorer

Server - All platforms: The new .net core server could reject all connections if remoting.conf exists

This is not a very common situation, and probably only hit us during testing, but if you start one of the new .net core based servers and by mistake an old remoting.conf was there (instead of network.conf) then all the socket settings are set to zero, including timeouts, so connections were established but the server would drop them immediately.

Client would see something like:

Windows - Plastic: repositories tree view fix

The error "an item with the same key has already been added" was displayed when creating and deleting repeatedly repositories with the same name.

Now you are allowed to see your repo list without any difference in your preferred view, list or tree view.

All platforms - Web UI: fix scrolling issues

Navigating diffs in code reviews is now a more consistent and enjoyable experience. Scrolling upwards with a touchpad in a diff no longer stalls and navigating to a comment in a code review doesn't scroll past the line in the diff.

All platforms - Web UI: Fixed the following issues

Ordered code review list by date instead of title

Fixed broken code review date

Fixed navigating submodules

macOS - Plastic, Gluon: plastic links now functional!

Plastic Links are a great way to share content from your plastic repositories with your colleagues. You can easily share diffs, links to files and links to code reviews using Plastic Links. This feature first came to Windows, and is now available on mac!

Just click on the link in the normal way and Plastic or Gluon will launch (if not already running) automatically and show you the content specified in the link.

From within Plastic you can share diffs from any diff view by clicking on the Plastic Link icon in the top right corner. This copies the link into your clipboard, ready to paste into a message.

You can also share links to code reviews.

From Gluon you can get links to controlled content by clicking the Plastic Link icon in the file properties panel.

All platforms - Plastic, Unity Plugin: Changed the Privacy statement text for Plastic to reflect Unity's privacy statement.

All platforms - Plastic, Unity Plugin: Added the "Turn off Plastic SCM" feature, with which you can disconnect your project from version control.

macOS - Plastic, Gluon: SSO credentials dialog now is cancellable

When you are trying to perform an operation on a cloud server and are not authenticated, the credentials are asked through a modal dialog. This dialog was not cancellable, so if you wanted to return to the application you had to enter some credentials.

Now we added the possibility to close this dialog by pressing the Escape key.

All platforms - Plastic: Fix "Invalid session token" error

When using SSO, if the current token has expired, Plastic renews it automatically. For some API calls, this renewal was not taking effect until the application was restarted, resulting in an "Invalid session token", even though the token was already renewed. We fixed this error and now the new token is used as soon as it is renewed.

Windows - Plastic: Fixed exception when closing code review too quickly

If you close a code review before it finishes loading, you may get an unexpected exception. We fixed this issue, and now you can close it as soon as it appears on the screen

macOS - Plastic, Gluon: stability improvements

We corrected a potential source of exceptions in the diff window and code review window. Hopefully you'll find Plastic on mac more stable going forward.

macOS - Plastic, Gluon: further stability improvements on mac

We found and fixed a potential source of crashes in the Pending changes view and the semantic diff outline caused by trying to display a dialog when it was not possible.

Windows - Server: All the windows installers will now bundle a netcore-compiled plastic server!

We moved all windows installers to netcore flavor on the server side. This is a step forward on move all our products to .Net Core stack on all supported OS, for the sake of stability, security and performance.

SQL-based backends support will end up with netcore installers. Just super-fast 'Plastic Jet' backend will be the way to go.

The installer & binaries size of netcore server increased compared to net framework server, but we will address this soon.

All platforms - Cloud Server: Reduced the number super-slow downloads (> 10s) from cloud regions.

The cloud servers use a local cache to reuse the data downloaded from the blob storage.

The process of calculating the data to clean from this cache was very slow. So, this could hit the performance of the calls that downloaded data from the cloud servers (update, merge, diff, etc) while this calculation was completed.

This time was greatly optimized from 30 s to 0.2 s, so client calls are not hit anymore by this calculation.

It only affected to the EU West & US East regions (since they are the ones with biggest usage) around 6-8 times per day.

All platform - Server: Improve calculate merge performance

We greatly improve the time to calculate a merge that involves several deleted files on both contributors. For example, we reduce from 273s to 1.5s the time to calculate a reported merge case with over 50 thousand deleted files on both contributors.

The incoming changes also takes advantage of this improvement.

All platforms - Server: potential deadlock on git server feature fixed.

The plastic server is able to act as a git server (More info here).

It could happen that performing a git push on a repo previously cloned from a plastic server acting as a git server to get stuck. Now it's fixed.

All platforms - Eclipse: Cannot create label in a cloud org repo.

The eclipse plugin is throwing an Invalid changeset spec error when creating a new label in the "Labels" view. This only happens when the server is a cloud server. Example: myrep@awesomeOrg@cloud.

Linux - GitServer: potential deadlock on git clone using http basic auth fixed.

We detected in some distros that using git server feature with http protocol and basic auth enabled on netcore server could cause a potential deadlock issuing a git clone from a plastic repo. Now it's fixed.

Example of the command that got stuck:

All platforms - Plastic, Gluon: Plastic 10 About image

To celebrate version 10 of Plastic, we updated the About dialog with a new design. Check it out:

All platforms - Web UI: Code Reviews overall performance fixes.

All platforms - Plastic, Gluon: Use the same SSO credentials for different organizations

If you use the same credentials for more than one organization, now you just need to sign in to one of them. When trying to access the other organizations, Plastic will try to reuse the already existing credentials, so you don't need to authenticate again

All platforms - Web UI: Repositories list redesign

We've just launched the redesign of repositories list.

We are still working and adding features on it, so, more to come in the following weeks.

All platforms - Gluon: Fixed UI freezing when loading previews for big images

Sometimes when selecting big images (> 10MB) in the workspace explorer or checkin changes views, calculating the preview made the GUI freeze for some seconds.

Now there is a warning before showing the preview that allows you to manually choose whether to calculate it or not. When selecting to show the preview, now the GUI doesn't freeze anymore.

All platforms - Command line client: fixed cm when language forced to English in config file

In a recent release we made it possible to force Plastic to run in English on non-English systems, by setting an arbitrary value (like "en_force") as the Language in client.conf. Unfortunately, this broke cm, because it would complain about the invalid language. We fixed this.

macOS, Linux - Plastic: Fixed issue when creating a distributed workspace

During the onboarding, when choosing to work distributed and selecting a repository from the "Browse" menu, Plastic was always showing an error: "The selected repository must be a cloud repository", even after selecting a cloud repository

All platforms - Web UI: Fixed an issue with Code Reviews where new comment line highlighting and icon were disappearing after opening the dialog to add a new comment.

All platforms - Web UI: Repositories & Code reviews fixes

Ordering repositories is now case insensitive

Increased repositories list limit from 10 to 20 items

Automatically focus on a reply or new conversation text area when changing conversations or adding a new one

Preventing file change if the current comment revision didn’t change

Fix not setting the changeset id when creating a comment

For single editor fix scrolling to the first comment

Windows - Installers: Fixed certificate validation issue.

We had to unpublish release 10.0.16.5362 since the signing certificate we use to sign the installers was suddenly revoked. The certificate has been renewed,

and installers are now properly signed with a valid certificate.

All platforms - Server: Improve calculate merge performance

We greatly improve the time to calculate a merge that involves several deleted files on both contributors. For example, we reduce from 273s to 1.5s the time to calculate a reported merge case with over 50 thousand deleted files on both contributors.

The incoming changes also takes advantage of this improvement.

All platforms - Server: potential deadlock on git server feature fixed.

The plastic server is able to act as a git server (More info here).

It could happen that performing a git push on a repo previously cloned from a plastic server acting as a git server to get stuck. Now it's fixed.

All platforms - Eclipse: Cannot create label in a cloud org repo.

The eclipse plugin is throwing an Invalid changeset spec error when creating a new label in the "Labels" view. This only happens when the server is a cloud server. Example: myrep@awesomeOrg@cloud.

Linux - GitServer: potential deadlock on git clone using http basic auth fixed.

We detected in some distros that using git server feature with http protocol and basic auth enabled on netcore server could cause a potential deadlock issuing a git clone from a plastic repo. Now it's fixed.

Example of the command that got stuck:

All platforms - Plastic, Gluon: Plastic 10 About image

To celebrate version 10 of Plastic, we updated the About dialog with a new design. Check it out:

All platforms - Gluon: Fixed UI freezing when loading previews for big images

Sometimes when selecting big images (> 10MB) in the workspace explorer or checkin changes views, calculating the preview made the GUI freeze for some seconds.

Now there is a warning before showing the preview that allows you to manually choose whether to calculate it or not. When selecting to show the preview, now the GUI doesn't freeze anymore.

All platforms - Command line client: fixed cm when language forced to English in config file

In a recent release we made it possible to force Plastic to run in English on non-English systems, by setting an arbitrary value (like "en_force") as the Language in client.conf. Unfortunately, this broke cm, because it would complain about the invalid language. We fixed this.

macOS, Linux - Plastic: Fixed issue when creating a distributed workspace

During the onboarding, when choosing to work distributed and selecting a repository from the "Browse" menu, Plastic was always showing an error: "The selected repository must be a cloud repository", even after selecting a cloud repository

All Platforms - WebUI: allow reopening of active comment

We've fixed an issue where toggling the conversation details panel closed prevented a user from clicking the active comment's icon in the diff panel and reopening the details panel.

All Platforms - WebUI: invalid code reviews now redirect to 404 page

Previously an invalid code review id would lead to a blank page. We've now added a 404 redirect for these invalid ids to ensure a consistent experience.

All platforms - Plastic: resolved issue where long running merge processes could accumulate on the server

The Plastic client checks the server for incoming changes every minute. This can trigger the server to calculate a merge. If this calculation took longer than a minute, the calculation would be triggered again and these processes could accumulate, pointlessly using server resources.

We fix this by ensuring that the calculation will not be requested if another calculation is already in progress.

Windows - Plastic: Fixed several issues in the initial Sign in/Sign up screen for high-dpi screens.

The initial screen for both Cloud Edition and Enterprise Edition had several issues when they were displayed in high-dpi screens.

Some elements were hidden under the Welcome onboarding process:

'''Sign In With Email Panel'''

'''Add a new connection profile'''

When trying to add a new connection profile, there were missing buttons at the bottom. If the connection the user was trying to establish was over a cloud server, the showed SSO Sign In button was scaled wrong. Finally, when clicking the button and tried to Sign In With Email, the entire panel looked like an accordion.

As you can see, those errors are fixed now:

Windows - Plastic: Plasticlinks for code reviews are here!

We heard you and now you can copy and share code reviews with your mates. Check the new link format:

All Platforms - WebUI: The new and improved Code Review experience is here!

We reworked the section in order to achieve base parity with the desktop experience and make it responsive and functional on all modern portable devices.

All platforms - Web UI: Creating a Code Review dialog removal

When clicking on the "Create Review" button, in the Branches and Changesets lists pages, it doesn't require filling a popup dialog form anymore. The title is pre-generated, and the reviewer is set to the current logged in user.

All platforms - Web UI: Filter Code Reviews by Date Range

When viewing the list of code reviews, one can now filter them by a date range. By default, the filter will be for the last month, but seeing the full list is just a click away with our handy date picker.

All platforms: Plastic 10 is out!

Plastic turns 10! It has been almost fifteen years since Plastic was initially released and we celebrate it upgrading to an iconic number: 10.

== What was released during last year ==

These are the key features added to Plastic during the last year:

cloud2. The new Cloud system, visibly faster, more scalable and with more features like triggers, shelves, move changesets from branches and more. We released it back in July 2020.

Code review for macOS. The code review system landed in macOS, another step towards feature parity across platforms.

New Unity Plugin. In August 2020, together with the announcement of the acquisition by Unity, we announced a shiny new Unity Plugin that did not stop evolving since. A much better experience for creators, and it is just the beginning.

Improved Perforce synchronization. Bi-directional sync with Perforce is now multi-branch and expands to Linux and macOS. A huge step ahead for teams willing to migrate out of P4.

Unity ID OAuth support. Added support to secured, two-factor authentication with Unity ID.

Added localization for Chinese, Japanese and Korean. We owed this to our great users in Asia. Now Plastic looks native in these languages and our commitment to keep improving and expanding to other areas like documentation stays.

Security configuration added to Linux and macOS. Now the users of these platforms no longer need to rely on the command line to set permissions.

We greatly improved image diff.

Upgraded Linux and macOS servers to run .net core builds. This improves speed and stability and opens a brighter future for cross-platform Plastic.

Plastic links for Windows. An awesome way to share links to specific changesets and files.

Whitelist restrictions in servers, both on-premises and cloud.

Added Incoming Changes support for Linux, a great way to deal with conflicts when working on single branch.

Added GitSync UI support to Linux and macOS!

Added Git LFS support when syncing repos from GitHub.

Plus hundreds of bug fixes, usability improvements, great performance gains and minor features.

There is really a huge number of new things coming with Plastic 10. Some of them cannot even be unveiled yet, but here you can find a short list:

Greatly improved code review for webUI.

Improved Single Sign On support, adding more providers like Google and Okta.

Plastic links on macOS and Linux.

Reduce cloud repo sizes.

Plastic links on macOS and Linux.

Improvements in how we handle locks.

Tons of usability improvements.

Lots of new great features for the Unity Plugin.

More code review improvements.

Windows - Server: Installers with .NET Core on server component are now available!

We're about to replace all our windows installers so they will bundle a netcore-compiled server component, replacing the net framework compiled server.

But there will be a transitory time frame where both flavors on Windows installers will live together. The recommended flavor is now the netcore server.

SQL-based backends support will end up with netcore installers. Just super-fast 'Plastic Jet' backend will be the way to go.

The installer & binaries size of netcore server increased compared to net framework server, but we will address this soon.

The default installer proposed to download in plasticscm.com site is still the net framework server.

All platforms - Server: Fixed file conflict not detected by the incoming changes.

The incoming changes feature didn't detect a specific type of file conflict: someone else modified a file in the branch head, while you moved it and checked it out in your workspace. It was wrongly detected as a file that just needs to update.

Additionally, Plastic didn't apply the change when you updated your workspace, to avoid overriding your local change. The incoming changes view showed the files modified in the branch head as pending, again and again.

Now the file conflict is show and its content is merged during the update.

Setup workspaces wk1 and wk2. Ensure both are up to date, they point to the same branch and contain the file '/foo.c'

In wk2, edit /foo.c and move /foo.c to /bar.c (don't check it in)

In wk1, edit /foo.c and checkin

In wk2, show the incoming changes view and click to update it. -> Item /foo.c appeared as a file that just needs to update. Now it is fixed, and appears as a file conflict.

All platforms - Plastic, Gluon, Command line client: Fixed wrong source path for a pending move after applying the incoming changes.

The incoming changes view left a wrong source path for a pending moved item. This happened when you exchanged the path of 2 items and both appear as pending moves when you apply the incoming changes.

In wk1, edit /readme.txt and checkin the change

In wk2, apply the incoming changes. After applying the changes, the two pending moves are still there but:

** Before this fix, the second one has a wrong source path:

** After this fix, the second one has the right source path:

All platforms - Plastic, Gluon, Command line client: Fixed generic error message while applying incoming changes.

The incoming changes view showed an error message ("An error occurred processing your request") if you updated the workspace in a scenario like the following one:

In wk1, edit /readme.txt and check it in.

In wk2, apply the incoming changes. Before these changes, the operation failed and displayed the error: "An error occurred processing your request". Now it's fixed.

All platforms - Plastic, Gluon: Reduce the times we ask for credentials when using UnityID.

When using Unity ID login, when the access token was expired, but the refresh token was not expired, the user was incorrectly asked to sign in. There was a bug in the renew token logic that now's fixed.

Windows - Plastic: Deadlock solved

Plastic could hang if it had to display the credentials dialog on start-up. Now it's fixed.

**Examples:**

Example 1 (unknown):
```unknown
cm find label "where owner='me' limit 10 offset 20"
```

Example 2 (unknown):
```unknown
cm find label "where owner='me' limit 10 offset 20"
```

Example 3 (unknown):
```unknown
cm find branches "where owner='me' order by branchname desc limit 10"
```

Example 4 (unknown):
```unknown
cm find branches "where owner='me' order by branchname desc limit 10"
```

---

## Support

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/support

**Contents:**
- Support#
- Resolve issues#
- Submit a suggestion#
- Send information to the support team#

Get help from the Unity Version Control (UVCS) support team.

If you have any issues with UVCS, want to request a new feature, or need help from the Plastic support team, you have the following options:

You can contact the support team with suggestions for a new UVCS feature, or improvements to existing features. To leave a suggestion, select UserVoice.

You might need to send the support team Plastic information such as configurations and log files. To create a .zip file with the required files, select Create bundle and send it to the support team member you're in contact with.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/billing

---

## Seasonal events

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/SeasonalEvents

**Contents:**
- Seasonal events#
- Prerequisites#
- Overview#
  - Initialization#
    - Event parameters#
  - Functionality#
    - Collect Rewards#
- Setup#
  - Requirements#
  - Unity Cloud services configuration#

Seasonal events can increase game sessions and overall interest in a game, because they give existing players new and fun content throughout the year to look forward to, and can entice new players to begin playing. This sample shows how you can set up seasonal events. It showcases four events, Fall, Winter, Spring, and Summer, however you can extend this example to configure events for anything you want. Each event displays the currency rewards you can win during the event, a countdown indicating how much time is left in the current event, and a Play Challenge button that opens a pop-up where players can collect their rewards for winning the challenge.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

To see this use case in action, open the samples menu and navigate to Seasonal Events. To open this scene directly and interact with the use case:

The SeasonalEventsSceneManager.cs script performs the following initialization tasks in its Start function:

The Remote Config service stores key-value data for displaying the active event name, the potential rewards for completing the event challenge. These keys are also used to retrieve the event’s themed interface visuals from the Addressables service.

Remote Config also conveys when the event ends, which the CountdownManager.cs script references to determine how much time remains for the current event. When that time runs out, it triggers a new call to Remote Config to get the updated values for the next event.

Note: This sample determines which Game Override data to return based on the last digit of the number of minutes in the current server time. This is a simplification to be able to frequently observe the season change. In a real app, developers likely set up a Game Override to have specific start and end dates, then Remote Config determines when the Game Override is shown based on the server’s date and time. In that case, the client and server implementations can be a bit different.

The Play Challenge button is an abstraction for gameplay that the player might engage in to earn event rewards. Clicking it opens a pop-up where players can collect rewards for "winning" the challenge. When you click the Collect Rewards button, the following occurs:

The button’s OnClick method calls the SeasonalEvents_GrantEventReward.js Cloud Code script, which queries the Remote Config service to determine which rewards to distribute.

Note: Rewards could potentially differ from what the player expects, if they're altering their device clock or if they initiated their claim at the very end of an event.

Cloud Code then calls the Economy service to grant the appropriate rewards and update the player’s currency and inventory balance.

Once rewards are distributed, the calling script updates the currency HUD and closes the collect rewards pop-up.

You can only play the challenge once per active event, so after the Cloud Code script distributes rewards, it saves the current event name and timestamp to Cloud Save. The client uses this information to determine whether the current event has already been played, and if it has, to disable the Play Challenge button.

To replicate this use case, you'll need the following Unity packages in your project:

Note: Although it is listed as a package and requires separate Dashboard configuration, Game Overrides doesn't actually have an SDK to install from Package Manager. It is a server-side offering that affects values returned from other services.

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys the following items:

The Deployment package doesn't support the following items:

To configure them, refer to Using the Unity Dashboard.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Publish the following scripts in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resources in the Unity Dashboard:

Set up the following config values in the Unity Dashboard:

Configure the following Overrides in the Unity Dashboard:

Select JEXL with the following JEXL code:

Select Choose content type > Config Overrides, then enter override values for the following keys:

Set the following start and end dates:

After finishing creating the Game Override, click Enable.

Select JEXL with the following JEXL code:

Select Choose content type > Config Overrides, then enter override values for the following keys:

Set the following start and end dates:

After finishing creating the Game Override, click Enable.

Select JEXL with the following JEXL code:

Select Choose content type > Config Overrides, then enter override values for the following keys:

Set the following start and end dates:

After finishing creating the Game Override, click Enable.

Select JEXL with the following JEXL code:

Select Choose content type > Config Overrides, then enter override values for the following keys:

Set the following start and end dates:

After finishing creating the Game Override, click Enable.

**Examples:**

Example 1 (unknown):
```unknown
SeasonalEventsSample.unity
```

Example 2 (unknown):
```unknown
SeasonalEventsSceneManager.cs
```

Example 3 (unknown):
```unknown
GetServerTime
```

Example 4 (unknown):
```unknown
CountdownManager.cs
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/update-player-data

---

## Custom dashboards

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/custom-dashboards

**Contents:**
- Custom dashboards#

Although you can't edit the built-in dashboards, you can create your own dashboards on the Custom Dashboards page.

Use custom dashboards to attach your custom reports to dashboards for comparing and monitoring data. You can also compare multiple charts side by side in one central view.

You can add reports from Data Explorer, Funnels, and SQL Data Explorer.

Note: SQL Data Explorer reports are charged query seconds each time they are loaded. Refer to Analytics billing for more.

For information, refer to:

To share individual dashboards, select Export > Export as PNG.

---

## WORKSPACESTATUS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/workspacestatus

**Contents:**
- WORKSPACESTATUS#
- Description#
  - Usage#
  - Options#
  - Legacy options#
  - Search types#
- Help#
  - Remarks#
  - Examples#

Shows changes in the workspace.

cm status [<wk_path>] [--changelist[=<name>] | --changelists] [--cutignored] [ --header] [ --noheader] [ --nomergesinfo] [ --head] [--short] [--symlink] [ --dirwithchanges] [--xml[=<output_file>]] [--encoding=<name>] [ --wrp | --wkrootrelativepaths] [--fullpaths | --fp] [<legacy_options>] [<search_types>[ ...]] [--pretty] [--machinereadable [--startlineseparator=sep] [--endlineseparator=sep] [--fieldseparator=sep]]

The 'status' command prints the loaded changeset on a workspace and gets the changed elements inside the workspace.

This command can be used to show the pending changes in a workspace; the type of changes that can be searched can be modified by using the command parameters. By default, all changes are displayed, be they controlled or local.

The percent of similarity parameter '--percentofsimilarity' (-p) is used by the locally moved search to decide if two elements are the same item. The default value is 20% but it can be adjusted.

It is possible to show workspace changes grouped by client changelists. The 'default' changelist includes the changes that are not included in other changelists. That being said, the changes the default changelist will show depends on the search types flags specified.

Showing changes grouped by changelists requires showing controlled changes too (items with status equal to 'added', 'checkout', 'copied', 'replaced', 'deleted', or 'moved'). So, the '--controlledchanged' option will be automatically enabled when changelists are shown.

The default encoding for XML output is utf-8.

By default, this command will print current directory relative paths, unless the '--machinereadable' or '--short' flags are specified. If any of them are specified, the command will print absolute paths.

If '--xml' flag is specified, workspace root relative paths will be printed (unless the '--fp' flag is also specified, printing absolute paths instead).

(Prints the working changeset and also all item types changed in the workspace, except the ignored ones.)

cm status --controlledchanged

(Prints the working changeset and also the items that are checkedout, added, copied, replaced, deleted, and moved.)

(Prints only the working changeset and the added items inside the workspace.)

cm status c:\workspaceLocation\code\client --added

(Prints the working changeset and the added items under the specified path recursively.)

cm status --changelists

cm status --changelist

(Shows all the workspace changes grouped by client changelists.)

cm status --changelist=pending_to_review

(Shows the changes on the changelist named 'pending_to_review'.)

cm status --changelist=default --private

(Shows the changes in the 'default' changelist, showing private items, along with items with controlled changes, if any.)

cm status --short --changelist=pending_to_review | cm checkin -

(Checkins the changes in the changelist 'pending_to_review'.)

cm status C:\workspaceLocation --xml=output.xml

(Gets the status information in XML format and using utf-8 in the file output.xml.)

(Shows all ignored items.)

cm status --ignored --cutignored

(Shows ignored files whose parent directory is not ignored and ignored directories but not their contents.)

**Examples:**

Example 1 (unknown):
```unknown
cm status [<wk_path>] [--changelist[=<name>] | --changelists] [--cutignored] [ --header] [ --noheader] [ --nomergesinfo] [ --head] [--short] [--symlink] [ --dirwithchanges] [--xml[=<output_file>]] [--encoding=<name>] [ --wrp | --wkrootrelativepaths] [--fullpaths | --fp] [<legacy_options>] [<search_types>[ ...]] [--pretty] [--machinereadable [--startlineseparator=sep] [--endlineseparator=sep] [--fieldseparator=sep]]
```

Example 2 (unknown):
```unknown
cm status --controlledchanged
```

Example 3 (unknown):
```unknown
cm status --added
```

Example 4 (unknown):
```unknown
cm status c:\workspaceLocation\code\client --added
```

---

## Multiplay Hosting

**URL:** https://docs.unity.com/game-server-hosting/en/manual/welcome

**Contents:**
- Multiplay Hosting#
- Get started#
- Interfaces#

Welcome to Multiplay Hosting, Unity's scalable server hosting platform.

Note: Multiplay Hosting is Unity's self-serve experience for hosting and scaling your game. If you’re using the legacy version of game server hosting, refer to the Clanforge documentation.

Typically, a game developer or studio has expertise in areas directly related to game creation, such as gameplay, animation, and level design. However, successfully managing the hosting and scaling of multiplayer games can be challenging, and time pressures to ship your game. These obstacles can make multiplayer games challenging to implement, especially if you don't have enough servers to meet the player demands. Refer to the Ecosystem overview and Integrations to learn more.

Multiplay Hosting removes the complexity of running and operating infrastructure at scale, so your development team can focus on creating engaging player experiences. It also provides ways for you to:

Use the Get started guide to learn how to start leveraging Multiplay Hosting in your project.

Also check out the following samples to help you get started:

There are multiple ways to integrate and manage your application with Multiplay Hosting:

---

## Merge

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/merge

**Contents:**
- Merge#

Note: To solve 3-way merge conflicts, you need to install the VCS desktop app.

You can merge your changes into your current branch.

In the Pending Changes tab, you can also find a list with the merge links which details all of your merges.

---

## FAQ

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/faq

**Contents:**
- FAQ#
- General#
- Events#
- Privacy#
- Data#
- Security#

What is Unity Analytics? Unity Analytics provides an end-to-end suite of tools that studios can use to understand how their players engage with their game. Answer questions about game performance and player behavior and take action to roll out new configurations or run AB tests without releasing new versions of your game.

Is there a cost associated with Analytics? Analytics uses a pricing model based on monthly active users (MAU). MAU is determined by the total count of unique user IDs within your organization that have engaged in at least one session during a month. Under this pricing structure, there's a free tier of 50,000 MAU per month to help you get up and running without incurring any costs. After that, the price you pay scales along with your player base. Find more information on our billing page.

How can I get started with Analytics? Follow our get started with Analytics tutorial.

What platforms are supported? Analytics supports the following platforms:

How can I submit feedback? Fill in this form to submit any feedback, bugs or feature requests. We plan to trigger an in-product customer satisfaction survey and reach out through email to schedule customer feedback calls.

What versions of Unity are supported? The minimum Unity Editor version required for Analytics is Unity 2021.3.

How long does it take before my data shows in the dashboard? After the SDK installation, it can take a minimum of one hour for the metrics to be processed for analysis in the dashboards and Data Explorer. To confirm your integration is successful, use the Event Browser to view your event stream.

What KPIs can I track? A full list of metrics can be found on the Data Explorer V1 metrics or Data Explorer V2 measures and metrics pages to track against your game KPIs. The list is limited to the ones predefined with no ability to create custom metrics.

Why do I get an Unexpected Error message when viewing Analytics? Check that you don't have an ad blocker enabled; they can cause issues on Analytics pages.

Are there limits to how many events I can send? There is currently no event limit for Analytics. We strongly recommend to limit the number of custom events per MAU to 500 custom events per MAU to be in line with our fair usage limits.

Are there any size limitations on my event parameters? We recommend you avoid sending events with large parameter values (greater than 100 characters); these are slower to analyze later. The overall size of each event or batch of events is limited to 4MB (including the entire JSON serialization of the event). The SDK automatically uploads events in valid batches, and discards outsized events with a console warning.

Where are my events, some are missing? First see the Event Browser. This is the first place events flow prior to the dashboards and Data Explorer. Verify that the events are valid. Select the Invalid Events tab which displays an invalid reason. For more ideas please see our debugging tutorial.

My events fail with the reason that duplicate events are detected. Duplicate events can appear within the Event Browser; this is mostly likely due to a player having network connectivity issues, meaning that the SDK is unable to confirm that events were received, so it sends them again. All the events have a unique eventUUID value so any duplicates are immediately rejected by the platform. This is not something to worry about.

What happens to events collected during offline play? Events recorded during offline play are cached locally on the client device and sent when connectivity is restored. For more information, see our SDK behaviour page.

Can I see what events are being sent? The events sent are seen within 5 - 15 minutes of being sent in the Event Browser. For more places to look, see our debugging tutorial.

Can I track player attribution? You can track the data provided by MMPs on the client side such as (but not limited to): the ad network, the specific ad which brought the user to your game, and the cost to acquire this user. All of this data can be recorded in our standard event, acquisitionSource. Find out more in the how to track user acquisition data tutorial.

Can I track revenue? Yes, you can track IAP revenue by manually recording transaction events, or if you are using the Unity IAP Package, it can do this automatically as long as Analytics is also installed and enabled.

You can also track ad revenue by recording adImpression events with the adEcpmUsd parameter populated. You are responsible for populating and recording this event in your code. Not all ad provider SDKs make the ad revenue available to the client at runtime.

Is Analytics COPPA compliant? To provide analytics for your games, Analytics generates an anonymized user ID for each user in your game unless provided with an external user ID by the developer. We do not use any of these IDs generated from Child Apps to track users across apps built by other developers or to map users between devices, or browsers on the same computer. See the privacy overview page for information on the personal data collected.

If your application is a Child App, you need to designate it as such within the Editor service panel or via the project creation process in the Unity Dashboard.

Is Analytics GDPR compliant? Maintaining compliance with GDPR when you use Analytics is a shared responsibility. Unity is the data processor and therefore provides the functionality for the developer to allow a player to opt in and out of data collection and to manage the personal data that Unity collects about them, as required by the GDPR. Please see our guide on managing data privacy with the SDK.

Can I send events from non-Unity apps? Yes. Although we only provide the SDK for Unity projects, you can still use the REST API to upload events from other sources, such as a server.

Can I send events from a server? Yes, events can be sent to the Analytics REST API.

Can I send data I exported from another service? You can't send data directly from another service, but you can send data to the Analytics REST API if you have exported it and transformed it to match the analytics event definitions in your project.

Can I backfill old data? No, events with an event timestamp older than 31 days ago are dropped automatically.

How long is player data retained? Player data retention on Analytics varies based on the type of data. Metric data (DAU, MAU, session length, etc.) for dashboards and user profiles are retained until either the player requests their deletion or the developer initiates their removal. Raw event data is kept for 13 months, and provides year-on-year analysis, then automatically deleted. Once raw event data is deleted, it cannot be retrieved, and developers should conduct analyses within the retention period. The data is primarily used for analysis and targeting purposes.

Developers can request data deletion on players' behalf either by requesting it through the dashboard or if you submit a data deletion request through the SDK. Data deletion requests affects metric data, raw event data and user profile data.

Can I export my data? Reports that are created within the dashboard can be exported to PNG or CSV. Alternatively, if you want to export raw data you can make use of Data Access to access your organization data through Snowflake.

Can I disable Analytics? Yes, Analytics can be enabled and disabled from the Settings page on the Unity Dashboard. Disable this setting to prevent further data from being recorded. You can re-enable it again at a later date to resume data recording.

Can I delete my data? Yes, use Game Data Deletion to delete your data per environment.

Can I delete a player's data? There is a "Request Data Deletion" function built into the SDK that is used to delete all the data for a given player. It records a ddnaForgetMe event that results in all the data for the player being deleted within the next 30 days. This event can also be submitted through the Analytics REST API. Note, if new data is received for the player it is recorded. See privacy overview for more information.

Can I block a player? No, it's not possible to block individual players.

Where are the servers hosted? Our servers are in Belgium and we use Snowflake instances in the Netherlands to store data plus a replicated copy in Iowa.

Where are my events stored at rest? Unity Analytics primarily stores customer data in a secure GCP-based Snowflake account in the EU. When you use Data Access, our systems create a replica of your data within a secure Snowflake account in your chosen region.

Where is my per-player metric data stored at rest? Unity Analytics stores per-player metric data in GCP BigTable to enable segmentation and targeting features (for example, Audiences).

Where is my data stored in-flight? Unity Analytics uses GCP Google Cloud Storage for short-lived storage, and GCP Pub/Sub topics for inter-service communications of data.

How secure is my data? We take security very seriously. All data is encrypted at rest, and we work closely with our technical vendors to adhere to industry best practices.

**Examples:**

Example 1 (unknown):
```unknown
acquisitionSource
```

Example 2 (unknown):
```unknown
transaction
```

Example 3 (unknown):
```unknown
adImpression
```

Example 4 (unknown):
```unknown
ddnaForgetMe
```

---

## Poll for updates

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/poll-for-updates

**Contents:**
- Poll for updates#

The Lobby service enables players to find and connect with other players. It provides a lightweight, non-realtime way to share data and jump into scenarios that best fit the player’s needs without requiring a dedicated game server. Players can also use this to establish a real-time connection with each other (for example, by using the Relay service).

The data in a lobby can change and might occasionally need to be polled. The following list details example scenarios where polling might be required:

It’s important that you ensure that polling is not used to mimic real-time data passing. In general, real-time events should be used for that purpose (see Using Events). The Lobby service uses rate limiting, and attempts to misuse Lobby’s APIs can lead to getting throttled. See Rate limits.

The following code sample shows how to get a lobby:

**Examples:**

Example 1 (unknown):
```unknown
try
{
    var lobby = await LobbyService.Instance.GetLobbyAsync("lobbyId");
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

Example 2 (unknown):
```unknown
try
{
    var lobby = await LobbyService.Instance.GetLobbyAsync("lobbyId");
}
catch (LobbyServiceException e)
{
    Debug.Log(e);
}
```

---

## Blueprint Integration

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/unreal-engine-sdk/blueprint-integration

**Contents:**
- Blueprint Integration#
  - Add the Authentication SDK as a dependency#
  - Get User Info#
  - Delete User#
  - Register State Changed Callback#
  - Sign Out#
  - Switch Profile#
  - Profile Exists#
  - Get Current Profile Name#
  - Get Profile Names#

Before you continue with the following blueprint demonstrations, make sure you’ve successfully installed the Authentication SDK plugin and can view Authentication-related functions in a Blueprint’s event graph or function under Unity Gaming Services > Authentication.

Use Sign In Anonymously to anonymously authenticate. This is a quick way to authenticate without any user information, and requires no interaction with external providers. If successful, this populates the current player profile with the retrieved credentials returned from the Unity Authentication servers.

Sign In Anonymously takes an FAuthenticationSignInOptions struct as a parameter that changes the way a sign-in is performed. More information about these parameters can be found on the official Unity API services documentation page.

The response from the SDK can be handled in a custom event, which needs to take in an Authentication Response as an output pin. To isolate response variables, right-click the response body output pin and select Split Pin.

Use Get User Info to retrieve information about the currently authenticated user. This includes their user Id, authentication timestamps, and any external Identity providers that are linked to their session.

The response from the SDK can be handled in a custom event, which needs to take in an Authentication User Response as an output pin, representing the user response from the Authentication SDK. To isolate response variables, right-click the response body output pin and select Split Pin.

Use Delete User to delete all information related to the currently authenticated player. This function also signs out the player, and deletes all player preferences and profiles connected to the player.

The response from the SDK can be handled in a custom event, which needs to take in a Boolean as an output pin, representing whether the deletion was a success.

Use Register State Changed Callback to assign a callback function that invokes upon the state of the subsystem changing. For instance, the assigned function executes when a player has successfully authenticated and the subsystem state has changed to Authorized.

The response from the SDK can be handled in a custom event, which needs to take in an Authentication State Changed Response as an output pin, representing the response from the Authentication SDK. To isolate response variables, right-click the response body output pin and select Split Pin.

Use Sign Out to sign-out of the currently authenticated player profile. This removes the current player profile and switches to the default profile. This function also has an optional parameter to remove any stored credentials associated with this player.

Note: If Sign Out is used while using the default profile, then the profile information is cleared and the profile stays intact.

This function returns a Boolean representing whether the operation was a success.

Use Switch Profile to switch to, or create, a player profile.

Note: Switch Profile can only be called while signed-out. If a profile switch is invoked while authenticated, a warning is logged and nothing happens.

Use Profile Exists to check if a given profile exists in the current session.

Note: Profile Exists cannot detect profiles from previous sessions that have not been re-created in the current session.

This function returns a Boolean representing whether the given profile name exists in the current list of player profiles.

Use Get Current Profile Name to retrieve the name of the current player profile.

This function returns a String representing the name of the current player profile being used by the Authentication subsystem.

Use Get Current Profile Names to retrieve a list of all player profile names being used in the current session.

This function returns a String Array representing all the names of the player profiles being used by the Authentication subsystem.

Use Register Profile Changed Callback to assign a callback function that invokes when a player profile changes. For instance, the assigned function executes when Switch Profile has executed successfully.

The response from the SDK can be handled in a custom event, which needs to take in an Authentication Player Profile Changed Response as an output pin. To isolate response variables, right-click the response body output pin and select Split Pin.

Use the Register Profile Changed Callback function to assign a callback function that invokes when a player profile is removed from the current session. For instance, the assigned function executes when Sign Out has executed successfully.

The response from the SDK can be handled in a custom event, which needs to take in an [Authentication Player Profile] Authentication Player Profile Deleted Response as an output pin. To isolate response variables, right-click the response body output pin and select Split Pin.

Use Is Signed In to check whether the current player profile is signed-in. Being “Signed-In” is defined as being either Authorized or Expired.

This function returns a Boolean representing whether the current player profile is signed-in.

Use Is Anonymous to check whether the current player profile is signed-in anonymously. This should return true after executing Sign In Anonymously successfully.

This function returns a Boolean representing whether the current player profile is signed-in anonymously. If the last sign-in was anonymous, this returns true even if the session has expired.

Use Is Authorized to check whether the current player profile is signed-in and currently authorized.

This function returns a Boolean representing whether the current player profile is signed-in and has been authorized successfully. This should return true after executing any sign-in function while the expiration time has not yet passed.

Use Is Expired to check whether the current player profile’s session has expired.

This function returns a Boolean representing whether the current player profile’s session has gone past the returned expiry time from its initial Authentication Response.

Use Session Token Exists to check whether a session token exists in player preferences for the current player profile.

This function returns a Boolean representing whether the session token exists.

Use Get Unity Project Id to retrieve the Unity Project Id associated with the current authentication session.

This function returns a Guid representing the current Project Id in use.

Use Get Unity Environment Name to retrieve the name of the Unity Environment Name associated with the current authentication session.

This function returns a String representing the current Environment in use.

Use Get Access Token to retrieve the access token for the current session. If none exists, this returns an empty string.

Use Get Session Token to retrieve the session token for the current session. If none exists, this returns an empty string.

Use the Get User Id function to retrieve the user Id for the current session.

Note: This is different from the player profile name. The user Id is the unique user identifier returned from the Unity Authentication System.

This function returns a String representing the current player profile’s user Id. If none exists, this returns an empty string.

Use the Get State function to retrieve the current state of the authentication session.

This function returns an Enum representing the state of the subsystem.

Use Set Unity Project Id to set the Unity Project Id for the current authentication session. This function takes a Guid.

Note: This overrides the Unity Project Id configured in Project Settings.

Use Set Unity Environment Name to set the Unity Environment Name for the current authentication session. This function takes a String.

Note: This overrides the Unity Environment Name configured in Project Settings.

**Examples:**

Example 1 (unknown):
```unknown
Sign In Anonymously
```

Example 2 (unknown):
```unknown
Sign In Anonymously
```

Example 3 (unknown):
```unknown
FAuthenticationSignInOptions
```

Example 4 (unknown):
```unknown
Get User Info
```

---

## Product Overview

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/data-privacy-unity-player-accounts

**Contents:**
- Product Overview#
- Personal data collected about app users and game players#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent (Opt in) vs Opt out#
- Data Subject Requests#
- Dependencies#
- Data Retention#
- Child Privacy#
- Privacy Policy Requirements#

Name: Unity Player Accounts

Description: Unity Player Accounts is Unity’s comprehensive sign-in solution that supports persistence across platforms and devices. The cross-platform and cross-device identity system allows players to continue their game progress on any developer-supported platform. Unity Player Accounts uses the OAuth2 specification and is compatible with OAuth2 client libraries.

Default Personal Data Collected (always collected in order for product to work):

Under European Privacy Law, Unity is the Controller. You, the developer, are an Independent Controller.

Under Californian Privacy Law, Unity is the Business. You, the developer, are an independent Business.

You can find our legal basis for processing in our Privacy Policy.

By default, a user has to opt-in to use the service as they need to create an account using their email. **Note**: this does not mean that we rely on consent as the legal basis for processing. As noted above, our legal basis is outlined in our Privacy Policy.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

Note: We will not accept requests from developers acting on behalf of their app-users. We have a direct relationship with the app-user, and as the account can be used to sign into multiple applications, requests must come from the data subject.

Access To request a Data Subject Access Request, the player needs to email: unity-player-login-privacy@unity3d.com.

Deletion This service has native functionality to support data deletion requests. Signed-in players can delete their Unity Player Account by either selecting Support in the footer, or going to this URL: https://player-account.unity.com/ Note that deleting this account does not delete their data associated with other integrated apps and services. To delete that data, they need to contact those apps and services.

Note: Data Subject Request functions only apply to this service. If you use other services which collect app user personal data you need to review that service's documentation for how it handles data deletion requests.

This service has no additional functionality to support Data Subject Requests for data collected by integrated applications. You, the developer, are responsible for actioning them.

This product does not have any dependencies on other products.

By default, personal data is retained until deletion while an account is active. In the event of inactivity of two years, users are prompted to delete their account.

This service is not intended to be used in applications with child users, unless you, the developer, have obtained Verified Parental Consent where required as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You need to ensure that the personal data practices are reflected in your Privacy Policy.

Additionally, you need to link out to our Privacy Policy from within your own, as required in the Unity Terms of Service.

Unity DPA applies to the transfer of data for this product.

**Examples:**

Example 1 (unknown):
```unknown
unity-player-login-privacy@unity3d.com
```

---

## Fleet analytics

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/fleet-analytics

**Contents:**
- Fleet analytics#
- User data analytics#
  - Concurrent users#
  - User capacity#
  - Users per build configuration#
- Server data analytics#
  - Server allocations/reservations#
  - Server instances by hardware type#
  - Server density#
  - Server crashes#

Each fleet has a collection of analytic data that Multiplay Hosting collects from the implemented server query protocol. The Unity Dashboard displays each data type as a chart or graph, and you can view the fleet data at a global or regional level.

The following live fleet analytic data is available:

Note: You can only view some analytics if you implement the corresponding values with a server query protocol through the build configuration.

To access fleet analytics:

Multiplay Hosting offers the following fleet user data analytics.

The Concurrent users graph displays the number of live concurrent players across all the fleet’s servers.

The User capacity graph shows the live number of allocated users against the unallocated user capacity for fleets of type Allocation, and reserved users versus unreserved user capacity for fleets of type Reserved.

The Users per build configuration graph displays the number of concurrent users connected to a game session running a specific build configuration. This graph overlays the data for each build configuration across the chosen time frame.

Multiplay Hosting offers the following fleet server data analytics.

This graph displays the number of server allocations or reservations (depending on the type of fleet) within the fleet over a specified time period.

This chart displays the live number of server instances by hardware type (cloud server versus metal server instances).

The Server density graph tracks server density as a percentage of users on allocated servers across time.

Crashes happen when a server within the fleet exits unexpectedly or when a server stops sending query data. The Crashes chart displays the number of server failures within the fleet over the specified period.

Major events include servers restarting and servers crashing. Most server events, apart from crashes, are triggered by performing a server action. The Major events graph displays the number of major events over the specified period.

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal data collected about app users/game-players#
  - Developer defines#
- Relationship under privacy laws#
- Legal basis for processing#
- Consent (opt in) vs opt out#
- Data subject requests#
  - Access#
    - Option 1: Player Self-Service#
    - Option 2: Admin API#

Unity Authentication - A white-labeled authentication solution that enables game developers to provide seamless and secure access to Unity Gaming Services for their players.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected (always collected in order for product to work)

Optional Personal Data Collected (personal data which may be collected at choice/action of the end user/Developer)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are a Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine the legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has native functionality to support data access requests.

As a developer, you can enable your players to retrieve their Unity Authentication account information. Please use Player info from Authentication SDK or Get Player from Authentication REST API.

As a developer, you can retrieve a player’s Unity Authentication account information. Please use Get Player from the Admin API.

Note: this functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data access requests.

As a developer, you can retrieve a player’s Unity Authentication account information. Please use Get Player from the Player Command Line.

Note: this functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data access requests.

This service has native functionality to support data deletion requests.

As a developer, you can enable your players to delete their Unity Authentication account. Please use Delete Accounts from Authentication SDK or Delete Player from Authentication REST API.

You can delete a player in the Player Management from the Unity Dashboard.

You can use the Admin API to delete a player.

As a developer, you can delete a player’s Unity Authentication account information. Please use Delete Player from the Player Command Line.

Note: this functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them.

This product has no dependencies on other Unity products.

By default, personal data is retained until the user or developer deletes the personal data through the mechanisms outlined in the deletion section above.

This service is not intended to be used in applications with child users, unless you, the developer, have obtained Verified Parental Consent where required as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your own privacy policy.

Additionally, you will need to link out to our Privacy Policy from within your own, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## Unity Dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/define-triggers/unity-dashboard

**Contents:**
- Unity Dashboard#
- Preview triggers#
- Trigger details#
  - Navigate to logs#
  - Navigate to action#
- Create a trigger#
- Filters in the Unity Dashboard#
  - Supported operators#
  - Join filters#
  - Define filters with the Cloud Save key-saved event#

The Unity Dashboard is a simple way to get started as it allows you to take full control of your triggers through a graphical interface. This section covers how you can preview, create and delete your triggers.

Note: The Unity Dashboard only supports event-based UGS trigger. To create scheduled events and triggers for scheduled events, you can use the CLI or the Triggers Admin API.

You can access a list of all triggers for an environment from the Unity Dashboard:

A list of all triggers in the selected environment for the project appears. The table contains the name, trigger, type, and last updated timestamp.

You can navigate to the trigger details page by selecting a trigger from the list of triggers. The trigger details page shows you the following information:

The trigger definition card shows a breakdown of the trigger configuration:

The filters are displayed in a chips, showing the attribute, operator, and value of the filter. If the dashboard can't display the filter in the chip format, the dashboard displays the filter in its original CEL format.

To navigate to the logs page for trigger and view the logs for the trigger execution, select the View Trigger Logs button. Learn more about logs in the Logs section.

If the trigger is associated with an existing script or module, the trigger definition card provides a link to the script or module. To navigate to the script or module details page, select the link.

You can create an event-based trigger in the Unity Dashboard.

In the Unity Dashboard, select Products > Cloud Code.

Fill in the following information:

In the next step, select the following information:

In the When this happens section:

Select the Add Trigger Event button.

Select the event you want to trigger the script.

Select Add Filter to add a filter to the event.

Note: You do not need to encase the string values for quotes. However, you must encase the values for JSON types in quotes.

In the Do this section:

Select the Add Action dropdown.

Select the action you want to perform when the trigger is activated. This action can be a script or a module.

Note: You can only select Cloud Code actions that are in the same environment as the trigger. If you selected a Moderation event in the When this happens section and want to a select script for your action, you can only select a Moderation script.

Trigger creation redirects you to the trigger list page. To inspect the trigger configuration, select the trigger name in the table.

Warning: If the trigger interacts with the same service that emits the event, you should define a filter to avoid infinite loops. Refer to Filters in the Unity Dashboard for samples.

You can add filters to the trigger configuration to specify the conditions under which the trigger activates. The Unity Dashboard supports a limited set of filters that you can use to filter the event payload.

Familiarize yourself with how filters work in the Filters section. Refer to Supported UGS events to inspect event payloads for each UGS event.

Note: The Unity Dashboard provides a limited amount of operators to offer a simple approach to filters. You cannot define type casting, nested expressions, or complex expressions in the Unity Dashboard. If you need more advanced filters, use the CLI or the Triggers API to define your own CEL expressions.

Warning: If your trigger interacts with the same service that emits the event, you need to define a filter to avoid infinite loops. Infinite loops over-process the event, cause unexpected behavior in your game, and eventually exhaust your Cloud Code resources for the project, which leads to a service outage.If you encounter this issue, delete the trigger that is causing the loop.

The Unity Dashboard displays different operators depending on the attribute type:

Note The JSON type refers to any JSON object, string, number or boolean. Although all operators are supported for JSON types, you need to use the correct operator for the attribute type within the JSON object. For example, you can't use a string operator for a JSON number.

You can define up to 10 filters for a trigger. You can join filters by the logical operators AND and OR. You can use these operators to combine multiple filters to create complex conditions.

Note The Unity Dashboard doesn't support nested expressions. You can only join filters with the logical operators AND and OR. If you need more advanced filters, use the CLI or the Triggers API to define your own CEL expressions.

You can define your trigger to only activate when a specific key is saved in Cloud Save. For example, you can define a filter to only activate the trigger when the key playerData is saved.

In the Unity Dashboard, you can add this filter to the trigger configuration:

If you define this filter, you ensure that the trigger only activates when the key playerData is saved in Cloud Save.

You can define your trigger to only activate when a specific score is submitted to a leaderboard. For example, you can define filters to only activate the trigger for a score in a specific range.

In the Unity Dashboard, you can add this filter to the trigger configuration:

If you define this filter, you ensure that the trigger only activates when a score between 0 and 100 is submitted to a leaderboard.

To delete triggers from the Unity Dashboard:

Note: If you delete a trigger that is in use by a live game, you may cause unexpected behavior in your game.

Alternatively, you can navigate to the trigger details page and select the Delete button to delete the trigger.

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.cloud-save.key-saved.v1
```

Example 2 (unknown):
```unknown
greater than
```

---

## Archive revisions

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/archive-revisions

**Contents:**
- Archive revisions#
- Archive a revision#
- Access archived revisions#
  - Configuration file in the GUI#
  - Configuration file in the CLI#
- Restore archived revisions#

Set up a separate disk device and store large revisions there so they don't take up unnecessary space in the database.

Some files, such as third-party compiled tools, programs, binaries, and other large files, rarely change and you rarely access them in a production environment. It costs disk space and time to store and retrieve these revisions from the database, so you can archive these files instead. Then, when you need to access those revisions, Unity Version Control (UVCS) searches for them in the external storage to retrieve them.

Note: The repository owner needs to execute the archive command for the revisions to archive correctly, otherwise UVCS continues to use the database to access the revisions.

To archive a revision, use the cm archive command, for example:

To archive several revisions, specify them one after the other in the same command. For more information, use the cm archive --help command.

To access data stored in an external location, you need to create an externaldata.conf file. This file contains a path per line, with each path as the locations of the stored revisions. The following is an example of an externaldata.conf file:

There are two locations that you can create the externaldata.conf file:

If a user tries to access any stored revision from the GUI and there is no externaldata.conf, a dialog appears to ask for the location of the data. After you identify the first chunk of the revision, UVCS can find the other chunks of the revision. UVCS can then create an externaldata.conf file in the local user directory, and from that moment on, UVCS tries to access the archived revisions from that location. If UVCS can't access the data at a certain point in time, it shows the same dialog again. If you identify a new location, UVCS adds this location to the existing externaldata.conf file.

From the CLI (command-line interface) an externaldata.conf needs to always be available. If not, the command line asks you for an externaldata.conf to look for the revisions.

You can use the command line to restore archived revisions back into the database, so you can safely delete the archives. Then, UVCS returns to using the database to retrieve the data.

To restore archived revisions, use the --restore command, for example:

The example restores revision 0 of the main branch of the file mybigfile.tar into the database. UVCS no longer uses the archives of that revision.

**Examples:**

Example 1 (unknown):
```unknown
cm archive C:\mybigfile.tar#br:/main#0 -c="big file of libraries" -f="/home/plastic/bigfileTARrev0"
```

Example 2 (unknown):
```unknown
cm archive C:\mybigfile.tar#br:/main#0 -c="big file of libraries" -f="/home/plastic/bigfileTARrev0"
```

Example 3 (unknown):
```unknown
mybigfile.tar
```

Example 4 (unknown):
```unknown
/home/plastic/bigfileTARrev0
```

---

## Create a label

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/labels

**Contents:**
- Create a label#
- Create a label in the Unity Dashboard#
  - Edit label permissions#
- Create a label in the GUI#
- Create a label in the CLI#
  - Additional commands#

A label is a name you can define and attach to a changeset. This means you can assign a name to the current version of every file within your workspace as of a specific changeset.

You can create a new label from the Labels tab of your repository in the Unity Dashboard. You can also view, rename and delete existing labels.

To create a new label:

Labels inherit the permission settings from the changeset that you apply them to. You can edit and override these object permissions for a specific label:

A label is a name you can define and attach to a changeset. This means you can assign a name to the current version of every file within your workspace as of a specific changeset. You can use a label to rebuild the status later if you need to.

UVCS marks labeled changesets with a circle. You can right-click the circle to access additional label options.

To manage your labels, use the cm label command. If the label doesn’t already exist, the command creates the label and applies it to the changeset you specify.

For example, you can use the following command:

**Examples:**

Example 1 (unknown):
```unknown
cm label BL002 cs:1203 -c="first release"
```

Example 2 (unknown):
```unknown
cm label BL002 cs:1203 -c="first release"
```

---

## Vivox Unreal SDK documentation

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unreal/manual/Unreal/overview

**Contents:**
- Vivox Unreal SDK documentation#
- Features#
- Vivox versions#
- Additional resources#

The Vivox Unreal SDK is voice and text chat system that brings in-app communications to your Unreal project.

Game developers can integrate these capabilities directly into game clients and companion applications by using the Vivox SDK.

Vivox offers additional features for speech-to-text transcriptions and text-to-speech for better accessibility for users. As well as server-side recording to help reduce in-game toxicity.

Note: The Unreal SDK does not currently support using Vivox with Unreal's Live Coding feature in Unreal 5.2.

---

## CCD FAQ

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDFAQ

**Contents:**
- CCD FAQ#
- How should I set up my buckets?#
- What is a release promotion?#
- What is the required content hash on entries?#
- What is my "RemoteLoadPath" in the Addressable profile?#
- How do I get my CloudBuild builds to work with Addressables?#
- Do I need to remove the slash after “path=/” from the Addressable Asset bundle when trying to download it?#
- Why are players experiencing connectivity issues when downloading content?#
- How do I check my bandwidth consumption and billing?#
- Does CCD support console?#

Unity recommends a bucket for every build target (for example, Android, iOS, Windows) across all environments (for example, development, staging, production). This means you would have buckets with the same name in different environments, such as an Android bucket both in your production and development environments.

Promoting a release means pushing that release from one bucket to another. It is best practice to promote to and from buckets of the same name in different environments (for example, development, staging, production) to best track content before it is live for your users.

The Content Hash is an md5sum of the file you specify when you create the entry. It must match the md5sum of the content uploaded, and the file sizes must match as well. A file is set as complete once the md5sum and size match. Only when a file is complete can you add it to a release.

You can find the RemoteLoadPath through CCD in the Unity Dashboard within the Addressable Remote Path URLs tab for each release. You can use the URL of either the release or the badge assigned to the release, though Unity recommends the latter. It should be of the format:

Add a profile specifically for Addressables. The URL needs to include “...content/?path=ServerData/[BuildTarget]”.

The leading slash should not have any effect on the path of your entry, and the system discards it.

A connectivity error, although rare, can exceptionally occur due to unstable client device connectivity. If there are connectivity errors, use the Unity Addressables group setting Retry Count, which is available in Content Packing & Loading > Advanced Options > Retry Count. This is a property that tells Addressables how many times to retry fetching the content in the event of a failure.

This property needs to be changed for every group for which you want to modify the retry count, and is not a global Addressables Settings property.

You can view your bandwidth consumption on the CCD Overview page of the Unity Dashboard. You can view your billing information on the Billing Overview, which is linked on the Overview page as well.

There aren't any known technical limitations for CCD console support, though some consoles might have specific restrictions around where you can pull content from. Accessing the API is platform-dependent; each platform has differing limitations to what remote content games can access.

**Examples:**

Example 1 (unknown):
```unknown
...content/?path=ServerData/[BuildTarget]
```

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/privacy-and-consent

**Contents:**
- Privacy and consent#
- Privacy overview for Cloud Code#
- Apple privacy survey for Cloud Code#
- Google Play data safety for Cloud Code#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## Callback server

**URL:** https://docs.unity.com/ugs/manual/vivox-unity/manual/Unity/server-side-recording/callback-server

**Contents:**
- Callback server#
- Set up a callback server#
- Callback payload#
- Error codes#

SSR provides a callback mechanism to notify you when a recording job is complete. This allows you to take action on the recording once it is complete.

The payload of the callback contains the following fields:

**Examples:**

Example 1 (unknown):
```unknown
callbackUri
```

Example 2 (unknown):
```unknown
callbackKey
```

Example 3 (unknown):
```unknown
Authorization
```

Example 4 (unknown):
```unknown
{
    "job_status": "string",
    "job_id": "string",
    "code": "string",
    "metadata": "object"
}
```

---

## Code reviews

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/code-reviews

**Contents:**
- Code reviews#
- Conversations#
- Changed files#
- Statuses#

Code reviews are a way for you to collaborate on your project through peer assessment. Once you complete work on a changeset or branch, you can request a code review from someone to check over or contribute to the changes. Code reviews can improve your code quality as they help you catch bugs, share knowledge, and enhance control.

For information on how to use code reviews, refer to Navigate code reviews.

A code review contains Conversations, which you can use to interact with collaborators. You can either add comments and replies in the Conversation tab, or you can add questions and request changes to a specific section of code in the Changed files tab. Each comment you add to the code appears in the Conversations panel.

A code review also contains a list of the changed files that are submitted for review.

This tab allows you to filter and navigate through the changed files, and add comments. You can also filter through any existing comments on the files, and view the status and type of comment.

These comments can either be a Question or Change request, and display as either Resolved or Unresolved.

A reviewer can change the status of the Code review to one of the following statuses:

If you leave a Change request comment unresolved, an unresolved button displays that directs you to the unresolved comments.

By default, you can’t merge the code review until a reviewer marks the review as Reviewed. For more information, refer to merge rules.

---

## Approaches to authentication

**URL:** https://docs.unity.com/authentication/en/manual/approaches-to-authentication

**Contents:**
- Approaches to authentication#
- Anonymous authentication#
- External authentication#
  - Platform-specific authentication#
  - Platform-agnostic authentication#
  - Bring your own identity#
- Code-Link#
- Recommended best practices#

Unity Authentication supports authenticating players anonymously and through external identity providers. The external providers can be divided into platform-specific and platform-agnostic providers. Each solution will have its own pros and cons depending on your use case. Refer to Best practices for general guidance.

Platform-specific providers include Google Play Games, Apple Game Center, Steam, and console-specific logins. Platform-agnostic providers include Username & Password, Facebook, Unity Player Accounts, and OpenID Connect.

Anonymous authentication is a platform-agnostic and frictionless way to implement player authentication, similar to a guest sign-in. It doesn't require players to enter credentials or create a player profile.

On sign in, the service creates a new player ID and returns the associated session token, or signs in a returning player. Refer to How to use Anonymous Sign-in and Sign in a cached player for more information.

However, anonymous authentication isn't portable across devices because there's no way to re-authenticate the player from another device. To sign in to the same game with the same player profile from a different device, players must use an external identity provider.

Note: Anonymous authentication is a way to describe the process of authenticating the player without collecting or using their personally identifiable information.

External authentication (also called third-party authentication) uses external identity providers. These identify the player based on information from an external source, either from the player directly or from the platform where the app is running. This requires you to create an identity provider configuration so that Unity Authentication can validate the player, making it possible to authenticate the same player from multiple devices. The external player identities are then linked to a Unity player ID. A player’s ID and thus experience will be consistent across devices and app installations if the player uses the same external credentials to authenticate.

Note that external identities will always be represented as being linked to a Unity player ID. The underlying Unity player ID can be created automatically by using the external provider sign-up methods in the Unity Authentication SDK, or by using anonymous authentication first and then linking the external identity. The end result will always be a Unity player ID with one or more linked external identities. For any given external identity provider, only one identity can be linked to a given Unity player ID.

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

Platform-specific external authentication providers use platform-native APIs to derive the player identity from the platform on which the app is running, and uses that to sign the player into Unity authentication. As a result it represents a form of frictionless external authentication, which is usually preferable to the non-frictionless platform-agnostic authentication solutions outlined below.

Typically the process begins when a player signs in to the platform with their email address, or their username and password. Within the app a token is then requested from the platform and sent to Unity Authentication for validation. If the token is validated successfully by the external identity provider, the token is then associated with the Unity player ID.

While the user experience of a frictionless sign in is generally excellent, platform-specific solutions might not be the best choice for advanced cross-progression requirements (tracking player state and progress across platforms).

The following platform-specific external identity providers are supported by Unity Authentication:

External platform-agnostic authentication providers require the player to manually sign in. This typically involves the player temporarily leaving your app to authenticate themselves to the external provider in a different app or web browser, and then return to the app. As a result it represents a form of challenge-based external authentication, which is usually less preferable to the frictionless platform-specific authentication solutions outlined above.

While the user experience of having to sign in externally is usually worse, platform-agnostic solutions better support more advanced cross-progression requirements (tracking player state and progress across platforms).

The following external platform-agnostic identity providers are supported by Unity Authentication:

You can use your existing authentication system by integrating a custom authentication solution with Unity Authentication. This means that you must create an identity provider configuration for your own authentication system so that Unity Authentication can validate the player, making it possible to authenticate the same player from multiple devices.

Currently, Unity Authentication supports:

The level of user friction and platform specificity when using custom authentication will depend on how your integration is implemented.

Code-Link is a feature which provides uncomplicated and fast cross-platform ID support across mobile, desktop, and consoles by generating simple codes on one logged-in device that can be used to sign in on another.

With Code-Link, you can provide your players with the flexibility to move across platforms without entering their login credentials multiple times while completely avoiding third-party sign-ins. Code-Link supports both anonymous and platform-specific sign-in methods.

For example, a player can start a game anonymously on their Android device. After reaching level 2, they decide to continue progress on their console. Opening the game on their console generates a code they can enter on their Android device. Once confirmed, they can continue playing on console.

Refer to the Code-Link page for more details.

Use the following decision flow diagram to find the best authentication approach for your app.

Learn more about anonymous authentication, and more about how best to manage a flow with anonymous authentication and linked external providers.

---

## Store data using Cloud Code

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/tutorials/cloud-code

**Contents:**
- Store data using Cloud Code#
- Authentication#
- Using Cloud Save with Cloud Code modules#
  - Set up the module#
  - Modify player data#
  - Modify cross-player data#
    - Read and write data#
  - Manage data with different access levels#
  - Query data#
  - Aggregate calls to Cloud Save#

You can use Cloud Code to interact with Cloud Save. For example, you can use Cloud Code to run a script when a player saves data to Cloud Save, or to modify data in response to a game event. With Cloud Code, you can achieve server authority and reduce the risk of players cheating in your game.

The Cloud Save SDK for Cloud Code allows you to read and write data for Player, to read and write Game Data and to query data (if you have configured indexes to make data queryable) from Cloud Code.

The Cloud Save SDK is available for both Cloud Code C# modules and Cloud Code JavaScript scripts.

Refer to the Cloud Save SDK for Cloud Code documentation for a list of all available methods.

Cloud Code offers two authentication methods you can use to interact with Cloud Save data. The recommended authentication method depends on whether you want to access data for a specific player, or for any player in the game:

Additionally, use access control to restrict access to the Cloud Save APIs. This is useful if you want to prevent players from accessing the APIs directly from the client.

You can use Cloud Code modules to interact with Cloud Save data.

To use Cloud Save with Cloud Code modules, you first need to set up a Cloud Code module. For more information, refer to the Getting started with Cloud Code modules guide. As with any other Unity services integrations in Cloud Code, you need to initialize the client SDK in the module.

Create a class that implements the ICloudCodeSetup interface. This class configures the Cloud Code module and sets up the dependencies.

This setup allows you to use the Cloud Save SDK in your Cloud Code module by passing the GameApiClient to the Cloud Code module as a dependency.

For more information on how Cloud Code integrates with Unity services, refer to Integrate with other Unity services.

To modify a player's data, use the Cloud Save SDK for Cloud Code modules. The following example shows how to update a player's data stored in Cloud Save. The example uses the access token to authenticate the request, which restricts the access to the data of the player who is authenticated in the client:

You can use editor bindings to call the Cloud Code module from the Unity Editor. After you generate the bindings, you can call the SaveData and GetData functions from your MonoBehaviour scripts:

When successful, the output should be similar to the following:

You can use the Cloud Save SDK for Cloud Code modules to modify cross-player data or Game Data. The sample code demonstrates how to access and modify any player's data that is stored in Cloud Save.

The sample code below shows how to read and write any player's data that is stored in Cloud Save. The playerId parameter identifies the player to access.

Note: If you want to interact with the data of the player who is authenticated in the client, use the access token instead of the service token. The service token in the sample below is used to access the data of any player in the game, allowing to read and write their Cloud Save data.

You can use editor bindings to call the Cloud Code module from the Unity Editor. After you generate the bindings, you can call the SaveData and GetData functions from your MonoBehaviour scripts with the same approach shown in the previous section.

To identify the player whose data you want to access, you need to provide the playerId parameter to the SaveData and GetData functions.

The recommended way to get another player ID is to retrieve it from another Unity service in Cloud Code. Refer to Cross Player Data for more information on how to access and modify another player's data.

The following sample code demonstrates how you can use different access modifiers for players and custom entities to access and modify Cloud Save data.

Note that the use of access modifiers depends on the type of data you work with and the operations you want to perform.

You can use editor bindings to call the Cloud Code module from the Unity Editor. After you generate the bindings, call the ManageDataAccessClasses function from your MonoBehaviour script:

To check the output, refer to the Cloud Code logs in the Unity Cloud Dashboard. The logs should show the retrieved items for each access class.

You can use Cloud Code to query Cloud Save data.

Before you use the sample below, you need to do the following steps:

Note: Only data submitted after index creation is available for querying.

The sample code demonstrates how you can query Cloud Save data using different access modifiers for players and custom entities:

You can use editor bindings to call the Cloud Code module from the Unity Editor. After you generate the bindings, you can call the ManagePlayerDataAsync function from your MonoBehaviour script:

To check the output, refer to the Cloud Code logs in the Unity Cloud Dashboard. The logs should show the retrieved items for each query.

You can use Cloud Code modules to aggregate calls to Cloud Save. This is useful in case of high-frequency calls to Cloud Save. Refer to Advance a community goal for an example.

You can use write locks to prevent concurrent writes to the same data in Cloud Save. This is useful if you want to ensure that only one player can modify a specific piece of data at a time. The sample below demonstrates how to use write locks in Cloud Code modules to prevent concurrent writes to the same data in Cloud Save.

The SetGameData function sets a write lock on the data being modified. If another call tries to modify the same data while the write lock is held, they will receive a conflict error. However, if there is a retry action provided, the function will retry the operation. The retryAction function argument is called to get the new value to set for the game data. This determines what value to set for the game data in case of a conflict, allowing you to implement custom logic for resolving conflicts.

You can use Cloud Code scripts to interact with Cloud Save data. The following examples show how to modify player data and cross-player data using the Cloud Save SDK for Cloud Code scripts.

To use Cloud Save with Cloud Code scripts, you first need to set up a Cloud Code script. Refer to the Getting started with Cloud Code scripts guide. Set up the Cloud Save SDK in your script by importing the Cloud Save package:

To interact with player's data, you need to authenticate using the access token. This restricts Cloud Code's access to the data of the player who is authenticated in the client.

The following example shows how to modify a player's data stored in Cloud Save.

To interact with cross-player or Game Data, you need to authenticate using the service token. To authenticate with the service token, pass the context object to the Cloud Save SDK client.

Note: When you pass in the context object to the client, you authenticate the client with the serviceToken by default.

By passing another player’s ID to the Cloud Save SDK, you can read and write their Cloud Save data, allowing asynchronous multiplayer interactions. This would not be possible from within the client, where users are only permitted to access their own data.

The following example shows how to provide a commendation to another player within the same lobby. The sample code demonstrates accessing and modifying another player's data stored in Cloud Save. The otherPlayerId parameter identifies the other player.

For samples on how to access different access-level data and query data using Cloud Code scripts, refer to the Read and write data. For more samples on how to use cross-player data in Cloud Code scripts, refer to Cross Player Data.

You can use Cloud Code to modify data in response to a game event. For example, you can use Cloud Code to update the player's data when they complete a quest or level up. This can be achieved by using Triggers, which allow Cloud Code to run in response to events in your game.

Cloud Save emits events when data is updated. You can use these events to trigger Cloud Code logic that modifies the data. Triggers can be activated either a Cloud Code script or a Cloud Code module, depending on your use case.

Refer to the table below for use case samples integrating Cloud Save with Cloud Code Triggers.

Note: The following samples use Cloud Code modules.

**Examples:**

Example 1 (unknown):
```unknown
ICloudCodeSetup
```

Example 2 (unknown):
```unknown
using Microsoft.Extensions.DependencyInjection;
using Unity.Services.CloudCode.Apis;
using Unity.Services.CloudCode.Core;

    public class ModuleConfig : ICloudCodeSetup
    {
        public void Setup(ICloudCodeConfig config)
        {
            config.Dependencies.AddSingleton(GameApiClient.Create());
        }
    }
```

Example 3 (unknown):
```unknown
using Microsoft.Extensions.DependencyInjection;
using Unity.Services.CloudCode.Apis;
using Unity.Services.CloudCode.Core;

    public class ModuleConfig : ICloudCodeSetup
    {
        public void Setup(ICloudCodeConfig config)
        {
            config.Dependencies.AddSingleton(GameApiClient.Create());
        }
    }
```

Example 4 (unknown):
```unknown
GameApiClient
```

---

## Debug event reporting

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/Debugging

**Contents:**
- Debug event reporting#
- View events in the Debug Panel#
- View events in the Event Browser#
- Web debugging proxy tools#
- Enable logging in console#

By default, the Analytics SDK doesn't log much information to the console, to ensure it runs as efficiently as possible in the background of your game.

When setting up the SDK and instrumenting custom events, there are three options for debugging and confirming that the integration works as intended.

New for version 6.0.0 of the Analytics SDK is the Debug Panel, which you can open from Services > Analytics > Debug Panel.

Keep the Debug Panel open as you test your game in the Unity Editor to display events as they are recorded and uploaded, along with other information such as whether the SDK has been activated and what user IDs are assigned to each event. You can also examine the raw JSON payload of each event to ensure that you are recording the data you want to record.

Note: The Debug Panel only shows events and uploads that occur while it is open. The Debug Panel will not display events recorded before it was opened.

The Debug Panel does extra work to marshall events for display while it is open. None of this logic executes outside the Unity Editor or when the Debug Panel is closed, so you can rest assured that the underlying SDK still runs as efficiently as ever.

The Event Browser has an event stream where you can see both valid and invalid events as they are sent by your game. Use this tool to confirm your integration and view errors and information about invalid events. Refer to Event Browser for more information.

Charles Proxy or Fiddler are examples of utilities that can monitor network activity on your mobile device from your PC. When configured correctly, you can see individual network requests and responses as they're generated on your mobile device. This can be used to confirm that your game is sending events over the network to Analytics.

To monitor network activity using a network proxy:

To view the debug messages about recording and uploading events in the Editor's console:

Note: It's advisable to disable logging before building for release.

**Examples:**

Example 1 (unknown):
```unknown
UNITY_ANALYTICS_EVENT_LOGS
```

---

## GETREVISION

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/getrevision

**Contents:**
- GETREVISION#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Loads a revision in the workspace.

This command modifies the revision loaded in the workspace, so it can affect future merges. It is an advanced command inherited from old versions, so use it with care.

cm getrevision <revspec>

cm getrevision file.txt#cs:3

(Gets changeset 3 revision of 'file.txt'.)

**Examples:**

Example 1 (unknown):
```unknown
cm getrevision <revspec>
```

Example 2 (unknown):
```unknown
cm getrevision file.txt#cs:3
```

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/privacy/overview

**Contents:**
- Privacy overview#
- Personal Data Collected about App Users/Game Players#
  - Developer Defines#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent#
- Data Subject Requests#
  - Access#
  - Deletion#
- Dependencies#

Unity Cloud Save service can be used to save persistent player data (such as game progress) from a game into the cloud, making it independent of device. Because it's cloud-based, players can access their data anywhere and across devices, mitigating data loss when a player changes devices or re-installs a game.

This documentation is intended to assist products display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading our Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy of a product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Personal data which is always collected in order for product to work:

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are an Independent Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they must implement it client-side in a way determined by the developer.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them.

You can action them by using the documented SDK or REST API functions for Cloud Save:

This service has native functionality to support data deletion requests.

This can be done using the Cloud Save REST API

Please note: this functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests. To delete the Player ID created by the Unity Authentication SDK, please use the Authentication API.

This product is dependent on the Unity Authentication service. By using this product, you will also be using the Unity Authentication service and you should refer to the Unity Authentication SDK documentation for more information.

By default, personal data is retained until the developer chooses to delete it.

This service is not intended to be used in applications with child users, unless you, the developer, have obtained Verified Parental Consent where required as outlined in Section 6.7 of the Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## Unity Version Control 7.x Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/7

**Contents:**
- Unity Version Control 7.x Release Notes#
- 7.0.16.2937#
  - New#
    - The "confirm ignored filter rules" dialog was too…#
    - Now, the About dialog displays the right Plastic…#
  - Bug#
    - A recently added file, still checked-out, display…#
    - After any update operation (e.g. switching to a b…#
    - When configuring Gluon in Cloud Edition mode for…#
    - The Plastic Proxy couldn't be configured and used…#

This document contains all release notes for Unity Version Control major version 7.x, organized from newest to oldest.

Plastic for windows: The "confirm ignored filter rules" dialog was too small. Now it's bigger.

Plastic (Windows and Linux) GUIs: Now, the About dialog displays the right Plastic website URLs in the "visit us" and "meet us" information lines, with the "https" protocol.

Gluon (all platforms): A recently added file, still checked-out, displayed 0 bytes in the size column of the Explore workspace tree. Now it's fixed.

Plastic for Windows: After any update operation (e.g. switching to a branch) you're prompted with a dialog that displays the issues reported by operation (if any) so you can "retry update" or "update forced" them. There was a bug that kept the last selected issue in the "Issues" view after you clicked "Update forced" but the "Path" view was cleaned up. Now it's fixed.

Gluon for linux: When configuring Gluon in Cloud Edition mode for the first time, the password textbox was not visible. Now it's fixed.

VSPackage: The Plastic Proxy couldn't be configured and used under the VSPackage. Now it's fixed.

CLI: 'cm hist' command: we added new fields to the output so it is now possible to print the repository name, server, full repository spec (name + server), and then we added format helpers like "tab" and "newline".

In addition, human-readable parameter names are now accepted. Note that the old parameters based in numbers are still supported:

All GUIs and command line client: It is now very easy to add ignored files if needed.

So far it was not possible to add an ignored file. You had to un-ignore it, and then add it.

We made two improvements:

Now you can select a single ignored file or directory and simply add it.

If you add a directory, all the files not explicitly ignored will be added, even if they are in ignored directories.

These changes affect both to the all GUIs and the command line.

Suppose that foo.c is ignored. You can right click on it on the GUI and simply add it. Or you can run cm add foo.c successfully.

Now, let's consider a more complex scenario. Check the following structure:

Now suppose you add a recursive add in the root of the workspace ("cm add -R . --addprivateparents" on command line or "add directory tree to source control").

Then the non-ignored file "bar.c", and its parent "lib", will be added.

The directory "other" will not be added because it does not contain any non-ignored files.

The following figure explains the scenario:

Server: Jet backend. We added detailed logging and additional integrity checks to the Jet backend to ensure its stability and improve traceability.

When the server detects that a Jet file is corrupt, it throws the following error:

"The content of '{filepath}' is not valid. Please contact support@codicesoftware.com for assistance.".

Before, the server tried to use it and failed with an unexpected error like an "End of file".

We also added extra log to monitor the file size and its changes. When every Jet file is used the server logs its size (e.g. "File '{filepath}' opened for reading. Length: X bytes. Size: Y bytes.").

The server also logs size changes (e.g. "Commit append for '{filepath}'. Length X bytes.").

We introduced these changes after detecting (and recovering) a corrupt Jet file in one customer after a big power failure in their server.

CLI: The cm diff command always displayed "Workspace revision" as symbolic name in both left and right revisions when the diff was launched from the command line using revision specs. Now it's fixed.

WebAdmin: The migration to Jet failed with the error 'Could not map file' when there was an existing Jet database in the destination database path. Now, we report correctly to the user that the database path must be empty instead of showing a weird error like 'Could not map file'.

Gluon for windows: When clicking the button "Scan network" in the preferences dialog, general section, a "missing resource" error was displayed. Now it's fixed.

Linux and macOS: We changed the workflow of opening workspaces. Now, the switcher window and any opened workspace window will be close when you select a new workspace in the workspaces view and execute the "Open" context action. To keep more than one workspace window opened at the same time, select the "Open in a new window" context action.

Gluon now includes a dialog to setup the preferences:

Windows GUI: Added a "preferences" button in the bottom right corner.

Linux GUI: Added a "preferences" button in the left side bar.

macOS GUI: Added a "preferences" menu option in the main application menu. Gluon -> preferences.

Visual Studio Package: Visual Studio integration is now compatible with Visual Studio 2019 Preview.

CLI: The 'clconfigureclient' tool caused some configuration values, present in the client.conf file and not collected by the clconfigureclient tool, to be lost after each execution. Now it's fixed.

Linux and macOS: The image preview and image diff features displayed error messages if the image files were corrupted or contained invalid image data. They'll now handle these errors properly and report you that the image format is not supported.

All GUIs and CLI: Fixed the size check for the objects name like branch or label names according to the database field length: 100 characters.

All GUIs: They failed to diff a changeset that received a merge from a branch without permissions. The same happened running a merge that involved that changeset (or some of its files in the case of Gluon). The error thrown was "You don't have permissions for operation read". Fixed.

Command line client: Commands which accept the -R or --recursive option will now also accept -r.

We have made the add command a bit more flexible. Previously it was not possible to add a directory if it contained a controlled item. Now you can run add on a directory containing controlled files and it will add only the private items. It also works recursively.

An example should make this clear. Suppose you have the following in your workspace:

You can now add all three private files with one command:

Command line interface: We have add using wildcards much nicer. You can now use wildcards to add files recursively, even if you already have controlled files in the directory tree.

For example, just use "cm add -r *.cs" to recursively add all your .cs files in one go.

Plastic & Gluon GUIs: We "bothered" users for years asking to confirm the inclusion of dependencies during the checkin operation when always they wanted them to be included. From now on, we will take care of including the dependencies directly in both, checkin and shelve operations, making life easier for users :)

Plastic for Windows: Improved workspace creation usability:

After creating a workspace from the repositories view using the "Create workspace for this repository" context menu option, the workspace is automatically opened.

After creating a workspace from the workspaces view, now the view scrolls and focus the recently created one.

Windows GUI: The root node in the items view was not expanded after refreshing the view the first time the workspace was updated. Now it's fixed.

Windows GUI 2D Version Tree: The "only relevant" button wasn't properly disabling the checkboxes in the "Version tree panel". Fixed.

Linux and macOS GUIs: The value "Check if there are newer changes in the repo" setting in the new Pending Changes Options dialog wasn't loaded correctly. In addition, if the OK button in that dialog was clicked without any changes in settings, the save and refresh operations were launched unnecessarily. Now they are fixed.

Windows Branch Explorer: The GUI sometimes displaying errors ('Index out of bounds') that prevented the Branch Explorer from loading. That happened if the user previously opened a 2D Version Tree, selected the "Version tree" option in the Options side panel, closed the GUI and reopened it again. Fixed!

KNOWN ISSUE: Due to a minor issue in an internal API, this release won't be friendly-named with a song in the "About" form as usual.

Plastic for Windows: The diff tab couldn't be closed using the default shortcuts Ctrl+W/Ctrl+F4. Now it's fixed.

Plastic for Windows: Using the tab key to navigate controls did not work in the diff viewer when it was embedded in the pending changes view. Now it's fixed.

Cloud Edition Plastic GUI: We introduced an error in the last release in the Welcome dialog -the one that pops up after a new Cloud Edition installation- when the credentials entered by the user to connect to the cloud were wrong (no validation is done since the user still can work locally). Now it's fixed again!

Plastic GUI: The annotate operation failed when the user didn't have permissions to view/read the branch where some line was added/changed. Now it's protected.

Command line client: In some cases, a recursive ls command would fail in the path was an xlink. We have corrected the behaviour here so that recursion into xlinks works as expected.

WebUI: The Diff view didn't update the visual change information when a changed Xlink was selected. Fixed!

DevOps: A new mergebot -named 'conflictsbot'- has been added to the built-in mergebots catalog!

'conflictsbot' it's a read-only mergebot that detects merge conflicts at early stages in the development lifecycle of your task branches.

Probably you heard about it in our blog, where its motivation and behavior is explained in detail.

Now, we provide the 'conflictsbot' as a built-in mergebot, to simplify deployment & configuration.

Gluon GUI: Remove a help message that appeared in the Checkin View but it didn't apply (only valid for Plastic Pending Changes View, slightly different).

Linux GUI: Finally linux applications (plastic, gluon and mergetool) have Semantic Diffs included! Available for C#, Java and Vb.Net files! C and C++ will come really soon :)

Cloud Edition Plastic GUI: We improved the Welcome dialog -the one that pops up after a new Cloud Edition installation- usability for users that want a workspace directly connected to the Cloud (e.g. avoid a push/pull setup). Now you'll find the cloud repos in the "Repository" drop-down list of the "Just create a workspace" tab.

Plastic & Gluon for Windows/linux/macOS: Added the full path in the item preview file properties.

This solves the following UserVoice request: Display full file path (Gluon)

Windows GUI: When creating a new workspace from the welcome dialog, and selecting a repository from a server different than the default one, it was ignored (it was creating using the default server). Now it's fixed.

Gluon for Windows: Gluon failed to diff a recently added file from the checkin changes view. Now the option "Diff workspace contents" has been disabled for added files since it is not applicable.

Gluon for Windows: The first time you opened gluon the workspace status info and the "switch branch" button were not displayed. Now it's fixed.

Gluon for Windows: The "Checkin changes" view was overlapped by the title when it was displayed as a side view (launched from the "Explore workspace" view). Now it's fixed.

Windows diffs: "An Item with same key has already been added" exception that happened having moved regions with differences and collapsing regions has been fixed!

Gluon (all platforms): If you displaying the search dialog while the configuration is loading, then it didn't produce any search result. Now it's fixed.

Windows, linux, macOS: The Branch Explorer used the UTC time zone to place changesets in the appropriate date column. This is especially important when working in a distributed team with different time zones: changesets could appear the day before. Now the Branch Explorer uses the local time zone to find out the actual date of a changeset.

Plastic/Gluon for Windows and Gluon for Gtk: Plastic and Gluon failed to calculate the preview for those images that were set as readonly in the filesystem. A "access is denied" error was displayed instead. Now it's fixed. This issue did not affected to macOS.

Windows: The GUI could throw an unexpected error when refreshing the Branch Explorer view when the mouse pointer is not visible. Now it's fixed.

Linux GUI: The Branch Explorer context menu options 'view changesets in this branch' and 'browse repository on this changeset' failed with an unexpected error.

This issue happened since 7.0.16.2761. Now, they are working again.

Linux/macOS GUI: We added a side panel to the branch, changeset and shelves views to display properties and attributes:

The properties viewer allows you to edit the comments of the selected changeset/branch/label/shelf.

The attributes viewer allows you to apply attributes to the selected changeset/branch/label/shelf.

Gtk and macOS: We added a scroll minimap to both the diff and merge tools! It shows where there are diffs/conflicts in the file. You can click on the minimap to jump to that position:

We changed how 'cm find' queries apply to changesets. If you don't have the 'view' permission in a branch, its changesets will be filtered out of any 'cm find changeset' query. This affects the CLI client ('cm find') and the query views in our GUIs as well, e.g. Changesets View.

Gluon: The configure view showed a help panel reporting that the repository was empty in some rare scenarios. Fixed!

BranchExplorer, all platforms: We fixed a bug that caused the checkout changeset -the one that represents the current status of the workspace in the branch explorer- to be drawn in the incorrect position, namely behind the last changeset.

macOS GUI: we found a crash opening the pending changes view for the first time when the first item in the list was a big file. Now it's fixed.

DevOps: The link of the "learn more" button of the trunk-bot built-in mergebot was broken since 7.0.16.2722. Fixed.

GitServer: The git clone operation failed when the plastic repository had defined a secured path rule that denied the view permission to the "ALL USERS" user. This happened because the server could not calculate the git objects from the plastic objects.

Now, the secured path permissions are not checked anymore for the GitServer calls.

Command line tool: We have made it really simple to checkin private files. Just specify --private when running a checkin, and any private files detected will also be included.

Linux GUI: We added a Filter text box in the History views. It'll allow you to filter revisions in the History list.

Linux GUI: We added a Search text box in the Browse Repository view. It'll enable you to find items in the repository tree located in that view!

Gtk and macOS clients (Gluon and Plastic): Display image diffs in the Pending Changes view and the Diff window.

Now, when you select any image in the Pending Changes view or the Diff window, the diff viewer displays differences for the selected image.

The tree of changeset 0 (which only contains the root) will be always visible from now on, even if the user doesn't have permissions to see the root path.

The rationale for this is to allow users with read permission only on a given path in a repository (e.g. path '/doc' in repository 'game') to create a new workspace pointing to said repository.

This was previously forbidden because the contents of cset 0 weren't visible to the user. So, the workspace creation failed with the error "The workspace cannot be initialized with the given selector. Probably you don't have enough permission to load the initial changeset of the repository of the selector.".

macOS: The Undo and Redo actions are now enabled in input text fields, such as the checkin comment or the Diff control!

Windows: the comment text in the Pending changes view was incorrectly deleted when the checkin operation displayed the "merge required" dialog. Fixed.

Plastic macOS: Implemented filter/search for dynamic views (those plastic views that appear on the right side of the window: e.g. history, shelves, browse changeset, etc ...)

GUI: New context-based help system: The Branch Explorer tip to hide non-relevant changesets won't be shown if you already have the "Only Relevants" option enabled.

Gluon: Checkin is now able to handle newly defined expansion rules of an added xlink. It works correctly with cm partial ci. We still have an issue with partial worskpaces where ci is unable to let users edit existing Xlinks.

Command line: cm rm --no-disk is now optional. It means it is now easier to "apply a delete" in the metadata of your workspace.

It is better explained with an example.

You delete it from disk: simply rm /src/foo.c, you don't do it with a Plastic command, just with the operating system.

If now you want to "apply" the deletion to the workspace, you'd have to do cm rm /src/foo.c --no-disk

But now, it will be easier: cm rm /src/foo.c and it will be clever enough to mark it as deleted since it is no longer on disk.

We added detailed logging and additional integrity checks to the Jet backend to ensure its stability and improve traceability.

macOS (Plastic and Gluon): Improved syntax highlight & diff region colors when using macOS Mojave with the dark theme (only macOS 10.14+).

When changing the macOS theme, the syntax colors and the diff region colors are adapted "on the fly" to improve contrast between the diff color and the text on the dark theme. Note that syntax colors were already adapted but required an App restart to be applied.

macOS: We changed the icons of PlasticSCM, Gluon and Mergetool so that their colors change according to the current UI theme (Dark/Light).

macOS: Improved the look and feel for the dark theme in macOS Mojave 10.14:

Diff and merge navigation toolbar buttons have been redesigned.

Explorer dialogs (branch, repository, changeset, server) has an improved look and feel.

Fixed dark theme checkbox icons in gluon configuration view.

Fixed some minor dark theme issues (background and foreground colors).

Gluon for macOS & linux: Creating a new workspace does not require an "update" or "configure" operation to convert the workspace to "gluon" mode anymore.

Command line client: Now "cm mv" seamlessly (and silently) applies local moves to metadata.

Easier to see with an example:

And the move is applied!

Windows GUI: New context-based help system: Disable "ding" sound when a new hint shows up.

Command line: cm rm now works for locally deleted directories.

Previously, attempting cm rm on a directory that is not in the workspace would fail. Now, it correctly marks the directory as deleted.

Plastic macOS Mojave: The branch explorer didn't render correctly (the canvas didn't get redrawn) when moving it with the scroll bars. It was ok when manipulating it directly. Now, it's fixed.

We also improved the rendering in the diffs. Sometimes the regions didn't get correctly repainted using either the scroll or the mouse wheel.

macOS: Three aesthetic issues have been fixed in the macOS GUIs:

The mouse pointer type "IBeam" (the textbox stick) appeared when you placed the mouse over the dialog bottom buttons (ok-cancel). Fixed.

The dialog bottom buttons were overlaying other components in few dialogs. Fixed.

You could also noticed about the "huge" size of some buttons in a few dialogs (Create workspace dialog, Apply attribute dialog,...). Now it's also fixed.

macOS: Plastic BranchExplorer's details view and Gluon details view, were not correctly shown/hidden. Now it's fixed.

Since the release 7.0.16.2740, you cannot checkin a file that is opened by some external tools like Microsoft Visio. You had to close the external tool to perform the checkin operation. Now you can perform the checkin operation without closing the external tool.

Gluon for macOS: If you typed something in the Search Files dialog text field and quickly hit the Enter key, you got an error message complaining about some component being used after its disposal. It's fixed now!

Gluon for macOS: You won't be able to dismiss the Search Files dialog anymore if you started an operation inside it (checkout, undo checkout, update). If you did so before, these operations remained in the background and tried to manipulate visual components that weren't there anymore. We changed that behavior to make the visual feedback more consistent.

Gluon for macOS: Changesets view: The "Advanced" button didn't expand the additional area where the user can customize the query. Now it's fixed.

Gluon for macOS: Gluon displayed an unexpected error when trying to calculate the preview for some files types, for example .eps files. Now it's fixed.

macOS: The Sync view didn't update the list of available sync views when a new sync view was created from the Cloud view context menu. Fixed.

Gluon for Windows: Fixed an exception when setting the move detection similarity percentage to its minimum value in the pending changes options dialog. Also, the similarity percentage label was not updated when the form was loaded. Now it's fixed.

Gluon for macOS: The preview for image file types were not properly centered, and also proportions were wrong. Now it's fixed. We have changed the mechanism how we calculate image thumbnails. We use the macOS's QuickLook feature to calculate them.

All GUIs: The new context triggered help system is out now!

We have been working on a new help system. It is a mix of UX improvements with empty states and a smart help that guides you while you learn how to master Plastic SCM.

It is implemented as a panel in all views that shows up to help you discover new features you never used, or in response to events that might be causing frustration.

It is better explained with an example: suppose you frantically click the "refresh" button of the labels view. Chances are you are not finding something you are looking for, otherwise you wouldn't click it so frequently. And, suppose you have a filter in the view that is preventing you to see what you are looking for. The GUIs will detect this and show a panel highlighting that you have a filter set and that's probably why you are not finding what you are looking for.

Another example: have you ever colored your Branch Explorer based on the authors of the changesets? The help system will help you discover that.

The new system comes with a good amount of art in the form of a new mascot: our wise Owl, a smart and methodic librarian that aligns well with the Plastic philosophy: preserve history to learn from it.

This new help system is a starting point to improve onboarding, usability and to help users becoming experts on version control in an active way.

Gluon: We improved the performance of the size calculation. Now it's about 5 times faster than before.

Server: New threadpool boosting system to avoid running out of threads when something goes wrong and some operations are blocked.

== How to see this new system in action ==

If this ever happens, you'll see the following on your server log:

Suppose you have a situation like this, with 5 methods blocking the server:

It shouldn't happen, but sometimes we found issues on very slow networks, or bugs, that blocked some requests.

Now, the server tries to attend a new request, and it enqueues it, and before this fix it had to wait for a free thread.

But now, the following will happen:

And a new thread will be created to attend the new request.

== What if there are many enqueued requests ==

If that's the case, the following happens:

A new batch of threads will be added to the thread pool (up to the thread pool limit which is normally the number of cores).

Gluon now displays the size of the private directories shown in the 'Explore workspace' view. Previously it was always 0.

Using Gluon against the cloud server or a server using SQL backend: the checkin operation failed in huge workspaces (with over 250000 folders) when a size calculation was triggered while a checkin operation was still running. The error message 'Trying to use a previously finished transaction' appeared. This happened e.g. when you hit the checkin button in the checkin view and then you switch to the 'Explore workspace' view and refresh it.

Windows GUI: The "Display branch task info" was not working in the branch explorer. Now it's fixed.

WebUI: Fixed some transaction errors in servers using SQL-based backends. These errors prevented the code review/diff views and the items tree to display the appropriate contents, showing blank views instead.

Command line: the help of several commands including checkout and update has been correctly formatted (some indentation was wrong).

CLI: The "cm statt" and "cm rmattr" commands now support shelves. This was already supported by the core and the Windows GUI, but it lacked CLI support.

cm statt att:status@quake@localhost:6060 sh:6@quake@localhost:6060 New

Server: Improved the log to show more info about each request.

Request: the number of the request, to help tracing calls.

Status: can be one of these values:

** SslAuth: If the request is negotiating SSL.

** Proto: Request reading protocol information.

** Read: Request reading incoming data from the network.

** Run: Request running on the server.

** Send: Request response being sent back to the caller.

Protocol: Remoting or Plastic.

Sec: Security - can be SSL or None

This greatly helps debugging calls that got stuck for some reason.

Add %property{RequestId} to DebugAppender and ChannelCallAppender.

Gluon for macOS and Linux: built-in search in explore workspace view. From now on, you can find files at light speed just typing Command-F in macOS or CTRL-F in Linux.

Correctly format replication fields in showfindobjects command.

Added better explanations about the rev specification and about the target field in the cm find review command.

Windows GUI: The previously used server drop-down has been made more usable by only showing servers used in the last 30 days.

CLI: The 'cm status' command no longer prints performance warnings (if any) with the flag '--short'. This way, it is easier to parse its output for task automation and the like.

macOS: client: Fixed frozen update from a Plastic Cloud repository.

Since we updated to support macOS Mojave, big downloads from Plastic Cloud stopped working. On-premise servers were not affected because they download using a different protocol.

Now it is finally fixed.

== Why this happened? ==

To fix issues in Mojave we did 2 things:

Upgraded to latest XCode.

Upgraded to Xamarin.Mac 5.0.0.0.

Colors and other things were fixed, but unfortunately something broke downloading lots of contents using HTTP.

We are going to report the case to Xamarin so they can fix it.

== How did we solve it? ==

We downgraded to Xamarin.Mac 4.4.1.193 from Xamarin.Mac 5.0.0.0.

Mergetool: The Mergetool comparison method 'Recognize all' failed when there was a conflict at the end of the file in the following scenario:

When the last two lines of any contributor were an empty line (just the LF '\n' char) followed by a line with no EOL char.

On a Linux client working against the Cloud, the checkin operation was failing during the upload step due to a memory leak when thousands of files were uploaded.

The problem was a Mono issue related to the connection limit, which is avoided.

We also improve the memory usage during the update phase adding some buffer pools and avoiding some objects creation.

Client: Server Alias: serveralias.conf supports now aliases to Cloud repos:

localhost:8087 my_org@cloud

This might be useful if you are migrating your on-premise server to the Cloud and you have writable Xlinks that are not configured to use a relative server. In that scenario, those Xlinks couldn't be resolved in the Cloud because the target repository wouldn't be found.

You can work around that if you add an alias to translate your on-premise server (locahost:8087) into your cloud server (my_org@cloud) when Plastic resolves the Xlinks.

WebUI: We improved the styling of the dropdown filter in the Items View!

We now tell the user how to view the help if they attempt to run the binmergetool utility with no arguments.

DevOps: TrunkBot is now capable of labeling the resulting changesets of merging task branches into trunk branch. The 'Learn More' section of TrunkBot has been updated with a full description of this feature.

Two variables can be used in your label pattern for this purpose:

*${BUILD_DATE_FORMATTED, <a_valid_date_format>}

It will substitute the variable with the current date specified in the a_valid_date_format string. See example below:

pattern will generate a label name like: Release_1.0_2018_10_25

It will substitute the variable by the next number, having a previously existing label match in the repository. If there are no labels matching the specified pattern, the variable will be replaced by a 0. See the example below:

will cause TrunkBot to find a previously existing label matching that pattern. If a label is found that way (e.g. Release_1.3.15), TrunkBot will create a new label named Release_1.3.16

DevOps: TrunkBot is now capable of running a different continuous integration build plans after a task branch is checked-in in the trunk branch. This is useful to deploy the merged code after check-in.

Server: DevOps: protect the load of the DevOps UI in the webadmin in case that the websocket to communicate with plugs can't be started.

Server: DevOps: The built-in trunkbot naming was not consistent. Sometimes it said Trunk bot, others TrunkBot. We made it consistent.

Greatly improved the help of the cm showfindobjects command. Now it really helps you doing finds with examples and in-depth explanations.

Linux CLI: We fixed an issue in newer distros (OpenSUSE Leap 15 and Ubuntu 18.10 among others) that caused CLI commands to crash when they had to output text to the terminal.

CLI: The command 'cm checkout' is now updated: the 'exclusive' flag is removed.

CLI: The command 'cm unco' (also, 'cm undocheckout') was correctly updated in the Spanish version of the command line help.

A branch with multiple heads cannot be pushed. Previously, the error message did not give any useful information. Now, it specifies the heads that need to be merged, so you can unify the heads and push the branch without error.

CLI: The 'cm help objectspec' command now displays the complete help about the different "specs" available.

WebUI: We fixed an issue in Firefox and Edge that prevented the diff view from loading the contents of the currently selected item (it kept the contents of the previously selected item).

We detected that the checkin operation could store a revision without data when these conditions were met:

The Plastic SCM Server uses the Jet backend

User performs a merge from a branch that contains files modified only on source

User shelves all changes using the CLI client ('cm shelve', no path specified)

User checks in the merge result

The copied revisions (i.e. modified only on merge source) in the resulting changeset wouldn't have any data at this point.

We fixed this scenario, so this shouldn't happen again!

DevOps: The server will ensure that the plug configurations linked from a mergebot configuration are started when you create a new mergebot configuration or you edit a mergebot configuration that was running at that point. This will also happen when you start a mergebot configuration!

Windows GUI: Added a close action in the Branch Explorer's diagram legend.

All GUIs and CLI: Server side merge is now enabled by default. You can learn more about server side merges here: http://blog.plasticscm.com/2018/03/workspace-less-merge-to.html

We reduced the amount of debug log generated by the replication operation. The server no longer logs replicated trees, which were the reason why replication logs grew up to 40 GB in some cases.

DevOps: merge failed with the error "Attempted to divide by zero." under certain circumstances when the file conflicts were resolved using the semantic merge. Now it's fixed.

Windows GUI: We added a panel to the Image Diff that ask you for confirmation before calculating the diff of big images. This is >2MB by default but you can customize it in the 'mergetool.conf' file using the 'big_file_size' key (in bytes).

WebUI: The Plastic SCM Server version number is now displayed in the page footer.

macOS: Support for macOS mojave Dark Theme (still beta, please feel free to report any theme issue to support@codicesoftware.com). REMARK: The diff viewer syntax highlighter does not change between themes on-the-fly. You need to close and reopen Plastic to get it working. We're working to support that asap.

Windows GUI: Now the GUI displays the current (working) workspace in bold font in the workspaces view. Note that branches, changesets, history ... already display the working object with a bold font.

CLI: The 'cm li' command now has a nicer, tidier output, some new flags, and a revamped help. Specifically, the new flags are:

The first filters out active users, while the second filters out inactive ones. The third one allows you to sort the license usage table by user name or by its status (licensed or inactive). As always, you can refer to the built-in documentation for further information like this:

This is part of our ongoing effort on making our CLI great, and we expect to enhance the 'cm li' command again soon!

We implemented a workaround to a regression in macOS 10.14 Mojave launching apps from Finder or via "open" on the command line. All our clients (plastic, gluon and mergetool) where affected by some graphical issues. Additionally, AppKit started drawing corrupted graphics randomly :'(

DevOps: We just published version 0.12 of our plasticscm-mergebot-plugin! Check the changelog in the Wiki page: https://wiki.jenkins.io/display/JENKINS/PlasticSCM+MergeBot+plugin

Jenkins plugin: We just released plugin version 2.20! Check the changelog in the Wiki page: https://wiki.jenkins.io/display/JENKINS/PlasticSCM+plugin

WebUI: We enabled code folding in the diff/content views, as well as bracket matching and control + G to navigate to a line by number.

Windows Image Diff: The '1:1' and 'Fit image' buttons had their functionality swapped! We fixed that so each button launches the appropriate operation.

Jenkins plugin: Requesting the list of affected files from our SCM plugin failed. This happened with the Slack notifier plugin, for instance. It's now fixed!

DevOps: merge failed and returned a cryptic error message ("The specified branch -1 can't be found.") if the merge contained xlinks with unresolved conflicts and there weren't any changes in the destination branch inside the xlink. We changed that to make the client display a helpful message: 'The "Merge-to" operation cannot be executed because the merge from changeset cs:32992@myRepo to branch br:/main/release_2308 has conflicts. It is necessary to run a "Merge from" operation from a workspace to resolve those conflicts.'

DevOps: We added support of recursive merges that include a file with conflicts among the ancestors and the merge contributors at the same time.

macOS: Fixed an issue that could make macplastic & gluon to crash when opening certaing views in Mojave.

Windows GUI: We added a panel to the Image Diff that ask you for confirmation before calculating the diff of big images. This is >2MB by default but you can customize it in the 'mergetool.conf' file using the 'big_file_size' key (in bytes).

WebUI: The Plastic SCM Server version number is now displayed in the page footer.

macOS: Support for macOS mojave Dark Theme (still beta, please feel free to report any theme issue to support@codicesoftware.com). REMARK: The diff viewer syntax highlighter does not change between themes on-the-fly. You need to close and reopen Plastic to get it working. We're working to support that asap.

Windows GUI: Now the GUI displays the current (working) workspace in bold font in the workspaces view. Note that branches, changesets, history ... already display the working object with a bold font.

CLI: The 'cm li' command now has a nicer, tidier output, some new flags, and a revamped help. Specifically, the new flags are:

The first filters out active users, while the second filters out inactive ones. The third one allows you to sort the license usage table by user name or by its status (licensed or inactive). As always, you can refer to the built-in documentation for further information like this:

This is part of our ongoing effort on making our CLI great, and we expect to enhance the 'cm li' command again soon!

We implemented a workaround to a regression in macOS 10.14 Mojave launching apps from Finder or via "open" on the command line. All our clients (plastic, gluon and mergetool) where affected by some graphical issues. Additionally, AppKit started drawing corrupted graphics randomly :'(

DevOps: We just published version 0.12 of our plasticscm-mergebot-plugin! Check the changelog in the Wiki page: https://wiki.jenkins.io/display/JENKINS/PlasticSCM+MergeBot+plugin

Jenkins plugin: We just released plugin version 2.20! Check the changelog in the Wiki page: https://wiki.jenkins.io/display/JENKINS/PlasticSCM+plugin

WebUI: We enabled code folding in the diff/content views, as well as bracket matching and control + G to navigate to a line by number.

Windows Image Diff: The '1:1' and 'Fit image' buttons had their functionality swapped! We fixed that so each button launches the appropriate operation.

Jenkins plugin: Requesting the list of affected files from our SCM plugin failed. This happened with the Slack notifier plugin, for instance. It's now fixed!

DevOps: merge failed and returned a cryptic error message ("The specified branch -1 can't be found.") if the merge contained xlinks with unresolved conflicts and there weren't any changes in the destination branch inside the xlink. We changed that to make the client display a helpful message: 'The "Merge-to" operation cannot be executed because the merge from changeset cs:32992@myRepo to branch br:/main/release_2308 has conflicts. It is necessary to run a "Merge from" operation from a workspace to resolve those conflicts.'

DevOps: We added support of recursive merges that include a file with conflicts among the ancestors and the merge contributors at the same time.

DevOps: We released version 0.11 of our plasticscm-mergebot-plugin for Jenkins! Upgrade it in your Jenkins instance!

Windows GUI: Added validation errors before closing the "Rename" dialog. This way, if you specify the same branch/label/repository/workspace/attribute name than the original, a validation error will be shown and the rename dialog will remain opened until you specify a different name.

Windows, Linux and OS X GUI: Merge-to operation: If new changesets are created while an user is running a merge-to operation in the same destination branch, Plastic will warn the user about this condition and will prompt the user to unify these heads by running a new merge-to operation.

REMARK: If multiple xlinked repositories are involved, you will need to fallback to workspace-side merge operation (switch workspace to the destination branch and run a "merge from" your source branch).

Mergetool: Fixed typos: Instead of showing "Keep base contributor & exit" in "Save" menu options, show "Keep base contributor & exit".

DevOps: We detected that Jenkins returns "ERROR: null" in pipelines if it's configured to use Pipeline script from SCM and the script path is invalid. We improved the message to show that the resulting 'cm cat' command failed.

GitServer: Aborting a git clone/fetch/pull/push command with ctrl+c could make the server crash in Linux due to an unexpected unhandled exception (related to setting the response http status code after the response headers were sent). All the GitServer threads are now protected to avoid crashing the server anymore.

The message in the console output after the server crashed was the following: "Cannot be changed after headers are sent".

Unity 3D plugin: Rename/move directories are working again! This issue happened since Unity 5.1.1f1 introduced a bugfix with side-effects that broke the rename/move folder in Plastic.

Thanks to the help of Jake Turner from Unity staff we were able to implement a valid workaround to fix this issue :)

Unity 3D plugin: decorators for folders are now updated correctly after running add/checkin operations.

DevOps: The trunk mergebot logging now makes more sense and introduces more detail in the failed operations, but in a readable way.

CLI: The 'cm showfindobjects' command now is way more useful than it was. We have added the type of each field you can search by, and some tips and tricks regarding replicationlog and date constants you can use on your queries. This is an ongoing effort on making our CLI great, so expect further improvements on this.

Replicating against 2 different organizations (orgA and orgB) at the same time from the same server, one of the replications could fail with the error "Plastic SCM server ssl://orgA@cloud.plasticscm.com:8086 wasn't able to open a connection to the database. Check the server log (plastic.server.log). Error: Login failed for user 'orgA_rep_22'."

Visual Studio Package: Plastic SCM plugin for Visual Studio was not listed as a valid Source Control Provider if the user that installed plastic was a Windows standard user. Fixed.

mergebots can now merge conflicts across files. A release note won't probably tell how awesome it is, but let's try :-)

You move a method to a different file and change it.

Meanwhile someone else modifies the method in the original location in a different branch.

Now the mergebot merges the first branch, no problem.

Then it goes and merges the second one: and it applies the changes made by your colleague to the method you moved. Automatically. No conflict needed if the changes do not collide.

Sufficiently advanced technology is indistinguishable from magic, and this, indeed, is magic ;-)

Can't say how proud we are for this.

macOS/linux GUI: Diff viewer: When clicking a line involving a difference, the diff navigation counter is updated. This allows navigating differences by clicking in the diff's textboxes, and not only using the navigation buttons (first, previous, next, last).

Windows GUI: Branch Explorer: we refactored the rendering code to greatly reduce memory usage. Now it should use 1/3 of the memory it used before. Our entire history with 11k branches since 2006 went down from 900MB to about 300. And this is just a first step :)

DevOps: Our jenkins mergebot plugin now supports Lightweight checkout for pipelines! Give it a try!

Windows GUI: "Diff with other changeset" dialog did not save/load the default query properly. Now it's fixed.

Windows installer: The installer failed to setup the Visual Studio package for Visual Studio 2017 if there was a running instance in the machine. Now the installer forces to close all instances before installing the package.

devops: We changed the date format in the .control.log log files so now dates are printed in the same format used by the other logs we produce. This is used each time a plug and mergebot is started.

WebAdmin: The License section displayed an expiration date (set to the license creation date) for Perpetual licenses, which is incorrect. Now, only subscription licenses will show their expiration date.

CLI: the 'cm cat' command failed for revisions specified from a server path and a shelve spec. Fixed.

Windows GUI: The last diffs were not correctly painted in the diff viewer when the last line was visible in the text editors. Now it's fixed.

Windows: We had an issue with advanced move detection (using the NTFS Journal):

Open Plastic & the "pending changes" view

Edit /src/foo.c using the notepad

Move /src/foo.c to /foo.c

No other change on /.

Refresh the "pending changes" view

The "pending changes" view showed:

But the edition is not detected (the item doesn't appear as changed).

Now it's fixed, and "pending changes" view shows:

Moved /src/foo.c to /foo.c

Windows: We had an issue with advanced move detection (using the NTFS Journal):

Open Plastic & the "pending changes" view

Rename /art/img001.png to /arc/conceptart.png

Edit /art/conceptart.png

Move /art/conceptart.png to /conceptart.png

Refresh the "pending changes" view

The "pending changes" view showed:

Locally deleted /art/img001.png

Private /art/conceptart.png

Now it's fixed and the "pending changes" view shows:

Changed /conceptart.png

Moved /art/img001.png to /conceptart.png

Print ServerStats every 10 minutes instead of every 30 seconds. This is the information in the log dumping memory usage, process info and more. It was creating 3 million lines per hour on some big customers so we decided clean some of the info. No more info about caches is dumped.

All clients: Added macOS 10.14 Mojave support!

Warning: We noticed that there might be graphical issues at this point regarding the Dark Theme. While we're on it, you can run /Applications/PlasticSCM.app/Contents/MacOS/PlasticSCM directly, which should display everything correctly.

We detected on a client running a server that uses a MySQL backend, that the MySQL fails under heavy load with unexpected errors (like saying that an existing column doesn't exist).

When those errors happen reading the license info, the server is terminated as the license info is corrupted.

Now the server will no longer shutdown when the license info is corrupted. It will inform the client that the operation cannot be done because the license info is corrupted but the server will continue running.

We also protect the license info from unexpected backend issues, so the license info should not be corrupted anymore.

macOS/linux GUI: Diff viewer: When clicking a line involving a difference, the diff navigation counter is updated. This allow navigate the differences by clicking in the diff's textboxes, and not only using the navigation buttons (first, previous, next, last).

WebAdmin: The "License token" text box doesn't show the whole token in some cases because of the width of the box. Fixed.

Semantic SCM: our semantic parsers (for Java and C++ languages) did not work with Java version 10 because of the way we checked that the correct JVM version was installed. Fixed.

Server: The license auto-renewal using license tokens wasn't working after our website migration of 2018-09-18. Our new website required TLSv1.2, not enabled in .NET Framework apps by default. We manually added TLSv1.1 and TLSv1.2 support in our server process, which should make the auto-renewal work again!

GitServer: Finally, GitServer can secure the git clients using the http basic authentication!

It means the git client will ask you to enter the username and the password when connecting GitServer if this authentication is enabled.

To configure it, you just need to add the following entry in the gitserver.conf file (located in the server folder).

Of course, GitServer must be configured to listen in the http protocol.

It is important to remark that to work this way, the Plastic SCM server must be configured in LDAP, AD or UP security mode so the git client can be authenticated against the server using an user/password pair.

The security is only checked at repository level which means that the server will only check if the authenticated user through Git has permissions in Plastic to view the specified repository (in the Git url).

For more info about GitServer, see the following link: https://www.plasticscm.com/gitserver/

Print ServerStats every 10 minutes instead of every 30 seconds. This is the information in the log dumping memory usage, process info and more. It was creating 3 million lines per hour on some big customers so we decided clean some of the info. No more info about caches is dumped.

Windows GUI: Branch Explorer hanged doing refresh if 'display branch task info' was enabled under some rare circumstances. We were able to reproduce it doing tons of refreshes, but support reported that they forced it launching Branch Explorer from Unity several times. Now it is fixed.

Windows GUI: Fixed an exception when setting the move detection similarity percentage to its minimum value in the pending changes options dialog. Also, the similarity percentage label was not updated when the form was loaded. Now it's fixed.

DevOps preview is now public!

You have probably read about our effort to help companies implement DevOps successfully (Read more about the story of our DevOps Initiative here). Wait no more, the DevOps Initiative is now live!

== What is the DevOps Initiative all about ==

It is a new web interface inside the Plastic webadmin to monitor how branches are automatically merged when they meet a set of conditions.

This is the key fundamental to greatly considerably speed up the cycle of task branches and blends perfectly well with many development methodologies and best practices: SCRUM, Kanban, and more.

== mergebots – the heart of Plastic DevOps ==

The branches are processed and merged by mergebots.

A mergebot will automate the following manual tasks responsible for:

Detect when a branch is ready to be merged. It can be an attribute set to the branch or the associated Jira issue/ticket set to a given status.

Merge the branch to the destination branch (typically main, but it can be customized can be configured). Instead of actually merging to main, it will create a shelve, so the merge is not confirmed until tests pass.

Launch the build of the shelve in your Continuous Integration System. This will be your Jira, TeamCity or Bamboo (support for more systems is coming, and customization is possible).

If the build passes, the shelve will be "confirmed": It will be checkedin to the branch.

Notify of each step accordingly using email or Slack.

== We include a default mergebot, but more are coming ==

This version includes a default mergebot capable of doing "branch per task" together with trunk-based development. All the information about how it works is included in the web interface, so you just have to go to the DevOps section of the webadmin and discover how it works.

Our goal is to work with teams like yours to develop more mergebots tailored to your specific needs, so, if you are interested in trying it out and want to some guidance, please don’t hesitate and reach us at support@codicesoftware.com.

== One more thing ;-) ==

The Plastic SCM server now is capable of merging files. This is in fact required for the mergebot to be truly effective. It means if a file was modified by two developers, the mergebot can merge it if manual intervention is not required.

To reduce the chances of manual intervention, the Plastic SCM server is now powered by SemanticMerge, which means many conflicts that text-based tools consider manual, can now be automatic.

Yes, as awesome as it sounds.

REMARK: to enable this feature, you will have to write the following entry in the server.conf server config file:

Windows GUI: Branch Explorer hanged doing refresh if 'display branch task info' was enabled under some rare circumstances. We were able to reproduce it doing tons of refreshes, but support reported that they forced it launching Branch Explorer from Unity several times. Now it is fixed.

Windows Gluon: Support Ctrl+Backspace to delete the previous word in Gluon textboxes.

WebUI: The File Explorer branch/label selector now includes a date filter to fine tune the server query.

Gluon, Plastic and Mergetool for Linux (GTK): From now on, launching these applications from a terminal won't show annoying debug warning messages. stderr was redirected to /dev/null in the launching scripts located in /usr/bin:

filetypes.conf is now used for diffs and merges to check if a file is binary or text.

Until now, the filetypes.conf configuration file was only used by the "add operation" to set newly added files as binary or text.

From now on it will be used to determine if a file is binary or text before running diffs or merges.

Example: suppose scene.config was wrongly added as binary. You can now configure filetypes.conf to consider scene.config as text, so the right text-based diff and merge tool will be selected instead of considering the "bin type" tracked for the file in the repo.

This is really useful when you are working with Plastic Cloud, since changing revision types is not allowed there.

Our goal is to get rid of the bin/txt tracking as metadata in the repo, and rely only on filetypes.conf.

WebAdmin: The upload license funcionality did not work. Now it's fixed.

With the new localization system released few days ago, the windows GUI complained about not finding the localization file if the language of the operating system was different than English or Spanish. Now it's fixed. The English localization will be used by default until we have more translations.

Fixed the message displayed in the diff viewer when a file changed the encoding. The message was wrongly displayed as 'Encoding changed from {0} to {1}'. Now it's fixed.

Gluon Windows: Under some circumstances, the changesets view was displaying an unexpected error when loading. Now it's fixed.

Plastic Windows: The pending changes options dialog did not display a form title when it was displayed. Now it's fixed.

Command Line Client: The 'cm unlock' command can now be executed by non-administrator users to unlock their locks (locks whose owner matches with the user that executes the command).

The owner of a lock can be checked in the second column of the 'cm listlocks' command output.

TeamCity Plugin: We improved the VCS Root polling performance by avoiding checks of branches whose head hasn't changed since last polling interval.

Gluon/Plastic for Windows: Improved the automatic change detection. The view is autorefreshed when the window or view is activated, but only if something changed in the workspace since the last refresh.

Gluon/Plastic for Gtk: Added auto-refresh option. Open the checkin/pending changes view options to enable auto-refresh. If enabled, the checkin/pending changes view is autorefreshed when the window or view is activated, but only if something changed in the workspace since the last refresh.

WebUI: We added links to column values in the Changesets and Labels tables.

Each changeset row includes a link to diff the changeset in the changeset number and a link to diff the changeset branch in the branch name, whereas each labels row includes a link to browse the repository in the label name and a link to diff the labeled changeset in the changeset number.

Windows GUI: Some buttons were cut on certain dpi resolutions. Now it's fixed. Controls fixed:

The workspace status bar refresh button

The textbox on the item's view search popup control.

TeamCity Plugin: Add support for the multiline changeset comments.

WebUI: The diffs for java, c and c++ files were not working since we published semantic diffs. Finally it's fixed and you can enjoy both, text and semantic diffs!

Server: We fixed a bug that prevented user info from being refreshed after an unexisting user was used. It only happened if the server was configured in LDAP Working Mode against an ActiveDirectory server. This bug was introduced in version 7.0.16.2505.

Moved the localization of the Linux, OS X and part of the Windows GUIs from the code to a .txt file. It means it will be super easy to translate Linux and OS X to French, German... whatever :)

WebUI: We added a toggle in the Branches List to allow you to select which kind of date filter you wish to apply. You can either filter by date using either the branches timestamp or the timestamp of the changesets in each branch!

The temporary path used by the Plastic SCM Server can be configured now. You just need to set the appropriate value in the 'TmpPath' property (edit the 'server.conf' file in the server binaries directory); you might need to add it if it's not present. If no custom temporary path is set, the OS tmp path value will be used.

CLI: Executing 'cm partial ci' caused the client to return the error message "Object reference not set to an instance of an object" because it didn't support added xlinks as part of the set of changes to checkin.

To fix this, we improved the 'cm partial ci' command so that it supports added xlinks!

WebUI: We've refurbished the Code Review view, give it a try! It now includes semantic information and displays differences as you're used to in Plastic SCM: rolling blocks of changes.

WebUI: We removed pagination from the File Explorer. We consider that it's generally more useful to have the complete list of files without pagination.

Linux (GTK) and macOS GUIs: Improved the performance of the checkin operation from the GUI for big checkins involving a lot of items. Some users reported troubles with checkins of more than half a million items. For such big operations, the GUI was having trouble calculating the items to include in the checkin operation, and their dependencies. Now, the checkin operation should start almost immediately after clicking the "Checkin" button. The time it took for the GUI to do the necessary operations grew up exponentially depending on the number of items on the Pending Changes view, so it is hard for us to give an accurate speedup. Our tests (using a workspace of ~900K items) concluded that the fix would reduce the time before the checkin actually starts from several hours (up to two and a half!) to a mere four seconds.

Plastic for Linux: Diffs are editable in the pending changes view. You can edit the right textbox, and then save (Ctrl+S) or discard the changes.

We also added two button bars that allows to delete/restore differences between left and right contributors.

Diff are also editable in the diff window, but only when you're displaying the same file version on the right textbox that you're loading in your workspace.

WebUI: History is available! You'll now find a "History" button next to the "Download" one when you browse the File explorer and click any file to display its contents. You'll see a table with all revisions of that file, and you'll be able to diff any given revision with the previous one in the server! Isn't that nice?

CLI: We fixed a stack overflow error that caused the 'ls' command to crash when the workspace contained symlinks with either direct (a -> a) or indirect (a -> b -> a) recursion.

WebUI: Added support for submodules. Before this release, submodules weren't detected as valid repositories in the WebUI, but that's changed! Feel free to browse repository contents, list branches or diff changesets in your submodules as you did for your root repositories! Just keep in mind that the submodule slashes in WebUI URLs will need to be URL-encoded (e.g. 'rootRepo%2FmySubmodule' instead of 'rootRepo/mySubmodule') at the moment.

Windows GUI: When the configuration file 'guivisualstate.xml' got corrupted, the user got a stupid message saying "Error loading views info" and that's all, plastic didn't open.

From now, a more informative message will be displayed and plastic will be auto recovered. The corrupt file will be discarded and a new one created.

WebUI: We broke the diffs for non-semantic files in the last published release where we announced semantic diffs :( Sorry for the inconveniences. Now it's fixed!

WebUI: The main branch of a repository, used in the File Explorer, will be requested to the server instead of just assuming that it's '/main'.

WebUI: Navigating directly to a repository URI (/webui/repos/:repoName) will now open the file explorer set to the main branch of that repository.

WebUI: Xlinks are now resolved and users can navigate inside them in the file explorer.

WebUI: Binary files can now have their metadata displayed on diff and content controls!

JIRA Extension: now you can filter the issues the JIRA extension retrieves by their type. This is useful, for example, if you only want to see in Plastic SCM "Bug" or "Task" issues, filtering out the rest.

To configure it on Windows, you can enter a comma-sepparated list of issue types under "Preferences > Issue trackers > Atlassian JIRA > Issue types".

If you are using GNU/Linux or macOS, you can copy and edit as you need the following line, and paste it in you jira.conf file (usually under $HOME/.plastic4/issuetrackers/host_port/allrepos):

WebUI: Say a big Hello to semantic capabilities in our diff view! We added a toggle button to switch back and forth between the Semantic Diff Mode and the Text Diff mode. Give it a spin!

WebUI: We added a new icon to identify Xlinks in the File explorer.

Windows GUI: Enhanced the performance of the repositories list. Until now, the GUI was trying to solve the name of the owner of each repository, which is useless, as it does not appear on the list. This could cause performance issues in some scenarios, such as with a slow LDAP server.

Server: UserInfoLoader. We catched a wild "An item with the same key has already been added" that could happen when a user is reloaded concurrently from the LDAP/AD. Should be fixed now.

WebUI: We fixed the horizontal scroll of side-by-side diff editors! They should now move appropriately now when you reveal the contents of really long lines.

WebAdmin: The User/Password authentication page was unable to redirect to the Edit User page if the targeted user name had any uppercase characters. Fixed.

WebAdmin: The confirmation dialog prompted to confirm the deletion of an user or group was always returning OK, even if the user clicked cancel. Fixed.

Server: Due to a trigger cache issue on a really uncommon scenario, the calls that use triggers (e.g. the push operation) could start failing with the error 'Explicit transaction expected, but found no transaction.' and continue failing until the server is restarted. Now it's fixed.

WebUI: Text files using encodings different from UTF-8 weren't properly rendered on the Diff/Content views. Fixed.

All GUIs: The "Similarity percentage" setting on the new Pending Changes options dialog was displayed wrongly. If you wanted to match moved files with at least a 90% of similarity, what was really happening is that the files were being matched with at most a 90% of differences, which is the opposite concept. Now it is fixed.

Windows GUIs (Plastic SCM and Gluon): The "Advanced Move Detection" tab on the new Pending Changes options dialog was removed because we found some issues with the precise tracking using the NTFS journal. We are working on bringing you this feature back as soon as possible.

WebUI: We added move detection to the side-by-side diff viewer! The moved regions will be painted in the editors with a lighter color and a new purple region in the splitter will appear joining them! Next step, allow you to put the regions side-by-side so you can easily see the differences :)

JIRA Extension: We added a new setting, "Use default proxy credentials". It automatically sets the proxy credentials with the default credentials for all JIRA extension connections. That will solve 407 errors for all users that have a proxy where they authenticate using the same credentials as the ones they use to authenticate in their domain.

Plastic and Gluon (all platforms): Improved the wait time in checkin/undo operations. Improved the background operation polling time from 500ms to 100ms. This will improve the overall performance of Plastic and Gluon, specially in Gtk and Mac.

LDAP integration: implemented a retry mechanism when creating a connection to LDAP to deal with network issues.

Also cached SID=>Name and Name=>SID to greatly reduce the number of requests to the LDAP server.

This affects to LDAP setups, whether they connect to pure LDAP servers or to Active Directories in LDAP mode.

Longer story: One of our heaviest loaded servers that uses a federated Active Directory for authentication but connects to it using LDAP instead of built-in AD (due to how the underlying infrastructure is). Sometimes the Plastic server failed to connect to the LDAP, causing spurious issues to users saying they couldn't be authenticated, and even more importantly to automated scripts (which wouldn't recover). This improvement should greatly reduce the load imposed on the LDAP server. Also, Plastic can now cope with retries when connecting to LDAP.

What you will see in the server log is something like:

Until it successfully reconnects.

Unity 3D plugin: Onboarding process on an already existing project improved in order to avoid unnecessary merge conflicts.

So far, there is no good way to -let's say- checkout sources from version control in Unity Editor.

The current way to proceed using Unity is to create an empty project, bind the project to Plastic SCM, type the repository name that contains the already existing game project, and click on "Apply all incoming changes" in "Version Control" tab.

But, even if the user selects to "do not perform automatic add" in the Unity preferences, the "ProjectSettings" folder will be marked as "added" when an empty project is bound to a VCS.

This fact will likely cause a merge conflict (EvilTwin conflict) when clicking "Apply all incoming changes", as "ProjectSettings" folder will probably exist on the repository already.

Now, the Plastic SCM Unity Plugin detects this scenario and skips adding the "ProjectSettings" folder when a new empty project is bound to a Plastic repo, and the "ProjectSettings" folder already exists on the repo.

When the user clicks on "Apply all incoming changes", the "ProjectSettings" folder in the repo will be downloaded.

REMARK: If the user edited any "ProjectSettings" file before applying all incoming changes, the files edited this way will be replaced by the server version. But don't worry: the local edited file will be backed up before by appending a ".private" suffix in the filename.

WebUI: The labels table now includes a new action button for each row to display the repository contents in that label.

WebUI: The server returned 404 Not Found for URL paths that ended with a file extension. This was harming the File Explorer user experience because users weren't unable to directly access files to display their contents. URLs like http://plastic.myorg.com:7178/webui/repos/myrepo/branch/main/content/src/main.js were broken until now.

Windows and OS X diff: the differences inside moved blocks were not painted in the file text diffs. Now it's fixed.

Windows: When the attributes combobox had upper and lowercase values, for example 'resolved' and 'RESOLVED', it did not update the values correctly in some scenarios. Now it's fixed.

GUI: Deleting an already deleted branch failed with a null-reference error. Now it says that the branch doesn't exist instead.

This could happen in the following case:

John & Robert open the branch explorer view.

John deletes the branch /main/task1

Robert also tries to delete the branch /main/task, but it fails with the null-reference error.

Jet storage: we protected a corner case that could lead to server crashes (super strange, very unlikely you experienced this).

Jet high-perf mode extensively uses memory mapped files (in all operating systems). We found that there could be a race condition that made metadata reads access to non existing data (basically outside the mapping range) crashing the server.

Jet has been serving all our heaviest loaded servers around the world seamlessly, but we had a crash last week in one of them, and we are looking into all possible causes to prevent it from happening again.

Linux and OS X: Showing the differences of a symlink whose destination was itself failed with message 'Error 31'. The difference resolution process was endlessly trying to solve the symlink instead of just showing its target path. We fixed it so the differences of the symlink now show the symlink target path.

Server: UserInfoLoader. We caught a wild "An item with the same key has already been added" that could happen when a user is reloaded concurrently from the LDAP/AD. Should be fixed now.

Gluon (Linux, Windows, OS X): Improved checkout operation with locks: now it asks the user if they want to skip the locked files and checkout the rest.

WebUI: The view filter contents will be saved when navigating through the app. It means that setting a custom date filter in the branches view will still be there if you open a branch diff and then you go back to the branches view! This applies to text filters as well.

When the merge operation cannot apply some of the changes it was returning the error 'Some merge operations cannot be applied.' without any info about which changes cannot be applied. Now, the error message includes which changes cannot be applied and why.

Triggers: before-editreview and after-editreview:

Two new environment variables are available for the before and after editreview triggers regarding the review comments:

"PLASTIC_REVIEW_COMMENT" and "PLASTIC_REVIEW_COMMENT_ACTION".

The first one contains the comment that fired the trigger, and the second one reflects the action on the comment ("Created", "Edited", or "Deleted").

These variables will be empty if the action that fired the trigger is changing the code review status or the assignee.

This closes the following UserVoice request: Add environment variable for added/changed comment on edit review trigger

Gluon (Windows, Linux, OS X): New feature to load/unload files using patterns (e.g. *.png).

Now it is possible to load/unload files using patterns (e.g. *.jpg) using the search dialog in the Configuration view!

Just click the "search files" button (or CTRL-F) when your Workspace Explorer is in Configuration Mode. Then type patterns (*.jpg, *.psd, ...) in the search text box and then toggle (load/unload) all the search results.

Pro tip: Use Ctrl+A/Cmd+A to select all the nodes in the tree, and then use the space bar to toggle the load/unload status.

NOTE: we detected on Gluon for Windows that changing the load state of tons of files (more than 5000) severely harms the operation performance. The performance looking for Unity3D .meta files isn't great, either. We'll fix these issues ASAP.

Plastic for linux and mac: Added a new context menu option ("undo changes") to undo selected files in the pending changes view.

You now can multi-select a subset of files in the pending changes view, then right click and select "undo changes" for that selection.

Plastic and Gluon (all platforms): Completely redo the pending changes options dialog. We better classified the options, and each one is now self-explained. We also added new ones:

Compare file contents instead timestamp to determine changed files.

Move files similarity percentage.

Check if fswatcher/inotify is enabled and working and warn if not (only Windows and Linux).

Added a property to enable the "precise change tracking" based on the NTFS journal (only Windows).

WebUI: We added move detection to the side-by-side diff viewer! The moved regions will be painted in the editors with a lighter color and a new purple region in the splitter will appear joining them! Next step, allow you to put the regions side-by-side so you can easily see the differences :)

Mergetool: When the last line of any of the contributor doesn't have an 'end of line' (EOL) and it's involved in a conflict, the result file showed this line plus the next one on a single line. This issue only happened when the EOL is not ignored by the comparison method. Now it's fixed

We fixed a scenario where changesets were created without data in the repository. This happened when the result of a checkin operation couldn't be saved on the workspace because the workspace metadata files were unavailable (e.g. the antivirus locked the plastic.wktree). It caused the server to keep only changeset information, discarding the content of the files. Now we ensure that when a changeset is created on the server, its data is also there.

We fixed an issue in complex recursive merge scenarios that could store incorrect item traceability data, potentially causing the checkin operation to fail on some backends.

This issue could be reproduced when a directory path was reused during a recursive merge. This means that a directory is deleted and then another one is added using the same path. The new directory had to have part of the contents of the old directory, and some of the old directory children had to be changed in any of the ancestors. If all these conditions were met, the stored revision ID in the merge traceability for that new directory could be wrong, set to a large negative number: the virtual revision ID used during the merge resolution.

At that point, some backends failed when they stored that virtual revision ID if the merge changes were checked in.

WebUI: The server returned 404 Not Found for URL paths that ended with a file extension. This was harming the File Explorer user experience because users weren't unable to directly access files to display their contents. URLs like http://plastic.myorg.com:7178/webui/repos/myrepo/branch/main/content/src/main.js were broken until now.

Windows and OS X diff: the differences inside moved blocks were not painted in the file text diffs. Now it's fixed.

Windows: When the attributes combobox had upper and lowercase values, for example 'resolved' and 'RESOLVED', it did not update the values correctly in some scenarios. Now it's fixed.

WebUI diff: Xlink changes are now supported. Added/changed/deleted xlinks will be properly displayed in the diff view when selected. Also, changed items inside xlinks were fixed.

WebUI: We added navigation to the side-by-side diff viewer! A small control will appear above the two editors displaying the currently focused difference, the total number of differences and buttons to navigate through them. Enjoy!

OS X GUI: Dynamic views didn't show any progress while running background operations. Now it's fixed.

We called dynamic views those that are displayed on the right side of the main view: history view, annotate view, browse repository view, shelves view...

Shelve operation: we fixed an issue that caused shelved changes to be deleted, even if they were applied later on, in some uncommon scenarios. We bumped into this issue when a shelve created from a cherry pick (i.e. cherry-picking a changeset and choosing to undo the changes after shelve) had the source changeset of the cherry-pick deleted. It happened to all files that were modified only on source. The problem was caused by the changeset where the shelve was applied because it reused the data of the deleted one. When the cherry-pick source changeset was deleted the data was no longer available.

Switch workspace to branch A

Change foo.c and check it in -> this creates changeset X

Switch workspace to branch B

Cherry pick changeset X from branch A to branch B, but don't check it in

Shelve the current workspace changes enabling the option 'Undo these changes in the workspace after shelving them' -> This creates shelve Y

Apply shelve Y to the workspace

Checkin (in branch B) -> This creates changeset Z

Delete changeset X (in branch A)

Show differences of changeset Z. We notice that changes of that foo.c file are missing. An error message 'Cannot download revision {revId} from server...' is displayed.

Jet backend: The server returned the error message "The given key was not present in the dictionary" when the first write operation in a repository was started by a server-side merge that only contained the merge link (no changed items). Now it's fixed.

Mergetool: When the last line of any of the contributor doesn't have an 'end of line' (EOL) and it's involved in a conflict, the result file showed this line plus the next one on a single line. This issue only happened when the EOL is not ignored by the comparison method. Now it's fixed

Gluon for Windows: The app no longer closes when it detects that the configured server requires a higher client version. You'll just be prompted with a warning message but you'll be able to navigate through the GUI when you dismiss it.

Windows GUI and CLI tool: improved shared workspaces integrity. Now, the workspaces can be safely shared among several different users (for example, through a network drive), thanks to changes in the way Plastic SCM guarantees the integrity of the files inside the .plastic directory.

WebUI: The labels view is now unlocked in the WebUI! You can now check the labels in your repositories from your favorite browser :)

Linux GUI: Added copy/cut/paste options to the diff textbox in the pending changes view and the diff view. Note that the cut and paste options are only enabled when the textbox is not read-only.

WebUI: The file explorer view is now unlocked in the WebUI! You can now browse the repository of any branch, label or changeset from your favorite browser :)

Also you can see the content of the files. We will be adding more functionality to this view in the next days, so stay tuned :)

WebUI: We've improved the diff changeset/branch UI. Now it has proper syntax highlight and the files are displayed side-by-side in a compact fashion, just like our desktop GUI does. This translates into a smoother navigation because it doesn't insert empty blocks to compensate for added-deleted lines! We're also working in applying this layout to the code review diffs, so stay tuned :)

before-clientcheckin trigger: now, the PLASTIC_PENDING_MERGE_LINKS environment variable includes the information about the merge links affecting the repositories under a xlink, and not just the merge link of the repository where the checkin occurs.

Bear in mind that, as always, the before-clientcheckin trigger will execute once per affected repository under a xlink, and then once again for the repository where the checkin occurs. If you don't want this to happen, you can add a filter. You can learn more about trigger filters here: https://www.plasticscm.com/documentation/triggers/plastic-scm-version-control-triggers-guide.shtml

Windows GUI: When the Plastic SCM server is down, the GUI displays a red notification bar saying that the license information cannot be obtained.

The red bar stays for 1 hour before refreshing, so even if the server is up again (or reachable), the GUI would continue to show the error message.

Now the GUI will try to reconnect every 60 seconds instead. Also, we added a "try again now" action link.

WebUI: We added a text box to filter the diff list entries. You will find it in the diff view, it's really helpful when there are dozens of changes in the diff list!

Path based security: We added the ability to grant read access to a subtree of a repository easily (without worrying about its parents). This is useful when you want to give access to a user or group to only one subdirectory but not the entire tree.

Remark: this is a server-side feature. You need to update your server to take advantage of it.

Consider the following structure:

We want James (our external contributor) to download '/game/art', but not the rest of the repo.

Deny James all permissions for path '/'

Remove 'Denied' read permission for him, overriding it in path '/game/art'.

After that, James will only see these items:

Merge operations deleted all contents of a directory, even private files, when the directory was deleted as a result of the merge. Now, private and changed files inside the deleted directory will be preserved to ensure that no local changes are lost.

Windows GUI: The "select merge contributor" in merge view for automatic conflicts was enabled, and made no sense. Now it's fixed.

Gluon for Windows: The app no longer closes when it detects that the configured server requires a higher client version. You'll just be prompted with a warning message but you'll be able to navigate through the GUI when you dismiss it.

Windows: fixed an issue in workspaces shared by different developers on a shared computer.

Short explanation: to update files inside .plastic we first wrote them to the user's tmp dir, then moved. It caused ACL issues under certain conditions.

John did a checkin in c:\workspaces\gamedemo. Then logged out.

Now Mike tries to update and gets a weird "can't access plastic.wktree" error.

Why? Because the shared path c:\workspaces\gamedemo directory has been configured to have read/write access to the entire "devel"

We changed the way in which we write workspace metadata files inside the .plastic directory.

All platforms: Improved the help message that is displayed when a binary file is selected in the pending changes view. Now it suggest to use the "external diff viewer" (if configured) to see diffs of binary files.

Linux/Mac: We improved the pending changes/checkin views refresh behavior to avoid accidental checkins. Until now, these views stole the focus from the comment text area when the refresh operation finished, then setting the checkin button as the focused element! That caused undesired checkins, for instance when a user was typing their next checkin comment with a refresh operation running in the background.

Windows: In some Remote Desktop scenarios, or after playing with the windows screen config, the SyntaxEditor (diff) crashed with a "The specified Visual is not a descendant of this Visual" exception. Now it's fixed.

Windows/OSX/Linux Gluon: The details panel (from the 'Explore Workspace' or 'Checkin changes' tab) threw an exception 'You don't have permissions for operation read.' when any revision of the selected file was created in a branch for which the current user doesn't have read permissions. Fixed.

Gluon mac: Added a --view argument to open gluon from the command line showing an specific view. Examples:

gluon --view=CheckinView

gluon --view=ChangesetsView

gluon --view=WorkspaceExplorerView

gluon --view=WorkspaceConfigurationView

UnityPlugin (OS X): Enabled the "Select loaded Assets" button in the "Version Control" tab, to allow users to select loaded assets when working in Gluon mode.

The fast-update operation failed when file system permissions of a directory were changed. Now it's fixed.

The merge operation failed with the error '{path} is not in a workspace' when it had to apply changes under a cloaked directory that was loaded previously on disk at some point (i.e. has out-of-date contents), and those changes are now under a different path.

Windows: Plastic got stuck when displaying the form to get archived revisions on disk. Now it's fixed.

Windows gluon: Selected checkboxes seemed disabled due to a grey color. Use normal color instead.

The new WebUI preview is available now!

We have been working on the foundation of a new web interface. Long-term users probably remember (and some even use) the original WebUI. It looks good and works well, but it is known to be hard to deploy.

That's precisely why we created the new version, which is based on the same infrastructure that we used for the WebAdmin; every Plastic SCM server can open the web interface without any further configuration.

The WebUI is currently in preview; it includes only basic functionality focused around code review. You can list branches and changesets and create code reviews for them.

We have created the new interface from scratch, based on modern web tech (JavaScript front-end with VueJS) and our goal is to continue building on top of it.

Stay tuned for new features and remember, we welcome all feedback!

To access the WebUI, just go to http://localhost:7178/webui/repos (or replace 'localhost' with the host name of your Plastic SCM Server instance). Make sure your server.conf file doesn't include a StartWebAdminTool entry set to false!

Note: It only works if your server is configured in LDAP or User Password working modes (it requires a username and password to login).

Windows GUI: The expanded directories, selected file, and scroll position was not correctly restored when you closed the Workspace Explorer view, and then closed Plastic. Now this configuration is saved to a config file called plastic.uisettings.conf.

Linux GUI and Gluon: Now both applications remember certain UI settings, such as the width, position, sorted column and order for all trees/lists views.

OS X and Linux GUIs: We found a failing case solving directory conflicts inside level-2 or deeper xlinks (a xlink inside a xlink inside the main repository) when picking the source changes (discarding the delete). Now it's fixed. Example:

Windows GUI: After refreshing the items view, the tree was collapsed and expanded again, creating a noisy UI experience. Now it's fixed.

We fixed a bug in rule matching, which affected the ignore, cloaked, hidden changes and readonly/writable rules. To illustrate this with an example, the rule '/game//tests/coverage/**' was incorrectly matching directory '/game//tests/coverage' but it should only ignore its contents. Now it's fixed.

The "undo unchanged" operation didn't handle the exclusive checkouts correctly. Fixed.

John checks out /branch.png, which is locked as a result (exclusive checkout)

Kate locally modifies /branch.png (no checkout)

Kate performs the "undo unchanged" operation to /branch.png

At this point, the operation left /branch.png as checked out for Kate, which was incorrect

We corrected this behavior so that /branch.png wouldn't be affected by either the "undo unchanged" (because it was changed) or the checkout (it can't be checked out because it's locked by John).

Diff performance: Improved calculation of moved text. Now it's about 10 times faster.

OS X checkin: we fixed an ugly and weird crash during checkin.

The crash was reported by several OS X users during the last 2 weeks, and we were finally able to fix it.

Users tried to checkin from command line or GUI, and Plastic crashed.

Then the adventure started:

First we were unable to reproduce it, although we spent several days on it.

Finally, after a couple of online meetings with customers, we found it only seemed to happen with low memory and on a real laptop, not a virtual machine as we were doing.

We upgraded Xamarin on our build machine from 4.0.0.216 to 4.4.1.193 because we initially thought the issue was fixed by a newer Mono. During testing we discovered that it failed much less often than before, but it still failed. We released 7.0.16.2306 just to mitigate the problem temporarily.

We started thinking it should be a GC issue. So we contacted Microsoft.

After some investigation, they told us that the issue seemed to be in the way we invoke zlib to compress files before sending to server.

Finally, and thanks to the detailed report from the Mono developer, we think the issue is gone.

It happened because we invoked zlib.compress2 passing an output buffer as large as the input buffer, then we handled Z_BUF_ERROR in case compression couldn't improve the original fragment size. Well, docu says the output buffer must be at least 1% + 12 bytes bigger than the original. We did that, and now it doesn't crash anymore.

The weird thing is that this code has been there for 10 years. Billions of files have been compressed using this code on Windows, Linux and OS X over the years. At this point we think it might be due to an upgrade from the older zlib 1.2.8 to 1.2.11 on latest OS X.

Special thanks to Vlad Brezae from Microsoft, who debugged Mono and pointed the issue and solution in the zlib client code.

OS X: Line numbers on diff viewer were not visible for moved regions. Now it's fixed.

File locking and LDAP/Active Directory: now we show the name of the user holding the log instead of the SID.

Historically, we displayed the SID, which was not very useful... Yes, shame on us hackers :'(

OS X: Now built-in semantic diffs fallback to text if files can't be parsed.

It also displays the error error message so you know what to do.

It happened often when semantic diff tried to parse Java files but the Java VM was not installed.

'cm crypt' can now handle * chars. Before it was trying to expand wildcards on the arguments, preventing it from correctly encrypting text with '*' symbols. Fixed.

Very weird null fixed in replica when the maximum number of licensed users was exceeded.

It was almost impossible to reproduce but we saw a "null object reference" when trying to replicate a branch and the maximum number of licensed users was exceeded. The null showed up instead of the real license issue. Now it's fixed.

OS X GUI: Pending Changes crashed when it was about to show the diffs for a file and the diff was undone (changes undone outside Plastic).

It happened because any unhandled exception makes the OS X UI crash. We reviewed all pending failure points.

OS X: Upgraded to newest Xamarin.

Two customers reported a crash doing a checkin in a laptop running out of memory.

We were finally able to reproduce it and found that a newer Xamarin reduced the chances of crashing.

The problem is not entirely fixed, we are working with Microsoft to solve what seems to be a Mono garbage collector crash.

Fixed a null in checkin related to Xlinks and security.

Here goes the full explanation, which is not trivial:

You need a workspace to a repo that has an Xlink.

You don't have checkin permission on the Xlinked repo (permission not granted, which doesn't mean it is denied).

You merge from a branch with changes on the Xlinked repo (someone else made the changes, since you don't have permission).

Now you try to merge and the null happens (object reference not set...)

OS X GUI: update forced didn't clean up the dialog correctly.

Plastic shows a dialog if an update finds issues.

The dialog shows 2 options: "retry update" and "update forced".

If you select all the issues and click "update forced" the "Issues" view wasn't cleaned.

Windows, linux, mac: In the diff viewer, when the text encoding changed between two versions of a file, now we display the old and the new encoding, instead "encoding changed".

Windows Installer: Added long path support for both Plastic and Gluon in Windows 10. Note that you may need to update your computer policy as described here

REMARKS: In case you already customized the plastic.exe.config file, a backup file named plastic.exe.config.installer.backup will be generated in the PlasticSCM "client" install folder.

Windows, linux, mac: Do not show the file content for big added/private files in then pending changes view and the diff viewer.

Big files are considered 2Mb by default. You can change this value adding/editing a property in the mergetool.conf file. For example, if you want a file to be considered as big when it's bigger than 50Mb, you need to specify the following in the mergetool.conf file.

big_file_size=52428800

Unity plugin: Now, the "UnityPackageManager" folder is considered for versioning, as Unity2017.2 requires according to the following info.

The "Packages" folder will also be considered. This means both folders and their contents will appear in the "Pending changes" view of "Version Control" window in Unity when they contain any change.

Mac: Now diffs are semantic by default for supported file types (C#, vb.net and Java)

2D version tree: make the changeset double click consistent. From now on, it will always be "Diff Changeset" (default changeset action).

Polarion extension: Fixed a null reference exception that seldom appeared when retrieving the task information of a branch.

There were no error notifications for the user when a null reference exception was caught in a thread operation. It was logged but not displayed. Now, it's fixed!

The fix affects to all platforms (Windows, OS X, Linux) and Gluon.

Undoing all changes in the Pending Changes view failed when a given item was deleted and copied during a merge operation at the same time. The message 'An item with the same key has already been added' appeared in an error dialog. Now it's fixed.

Linux CLI: The "cm diff" from the command line in a non-existing directory failed with a "path null" error. Now it's fixed.

Linux, mac: Syntax highlight was not correctly enabled on the pending changes view and the diff view. Now it's fixed.

Windows: The "Workspace Explorer" went blank and ugly if you clicked on it during update or checkin. Now it's fixed.

Windows: The file size in the Workspace Explorer for changed files was wrong. The value was get from the server revision size. Fixed by reading the disk file size instead.

Browsing the contents of a repository in a given changeset or branch failed with a null reference exception if the browsed tree contained an Xlink whose repository was unreachable. Fixed.

Windows, Linux, and Mac OS: Now it is possible to undo changed files in the 'Items' view (a.k.a. 'Workspace Explorer' view).

Windows: Sometimes, the proxy server configuration was not displayed in the configuration window altough it was correctly configured it in the client.conf file. Now it's fixed.

On the following scenario, the 'merge' operation was wrongly checking out a locally changed file although the exclusive checkout could not be acquired. Now it's fixed and the checkout is not done.

The repository is configured to require exclusive checkouts (locks) for .png files

User A and user B have their workspaces pointing to the latest changeset of '/main' branch (both are up-to-date)

User A modifies & checks-in foo.png file.

User B modifies foo.png file (without performing a checkout).

User B: the pending changes view shows a notification telling that there are new changes on the server and gets the new changes from the server.

The merge from the head changes fails because the merge cannot checkout foo.png to merge its content. But after the error, foo.png file is wrongly checked-out.

Windows: The filetypes.conf file could contain usage comments in spanish language, even if the english language was configured. Now it's fixed.

Windows: Diff dialog: Fixed the following scenario:

Select a changeset from the 'Branch Explorer' view.

Select "Browse repository on this changeset" on the context menu.

Select a file on the items view.

Selected 'Diff' >> 'Diff revisions...' on the context menu. A dialog will appear to diff the selected revision with the workspace revision.

Click ok -> An error appears. The branch name of the target revision was not well formed. Now it's fixed.

Windows: Branch Explorer: after a redesign we made a few weeks ago, many users reported that the option tab displayed when restarting Plastic was not the right one.

We also realized the zoom level was not stored correctly.

We fixed both things and refactored the code that stored BrEx visual settings.

When a big added file was selected in the pending changes view, the application gets hung for a couple of seconds. Now, it's fixed!

This fix applies to all platforms (Windows, OS X, Linux) and Gluon.

Now the server-side merge (preview feature) can apply an existing shelve.

cm merge sh:2 --to=br:/main --merge

If that shelve was created using the server-side merge (so it contains merge traceability info) and it's applied on the same destination than the original merge, the created changeset will include merge traceability from the original merge. What this is mean:

Using the server-side merge, we perform a merge from changeset 5 (br:/main/task head) to changeset 10 (br:/main head), leaving the result on the shelve 2.

Using the server-side merge, we apply the shelve 2 on the changeset 10, creating the changeset 11.

The changeset 11 will include a merge link from changeset 5 and all info about the changes done on that merge. The same merge traceability that if we merge the changeset 5 to the changeset 10 directly without using the intermediate shelve.

Additionally, the merge operation can now ensure that there are no changes on the destination contributor (because the ancestor and the destination contributor are the same) using the option '--no-dst-changes'. This option is particularly useful to ensure that the destination branch head is the same one that was there when the shelve was created. It also ensures that the original merge traceability can be applied.

cm merge sh:2 --to=br:/main --merge --no-dst-changes

Gluon UI: Switching a workspace between gluon and standard modes could easily leave an out-of-date directories configuration. Now, the directories configuration is automatically restored by the gluon update when switching from a workspace in standard mode. This way, new files in the repository are automatically downloaded from Gluon again.

Windows GUI: we have made more improvements to the 2D version tree!

Now when you launch it with no options selected ("version tree" options in Branch Explorer without "filter only parents" or "Display all merges in history", the diagram will be much more compact than it used to be.

It is a simplified graph, much easier to understand :)

In addition to that, there will be no nodes without parent in the graph anymore, so you will be able to navigate through the history from any node.

Fixed a few texts in Gluon merge after editor review :-)

Windows GUI: fixed a regression introduced in 7.0.16.2237 related to modal dialog without parent window.

The fix we made didn't take into account that an intermediate modal dialog could be displayed, and failed when that happened, hanging the GUI.

Pepper is working on workspace 1 updated to latest on main.

Tony on workspace 2 checkins foo.prefab.

Pepper doesn't have last change on foo.prefab.

Pepper modifies foo.prefab without checking out (and forgetting to claim the lock).

Now Pepper wants to update:

** She has the following setting turned on: "Preferences" panel --> Other options --> Behavior when updating workspace with changed items --> Allow.

** She is asked to merge during update, because of colliding changes.

** Plastic tries to lock foo.prefab, but it can't because it is not in HEAD version, it tries to show an error message, but it fails due to the bug with the modal dialogs shown above.

GitSync failed with the error 'An item with the same key has already been added' when two different Plastic SCM branches had their names translated to the same git branch name. We have fixed it so the second branch adds a numeric suffix ('${branchName}-0', '${branchName}-1', ...) to the git branch name, which solves the duplicate key issue.

Both names of Plastic branches '/main/task wksp' and '/main/task-wksp' were translated to the same git branch name: 'master-task-wksp', causing GitSync to fail. After this fix, they will be translated to 'master-task-wksp' and 'master-task-wksp-0'.

Configuration to merge Unity files on Windows: Added "SmartMerge" support out-of-the-box for new installations:

.prefab and .unity files will use "UnityYAMLMerge.exe" (a.k.a "SmartMerge") to merge both contributor contents on a file during a merge

If SmartMerge requires manual conflict resolution, it will fallback to regular PlasticSCM text mergetool.

.meta files will use Plastic SCM regular text mergetool too.

The Unity SmartMerge configuration is hard-coded in Plastic SCM configuration. We assume that, if you are managing .prefab and .unity files, you will likely have Unity & SmartMerge installed

Attempting to merge a .prefab or .unity file will throw an error if SmartMerge application does not exist in expected install path:

If that happens, you will have to manually edit the SmartMerge path in Plastic SCM Merge Tool preferences.

More info about Unity Smart Merge can be found here

The branch, label, attribute and repository name cannot longer include the character \r nor the character \n on it.

SemanticSCM: Now, the 'skip format changes' and 'comparison method' options are updated according to the option selected by the user (e.g: if the user checks the 'skip format changes' option, the 'comparison method' is updated with the "Ignore EOL and whitespaces" value and vice versa).

Gluon: We redesigned the set of actions you're allowed to perform during long checkin operations:

The items tree will be locked in order to prevent checkboxes from being toggled (windows, linux, mac)

The Switch button will remain disabled during the checkin operation (windows, linux, mac)

The auto-refresh feature will be disabled while the checkin operation is still running (only windows)

We fixed the message displayed when there's an operation running (only windows)

Modified lock strategy during merge.

Now files that are copied to the workspace during merge but are not in conflict will not be checked out and hence locked.

As a result, merges from the head of the branch can be completed even if one of the files to copy from head is locked by another user.

This fix is relevant for teams where users do locking and merging no a single branch on the same repo. It won't be a problem if developers use branches or if binaries and code (typically art and code in games) are on separated repos.

== Scenario description ==

Jim touches CarBehavior.cs.

Meanwhile Tony checked in CarBehavior.cs.

Beth checkins Car.prefab and locks it again to continue working.

Now Jim wants to checkin CarBehavior.cs but requires a merge because Tony modified it too.

The merge requires Car.prefab to be downloaded, and the previous lock strategy tried to lock it. The merge couldn't proceed because the file was already locked.

== When was it modified previously ==

We modified the strategy back in 7.0.16.1857 (Dec 18th 2017) and this has created several issues with locks and merges.

Gluon can now merge files!

We just added merge capabilities to Gluon. So, now when files are in conflict during checkin, Gluon will launch the configured merge tool (same tool configured for regular Plastic) and help you solve the conflicts.

It works on the 3 platforms.

Mac OS GUI: the application crashed when the browse repository view was opened and closed several times. Fixed.

Gluon for Linux: Added a "switch to branch" button (next to the switch workspace button) that allows to switch the working branch in the current workspace.

The status performance (cm status & pending changes view) was improved to skip looking for non-ignored items under ignored paths when there are no exception rules in the ignored.conf file.

In a workspace with 30k ignored items out of 60k total, the cm status command runs 2 times faster.

Windows Gluon: when you disable the auto-refresh of Checkin Changes, it won't be refreshed when you switch tabs either.

Gluon: fixed renames involving only upper-case/lower-case.

The issue happened with Gluon on case-insensitive filesystems. The checkin of a case-sensitive rename (move Foo.c to foo.c) failed with the error "The item '/Foo.txt' cannot be moved to '/foo.c' because it is already loaded in the destination in the server. Please undo the move operation and update to the latest version".

But now it's fixed :-)

SemanticSCM: The differences were not calculated according to the "skip format changes" option in the diff viewer. Fixed.

The cm update --cloaked was not working. The --cloaked option was ignored. Fixed.

The server-side merge (in-preview) wasn't properly tracking changes on file system (FS) permissions when those were the only changes applied to an item (i.e. no content changes). This issues didn't make the server-side merge fail, but the differences of the resulting changeset didn't properly group the merge changes related to those FS permissions changes.

Windows GUI: there were cases where a modal dialog was displayed but it was not set as parent of the main window, so you could go outside plastic, return, and be unable to click on any action thinking it was frozen. It was fixed long ago but now we removed a few more corner cases.

Gluon auto-refresh pending changes is now configurable.

New option added to Pending Changes option, so that you can now configure whether you want to auto-refresh or not.

We fixed some server-side merge (in-preview) issues, detected in complex merge scenarios with moved items dependencies (related to cycle move conflict).

Diff/Mergetool: Disabled the auto case corrector language feature of the textbox -developed by ActiPro- in order to avoid unexpected behaviors when the editing occurs (e.g: restore difference using the action bar).

Windows GUI: The warning message shown by the switch operation with pending changes was not modal. Fixed.

The error message when trying to update with checkouts in a Gluon workspace was improved: "Cannot switch from a Gluon workspace to a standard one with checkouts. You can checkin from Gluon (or undo) and retry the update."

OS X and Linux GUI: We changed the Pending Changes "options button" behavior, so that it can always be clicked.

This means you can change the options while the pending changes is being refreshed.

This is useful if, for some reason, the Pending Changes takes forever, due to move detection, most likely. You can disable move detection before waiting for the search to finish.

Windows GUI: Some users reported that merge link colors in the Branch Explorer don't have enough contrast and they are not visible enough. Changed to use a stronger green.

Windows GUI: The GUI didn't show any error message when the update/switch operation failed. Fixed.

The error message when using the 'fast update' operation in a Gluon workspace was improved: "The 'fast update' option is not allowed in Gluon workspaces. Please disable the option and retry the operation again."

Now Plastic can switch a workspace to a shelve using the cm switch command (e.g. 'cm switch sh:2'). The workspace will load the shelve content in read-only mode, the same way a 'switch to label' does. This feature allows you to test and build temporary changes before committing, and it is essential for the devops initiative.

CodeBeamer issue tracker extension: Taking advantage of the new External SCM Integration capabilities of CodeBeamer, we added an option to log every checkin using that feature instead of just adding a comment to the affected issues. This increases traceability and provides a tighter integration with your issue tracker. Please make sure you're using a compatible CodeBeamer version before you enable it!

Windows GUI: From now on, we will automatically search for code moved between files in the diff window. If there are matches, you'll be notified.

We will only find refactors automatically if there are less than 50 files. Up to that, a button will appear to launch it, just as it did before. Please have in mind that analyzing refactors can be a time/resource consuming operation.

Linux GUI: We implemented a context menu for annotate/blame with the following actions:

Diff branch: Diffs the branch where the selected line was changed.

Diff changeset: Diffs the changeset where the selected line was last changed.

Annotate parent revision: Annotates the parent of the current revision.

Annotate before this changes: Annotates the changeset parent of the one where the selected line was changed. This is good to navigate back changes.

Add diff selection: Copies a text to the clipboard. Use diff with previous selection to diff with selected text.

Diff with previous selection: Diffs the previously selected text vs the current selection.

Annotate options: To configure the fields to show in the left pane (date, author, changeset, branch, etc ...)

Also you can use back and forward buttons to navigate between annotated versions.

Basically we applied to Linux the same changes we released for Mac a few versions ago.

Gluon: The error messages when trying to configure an item that is changed in the workspace were improved to give better information to the user.

The file 'voice/player.wav' cannot be loaded/unloaded because it is already changed at 'voice/player.wav'. Please undo the change and retry the operation.

The directory 'voice' cannot be loaded/unloaded because it contains changes inside 'voice'. Please undo all the changes inside the directory and retry the operation.

The root item cannot be loaded/unloaded because there are pending changes in the workspace. Please undo all the workspace changes and retry the operation.

The client update triggers (before & after) were only executed by the standard update operation. Now, they are also triggered by the 'fast-update' operation and the Gluon update.

We enhanced the server-side merge (preview feature) so it can create a shelve with the merge result instead of checking it in. This allows users to review the merge result before it's confirmed. To take advantage of this staged merge you just need to include the '--shelve' argument in the merge command.

cm merge br:/main/task --to=br:/main --merge --shelve

Now the shelve content can be checked using the diff command. Example: cm diff sh:2

TeamCity CI Plugin: Improved the format used by the branch filtering based on an external program.

The external program receives a JSON list of branches to filter from the stdin and returns a list with the actual branches that you want TeamCity to process in the stdout, also in JSON format.

The following is an example of a possible input and output if the external program just wants TeamCity to process DTC-14:

This way we basically enable users to create the custom filters they need, connect to their issue trackers, project management tools and the like.

We have published Java code implementing a custom filter here.

Gluon Mac: Added a "switch to branch" button (next to the switch workspace button) that allows switching the working branch in the current workspace.

We fixed some item merge-tracking issues in the server-side merge (in-preview), detected in complex merge scenarios. These issues didn't make the server-side merge fail, but the differences of the resulting changeset didn't properly group the merge changes.

We fixed a corner case merging an edited Xlink that threw a 'merge needed' message incorrectly.

The case happened if you had a common repository, let's say 'engine', xlinked by two repositories, GameA and GameB.

Each repository uses a custom main branch, /main/GameA and /main/GameB.

If the "engine" Xlink is edited manually in GameA to include engine changes that were performed in GameB (main/GameB@GameB)

And then the change is merged to main/GameA@GameA,

The checkin operation could throw a 'Merge needed' when no merge was needed.

Jenkins plugin: The parameters of the plastic workspace name were not correctly resolved. It means, it used the exact workspace name string (e.g. 'Jenkins-${JOB_NAME}-${NODE_NAME}') without resolving the parameters JOB_NAME and NODE_NAME (e.g. 'Jenkins-project-MASTER').

CLI: The 'cm revert' command of an xlinked item can be executed in any path. Before, it failed if executed outside the xlink path with the following error: "Object reference not set to an instance of an object."

OS X GUI: Implemented a context menu for annotate with the following actions:

Diff branch: diffs the branch where the selected line was changes.

Diff changeset: diffs the changeset where the selected line was changes.

Annotate parent revision: annotates the parent of the current annotated revision.

Annotate before these changes: annotates the changeset parent of the one where the selected line was changed. This is good to navigate back changes.

Add diff selection: copies a text to the clipboard. Use diff with previous selection to diff with selected text.

Diff with previous selection: diffs the previously selected text vs the current selection.

Annotate options: to configure the fields to show in the left pane (date, author, changeset, branch, etc ...)

Also you can use back and forward buttons to navigate between annotated versions.

Jenkins plugin: The Plastic SCM plugin can work with multiple plastic workspaces or just a single plastic workspace. Now, the jenkins workspace and the plastic workspace paths will match in the single workspace mode. Therefore, some jenkins features (such as pipeline shared libraries) that need both paths to match will correctly work.

Windows GUI: We changed the pending changes options behavior, so that it can always be invoked. This means you can change the options while the pending changes is being refreshed.

Command line: The merge-to command was not working outside a workspace. Fixed.

Windows GUI: 2D version tree is now able to filter only parents.

It means that you will only see changes that are related to the version you are loading.

You will find the new filtering option in the 'Version tree' options tab. By default, it's set to true.

This is the only option that depends on the working changeset. You will get different results depending on the changeset you are loading.

Overall performance of user and group reloads has been greatly improved since the reload is now a background operation, so users won't be affected by slow LDAPs or Active Directories during regular operation.

We fixed some server-side merge (in-preview) issues, detected in complex merge scenarios with reused paths.

Windows GUI and Gluon for Windows: Detected a performance downgrade in the pending changes view due to an interference of Windows Defender antivirus with the log files that Plastic GUI applications write.

This problem happens since release 7.0.16.2068. Now we have fixed the issue by updating the log configuration files for Plastic GUI, Gluon and Mergetool applications, removing the "MinimalLock" locking model. This way, Windows Defender antivirus won't be exhaustively analyzing the Plastic log files.

REMARKS: In case you already customized the plastic.log.conf, gluon.log.conf or mergetool.log.conf, a backup file will be generated with the ".installer.backup" suffix in the same folder.

Gluon for Windows: Using a Unity project, having checked out multiple regular file/meta file pairs, if you select/deselect a file, its meta file pair is updated accordingly. But, if the commit view was refreshed, the pair state was lost. So, the user saw the checkboxes state change automatically, without any user interaction. Now, it's fixed.

Windows GUI: Improved annotate view:

Redo the textbox context menus: Now use the same context menu for both annotated lines area and the file content area.

Reorganize information: We reorganized the information in the panel that shows the information (owner, changeset, branch, date and comments) of the selected line.

Windows GUI: Implemented a way to navigate annotates.

Added a new option in annotate context menu, "Annotate previous changes (parent of cs:xxx)". This options shows the annotated file of the parent changeset of selected line. This way you can go back in versions of a file to track a change.

We also added two buttons to navigate back/forward in the annotate history.

The goal of this task is to help finding where a given change was made.

TeamCity CI Plugin: Enable filtering active branches based on Plastic SCM attributes.

The goal is to test and merge task branches to main only when a given attribute is set. This way trunk-based development and DevOps can be easily implemented.

The recommended configuration for TeamCity build configuration is as follows:

Default branch to track in the VCS root is "/main".

Branch specification for branches to monitor besides the default one in the VCS root is "+:(/main/*)" (The parenthesis are very important, as they define the logical TeamCity branch name, and has to match with plastic full branch name!).

Enable the "Automatic merge" feature under the "Build features" section of the build configuration. Set the "Branch filter" to "+:*" so that TeamCity merges all that match the filter. Leave the other fields with the default values (the branches will be merged + checked-in to the default tracked branch "/main").

Add "VCS Trigger" in "Trigger" section of the build configuration. Set the "Branch filter" to "+:*" too.

When configuring the VCS root for a build configuration, a new section named "Plastic SCM advanced branch filtering" will show up.

Once it is enabled, a textbox allows filtering the candidate branches to be visible by TeamCity in two ways:

Example: status=resolved which means that only the branches with an attribute named "status" with the value "resolved" will be visible to TeamCity to queue & build them.

TeamCity CI Plugin: Enable branch filtering based on an external program.

When configuring the Plastic repository for TeamCity, a new checkbox named "Enable custom brach filtering" will appear.

Once it is enabled, a textbox allows specifying the command to run the branch filter and other textbox allows defining the environment variables to be passed to the filter (the format is key=value pair per line).

The external program will receive from TeamCity plugin a list of plastic branches serialized in JSON, and it is expected to return a filtered list serialized in JSON too.

An example of a list of just one plastic branch in JSON format is shown below:

This communication format has been modified in release 7.0.16.2220

This way we basically enable users to create the custom filters they need, connect to their issue trackers, project management tools and the like.

We have published Java code implementing a custom filter here.

Windows GUI: We use tmp files when displaying diffs, in both diff windows and pending changes view. We download the revision contents to a tmp files, so we can reuse them later. Sometimes a "Could not find file ''" error was displayed. Now it's fixed.

When clicking on individual changesets in the branch explorer, the info in the "Properties" panel updated instantaneously. However, it slowed down from version 7.0.16.1944, making the user to wait 0.5-1 seconds after each click for that information to update. Fixed.

TeamCity CI Plugin: The plugin was unable to diff changed files when browsing changed files in TeamCity dashboard. Fixed.

TeamCity does not handle moved status (but added/removed)

If a file was moved and changed in the same changeset, the teamcity plugin will show an error, as the queried path does not match with the new destination path. Will be fixed soon.

SQL Server and Branch Explorer: we protected a strange case where certain huge Branch Explorers (years of graphic) caused the data storage to throw the following exception:

'Cannot access destination table '#tmpe17c62c0fc2f46d2b1bbc2d1649e6fe0'

It seems it only happens when several branches are visible but their parent branches are not.

It is related to a Bulk Copy we use to speed up lookups under certain circumstances (most likely not being enabled in most cases).

We hope to make the life of one of our customers better with this fix :-)

Gluon for OS X: Fixed the preview generation for PDF files (and other non-image file types).

Windows GUI: When using plastic in spanish localization, the ok/cancel buttons were not visible in the "enter comment" dialog, when executing a "merge to" operation. Now it's fixed.

Gluon: If all the specified paths in the 'cm partial update' command are files inside the same xlink and the --changeset option is used, then the versions to download are searched in the specified changeset of the xlinked repository instead of using the top-level repository.

Some server-side-merge (in-preview) issues detected on complex merge scenarios have been fixed.

The fixed merge scenarios are related to:

An item that is moved on one contributor and deleted on the other plus other conflicts.

A deleted item in conflict plus an added item on the same path.

A deleted directory involved in multiple conflicts.

macOS GUI: Now, you can create new attributes directly from the GUI. To do so, click on the "Apply attributes" button on the right of the Branch Explorer, and click on the "Create" button next to the attribute list.

Windows GUI: we cleaned up the Branch Explorer view button layout.

We made a number of changes to try to make the Branch Explorer view cleaner.

Added a date picker for quick filter by date from the toolbar.

Added a push button to quick show/hide relevant changests from the toolbar.

Zoom and home buttons moved to the diagram's right-bottom corner.

Legend and keyboard shortcuts buttons moved to the help panel.

Navigator and statistics buttons moved to the "Display options" panel.

Bookmarks buttons aligned to right.

Right-align the options (details) button.

This should reduce cluttering and make it more usable :-)

Gluon for Windows now can switch branches.

It is very easy to use: just click the "Switch" in the bottom panel and choose the branch you want to switch to.

Of course, remember that locks don't blend well with branches (yet, we are working on it).

While the initial design of Gluon was "as an artist I don't want to see branches", world evolved since, and teams did too. The same team that asked us to develop Gluon originally (Telltale) now needs to switch branches easily. More to come in this area.

Gluon UI: The option '--restorefulldirs' was added to the 'partial configure' command. This option allows to reset the directory configuration in partial workspaces.

Check 'cm partial configure --help' for more info.

Gluon: New cm partial switch command allows to change the working branch of the workspace as long as there aren't local changes.

Check cm partial switch --help for more info.

Unity plugin: improved the checkout warning including a summary message to show the info related to the locked items. Now, the warning message can be easily read in the bottom bar.

(e.g: "PlasticSCM: Checkout: Unable to checkout Scene1.unity (locked by tester), BehaviourScript.cs (locked by validator)")

The cm mkwk command shows the usage and does nothing if it is not correctly invoked (for example, if we specify repo@server:8087 instead of --repository=repo@server:8087).

The server-side merge operation failed if the source contributor had deleted an item and a Xlink was added in the same path. Now it's fixed.

Unity plugin: the 'Gluon mode' setting is now automatically detected from the workspace on already existent projects.

(On new projects, if the 'Gluon mode' value is not set, the plugin will assume the workspace that has to be created is a non-gluon mode workspace).

Windows GUI: we made some changes in the tabs of the main window, including resizing and rewording.

We made the tabs adjust better to the title, so more text is readable now.

We also made a big change: "Items view" is gone and now we call it "Workspace Explorer". Hope this won't annoy old users, but we think "items view" is too abstract for many newcomers.

This will solve this User Voice Reduce tab text to fit within tab shapes

Now, a story about "items view": back in 2005 we named versioned files and directories "items". In fact, each version of a file or directory was called "revision" but in order to refer to the abstract object itself we called it "item". See what I mean? An item can have many revisions, each of them containing data (contents of a given file or the directory entries if the item is a directory). Item/revision is like class/object. We had this "item" concept so deep in our minds, that we kept the "design name" in the GUI. And it survived 13 years :-) Now it almost sounds ridiculous to us, but for a long time we didn't almost pronounce file&directory but "item". Fortunately, now we simply try to make things simpler for users :-)

When you try to cancel a replication operation that failed just while it was starting, the cancel failed with the error 'AssertFalse has found a positive condition'. Now it's fixed.

Jenkins plugin: In Blue Ocean, if a build included multiple changesets, only the first one was rendered in the details. Also, the info for the commit and timestamp columns were not filled. Fixed.

The merge-to operation failed under some circumstances when the merge included at least a deleted directory and a moved directory. This could happen only when the moved directory contained one item involved on the merge. Now it's fixed.

OS X GUI: A null value message was shown, in rare circumstances, during the merge. It didn't have any effect on the operation. It was only an issue in the progress notification. Now, it's fixed.

Windows GUI: we have done some improvements in the merge window after the new "merge-to" feature was implemented:

New title for "merge-to" with conflict resolution.

Handle the error when the server doesn't support thew new merge-to.

SemanticSCM: The semantic differences reported a parsing problem on launch when the source code parser was terminated. Fixed

Linux GUI: Fixed an index out of bounds exception when clicking the last line of an annotated file.

New feature in preview: server-side merge (or "merge-to" with conflict resolution, if you prefer).

To enable it: add this in your client.conf:

If you have been using Plastic for a while, chances are you are familiar with the "merge-to" feature. It lets you do "workspace less" merges. Like, you don't even have a workspace, but you can merge "main/task127" into "main".

But, merge-to had a big restriction: it only worked if there were no manual conflicts. As soon as a file had a conflict (even a simple one that could be fully automated), or a directory was in conflict, merge-to stopped.

Now this changed, and all type of conflicts, including file merges, can be resolved in merge-to.

The motivation behind the change? We are all moving towards more automated workflows where every single branch is tested before being merged. So, under that way of thinking, testing in your workspace first is not always necessary. We changed our minds here because, for years, we thought it was good to build and test your code locally prior to checkin the result of the merge, but DevOps and automation are changing all that, so now we feel confident of this merge-to with conflict resolution approach.

The feature is in preview at this point because is just out from the oven, but it will be enabled by default soon.

Linux GUI (Gtk): Now, you can create new attributes directly from the GUI. To do so, click on the "Apply attributes" button on the right of the Branch Explorer, and click on the "Create" button next to the attribute list.

Linux GUI: annotate is now ready (blame). Just right click a controlled item in the workspace explorer view, and select the "annotate" menu item.

Linux GUI: Load only the last 500 values of an attribute due to a performance issue with the dropdown control. Otherwise it takes forever to load. We tested with 30k values (reported by a customer) and it freezed for more than 30 secs.

GUI client apps (Plastic, Gluon and Mergetool) will now leave rolling log files in $HOME\.plastic4\logs folder. In case of windows, the folder path is %LOCALAPPDATA%\plastic4\logs\.

Those apps will generate an info log file with relevant telemetry and another log file with more details and debug info.

Server: Add support for OpenLDAP with the anonymous access disabled.

Windows GUI, Gluon, Linux and OS X: Remember the workspace base path between sessions. By default, PlasticSCM proposes the $HOME/wkspaces directory to create new workspaces. Now, if the user changes this directory, Plastic will remember the base path and will propose it for the next time.

TeamCity plugin: The auto-merge capability is now able to merge branches when the file conflicts are automatic. Before the fix, any file conflict (automatic or not) rejected the merge.

Changesets can't be deleted when there are shelves depending on them. However, the Jet backend incorrectly allowed this to happen. As a result, the dangling shelves became unusable (they couldn't be applied nor viewed). We've fixed this so this scenario of the 'delete changeset' operation won't happen anymore under Jet.

Jenkins plugin: Reduced the number of duplicated builds that can happen using the Plastic SCM plugin. Now, the scm polling takes into account the current build avoiding to start a new build for the same changeset.

Linux GUI: Fixed a "collection modified" exception when closing the annotate view.

The Bamboo plugin can now update Jira status based on the build & merge progress. The Jira task directly related to the branch being tested will be updated to reflect the actual status.

Example: when a build starts, the Jira 'status' workflow attribute can be set to 'Testing', then updated to 'Reopened', 'Closed' or even 'Merged' depending on the final result.

For further info about DevOps, trunk based development and task-per-branch check:

DevOps with Bamboo and Plastic

To configure this new feature, enable Monitor Jira to filter branches configuration field in Bamboo's Repository configuration. New textbox fields will appear to set the status of the Jira issue with a desired value when Bamboo triggers the following events:

A plan branch starts its build plan

A plan branch build fails

A plan branch build succeeds

A plan branch is automatically merged (only if gatekeeper automatic merge feature is enabled).

The allowed values for these fields are <issue_status>

REMARK: remember the <issue_status> has to be previously created in Jira Workflow!

Windows GUI: Several fixes have been done in the 2D version tree:

Set correct initial date in the branch explorer calculated taking into account the history revisions date.

Fix view options: version tree vs complete Branch Explorer. They were not doing anything at all. By default, the version tree is set. So, only relevant changesets are displayed.

Windows GUI: Fixed an error deleting repositories using the "Del" key when the selection was empty.

Windows, Linux and OS X GUI apps: The "repositories" view will now remember the last typed server between application restarts if user modifies the default value.

Remark: It only works for the regular "repositories view" and not in the "cloud repositories" view.

TeamCity plugin: The plugin do not request anymore all the repository branches when there is no branch specification filter defined. In that case, it only requests the default branch to watch.

Gluon: improved the "Checkin conflicts" dialog. Now, the conflicts list is just plain text, so all the messages can be easily read and copied.

Mac GUI: New annotate (blame) is here. Just right click a controlled item in the workspace explorer view, and select the "annotate option".

The 'code reviews view' failed with the following error: "You are working with out-of-date objects. Maybe your client or workspace is out of date, please update it." when there was any review of a branch that had been previously deleted.

Crucible plugin: The plugin was unable to list repositories from cloud server. Fixed: just enter the server name in the format "<your_organization>@cloud" and leave the port field empty when adding a new repository.

Plastic SCM 7.0 is officially out!

7.0 was first introduced back in December 18th 2017 (release 7.0.16.1857) as a preview and was finally moved as official with BL2047.

7.0 is backwards compatible with 6.0 and 5.4.

Compatibility is marked by the middle number 16 in the full version number, and it didn't change since 5.4.

We strongly recommend to update all clients and servers, but progressive roll outs of the new versions are totally possible, which is especially helpful in big deployments.

These are some of new features in 7.0:

New Branch Explorer design (applies to all platforms).

New web-based server admin tool: it was previewed as a late 6.0, but it is now officially supported in 7.0. http://blog.plasticscm.com/2017/10/webadmin-introducing-new-server-admin.html

Gluon for Linux and Mac: the tool and workflow for non-coders is now available in all platforms.

Attributes support for Linux and OS X GUIs.

Greatly improved Bamboo DevOps support: http://blog.plasticscm.com/2018/03/devops-atlassian-bamboo-plasticscm.html

Greatly reviewed command line help and usage.

OS X usability improvements and restyling.

Added support for Polarion 3.17.1+

Windows GUI: much better responsiveness since lots of calls made in the main thread were removed. Clearly noticeable with distant servers (like Cloud).

7.0 past pace evolution continues with new weekly releases. Here are some of the great features in the backlog:

Merge-to with full conflict resolution: ability to do workspace-less merges with conflict resolution. Great for teams with full test automation.

Enhanced DevOps: we are working on improving the integrations with TeamCity and Jenkins as we recently did for Bamboo. DevOps is a core priority for us.

MergeBot as DevOps core: Plastic server will be able to run merges when branches are ready and trigger builds in CI systems.

New WebUI: we are working on a full redesign of the web interface to browse repositories, perform code reviews, run diffs. It will be auto-deployed with the regular server as the WebAdmin does.

More flexible workspaces: regular Plastic (developer mode) will be able to work in "partial mode" (Gluon mode) to enable more flexibility. We are also considering the option to mix working in full and partial mode together, for teams who require more flexibility.

Improved code review: one of the big requests from customers. We will be finally working on updating the core feature and pushing it to the next level.

Bamboo CI Plugin can now update branch attributes based on the branch status.

Example: when a build starts, a 'status' attribute on the branch can be set to 'testing', then updated to 'failed', 'passed' or even 'integrated' depending on the final result.

This feature is key to implement a DevOps pipeline using Bamboo and Plastic SCM.

For further info about DevOps, trunk based development and task-per-branch check:

DevOps with Bamboo and Plastic

To configure a Plastic repository in Bamboo and enable this new options:

Enable Enabled plan branch filtering (feature recently launched and explained in the 7.0.16.1995 release notes),

New fields will appear to set a given attribute name with a desired value when Bamboo triggers one the following events:

A plan branch starts its build plan

A plan branch build fails

A plan branch build succeeds

A plan branch is automatically merged (only if gatekeeper automatic merge feature is enabled).

The allowed values for these fields are <attribute_name>=<attribute_value>

REMARK: remember the <attribute_name> has to be previously created in plastic repository! Example:

(The attribute can be also created through Windows GUI too)

Windows GUI: The 'items' preview now supports IrfanView as an external viewer. IrfanView is a famous image viewer sofware that supports several image types. Now you can generate item previews of some image files using IrfanView as an external preview provider. To configure it just go to Preferences -> Preview tools -> Add, select it from the combo, and adjust the settings.

Mac OS X Server: An issue related to self-signed certificates with bundled Mono Framework prevents Mac Server to pull data from another server through SSL.

Linux and Mac apps: Sync with Git feature don't support the TLSv1.2 cryptographic algorithm for HTTPS, so synchronizing against some providers (e.g. GitHub) fails.

The item preview locked the images when reading, so when you opened the preview of the same revision in both items and history view, an error occurred. Now it's fixed.

If you were using spanish localization for mergetool and difftool, lot of texts were missing. Now, it's fixed.

Windows GUI: Fixed a "index out of bounds" exception when restoring a difference in the pending changes view, when the source file has a encoding mark (BOM).

Gluon and Plastic for Linux: both the "Checkout" and the "Open" menu items of the workspace explorer had the same accelerator keys. Fixed. Now, the accelerator for "Checkout" is "Ctrl + Shift + O", while for "Open" is still "Ctrl + O".

Improve the analyze differences feature so, if it fails when analyzing the differences for a revision, show the information for the rest of the revisions (not like now that it showed nothing). In case of any error, an error message will appear in the diff view notifying the user.

Mergetool: Disabled the C# language error highlighting feature of the textbox -developed by ActiPro- until it supports C#6/7. This will help avoid the confusions reported by users. We're in contact with the ActiPro guys to get it available as soon as possible.

GoCD plugin: now, the plugin binary .jar file is distributed in windows and linux installers inside "client" install folder.

Linux GUI: The attributes tab is finally in the branch explorer! The panel is updated each time the branch explorer selection changes, showing the attributes of the selected object.

The user will be able to apply new attributes, editing the value of the existing ones or remove them from this new panel.

CLI: A new 'cm patch' command is now available! It allows patches to be generated from a diff and applied in a workspace. The patch output is in the diff unified format, as usual.

By default, patches are written to standard output unless a path is specified using the --output optional parameter. There's also the possibility to manually set the external tool to be used (diff to generate patches, patch to apply them) using the --tool optional parameter. These tools will be searched in the PATH environment variable if the --tool parameter is not used.

The 'patch' command is not supported in our Java client.

OS X GUI: The attributes tab is finally in the branch explorer! The panel is updated each time the branch explorer selection changes, showing the attributes of the selected object.

The user will be able to apply new attributes, editing the value of the existing ones or remove them from this new panel.

Mac: The dynamic pending changes view shown next to the items view could be displayed in an inconsistent state after Add or Checkout operations in the items view tree. Fixed.

Mac: Sometimes a message like "Unexpected error: Cannot access a disposed object. Object name: '[name]'." would appear when a workspace window with an open dynamic view was closed. Fixed.

Command line help failed to display if language was not English or Spanish. Now it default to English if the specific translation is not available.

If you launched the mergetool for Windows directly without any argument, it failed because it couldn't find the appropriate resources for the launcher form. Fixed.

From now on, the merge tools included with plastic will have their own configuration. Before they were using both config files, the client.conf and the mergetool.conf. Now, they will get the configuration only from the mergetool.conf file. The configuration moved is:

Please add these keys to your mergetool.conf file in case you want to change those values.

OS X GUI: The merge view opened the branch explorer properties in the side panel when a merge finished. It was a minor detail, but it could be slightly confusing to users. Fixed.

OS X and Linux GUI: After processing a merge, the hint message at the bottom of the merge view was wrong. It informed that the merge search finished without results, instead of notifying that the merge was successfully completed. Fixed.

Workspace update (you know, switching to a different branch or cset) had an issue if a directory or file was locked (i.e. directory in use). Now the operation keeps the locked item as private (or out-of-date) and goes on updating the rest of the workspace.

Example: you have a console open in src/server and then you switch back to changeset where src was named "code". Before, the operation failed and the workspace was dirty. Now it works great, leaving just src/server as private. In fact, if you later go back to the initial changeset, the private is reused.

Windows: Sync with Git feature didn't support the TLSv1.2 cryptographic algorithm for HTTPS, so synchronizing against some providers (e.g. GitHub) failed. Fixed.

REMARK: Still pending to fix this issue for non-windows plastic applications.

We made some changes in our custom file preview sytem so you can configure IrfanView as a external preview tool and, this way show previews for .psd files.

You can configure it by using the following command options to generate the thumbnail previews:

"@src" /convert="@output" /resize=(1024, 1024) /aspectratio

Bamboo CI Plugin: Added support for Bamboo 6.x.

Bamboo CI Plugin: Enable plan branch filtering based on Plastic attributes.

The goal is to support testing and merging task branches to main when a given attribute is set. This way trunk-based development can be easily implemented.

The recommended configuration for a Bamboo plan is as follows:

Branch to track in the Bamboo plan when configuring Plastic repo is "/main".

Enable automatic plan branch creation ("when new branch in repository is created" option is OK).

Enable automatic plan branch merging. Select the Gatekeeper strategy (with "push on successful" enabled, which means the resultant merge will be checked-in to /main on successful build).

Do not enable the "After branch was deleted from repository" checkbox when configuring the plan branch.

Enable the plan branch deletion for just a couple of days of branch inactivity ("After branch inactivity in repository" option). Once the branch is merged to /main, you shouldn't be working on it anymore (this way you will save disk space and Bamboo plan branches available, if limited).

Enable repository polling to track new changes once the plan branch is created.

When configuring the Plastic repository for a Bamboo plan, a new checkbox named "Enable Plan Branch filtering" will appear.

Once it is enabled, a textbox allows filtering the candidate branches to create a new plan branch in Bamboo in two ways:

Specifying an attribute name and value pair as follows: attribute_name=attribute_value. Example: status=resolved which means that only the branches with an attribute named "status" with the value "resolved" will be sent to Bamboo to create a plan branch.

Specifying a complex query valid for "cm find branch" command (which is the underlying plastic command executed to retrieve the candidate branches). It is not mandatory to specify a plastic attribute in this mode. Two examples below:

Remember to create the Plastic attribute and apply the desired value (manually or through an external trigger) to the branches that you want to be built and merged by Bamboo.

Find more info about Plastic attributes here

Mac: There were two BranchExplorer display options that weren't properly working: "display full branch names" and "display branch task info". Fixed.

Unity 3D Plugin: It failed to get the status of a locked item when the lock configuration was done through the webadmin. This happened because webadmin does not fill the lock server field in the lock.conf file and the unity3d plugin did not support an empty lock server specification.

Using Gluon, when we try to move a file that is in exclusive use by another application (another application has it open and locked), the move operation fails as expected with the error 'The process cannot access the file because it is being used by another process.'. But sometimes after release the file, when we try to move the file again, using gluon, the operation failed unexpectedly with the error 'Selector can't locate a revision for the item foo'. Now it's fixed and after release the file, gluon can perform move operation.

The new version for the Polarion plugin referenced '3.17.1+' instead of '3.17.3+'. Fixed

Bamboo plugin: The bamboo plugin was unable to retrive source code for a plan branch from Plastic repository after the first auto-merge operation performed on that plan branch. Fixed.

Bamboo CI Plugin: The path to the Plastic SCM command line was not printed when saving the configuration. Fixed.

Bamboo plugin: The bamboo plugin shown the data of the default repository instead of the selected one when users edited a repository in the plan configuration. Fixed.

KNOWN ISSUE: We have just detected an issue with "Sync with Git" feature targeting a GitHub repo. This issue prevents performing a sync operation correctly due to SSL/TLS restrictions on GitHub side. We're working on fixing this.

Crucible plugin: a bug slipped into our code and prevented our plugin from loading the Crucible repositories. Fixed.

'Welcome to Plastic SCM' dialog: If the configured server is using Jet as its backend, some corner concurrency circumstances could cause the OK button in the 'Start a new project' tab to start an action that never ends. If that happens, the server will fail the next time it starts and it will log this message: "FATAL LicenseManager: Can't load information". Now it's fixed.

Windows GUI: The image properties were not correctly updated when changing between different image files in the diff viewer. Now it's fixed.

Windows GUI: When creating a new workspace, Plastic got locked when typing a non-existing root path (for example j:) in the path textbox, and then clicked the 'browse' button. Now it's fixed.

Windows GUI: The pending changes, items and branch explorer views were not refreshed after checking changes with an update operation without conflicts. Fixed.

OS X GUI: Since we released Gluon for OS X (release 6.0.16.1779), we accidentally hid the semantic differences feature.

Now it's fixed, and the diff mode selection (text diff vs semantic diff) is visible again in the diff viewers.

In after-replicationwrite triggers, the PLASTIC_BRANCH env variable indicates the replicated branch.

There was a bug and the env var was not filled for "push" operations.

Performing a push operation from server A to server B:

The server B wrongly executed the after-replicationread triggers.

The server A wrongly executed the after-replicationwrite triggers.

These are the executed triggers performing a push operation from server A to server B:

On server A: before-replicationread & after-replicationread

On server B: before-replicationwrite & after-replicationwrite

Performing a pull operation from server A to server B, the server B wrongly executed the after-replicationread trigger. Also, the server A was wrongly executing the after-replicationwrite trigger. Now, none of them are executed.

These are the executed triggers performing a push operation from server A to server B:

On server A: before-replicationread & after-replicationread

On server B: before-replicationwrite & after-replicationwrite

The import package and the push operation are not properly setting the PLASTIC_BRANCH for the before-replicationwrite and after-replicationwrite triggers. As a result, when a child branch is pushed (or imported using a package) with any of those triggers registered the operation was failing.

The repository trigger filters were ignored for the before-merge trigger. It's fixed now.

If you'd like the before-merge trigger to affect just the repository 'default', you'd run the following command to register the trigger:

There was a log issue with requests: send time (sendt) was also wrongly used in receive time (rect). Fixed.

java cm client (a.k.a. java CLI ): Sometimes the checkin operation could throw a NullPointerException when multiple threads were used for data transferring. This could be achieved by tuning the client.conf configuration file. (It's important to remark that the integrity of the data never was affected). Fixed.

Windows GUI: much better responsiveness since lots of calls made in the main thread were removed. Clearly noticeable with distant servers (like Cloud).

Added support for Polarion 3.17.1+. The API changed at this version and our Polarion plugin was not compatible. Now we ship two versions. The old one (compatible until Polarion 3.17.1, and the new one, compatible from Polarion 3.17.1 and higher).

The plugins and instructions about how to install it can be found in the /client/plugins directory.

Windows GUI and Mac OS X GUI: Semantic diff engine now supports C# 7 language specification!

REMARK: Windows installer will now require .NET Framework 4.6 to be installed before proceeding any further.

Windows GUI: Fixed "An error occurred processing your request" when double clicking files in the pending changes view after a merge, when the status of those files was "Copied (new)".

Visual Studio Package: The issue tracker extensions did not work properly under the Visual Studio Package. A "File or assembly Newtonsoft.Json.Net20.dll cannot be found" exception was thrown. Now it's fixed.

Windows Installer: Recently we fixed troubles we had with Plastic SCM windows services startup when upgrading installed Plastic SCM version from a non-administrator user account. And we fixed it for Plastic SCM versions starting from release 7.0.16.1873. This means that users upgrading from - let's say - versions 7.0.16.1873 to 7.0.16.1912 won't be hit by such trouble.

We have fixed this issue too when the upgrade is done from a version minor than 7.0.16.1873.

This means that users upgrading from version 6.0.16.1873 to 7.0.16.1935 won't have troubles with Plastic SCM windows services.

Gluon for Mac OS X: The application menu in the Menu Bar and the Dock icon displayed 'macgluon' instead of 'Gluon'. Fixed.

Windows GUI: Fixed a high DPI issue. The update and checkin progress panels were cut on hightDPI screens. Now it's fixed.

Windows GUI: The branch explorer view memory was severely increased with the redesign for Plastic 7.0. Now it's fixed.

Linux & Mac OS X GUI: Some merge links were drawn out of its bounds. Now are ok.

The pending changes view performance was severely degraded when there were tons of changed items in view. This was broken when the tree mode ("view items as a tree"). It was only appreciable with tons of pending changes. Now it's fixed.

Lots of Linux GUI code refactored to simplify and clean up the use of lists. Big internal refactor :-)

Gluon (windows, gtk, mac): When you deconfigured a file or directory, the root node was always selected in the "explore workspace" tree. This was annoying when the node were on the bottom of a big tree.

Now, when you deconfigure an element, the focus go to the previous element or the parent directory, not the root.

Mergetool for Linux: the difference drawing was not work fine when the region bounds exceed the textbox lines. Fixed.

Server: We had some reports of the server being unable to start after a sudden shutdown of its host machine if it was performing a background maintenance task at that moment. That sudden shutdown prevented the OS from flushing its buffer into the disk. From now on, the involved maintenance tasks will force the OS buffer flush to avoid any further issues in case of an unexpected system shutdown.

The replication process of a branch failed if the replicator user wasn't granted the 'replicatewrite' permission for its parent branch on the destination repository. Fixed.

Gluon for OS X: The image preview for pdf files was broken few releases ago when the preview image size was changed depending on the image resolution. Also, the aspect ratio of the files in the preview was not respected. Now both issues are fixed.

Linux & Mac OS X GUI: replica now shows detailed progress during metadata transfer.

Mac OS X GUI: Added TrackPad support to scroll the diff viewer and the mergetool. Now you can use the scrolling gestures to scroll horizontally and vertically in the diff viewer and the merge tool.

New style for Plastic for OS X. We redesigned the looks of the entire gui introducing same ideas we applied developing Gluon for OS X. We hope you like it :-)

We refactored the code of the configuration dialogs in OS X, Linux and Windows, including Gluon on the 3 platforms.

We also fixed a few things in Windows:

And redesigned the config dialog for Gluon on Windows: no more cut texts, better layout.

Jenkins plugin: The Plastic SCM configuration will automatically propose a default workspace name for the first (mandatory) workspace.

Mac OS X GUI: The Plastic SCM client will open as soon as you install it for the first time! Now it's easier than ever to start working with Plastic SCM on your Mac :)

Unity 3D Plugin: The "Show branch explorer" button from the "Version Control" tab was not showing the Branch Explorer view in Mac OS. Fixed.

The subtractive merge operation failed if the source changes to subtract contained a deleted xlink. Now it's fixed.

Sync with Git: The operation failed with the error "˜The changeset X could not be imported" when the targeted Git repository contained a submodule whose URL was changed from the one that was originally used to sync. It's fixed now.

Jenkins plugin: There was an issue configuring existing pipeline projects. The PlasticSCM entry didn't appear in the SCM dropdown list if the pipeline was set to get the script from SCM. Fixed.

New Branch Explorer design arrived to Linux. We hope you like it :)

The 'cm partial update' command allows the '--changeset=number' parameter so it can go to previous/newer changesets for an specific item or the whole workspace. This is only useful in Gluon workspaces.

Updates the entire workspace to changeset 23. Files that are changed or checked out will be skipped and will remain on whatever version they had. It is useful to go back and skip newer changes you didn't want to download to your workspace.

Downloads the version of foo.psd that was loaded on changeset 15. In case foo.psd is modified or checkedout the update will fail.

Gluon for OS X: Now the image diff viewer loads the image properties (EXIF, TIFF, PNG, and other properties) in the properties viewer.

Mac OS X GUI: Improved the trackpad support for the branch explorer. Scrolling and zooming gestures have been improved (now the diagram draws smoother while scrolling and zooming). Also improved the drawing when clicking&dragging using the mouse to scroll the diagram.

Windows GUI: The "Analyze differences" functionality in the diff window was broken. The information was calculated but not shown in the view. Fixed.

In addition, we renamed the 'cloc' executable file from 'cloc-1.60' to 'cloc' (without the version number). We were a little bit out-of-date (cloc latest version is 1.72). We have also improved the message displayed when the cloc executable is not found, so we hope there won't be any more problems to use it :)

Windows GUI: The diff window performed an unwanted refresh after checkin/checkout/undo files in the items or the pending changes view. Now it's fixed.

Gluon for OS X: When using the items view in Gluon, the preview image size could be wrong depending on the image resolution. Now it's fixed.

Gluon for Linux: The revision history list in the details panel wasn't updated (cleared) if a directory or a private item was selected. Fixed.

Gluon for Linux: The content view wasn't displayed for private/added items. This meant that the checkin view held a big empty space where the content view should be -if there were only private/added items- or that the diff view of a previously selected changed item wasn't replaced with the contents view of the selected private/added item.

Linux GUI: The application icons were corrupted and couldn't be displayed properly. Fixed.

We have done and in depth review of the help of the command line (cm) to document flags that were missing and better explain some options.

Documentation is now much more complete than it used to be. It is an ongoing effort to make cm shine :-)

Until now, "Update workspace" operations (either on the GUI Items View / Workspace Explorer or through "cm update") warned about the changed items that would be left out of date. As a result, the checkin operation could fail if the user didn't force-update them and they try to checkin one of those files after performing some changes on it: an out of date item cannot be checked in. Now, changed items are checked on a workspace update. If they are in conflict with the new server changes, a merge operation will be launched.

Windows GUI: Since new Branch Explorer for Plastic SCM 7.0, bookmarking a changeset/branch could show an error after the branch explorer is closed and reopened again. Fixed.

Installer: Upgrading Plastic SCM on windows logged as a windows standard user could lead the installer not to detect a previous installation. When this happens, the installer show errors when starting Plastic Server and Change Tracker services. The issue only happened if the elevated admin user never configured Plastic SCM client. Now the issue is fixed.

Mac gluon: Sometimes, when switching between the explore workspace view and the configure view, the selected paths are not visible, the scroll position is wrong. Fixed.

New Branch Explorer coming to Plastic 7.0!

We redesigned the looks of the Branch Explorer for Windows and OSX (Linux will follow soon) introducing some new ideas we have been tinkering with for a while.

We hope you like it as much as we do and it soon becomes the new standard for all the branch diagrams we draw even on blackboards :-)

Gluon for Mac learns how to undelete files, so now recovering past work becomes much easier.

Gluon on Linux learns how to undelete items :-)

A small game added to the Branch Explorer as a result of a HackWeek we did a few months ago :-)

When the branch explorer is focused, press Ctrl+Alt+P to show the game

Press Enter key to start the game

Use left and right arrow keys (or use the mouse) to move the paddle

Press 1 to decrease the game speed

Press 2 to increase the game speed

Press space bar to add more balls to the game

Press P to pause the game

Press Esc to exit the game

From now on, copied items (those modified only on the merge source) will perform exclusive checkout (if needed) during the merge operation. As a result, the merge operation will no longer be able to modify a file that requires exclusive checkout while another user has checked out that particular file in their workspace to change it.

Linux/OS X: when you ignore files, you can now edit the rules.

It works both from "pending changes" and "explore workspace".

It is very convenient to select a file and set rules to one of its parent directories.

The undo changes performance has been greatly improved.

It is specially noticeable when undoing changes from a merge.

Now undoing the changes of a big merge with thousands of changes is about 10 times faster. The bigger the merge is, the better is the improvement.

This improvement benefits the command line and all GUIs.

The undo checkout operation of a non-hydrated file was wrongly leaving the item set as if it came from the hydration source repository on the workspace.

Cloud: Fixed some uncommon scenario where the same revision could be loaded on multiple locations. This could happen if the same repository was loaded multiple times across the same workspace (i.e. the workspace contains multiple Xlinks pointing to the same repository) and an update operation needed to download the file revision X to multiple paths: the operation could fail for some of those paths.

GTK Gluon: The "Update Forced" button in the Update report dialog was always enabled. It should be enabled only if there is at least one checked error.

GTK Gluon: The Update Forced action in the Update report dialog wasn't taking effect. Fixed.

**Examples:**

Example 1 (unknown):
```unknown
src/
 src/lib/           - ignored
 src/lib/bar.c      - not ignored
 src/lib/foo.c      - ignored
 other/             - ignored
 other/other.txt    - ignored
```

Example 2 (unknown):
```unknown
src/
 src/lib/           - ignored
 src/lib/bar.c      - not ignored
 src/lib/foo.c      - ignored
 other/             - ignored
 other/other.txt    - ignored
```

Example 3 (unknown):
```unknown
src/client/foo.cs      -controlled
|   |-----/bar.cs      -private
|--/common/roo.cs      -private
|--/server/far.cs      -controlled
    |-----/net/goo.cs  -private
```

Example 4 (unknown):
```unknown
src/client/foo.cs      -controlled
|   |-----/bar.cs      -private
|--/common/roo.cs      -private
|--/server/far.cs      -controlled
    |-----/net/goo.cs  -private
```

---

## Debugging

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/logging

**Contents:**
- Debugging#
- Logging#
- Files#
- Core dump access#

With Multiplay Hosting's Debugging feature, you can investigate issues you might have with your servers.

Debugging offers you the following tools:

Logging provides a way to view, search, and download logs from the Unity Dashboard without setting up a custom integration with a third-party service.

Note: Multiplay Hosting Logging is in closed beta. Unity is collecting as much feedback as possible to improve the feature. Please share any issues, thoughts, or feedback with the engineering team.

Game server files provide a list of files present on a server instance. You can optionally download these files.

Note: Before Multiplay Hosting can surface your files through the Unity Dashboard, you must specify the location of your files through your build configuration launch parameters.

A core dump is a file which contains a process's address space (memory) when it terminates unexpectedly. This file provides a snapshot of what happened when a process crashed.

Note: Before Multiplay Hosting can generate core dumps, you must configure the core dump storage settings.

---

## LOCATION

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/location

**Contents:**
- LOCATION#
- Description#
  - Usage#
- Help#

Returns the path of 'cm'.

Bear in mind this is related to your environment variables. If you have several installations of the client, it will return the first one in the path.

**Examples:**

Example 1 (unknown):
```unknown
cm location
```

---

## XLINK

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/xlink

**Contents:**
- XLINK#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Branch auto-expansion#
  - Examples#

Creates, edits, or displays details of an Xlink.

cm xlink [-w] [-rs] <xlink_path> / (<csetspec> | <lbspec> | <brspec)> [<expansion_rules>[ ...]]

cm xlink [-rs] <xlink_path> /<relative_path> (<csetspec> | <lbspec> | <brspec>) [<expansion_rules>[ ...]]

(Creates a readonly partial Xlink pointing to /<relative_path> instead of the default root / .)

cm xlink -e <xlink_path> (<csetspec> | <lbspec> | <brspec>)

(Edits an Xlink to change the target specification.)

cm xlink -s|--show <xlink_path>

(Shows the Xlink information including the expansion rules.)

cm xlink -ar|--addrules <xlink_path> <expansion_rules>[ ...]

(Adds the given expansion rules to the Xlink.)

cm xlink -dr|--deleterules <xlink_path> <expansion_rules>[ ...]

(Removes the given expansion rules from the Xlink.)

This command creates an Xlink to a given changeset. By default, a read-only Xlink is created. This means that the contents loaded in the workspace inside the Xlink cannot be modified. To be able to make changes in the Xlinked content, create a writable Xlink instead (using the '-w' option).

It is possible to use a simplified syntax of the command when editing the target changeset of an Xlink. This way, the only required parameter is the new target changeset. The rest of parameters of the Xlink will not be modified.

When a change is made in any writable-xlinked repositories ('-w' option), a new branch needs to be created in the target repository. The name of the new branch is based on the checkout branch defined in the top-level repository. To determine the name of the branch to use, these rules apply:

Finally, the complete Xlink structure is kept up to date with the latest changes in the right versions.

cm xlink code\firstrepo / 1@first@localhost:8084

(Creates an Xlink in folder 'firstrepo' in the current workspace where the changeset '1' in the repository 'first' will be mounted.)

cm xlink opengl\include /includes/opengl 1627@includes@localhost:8087

(Creates a readonly partial Xlink in directory 'opengl\include' in the current workspace where the path '/includes/opengl' in changeset '1627' in the repository 'includes' will be mounted as root. It means that whatever is inside '/includes/opengl' will be mounted in 'opengl\include' while the rest of the repository will be ignored.)

cm xlink -w -rs code\secondrepo / lb:LB001@second@localhost:8084

(Creates a writable and relative Xlink in folder 'secondrepo' in the current workspace where the label 'LB001' in the repository 'second' will be mounted.)

cm xlink code\thirdrepo / 3@third@localhost:8087 br:/main-br:/main/scm003

(Creates an Xlink in folder 'thirdrepo' in the current workspace where the changeset '3' in the repository 'third' will be mounted.)

cm xlink -e code\secondrepo br:/main/task1234@second@localhost:8084

(Edits the Xlink 'code\secondrepo' to change the target repository by linking the branch 'main/task1234' in the repository 'second'.)

cm xlink --show code\thirdrepo

(Shows information of the Xlink 'code\thirdrepo' including its expansion rules if exist).

cm xlink -ar code\secondrepo br:/main-br:/main/develop br:/main/fix-br:/main/develop/fix

(Adds two expansion rules to the xlink 'code\secondrepo'.)

cm xlink -dr code\secondrepo br:/main/fix-br:/main/develop/fix

(Deletes the expansion rule from the xlink 'code\secondrepo').

**Examples:**

Example 1 (unknown):
```unknown
cm xlink [-w] [-rs] <xlink_path> / (<csetspec> | <lbspec> | <brspec)> [<expansion_rules>[ ...]]
```

Example 2 (unknown):
```unknown
cm xlink [-rs] <xlink_path> /<relative_path> (<csetspec> | <lbspec> | <brspec>) [<expansion_rules>[ ...]]
```

Example 3 (unknown):
```unknown
cm xlink -e <xlink_path> (<csetspec> | <lbspec> | <brspec>)
```

Example 4 (unknown):
```unknown
cm xlink -s|--show <xlink_path>
```

---

## Troubleshooting tips

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/Troubleshooting

**Contents:**
- Troubleshooting tips#
- 1. (Android) Verify your Firebase values inside the Push Notifications settings#
- 2. (EDM4U/MDR) Verify that the dependencies for the Push Notifications SDK have been resolved#
- 3. (Android) Check that Minify isn't excluding the Push Notifications SDK during the build process#
- 4. (iOS) Ensure remote notifications are enabled in XCODE#
- 5. Check your API keys in the Unity Dashboard under Push Notifications settings#

The following are common troubleshooting tips to follow if you encounter any issues or errors using the Push Notifications SDK.

Some of the troubleshooting tips may make reference to specific common errors. However, even if you don't encounter these issues, it's still recommended to go through them in order.

If you encounter issues while attempting to register your test device to Firebase while using the Push Notification SDK, it's likely that your Firebase values are either empty or invalid.

You can check how to add your Firebase details in the Push Notifications Settings segment.

Alternatively, if you're sure that the values you provided are correct, check there's no whitespace/space after your values. This has been known to cause issues.

Applicable to users integrating the External Dependency Manager for Unity (EDM4U) or the Mobile Dependency Resolver (MDR) alongside Push Notifications.

As noted in the External Dependency Manager for Unity (EDM4U) support section, the Push Notifications SDK doesn't require or bundle the External Dependency Manager for Unity (EDM4U) or the Mobile Dependency Resolver (MDR) to resolve its own dependencies. However, if either is used, the Push Notifications SDK integrates with them.

If you don't require EDM4U or MDR for any other packages, it's recommended you uninstall them.

Otherwise, we recommend you follow these steps:

If you've gone through the EDM4U / MDR troubleshooting section and still receive something similar to the following error:

check your Minify options under Player Settings > Publishing > Minify. If the Release or Debug checkboxes are ticked then you're using Minify, which might remove the Push Notifications SDK from the release/debug build as part of the minification process. causing the "class missing" error.

If you don't require Minify, you can turn it off to resolve this issue.

If you want to continue using Minify, you'll need to add the Push Notifications classes under a custom proguard file to prevent the Push Notifications SDK functionality from being excluded during the Minification process.

Enable the Custom Proguard File under Player Settings > Publishing > Build > Custom Proguard File.

Open the file created under the path specified and append the following line:

This should resolve the issue.

For iOS apps to be able to receive Push Notifications, Remote Notifications capabilities need to be granted.

Your app will provide the following error if you fail to do this:

Go to Signing & Capabilities > Capability > Background Modes > Remote Notifications to provide Remote Notifications capabilities.

To send Push Notifications to end-user devices, add your Google and Apple keys to the Unity Dashboard inside Settings, found under LiveOps > Push Notifications.

You can find a guide to adding your Google Key here and Apple Key here.

For iOS, ensure your key matches the target build version. For debug builds, set the Sandbox option to True, and for production builds, set it to False. If there's a mismatch between the key and build version, the test device won't receive notifications.

When building your iOS app from the generated XCODE project, you might need to switch the scheme of every target (for example, Unity-iPhone, notificationservice) in the run section from debug to release. if Sandbox is set to False, and from release to debug if Sandbox is set to True.

Check your keys work by using the testing guide.

**Examples:**

Example 1 (unknown):
```unknown
PushSDKDependencies.xml
```

Example 2 (unknown):
```unknown
Assets/Push Notifications/Editor/Android
```

Example 3 (unknown):
```unknown
Force Resolve
```

Example 4 (unknown):
```unknown
Display Libraries
```

---

## SSL certificates

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/ssl/overview

**Contents:**
- SSL certificates#

Create self-signed SSL certificates for development, and use an SSL certificate to improve the security of your Unity Version Control (UVCS) traffic. SSL certificates are what enable websites to use HTTPS, which is more secure than HTTP.

---

## TRIGGER SHOWTYPES

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/trigger-showtypes

**Contents:**
- TRIGGER SHOWTYPES#
- Description#
  - Usage#
- Help#
  - Examples#

Displays available trigger types.

Displays the list of available trigger types.

**Examples:**

Example 1 (unknown):
```unknown
cm trigger showtypes
```

Example 2 (unknown):
```unknown
cm trigger showtypes
```

---

## Filters

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/concepts/filters

**Contents:**
- Filters#
- CEL syntax#
  - Equality#
  - Regular expressions#
  - Nested fields#
  - Logical operators#
- Type mismatch#
  - Type casting#

You can use filters to determine whether to execute a trigger and avoid the unnecessary execution of triggers. You can define the filters in the filter field of a trigger's configuration.

You define filters in the filter field of a trigger's configuration. The value of this field is a CEL expression that evaluates to a boolean value. If the expression evaluates to true, the trigger will be executed.

For example, the trigger configuration below is only executes when the leaderboard with a my-leaderboard leaderboard ID resets.

Triggers use the event payload as the input. The event payload is a JSON object that contains the data relevant to the event. For example, the payload for the com.unity.services.leaderboards.reset.v1 event looks like the following:

You need to write filters in CEL (Common Expression Language), an expression language that Google Cloud products use. For more information on CEL, refer to the Language Definition.

The samples below show some common CEL expressions that you can use in filters.

You can set a filter to be true when a field is equal to a specific value. These filters allow you to ensure that a passed-in parameter is a specific value.

For example, you can use the following filter to check if the value of leaderboardId is my-leaderboard:

You can use regular expressions to match a field against a pattern. For instance, you can use the following filter to check if the value of leaderboardId starts with tiered-leaderboard#:

You can use filters with nested fields. For example, your script or module parameter might look like the following:

You can then use the following filter to check if the value of inventory.primaryWeapon is sword:

You can use logical operators to combine multiple expressions.

For example, you can use the following filter to determine when to issue a quest to a player. You issue the quest when the player reaches level 5, or when the player completes the collectWood quest and the current quest is buildFence:

If the type of the value in the event payload doesn't match the type of the value in the filter, the filter returns an error message in logs, and the trigger isn't executed.

For example, the following filter checks if the Cloud Save event payload contains a value field that is greater than 5:

If the value of data['value'] is a string, the filter doesn't work as expected. This filter is only evaluated if the value is a number in the event payload.

You can cast the type of a value in the event payload to a different type. This can help you avoid type mismatch errors. For example, if you pass in a string value that is a number, you can cast it to a number, and still use it in a filter that expects a number.

However, if the value of data['value'] is a string that isn't a number, the filter returns an error message in logs, and the trigger isn't executed.

To check available types you can cast to, refer to List of Standard Definitions.

**Examples:**

Example 1 (unknown):
```unknown
my-leaderboard
```

Example 2 (unknown):
```unknown
{
  "name": "reset-another-leaderboard",
  "eventType": "com.unity.services.leaderboards.reset.v1",
  "actionType": "cloud-code",
  "actionUrn": "urn:ugs:cloud-code:test-script",
  "filter": "data['leaderboardId'] == 'my-leaderboard'"
}
```

Example 3 (unknown):
```unknown
{
  "name": "reset-another-leaderboard",
  "eventType": "com.unity.services.leaderboards.reset.v1",
  "actionType": "cloud-code",
  "actionUrn": "urn:ugs:cloud-code:test-script",
  "filter": "data['leaderboardId'] == 'my-leaderboard'"
}
```

Example 4 (unknown):
```unknown
com.unity.services.leaderboards.reset.v1
```

---

## Common problems

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/troubleshooting

**Contents:**
- Common problems#
  - When polling for a ticket status, I get a "Max Capacity Reached" error.#
  - When polling for a ticket status, I get a timeout allocation, but a server is still allocated on Multiplay Hosting.#
  - When polling for a ticket status, I get a timeout allocation every time.#
  - When polling for a ticket status, I get a ticket incompatible with config error.#
  - When creating a backfill ticket through the HTTP API, I get an “The supplied value is invalid for Properties” error.#
  - I have backfill enabled, but my servers are not full and new servers keep getting allocated.#
  - I am trying to test locally but I keep getting rate-limited.#
  - I see a high time-to-match when the Matchmaker initially processes the first ticket.#
  - Match and Teams are not filling as expected.#

The following is a list of common Matchmaker problems and their respective solutions. If you need additional support, contact our technical support team.

This is a common error from Multiplay Hosting. This occurs because of the scaling settings of the Multiplay Hosting fleet. Increase the maximum number of available servers in your fleet and then try again.

Additionally, ensure that your DGS terminates properly so it gets deallocated. Sometimes when a server is stopped manually through the Unity Dashboard, it does not get deallocated correctly.

This can happen if the timeout you have set for the pool or the queue is less than 2 minutes. Increase your timeout and then try again.

This can happen if you are testing during development with low traffic. Some common causes of this scenario include the rules in the pool being too constrained or the tickets being created with different attributes and targeting different pools.

This error usually means that the matchmaker was unable to find a match for this ticket. This includes trying to put this ticket in its own empty match but with unsuccessful results.

Other common reasons for this error include:

The following error occurs if the Data field in your properties is encoded in base64 without padding.

For example, in GO, use base64.RawStdEncoding.EncodeToString and not base64.RawURLEncoding.EncodeToString.

When backfill is enabled, the matchmaker creates a backfill ticket for each match that reaches the minimum number of players but does not reach the maximum number of players. In order for the backfill ticket to remain active in the matchmaker, the DGS needs to periodically approve the backfill ticket. Ensure that your server boots up and approves the backfill ticket within 20 seconds of the allocation.

Because rate-limiting on the matchmaker is per player ID, running two clients on a single machine usually results in the same player ID when using the Unity Authentication service.

There are two ways to address this issue:

If it has been more than 36 hours since the Matchmaker received a ticket, you might experience a slight increase in the time required to process the first newly-received ticket. However, once the first ticket is matched, the time-to-match should return to its usual level.

If your game is in development and has less constant traffic on Matchmaker, the recommended best practice is to pre-warm your matchmaker pools before testing. This allows Matchmaker ample time to create the dedicated resources necessary for your game to seamlessly create matches.

Matchmaker first tries to fill matches and teams to the minimum number of players required by the matchmaking configuration and then tries to add more players to the teams to reach the maximum number of players.

Matchmaker will add all the players of a ticket in the first team of a match, then will add all the players of another compatible ticket to the second team and so forth until the minimum number of players is reached. Then Matchmaker will add tickets to keep the teams balanced until the match is full or the number of players relaxes.

**Examples:**

Example 1 (unknown):
```unknown
base64.RawStdEncoding.EncodeToString
```

Example 2 (unknown):
```unknown
base64.RawURLEncoding.EncodeToString
```

Example 3 (unknown):
```unknown
"Unexpected end when deserializing object. Path '', line 8, position 1.",
"The supplied value is invalid for Properties."
```

Example 4 (unknown):
```unknown
"Unexpected end when deserializing object. Path '', line 8, position 1.",
"The supplied value is invalid for Properties."
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/manage-incidents

---

## Welcome to Cloud Content Delivery (CCD)

**URL:** https://docs.unity.com/ccd/en/manual/UnityCCD

**Contents:**
- Welcome to Cloud Content Delivery (CCD)#
- CCD interfaces#
- CCD organization#
  - Environments#
  - Buckets#
  - Entry#
  - Release#
  - Badge#

Cloud Content Delivery (CCD) is Unity's managed cloud service that hosts and delivers content to your application’s users worldwide without having to reinstall a new version of the application. The service is fully integrated into the Unity development platform, saving you months of building and maintaining your own similar service. CCD is most valuable for content-rich, live games or applications that require content updates on a regular basis.

There are multiple ways to integrate your application content with Cloud Content Delivery (CCD):

In CCD, you organize your content into buckets per environment to create a clear workflow for your project. A typical workflow example could be having separate buckets per platform (for example, an iOS bucket and an Android bucket), across multiple environments. You start with a production environment, but you can add other environments such as development and staging.

Within a given bucket, you group specific versions of each asset to create a release. As these versions change, or you add and remove entries, you designate new releases as required.

A release can also have a unique identifier associated with it, called a badge. Give this badge a meaningful name, then use it to query content, and move it between releases to add flexibility to your workflow.

You can create environments in the Unity Dashboard. A project can contain multiple environments (such as production, staging and development), but only one of them is the default one. By default, every project has a production environment.

Using Cloud Content Delivery, you organize your content into buckets to create a clear workflow for your project. A bucket is a single context for publishing content. A typical workflow example could be having separate buckets for different platforms, with names such as ios and android. The buckets could be in different environments, such as the production and development environments. A bucket can be private or public. Private buckets protect read access to buckets with an access token, so only those users with that access token can retrieve content from that bucket. You can also mark a bucket as "promotion only" to restrict write access to that bucket and prevent mistakes such as uploading incorrect content to the wrong bucket. The image below shows a sample bucket as it appears in CCD, including its bucket ID, Promotion Only setting, Privacy setting, description, and the details for a release within the bucket.

You can create and edit buckets either through CCD in the Unity Dashboard or through the CLI.

An entry is a single unit of content within a bucket. Entries support labels and metadata. Creating a release captures the current state of all the entries in the bucket, similar to a versioning process.

Uploading entries to a bucket pushes a local folder’s contents to the remote bucket, which automatically adds, updates, and deletes contents in the bucket, as necessary. CCD supports entries of many file types, the most popular being .gzip, .txt and .bundle (AssetBundles).

Each entry has the following information:

When you create a release, CCD takes a snapshot of all the entries (at their current versions) contained in a bucket at that specific point in time. To remove, update, or add entries, you must create a new release in order to deliver the new or changed entries. You can move releases between buckets by a process called promotion.

Creating or promoting a new release does not create copies of the entries in a bucket.

Badges enable you to select which release your application uses. You can assign a unique badge to a release, and request the badged content using that badge’s name. The image below shows how badges appear in CCD.

You can move this badge between releases, adding more flexibility to content workflows. Moving a badge removes it from the previous release that it was associated with. You can only assign a badge to a single release at a time, but you can associate multiple different badges to a release.

By default, an automatically generated badge named latest is assigned to the latest release.

---

## Text Chat Sample

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/text-chat-sample/text-chat-sample

**Contents:**
- Text Chat Sample#
- Import the Text Chat Sample#
- Use the Text Chat Sample#

This text-focused sample showcases a comprehensive chat experience that demonstrates sending, editing, and deleting DMs or channel messages along with retrieving past conversations and their message history.

After adding the Vivox package to your Unity project, you can find a Samples tab on the Vivox page of the Package Manager.

When this process is complete, the Text Chat Sample is imported into your project's Assets folder.

Note: The Text Chat Sample is only available in versions 16.4.0 and newer.

Prerequisite: Before running the sample scene make sure your Unity project is connected to the Unity Dashboard and your Vivox credentials have been set. You can do this from within the Unity Editor by navigating to Services > Vivox > Configure.

After you have imported the sample you can find it in the Samples folder under Assets. Navigate to Samples > Vivox > versions # > Text Chat Sample > Assets > TextChatSample > Scenes and run the TextChatSample scene.

Entering Play mode will display the sign in screen. To begin using the sample choose a username and select Sign in.

Note: The sample works best in portrait mode. Set your aspect ratio to 9:16 or use Simulator view with a mobile phone selected to have the best experience with the sample.

---

## Pricing list

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/pricing-list

**Contents:**
- Pricing list#
- License#
- Core#
- RAM#
- Network#
- Storage#
- Additional resources#

Multiplay Hosting meters your resource consumption. You’re charged based on your usage according to the following pricing rates. Prices vary by region.

Warning: Minimum available servers can incur costs, even with no traffic. If you are trying to limit costs, the recommended best practice is to set your Fleet scaling setting to a minimum of 0.

---

## Authentication lifecycle

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/unreal-engine-sdk/authentication-lifecycle

**Contents:**
- Authentication lifecycle#
- Signed out#
- Signing in#
- Authorized#
- Expired#

Since Unity Authentication is a volatile, session-based system, the state of an authorized player changes as time goes on. The possible states of a player's authentication session are as follows:

This is the default state of a player’s authentication session, and the state a player returns to after they successfully sign out. When signed out, a player can sign in anonymously, with an existing session token, or via a third-party service provider.

This is an intermediate state, meaning that the player has sent a sign-in request but has not yet received a response from the server.

When a player session becomes Authorized, the server has sent a success response and the player has successfully signed-in. From here, the player can choose to authenticate with other third-party providers via account linking, or choose to sign out.

A player's session becomes Expired when the expiry time for the retrieved authentication token has been passed. When a session has expired, the player can either choose to sign back in, or sign out.

---

## CCD Insights

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/ccd-insights-landing

**Contents:**
- CCD Insights#

The Insights feature allows you to access detailed CCD usage metrics related to downloads and errors, using customizable filters.

Refer to CCD Insights usage.

---

## Parameters of operation

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/parameters

**Contents:**
- Parameters of operation#
- Parameter caps#
  - Currencies#
  - Configuration items#
  - Cost items in a purchase#
  - Reward items in a purchase#
  - Custom data#
  - Inventory instances#
- Summary of limits#

To ensure the proper operation of Economy, there are some parameters in place to keep the service running optimally, both from a storage and runtime usage perspective.

The maximum number of currencies you can configure in a project is 20. If you try to configure more than 20 currencies, the system returns an error.

The total number of configuration items in a game is 750 per project. This includes up to 20 currencies you might have.

For virtual purchases, the maximum amount of cost resources allowed for a single transaction is 20. A cost resource is any currency or inventory item needed to proceed with a transaction. Economy disables the Add button in the Unity Dashboard UI when you try to add more than 20 cost items to a purchase.

For all purchases (virtual and real money), the maximum amount of items given to the player as the reward of a single purchase transaction is 20. Economy disables the Add button in the Unity Dashboard UI when you try to add more than 20 items as a reward.

If the Custom data associated with an item exceeds 5 KB per item or item instance, Economy displays an error message in the Unity Dashboard UI, if the error originates from the configuration. If the error originates from the game itself, the API returns an error message.

There is a limit of 1000 inventory instances per player. An error is only reported in the Player API. Trying to add more items to a player will result in an error returned by the API.

---

## Allocations

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/allocations

**Contents:**
- Allocations#
- Allocation requests#

An allocation is a reservation of a game server for a game session. It’s a way to temporarily put aside a specific game server for a game session so that it’s unavailable for other purposes (such as another game session).

Note: You can also use an allocations payload to send a file to a server along with the allocation request.

You can think about allocations from different perspectives, depending on the stage of the allocation lifecycle.

When you first request an allocation, it’s just that–an allocation request. It remains a request until Multiplay Hosting finds the best possible server based on information from the request and quality of service (QoS) data.

After finding the best available server, Multiplay Hosting removes the selected server from the available server pool and sends its information back to the caller.

The selected game server remains allocated until you (or Multiplay Hosting) deallocates it, freeing it up for the next game session. Deallocations usually occur when a game session ends, but a few other scenarios might trigger deallocation, such as an unexpected exit.

Although it varies depending on the game, a typical allocation flow (using a matchmaker) looks something like this:

You can create an allocation in multiple ways:

When you create an allocation request, you must supply an allocation UUID (unless it’s a test allocation made through the Unity Dashboard). After you create the allocation, you can access the allocation UUID from the server.json file or the Multiplay Hosting SDK.

After Multiplay Hosting receives an allocation request, it uses information from the request and QoS to select the best possible server for the game session while considering the following:

This way, the allocation system always fulfills allocation requests with a game server instance that optimizes performance, availability, and costs.

**Examples:**

Example 1 (unknown):
```unknown
server.json
```

---

## Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/authentication

**Contents:**
- Authentication#
- UAS authentication#
- Relay BIND message authentication#
  - HMACs and shared secrets#
- DTLS authentication#

Relay uses several layers of authentication to support secure communication across the service:

UAS authentication is HTTP-based and communicates with the Allocations service and other Unity services, such as Lobby.

Before requesting an allocation, game clients must get an access token by using UAS, then pass the access token in the Authorization header of the allocation request.

Note: See Relay and UTP, How to use Anonymous Sign-in, and How to use Platform-specific Sign-in.

Relay authentication uses HMAC signatures to authenticate players. The secure signatures use secret keys and nonce values.

An HMAC (hash-based message authentication code) is a message authentication code that uses a cryptographic hash function and keys to authenticate messages. Relay uses the shared secret key generated by the Relay server to sign an HMAC that has the connection data and an incrementing nonce.

If the client’s IP address or port number changes, the supplied nonce must be larger than the last known value (the previous nonce) to mitigate a replay attack. However, if rebinding from the same IP address and port number, the client doesn't need to increment the nonce.

DTLS authentication uses a pre-shared key (PSK) whose value is equal to the HMAC secret key used in the BIND message authentication. The PSK hint in the DTLS handshake is equal to the allocation ID. Check out DTLS encryption.

---

## Cloud Repositories update

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/updated-uvcs-experience

**Contents:**
- Cloud Repositories update#
- Cloud Repositories project#
  - Pre-existing repository permissions#
  - Manage your Cloud Repositories project#
    - Grant or revoke access#
    - Convert to the new permission system#
  - Missing Cloud Repositories project#
- Additional Resources#

On 2025-04-14, Unity DevOps introduced a new experience for all users of Unity Version Control (UVCS) to simplify repository management, enhance collaboration, and integrate permissions with Unity organizations and Unity Cloud projects.

If you had any existing repositories when this change went into affect, DevOps created a new Unity Cloud project, named Cloud Repositories by default, that contains those existing repositories.

Note: In the desktop application, your workspaces might not appear under the associated repository in the Repositories view. You can still find your workspaces in your list of workspaces.

Because of the updates to permissions, to avoid the risk of exposing sensitive repositories to all members of your Unity organization, DevOps created a special project, named Cloud Repositories as default. DevOps only creates a Cloud Repositories project for accounts that have existing repositories when they update to the new experience.

The Cloud Repositories project has different access controls to standard projects. These specific permissions ensure that only users that previously had access to the repositories can access them after the update.

The Cloud Repositories project contains all your pre-existing repositories, and retains any existing permissions that apply to those repositories:

This setup maintains secure and predictable access but gives you the option to align repository permissions with Unity’s standard organization and project model if you choose to do so later.

After the update, the Cloud Repositories project functions the same as any other Unity Cloud Project. You can rename this project at any time to better fit your organization's preferences.

You can continue to use the Cloud Repositories project indefinitely to store and manage your repositories. If you manage the project permissions appropriately, the Cloud Repositories project can serve as a permanent location for your repositories under the same access model used before the update to the new experience.

You have the following options to manage the Cloud Repositories project:

To grant a user in your organization access to the repositories in the Cloud Repositories project, do both of the following:

To revoke a user's access to the repositories in the Cloud Repositories project, do either of the following:

If you convert your Cloud Repositories project to the new permission system, the new permission model applies:

To convert the permissions:

If you can't find a Cloud Repositories project in your Unity Cloud organization, there are the following possible reasons:

---

## Configure UVCS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/configure-uvcs

**Contents:**
- Configure UVCS#

Use configuration files to configure how your Unity Version Control (UVCS) On-Prem environment functions.

---

## Create a custom dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/create-custom-dashboard

**Contents:**
- Create a custom dashboard#

You won’t be able to edit the filters and visualization types from here, but they display according to what's saved in the report.

To set up a custom dashboard:

---

## Opt-in compliance

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/sdk-compliance-opt-in

**Contents:**
- Opt-in compliance#
- Unity 6.2 and later with Analytics SDK 6.1 and later#
- Unity 6.1 and earlier, or Analytics SDK 6.0 and earlier#
- PIPL consent#

Some jurisdictions, including China where PIPL applies (more information below), are opt-in based legislations, regardless of whether the analytics are privacy invasive or not. For China specifically, players need to opt-in to both the collection of their data and the transferring of their data outside of China. If a user is currently in China, you must request user consent.

The Analytics SDK is controlled by the Developer Data framework EndUserConsent API, present in the Unity Engine from 6.2 onwards. To start or stop data collection, you must set the consent status for AnalyticsIntent to Granted or Revoked respectively.

For specific information about granting consent with the EndUserConsent API, refer to Developer Data framework.

Important: Unity Analytics requires you to implement a privacy solution separate from Unity Ads. If you're using both Unity Ads and Unity Analytics, the Unity Ads opt-out mechanism does not apply to both services.

Note: If you're using the REST API, refer to recording an event with the REST API.

If consent is given call AnalyticsService.Instance.StartDataCollection() to enable the collection of their data. If consent is not given, don't call this method and the SDK will continue to ignore events.

Note: Legacy versions (below version 3.0) of the SDK no longer collect data from users in impacted regions, strictly based on geographic location. No aggregated historical data is lost, but you will see a decline in core metrics such as DAU if you have players in these regions.

Warning: 3.x and 4.x versions offer developers functions to pass the appropriate consent flags to the Analytics package for players to opt in to data collection. These functions have been deprecated as of 5.0.0 and are no longer recommended for use. You should migrate to version 5.0.0 or newer as soon as possible. For more information, see the SDK 5.0.0 migration guide.

China's data privacy law - Personal Information Protection Law ("PIPL") - came into effect on 1 November 2021. Personal information is data that can identify a person, such as name or address, and is stored electronically or otherwise. Sensitive personal information refers to biometrics, gender identity, religious beliefs, medical history, finance, and any personal information of minors under fourteen years.

Please visit Unity's legal site for more information on Unity's approach to PIPL.

PIPL is an opt-in based legislation. You're obligated to ask the user for their consent before any other actions are allowed in the SDK. Call the StartDataCollection() method as seen below to signal that consent has been provided.

Note: these API methods changed in version 5.0.0 of the SDK. Please ensure you have the latest version of the SDK installed!

**Examples:**

Example 1 (unknown):
```unknown
EndUserConsent
```

Example 2 (unknown):
```unknown
AnalyticsIntent
```

Example 3 (unknown):
```unknown
EndUserConsent
```

Example 4 (unknown):
```unknown
AnalyticsService.Instance.StartDataCollection()
```

---

## REPOSITORY DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/repository-delete

**Contents:**
- REPOSITORY DELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Deletes a repository from a server.

cm repository | repo delete | rm <repspec>

Deletes a repository from the repository server. The data is not removed from the database backend, but unplugged so that it will not be accessible anymore. (Data can be reconnected afterwards, see 'cm repository add'.)

cm repository delete myrepository@repserver:myserver:8084

cm repository rm myrepository@myserver:8084

cm repo rm myrepository

**Examples:**

Example 1 (unknown):
```unknown
cm repository | repo delete | rm <repspec>
```

Example 2 (unknown):
```unknown
cm repository delete myrepository@repserver:myserver:8084
```

Example 3 (unknown):
```unknown
cm repository rm myrepository@myserver:8084
```

Example 4 (unknown):
```unknown
cm repo rm myrepository
```

---

## Write configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/configuration

**Contents:**
- Write configuration#

Write configurations using different authoring methods.

---

## PARTIAL SHELVESET CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-shelveset-create

**Contents:**
- PARTIAL SHELVESET CREATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Requirements to shelve an item#
  - Examples#

Shelves chosen pending changes.

cm partial shelveset | shelve create | mk [<item_path>[ ...]] [-c=<str_comment> | -commentsfile=<comments_file>] [--applychanged] [--symlink] [--ignorefailed] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

The 'partial shelveset create' command stores the contents of checked out items

inside the repository. This way the contents are protected without the need to checkin the files.

If neither <item_path> nor any option is specified, the shelveset will include all the pending changes in the workspace.

The 'partial shelveset create' operation is always applied recursively from the given path.

The 'partial shelveset create' operation is the default, which means that, if no other operation is defined, the command will try to perform a creation.

Set the PLASTICEDITOR environment variable to specify an editor for entering comments. If the PLASTICEDITOR environment variable is set, and the comment is empty, the editor will be automatically launched to allow you to specify the comment.

cm partial shelveset figure.png landscape.png

(Creates a new shelveset with 'figure.png' and 'landscape.png' checked-out files.)

cm partial shelveset . -commentsfile=mycomment.txt

(Creates a new shelveset with every checked-out file in current directory and sets the comment from the 'mycomment.txt' file.)

cm partial shelve background.png -c="my comment"

(Creates a new shelveset with 'background.png', includes a comment.)

cm partial shelveset --applychanged

(Creates a new shelveset all pending changes in the workspace.)

cm partial shelveset link --symlink

(Creates a new shelveset with the symlink file and not the target.)

cm partial shelveset . --ignorefailed

(Creates a new shelveset with every checked-out file in current directory, ignoring (skipping) the changes that cannot be applied.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial shelveset | shelve create | mk [<item_path>[ ...]] [-c=<str_comment> | -commentsfile=<comments_file>] [--applychanged] [--symlink] [--ignorefailed] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
cm partial shelveset figure.png landscape.png
```

Example 3 (unknown):
```unknown
cm partial shelveset . -commentsfile=mycomment.txt
```

Example 4 (unknown):
```unknown
cm partial shelve background.png -c="my comment"
```

---

## TRIGGER LIST

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/trigger-list

**Contents:**
- TRIGGER LIST#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Output format parameters (--format option)#
    - The output parameters of this command are the following#
  - Examples#

Lists the triggers of a given type on a server.

cm trigger | tr list | ls [<subtype-type>] [--server=<repserverspec>] [--format=<str_format>]

If the type is not specified, lists all the triggers on the server.

This command accepts a format string to show the output.

cm trigger list after-mklabel

(Lists all triggers of type 'after-mklabel' on the server configured on the client.)

cm tr ls before-mkbranch --server=myserver:8084

(Lists all triggers of type 'before-mkbranch' on server 'myserver:8084'.)

**Examples:**

Example 1 (unknown):
```unknown
cm trigger | tr list | ls [<subtype-type>] [--server=<repserverspec>] [--format=<str_format>]
```

Example 2 (unknown):
```unknown
cm trigger list after-mklabel
```

Example 3 (unknown):
```unknown
cm tr ls before-mkbranch --server=myserver:8084
```

---

## BRANCH SHOWMERGES

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/branch-showmerges

**Contents:**
- BRANCH SHOWMERGES#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Shows branches pending to be merged.

cm branch | br showmerges <item_path>[ ...] [--format=<format_str>] [--dateformat=<date_format>]

Output format parameters (--format option): This command accepts a format string to show the output. The output parameters of this command are the following:

cm branch showmerges file.txt

(Displays branches involved in the pending merge of 'file.txt'.)

cm branch showmerges file.txt --format="{date} {name}" --dateformat="ddMMyy"

(Displays branches involved in the merge, printing only the date and the name, with a given date format.)

**Examples:**

Example 1 (unknown):
```unknown
cm branch | br showmerges <item_path>[ ...] [--format=<format_str>] [--dateformat=<date_format>]
```

Example 2 (unknown):
```unknown
cm branch showmerges file.txt
```

Example 3 (unknown):
```unknown
cm branch showmerges file.txt --format="{date} {name}" --dateformat="ddMMyy"
```

---

## ARCHIVE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/archive

**Contents:**
- ARCHIVE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Archive example#
    - Unarchive (restore) example#
  - Reading input from stdin#
  - Examples#

Archives data in external storage.

cm archive | arch <revspec>[ ...] [-c=<str_comment>] [--file=<base_file>]

(Extracts data from the repository and stores it on external storage.)

cm archive | arch <revspec>[ ...] --restore

(Restores previously archived revisions back into the repository.)

This command extracts data from the repository database and store it on external storage, saving database space. The command can also restore (--restore) previously archived revisions back into the repository database.

Use 'cm help objectspec' to learn how to specify a revspec.

The user running this command must be the UVCS server administrator (repository server owner) to be allowed to complete the operation.

Every data segment from the specified revisions will be stored in a different file, with a name starting with the value defined by the --file argument. This argument can contain either a full path value including a prefix for future archive files or just this prefix value.

Once archived, the data from the specified revisions will be accessible in two ways:

To unarchive (restore) a revision (or set of revisions), the archived files must be accessible from the client. Hence, it is not possible to unarchive data being resolved by the server (method 2) because the client will not be able to identify it as archived. If method 2 is used, to unarchive successfully, the administrator will have to edit the externaldata.conf server file first to remove access to the archived files which have to be unarchived.

See the archived revision in the specified output path: ls -al /Users/ruben/archive/battle* -rw-r--r-- 1 ruben staff 2220039 Nov 9 10:52 /Users/ruben/archive/battle-100280-167

Set the PLASTICEDITOR environment variable to specify an editor for entering comments. If the PLASTICEDITOR environment variable is set, and the comment is empty, the editor will be automatically launched to allow you to specify the comment.

The 'archive' command can read paths from stdin. To do this, pass a single dash "-". Example: cm archive -

Paths will be read until an empty line is entered. This allows you to use pipe to specify which files to archive. Example:

dir /S /B *.c | cm archive -

(In Windows, archives all .c files in the workspace.)

cm archive bigfile.zip#br:/main

(Archives the last revision of 'bigfile.zip' in branch 'main'.)

cm archive bigfile.zip#br:/main --restore

(Restores the archived revision.)

cm archive rev:myfile.pdf#cs:2 -c="big pdf file" --file=c:\arch_files\arch

(Archives the revision with changeset 2 of myfile.pdf in 'c:\archived_files' folder. The archived file name will start with 'arch' (for example, arch_11_56).)

cm find "revs where size > 26214400" --format="{item}#{branch}"

--nototal | cm archive -c="volume00" --file="volume00" -

(Archives all the files bigger than 25Mb on files starting with name 'volume00'.)

**Examples:**

Example 1 (unknown):
```unknown
cm archive | arch <revspec>[ ...] [-c=<str_comment>] [--file=<base_file>]
```

Example 2 (unknown):
```unknown
cm archive | arch <revspec>[ ...] --restore
```

Example 3 (unknown):
```unknown
dir /S /B *.c | cm archive -
```

Example 4 (unknown):
```unknown
cm archive bigfile.zip#br:/main
```

---

## Enable dynamic workspaces (Windows)

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/enable-dynamic-workspaces

**Contents:**
- Enable dynamic workspaces (Windows)#
- Disable dynamic workspaces#
- Manually enable dynamic workspaces#
  - Start plasticfs automatically on startup#
- Additonal resources#

Note: Dynamic workspaces are currently only available on Windows operating systems.

PlasticFS is the executable that runs for dynamic workspaces. For more information about dynamic workspaces, refer to the introduction to dynamic workspaces. To enable PlasticFS for in the Unity Version Control (UVCS) desktop application:

After you enable dynamic workspaces, you can select a Make this workspace dynamic (alpha) checkbox when you create a new workspace.

To disable dynamic workspaces, right-click the PlasticFS icon in the system tray and select Exit.

To enable dynamic workspaces, you need a Unity Version Control (UVCS) installation:

After you start plasticfs.exe, you can create a dynamic workspace from the command line if you check the cm workspace create --dynamic.

**Examples:**

Example 1 (unknown):
```unknown
c:\program files\plasticscm5\client
```

Example 2 (unknown):
```unknown
plasticfs.exe
```

Example 3 (unknown):
```unknown
plasticfs.exe
```

Example 4 (unknown):
```unknown
cm workspace create --dynamic
```

---

## Queues and pools

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/advanced-topics-queues-pools

**Contents:**
- Queues and pools#
- Queues#
  - Default queue#
- Pools#
  - Default pool#
  - Filters#
    - Examples of filters#

A queue contains a mutually exclusive set of tickets that you can match together. Tickets in a queue will not be matched with tickets found in another queue. This behavior is useful when building a game with discrete game modes that don't overlap, such as Team Deathmatch, Free-For-All, and Capture the Flag. It’s also useful in a game where the type of game is different, such as a competitive game with Ranked and Unranked modes.

The default queue serves as a fallback queue if the ticket created does not specify the name of the queue. This fallback method allows you to dynamically switch to the default queue after the game goes live without changing the game client.

This ability to fall back to the default queue also supports legacy versions of Matchmaker where the game clients do not specify queue names. Therefore you do not need to update your game client to include a queue name when migrating your services.

A pool represents a dynamic separation of tickets within a queue. Pools contain filters that indicate which tickets the pool will process. The matchmaker assigns tickets that do not match the filters of a pool to a subsequent pool. If the ticket is not compatible with any of the pools, it uses the default pool of that queue.

For each pool, it is possible to specify hosting information as well as the matchmaking logic to use when building matches with the tickets within the pool.

In this way, you can separate pools by platform by using filters to target the specific platforms, such as a console or Windows. You can also use pools to target regions, such as North America, the European Union, or Asia.

Similarly to queues, the default pool serves as a fallback to make sure you can still process tickets that are not compatible with any other pool. If we take our example with pools for each region, the default pool would be used to put players in a fallback region.

A filter is a way for pools to decide which tickets it will process. When a client creates a matchmaking ticket, custom values can be added under the Attributes section. These attribute values are the ones used in pool filters.

The matchmaker supports two types of values: text and numbers and the filters currently support four operations =, !=, <, and >.

If a pool contains multiple filters, all the filters must pass in order for a ticket to be accepted in this pool.

Here's an example of a pool that matches tickets only on a Windows platform:

**Examples:**

Example 1 (unknown):
```unknown
var attributes = new Dictionary<string, object>
{
    { "platform", "Windows" }
};
```

Example 2 (unknown):
```unknown
var attributes = new Dictionary<string, object>
{
    { "platform", "Windows" }
};
```

Example 3 (unknown):
```unknown
"attributes":[{
        "platform":"Windows"
    }
]
```

Example 4 (unknown):
```unknown
"attributes":[{
        "platform":"Windows"
    }
]
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/trigger-types

---

## Products and catalogs

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/products-and-catalogs

**Contents:**
- Products and catalogs#
- Product attributes#
  - Product ID#
  - Product types#
  - Payouts#
- IAP Catalog#
- Additional resources#

The Products and catalogs page explains how to define, organize, and manage Unity IAP products for your application using the Unity IAP Catalog.

In Unity IAP, a product is any digital item that users can purchase within your application, such as virtual currency, new game levels, premium features, or subscriptions.

You can define your products in two main ways:

Every product is defined by a standard set of attributes that control its behavior and how it appears to users and in the digital store.

To implement coded IAP, call ProductCatalog.LoadDefaultCatalog to access the IAP Catalog in your scripts. For codeless IAP, the catalog is integrated automatically, so no additional action is required. If you prefer to define your own products in code, Unity also provides the optional CatalogProvider class, which helps simplify the process of creating a custom catalog.

Each product has several key attributes that determine its behavior and presentation:

The Product ID is a unique, cross-platform identifier for your product. It is used to communicate with the app stores and can be overriden with store-specific IDs if needed. Product IDs must only contain lowercase letters, numbers, underscores, and periods.

The Product type defines how an item can be purchased and whether it can be restored. The following product types are available:

The Payout attribute (optional) specifies the content a user receives after a successful purchase, such as "100 Gold Coins". Specify the payout to associate each transaction with a particular item and quantity, for example, 100 Gold Coins. The Payouts attribute simplifies in-game inventory management and ensures users receive the correct rewards or items for their purchases.

The IAP Catalog is a Unity Editor window that provides a codeless, visual interface to define and manage your product list.

The catalog is the required method for implementing Codeless IAP and provides a central location in the Unity Editor to configure product attributes, pricing, and store-specific information.

Important: The IAP Catalog defines products, but does not manage inventory. You must implement the logic to deliver purchased content to the user after a successful transaction.

**Examples:**

Example 1 (unknown):
```unknown
ProductCatalog.LoadDefaultCatalog
```

Example 2 (unknown):
```unknown
CatalogProvider
```

---

## Zero downtime releases

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/zero-downtime-releases

**Contents:**
- Zero downtime releases#

Zero downtime releases are build updates you release without taking any game servers offline, allowing you to update your build without subjecting your players to inactive servers or downtime.

You can implement a zero downtime release by following the A-B build pattern. The A-B build pattern is where you keep two builds for one game. While one build (for example, build A) is active, you can update the other build (for example, build B). When build B is ready to release, you can start allocating servers with build B (using build configuration B). As game sessions using build A end, your fleet gradually transitions to using build B as you make new allocations.

Because you use build configurations to point to builds, you’ll also need two build configurations:

In practice, using the A-B build pattern looks like this:

The following flowchart shows the release cycle of a fleet using the A-B build pattern.

**Examples:**

Example 1 (unknown):
```unknown
GetBuildInstalls
```

---

## Create a branch

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/create-branch

**Contents:**
- Create a branch#
- Create a branch in the GUI#
- Create a branch in the CLI#

In Unity Version Control (UVCS), you can work in branches. You can create and switch between branches in both the Unity DevOps Version Control desktop application, and the command line.

On the Branch Explorer tab, right-click the changeset from which you want to create a branch.

Your current changeset shows a house icon.

Select Create branch from this changeset.

Select whether you want to create manually or from a task:

To start development on the branch, select Switch workspace to this branch and select Create.

To create a new branch, run the cm branch command:

If you don’t specify a changeset, the new branch branches off the latest changeset on the parent branch. To specify a changeset, use the --changeset or --label modifier.

Run the cm switch command to switch your workspace to the new branch:

**Examples:**

Example 1 (unknown):
```unknown
cm branch main/fix-1342
```

Example 2 (unknown):
```unknown
cm branch main/fix-1342
```

Example 3 (unknown):
```unknown
--changeset
```

Example 4 (unknown):
```unknown
> cm switch main/fix-1342
Performing switch operation...
Searching for changed items in the workspace...
Setting the new selector...
Plastic is updating your workspace. Wait a moment, please...
The workspace c:\Users\pablo\wkspaces\quake_path is up-to-date (cset:573@quake@localhost:6060)
```

---

## Switch to changeset

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/switch-to-changeset

**Contents:**
- Switch to changeset#

The Switch to Changeset feature allows you to revert the local workspace of your Unity project to the state it was in at a previous changeset. Use this feature to view:

To switch to a selected changeset:

To understand how UVCS behaves when you switch your local workspace with pending changes, refer to the documentation on how to Switch with pending changes.

---

## Add a currency to your game

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/add-currency

**Contents:**
- Add a currency to your game#
- Additional resources#

The following instructions describe how to add a currency resource to your game’s economy system.

The new currency now appears on the Configuration page of Economy.

---

## Common environment variables

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/common-variables

**Contents:**
- Common environment variables#

This table details the environment variables that are available for every trigger script:

**Examples:**

Example 1 (unknown):
```unknown
PLASTIC_USER
```

Example 2 (unknown):
```unknown
PLASTIC_CLIENTMACHINE
```

Example 3 (unknown):
```unknown
PLASTIC_SERVER
```

---

## Access control

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/access-control

**Contents:**
- Access control#
- Control player access to Cloud Code modules example#
- Prerequisites#
  - Authenticate using a Service Account#
  - Configure the UGS CLI#
  - Create a module endpoint#
  - Create an Access Control project policy to restrict access#
  - Set up Scheduling and Triggers#
    - Create a schedule configuration#
    - Create a trigger configuration#

You can control access Unity Gaming Services (UGS) including Cloud Code via the Access Control service.

Using Access Control enables you to create rules to restrict access to service APIs that should not be made available to players.

If you allow player access to modules, you reduce the security of your game. For more information, refer to Server authority.

The example below demonstrates how you can create a project-based policy that denies access to the Cloud Code service APIs. You can wire a Cloud Code C# module to a trigger while denying direct requests from players, increasing the security of your game. You are able to create access policies with the UGS CLI tool.

First, you need to create a service account with required access roles and configure the UGS CLI.

Before you can call the Scheduling and Triggers services, you need to use a service account to authenticate.

Add Product roles and create a key:

For more information, refer to Authentication.

Follow the steps below to get stated with the UGS CLI:

Use the following to configure your Project ID and Environment:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Authenticate using the service account you created earlier. For more information, refer to Get Authenticated.

Create a Cloud Code module that broadcasts a message to all connected players in the project.

Refer to send push messages for more information.

Refer to Deploying Hello World to learn how to deploy a module.

Create a project-policy.json file with the following content to create a policy that denies players direct access to the module endpoint.

Use the UGS CLI tool to apply this policy to your project:

ugs access upsert-project-policy project-policy.json

Test that the policy has successfully denied players from making requests directly to the SendProjectMessage module endpoint when authenticated as a player.

If the policy is successfully applied, this request should return a response with a 403 HTTP status code:

Test that the Cloud Code module is able to execute when authenticated with a service account with the same request. To continue, you need to obtain a stateless token and use it as a Bearer token in the request.

Refer to Cloud Code Client API Bearer Authentication) for more information.

If the request is successful, Cloud Code should respond with a 200 HTTP status code.

You can set up a schedule and trigger to invoke the SendProjectMessage module endpoint.

Run the new-file command to create a schedule configuration locally:

Update the schedule-config.sched file with the following configuration:

Note: Make sure the schedule timestamp is in the future.

Run the new-file command to create a trigger configuration locally:

To create a trigger that invokes the SendProjectMessage module endpoint when the announcement event fires, update the triggers-config.tr file with the following configuration:

Deploy the files using the UGS CLI tool:

If configured correctly, the trigger should invoke the SendProjectMessage module endpoint when the announcement event is fired.

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
using Microsoft.Extensions.DependencyInjection;
using Unity.Services.CloudCode.Core;
using Unity.Services.CloudCode.Apis;

namespace HelloWorld
{
    public class HelloWorld
    {
        [CloudCodeFunction("SendProjectMessage")]
        public async Task SendProjectMessage(IExecutionContext context, PushClient pushClient, string message, string messageType)
        {
            await pushClient.SendProjectMessageAsync(context, message, messageType);
        }
    }

    public class ModuleConfig : ICloudCodeSetup
    {
        public void Setup(ICloudCodeConfig config)
        {
            config.Dependencies.AddSingleton(PushClient.Create());
        }
    }
}
```

Example 4 (unknown):
```unknown
using Microsoft.Extensions.DependencyInjection;
using Unity.Services.CloudCode.Core;
using Unity.Services.CloudCode.Apis;

namespace HelloWorld
{
    public class HelloWorld
    {
        [CloudCodeFunction("SendProjectMessage")]
        public async Task SendProjectMessage(IExecutionContext context, PushClient pushClient, string message, string messageType)
        {
            await pushClient.SendProjectMessageAsync(context, message, messageType);
        }
    }

    public class ModuleConfig : ICloudCodeSetup
    {
        public void Setup(ICloudCodeConfig config)
        {
            config.Dependencies.AddSingleton(PushClient.Create());
        }
    }
}
```

---

## Fleets

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/fleets

**Contents:**
- Fleets#
- Additional resources#

A fleet is a collection of servers that host a game or application in specific regions. After your fleet is online, you can start making allocations via your matchmaker. You can have one or more fleets, and each fleet has a view where you can view the fleet details, the linked build configurations, the scaling settings, and the fleet analytics.

Each fleet has the following associated information:

---

## Google Play data safety

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/privacy/google-play-data-safety

**Contents:**
- Google Play data safety#
- Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Unity Leaderboards.

Important: The following data disclosures are for the Unity Leaderboards SDK only. You are also responsible for providing any additional disclosures for your app, including other third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please visit the Google documentation.

The SDK doesn't currently provide a way to do delete player data, but developers can this via an Admin API and/or Cloud Code script.

Player ID is collected. The Player ID is a random string of numbers generated by the Authentication SDK, which is used to identify returning and new players on different devices and external providers.

---

## Push Notifications

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/overview

**Contents:**
- Push Notifications#
  - Additional resources#

Use Push Notifications to schedule messages to players while they're not actively playing your game. Push Notifications is available for iOS and Android mobile devices and messages can be scheduled to send at a specified time in the future or on an ongoing basis. You can measure how many players have opened them and then started your game as a result.

Note: Unity Analytics is a requirement for Push Notifications and the feature is bundled with the existing Analytics price. For more information about Analytics pricing, refer to UGS Pricing.

---

## Use the JIRA integration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/issue-tracking/jira/use-jira

**Contents:**
- Use the JIRA integration#
- Task on branch workflow#
  - Link a branch to an issue#
- Task on changeset workflow#
  - Link a changeset to an issue#
- Transition JIRA statuses#
  - Configure status transitions#
    - Map keyword-status pairs on Windows#
    - Map keyword-status pairs on Linux or macOS#
  - Status transition syntax#

Choose a workflow for your JIRA integration to link tickets and transition statuses.

Use one of the following working modes for your JIRA integration:

You can also transition JIRA statuses.

Find issue information in the JIRA extension panel. You can open the issue in the browser, add a new issue, or delete an issue. If you select the Open issue in browser icon, or double-click on the JIRA task, UVCS opens the associated issue in a browser window. JIRA displays the details of any changes in the linked issue, under the custom field.

Task on branch is the default working mode. Each JIRA task links to a branch in Unity Version Control (UVCS).

If you select the Open issue in browser icon, or double-click on the JIRA task, UVCS opens a browser window with the associated branch issue.

The task on changeset working mode allows you to link multiple changesets to multiple branches.

Use the UVCS desktop application to link changesets to JIRAissues:

To log the checkin information in the related JIRA issue, enter a comment in the Checkin comments field, start the comment with the # character followed by the issue key. For example, VCS-1: update.

Use changeset comments in Unity Version Control (UVCS) to change the status of a linked issue in the JIRA integration. Your JIRA workflow must allow these transitions.

Define your own keyword-status mappings so that if the keyword is in the changeset comment, the issue status transitions to the status mapped to that keyword.

Configure the status transitions in the UVCS desktop application:

Use the following format for the keyword-status mapping:

For example, the following keyword-status mapping configures the following transitions:

**Examples:**

Example 1 (unknown):
```unknown
VCS-1: update
```

Example 2 (unknown):
```unknown
Name=Status transitions;Value=[FIXED]-Ready for QA|[WONTFIX]-Done;Type=Text;IsGlobal=True
```

Example 3 (unknown):
```unknown
Name=Status transitions;Value=[FIXED]-Ready for QA|[WONTFIX]-Done;Type=Text;IsGlobal=True
```

Example 4 (unknown):
```unknown
[<KEY>]-<VALUE>|[<KEY>]-<VALUE>
```

---

## Resolve an incident

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/incident-resolution

**Contents:**
- Resolve an incident#
- Resolve an action conflict#

Safety Moderators and Admins can resolve incidents from the incident report page regardless of whether they responded to the incident with an action or not.

To resolve an incident:

After a moderator resolves an incident, other moderators can see the resolution, including any applied actions and their duration, from the incident report’s Detail view.

If a Safety Moderator or Admin applies an action to a player and an existing action of the same type already exists on the player, the Unity Dashboard displays a warning. At this point, the user can choose to overwrite the existing action.

To overwrite the existing action, and apply the new action, when resolving an incident, select the confirmation box before resolving the incident.

Overwriting the existing action reflects in the activity log by showing that the old action was revoked when resolving the incident with the new action.

You can view active actions taken against the players by hovering over the Active action warning.

---

## About User Reporting

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/UserReporting/AboutUserReporting

**Contents:**
- About User Reporting#
- Benefits of user reports#
- Reporting overhead#
- User Reporting and Compliance with PIPL#
  - How PIPL impacts User Reporting#
  - Actions you need to take#
- What’s next?#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

User Reporting is a service that collects bug reports or feedback from your players during development. A report includes a collection of name/value pairs, screenshots, or optional attachments you can use to analyze issues and feedback about your game.

In your app you can use built-in reporting, build customized reports, or use a combination of both. The built-in functionality provides a form that your users fill out and submit with a title, description, and screenshot. If you build your own reports, you can design the form to collect any specific data you need. You can adjust which types of reports you collect from users. You don’t need to display a form to capture information for a report, as you can configure automatic user reports.

User Reporting doesn’t allocate resources and has negligible overhead when idle. When it runs, most reporting operations also have a negligible impact on performance. However, screenshots use data and might impact performance.

Memory usage is directly related to the limits set when configuring a user report.

From November 1 2021, a new data privacy law came into effect from the People's Republic of China (hereinafter “China”) . The new law, known as Personal Information Protection Law (or PIPL), is a data privacy law passed by China’s National People’s Congress to protect the data privacy of people based in China. Game players located in China are now required to consent (“Opt-In”) to having their personal information transferred and processed or transferred outside of China. Read more on PIPL.

To respect user privacy, the User Reporting SDK now includes the following changes:

We’ve updated the User Reporting SDK to implement these changes. If you already use User Reporting, upgrade to the latest SDK as of November 2021. If you install the User Reporting SDK for the first time, the User Reporting SDK version is compatible with PIPL as of November 2021.

---

## Create a lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/create-a-lobby

**Contents:**
- Create a lobby#
- Create a public lobby#
- Create a private lobby#
- Create a lobby with standard, non-indexed data#
- Create a lobby with indexed string data#
- Create a lobby with indexed numeric data#
- Create a lobby with player data for the host#
- Active and inactive lobbies#

When a player creates a new lobby, they can set the following properties with the create call:

Note: When a player creates a lobby, they automatically become the host.

Public lobbies do not require a lobby code to join and are displayed in query results for anyone to join.

The following code sample shows how to create a public lobby:

Private lobbies are never visible in query results and require the lobby code or ID to be manually provided to new players.

The following code sample shows how to create a private lobby:

Lobby data can be included in the create request as well as in subsequent update requests.

The following code sample shows how to create a lobby with standard, non-indexed data:

The following code sample shows how to create a lobby with indexed string data:

The following code sample shows how to create a lobby with indexed numeric data:

As with lobby data, player data for the host can also be included in the create request instead of adding it with a separate update request.

The following code sample shows how to create a lobby with player data for the host:

Lobbies are marked as inactive if they haven’t been updated or sent a heartbeat request in the past 30 seconds. You can configure this timeout period. Inactive public lobbies do not appear in query results, and both public and private inactive lobbies are automatically deleted. Inactive lobbies can be reactivated by being updated or sending a heartbeat request.

Because there is a rate limit of 5 heartbeat requests per 30 seconds, users are capped at hosting 5 lobbies at a time. See Heartbeat a lobby for more information.

**Examples:**

Example 1 (unknown):
```unknown
string lobbyName = "new lobby";
int maxPlayers = 4;
CreateLobbyOptions options = new CreateLobbyOptions();
options.IsPrivate = false;

Lobby lobby = await LobbyService.Instance.CreateLobbyAsync(lobbyName, maxPlayers, options);
```

Example 2 (unknown):
```unknown
string lobbyName = "new lobby";
int maxPlayers = 4;
CreateLobbyOptions options = new CreateLobbyOptions();
options.IsPrivate = false;

Lobby lobby = await LobbyService.Instance.CreateLobbyAsync(lobbyName, maxPlayers, options);
```

Example 3 (unknown):
```unknown
string lobbyName = "new lobby";
int maxPlayers = 4;
CreateLobbyOptions options = new CreateLobbyOptions();
options.IsPrivate = true;

Lobby lobby = await LobbyService.Instance.CreateLobbyAsync(lobbyName, maxPlayers, options);
```

Example 4 (unknown):
```unknown
string lobbyName = "new lobby";
int maxPlayers = 4;
CreateLobbyOptions options = new CreateLobbyOptions();
options.IsPrivate = true;

Lobby lobby = await LobbyService.Instance.CreateLobbyAsync(lobbyName, maxPlayers, options);
```

---

## BRANCH SHOWMAIN

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/branch-showmain

**Contents:**
- BRANCH SHOWMAIN#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Output format parameters (--format option)#
  - Examples#

Shows the main branch of a repository. The main branch of your repository is '/main' by default.

cm branch | br showmain [<repspec>] [--encoding=<name>] [--format=<format_str>] [--dateformat=<date_format>]

This command shows the main branch of a repository.

This command accepts a format string to show the output. The output parameters of this command are the following:

(Displays the main branch for the repository of the current workspace.)

cm branch showmain repo@server:8084

(Displays the main branch for the repository 'repo' in server 'server:8084'.)

cm br showmain --dateformat="yyyy, dd MMMM" --encoding=utf-8

(Displays the main branch of the repository with a given date format, and the output is in utf-8.)

cm br showmain --format="{id} - {name}"

(Displays the main branch of the repository, printing only its id and name.)

**Examples:**

Example 1 (unknown):
```unknown
cm branch | br showmain [<repspec>] [--encoding=<name>] [--format=<format_str>] [--dateformat=<date_format>]
```

Example 2 (unknown):
```unknown
cm branch showmain
```

Example 3 (unknown):
```unknown
cm branch showmain repo@server:8084
```

Example 4 (unknown):
```unknown
cm br showmain --dateformat="yyyy, dd MMMM" --encoding=utf-8
```

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/game-overrides/manual/get-started

**Contents:**
- Get started#
- Set up Game Overrides#
- Create an Override#
  - Targeting#
  - Content#
    - Remote Config#
    - Economy#
      - Currency#
      - Inventory Item#
      - Virtual Purchase#

You can set up and manage Game Overrides in the Unity Dashboard:

When you launch Game Overrides for the first time, this adds Game Overrides to the Shortcuts section on the sidebar and opens the overview page.

Select Create Override. Add a name and select Next.

To enable testing with statistical significance tracking for this Override, refer to A/B testing.

Targeting is only available for Game Overrides that don't use statistical significance tracking.

Select the targeting method to use to choose your audience: JEXL (stateless) or Audiences (stateful). To target all players, don't specify an audience.

JEXL (Java EXpression Language) conditions are evaluated against various factors in each request. This method uses contextual data attributes to define the audience for which you want to apply a Rule. You can use multiple criteria, for example:

This example targets English-speaking users who are using an app version greater than 1.2. Remote Config requests are often implemented in the code when making a fetch at the start of a session, but you can implement them at any time. You can then use that information to segment statelessly. Refer to predefined conditions.

Audiences are grouped by criteria such as behavior (for example, in-game spending, days active) or location. Audiences can be analyzed and targeted with personalized content (Game Overrides) to boost interactions and promote in-app purchases. For example, you can target and send extra lives and boosts to players who have stopped playing at specific points in your game. Refer to Audiences for a list of predefined Audiences.

Choose from stateless or stateful players, or all players by selecting True.

You can control the percentage of players in this group who receive your changes; use this to progressively roll out a new feature. Audience Targeted is the percentage of your defined Audience/JEXL group that receive the Override. For example, if you have 1000 players in the All Spenders Audience and target 60% of them, 600 of those players receive the change and 400 don't.

Game Overrides can control Remote Config keys, Cloud Content Delivery (CCD), and various Economy resources. These can be used to make changes to various components in your game directly from the Unity Dashboard.

Override the Remote Config keys you have configured in your game.

To make a change to your keys:

On the Content page, select Choose content type.

Select Config Overrides, and select Done.

Set the Key Name to your Key.

Select on the field you want to change and enter the new values in the dialog.

You can add multiple content types at once, as outlined in the Economy and CCD sections below. For example, you can enable a new game mode with Remote Config keys, increase the rewards for an Economy Virtual Purchase, and enable new assets with CCD at the same time.

You can add additional keys, and split configuration between multiple variants. In the following example, the StartingBalance is 500, and the MaximumBalance is 20,000. You can also change the weighting of the groups.

Economy overrides allow you to make changes to your Economy configuration for groups of players, schedule changes, and compare them, without releasing new versions of your game.

Economy overrides provide a method of making changes to your live game, and give you the flexibility to choose who will see those changes.

Note: Unity Analytics is a prerequisite to enable targeting and variant reporting for Economy.

You can override the following Economy resources:

On the Content page, select Choose content type.

Select Currency > Done.

Set the Currency name to your Currency.

Select on the field you want to change and enter the new values in the dialog.

Note: If you haven’t yet set up an Economy resource and published it, it won’t be available for selection in the content type dialog.

To make a change to a Virtual Purchase:

On the Content page, select Choose content type.

Select Virtual Purchase > Done.

Set Virtual Purchase name to your Virtual Purchase.

Select on the field you want to change and enter the new values in the dialog.

On the Content page, select Choose content type.

Select Real Money Purchase > Done.

Set Real Money Purchase name to your Real Money Purchase.

Select on the field you want to change and enter the new values in the dialog.

Use Cloud Content Delivery overrides to change the Badge Releases for your Buckets. Target assets at different player groups or schedule assets to be available for a time period.

To change your Badge Release for your Buckets:

On the Content page, select Choose content type.

Set Bucket Name to your Bucket.

Select your Target Badge in the dialog.

Select Next and set your schedule. If the End Date is not set, the Override runs indefinitely.

Select Finish. Verify your changes and select Enable to make your changes live. Players will start receiving new content in real-time.

If you’re using Unity Analytics, you can see the impact your changes have on your KPIs. On the Details page, select Reporting. You can select a KPI and the dates (today, last seven days, last 14 days, last 30 days, last quarter) to access your data.

The following metrics are available:

**Examples:**

Example 1 (unknown):
```unknown
unity.language == “EN” && unity.appVersion > 1.2
```

Example 2 (unknown):
```unknown
unity.language == “EN” && unity.appVersion > 1.2
```

---

## Add a virtual purchase to your game

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/add-virtual-purchase

**Contents:**
- Add a virtual purchase to your game#
- Additional resources#

The following instructions describe how to define the parameters of virtual purchase in your game’s economy.

From the Unity Dashboard, open Economy and select Configuration.

Set Choose a type to Virtual purchase.

Give the transaction a resource name, and an ID for use in API calls. For example, if your virtual purchase is for a sword, the item name could be Buy Sword, and the ID is auto-generated from the name but you can change it to anything that suits you and your game.

The next screen contains these sections to fill.

You can add any optional custom JSON data you want allocated to this virtual purchase by entering it into the Custom Data box. See Custom data.

The new virtual purchase now appears on the Configuration page of Economy.

---

## Metadata

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/concepts/metadata

**Contents:**
- Metadata#
- Limits#

Scores can have associated metadata to store details about a score.

For example, if a player gets a score using a certain item or while in a certain clan, this can be stored as a JSON object alongside the score.

Metadata is always optional. It is only retrieved when requested. When an archive is created, associated metadata is also archived.

---

## Player evidence report HTTP request

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/text-evidence/player-evidence-report-request

**Contents:**
- Player evidence report HTTP request#

The following code is an example of a player evidence request:

Note: Add the request_start_ts parameter to the request if using pagination to make subsequent requests.

**Examples:**

Example 1 (unknown):
```unknown
curl https://services.api.unity.com/vivox/text-evidence-management/v1/organizations/<organization_id>/projects/<project_id>/player-evidence-report?user_uri=sip:your-issuer.john@yourvivoxdomainname.vivox.com&start_ts=1234567&end_ts=1234568&num_conversations=1 -u service-acct-username:service-account-password
```

Example 2 (unknown):
```unknown
curl https://services.api.unity.com/vivox/text-evidence-management/v1/organizations/<organization_id>/projects/<project_id>/player-evidence-report?user_uri=sip:your-issuer.john@yourvivoxdomainname.vivox.com&start_ts=1234567&end_ts=1234568&num_conversations=1 -u service-acct-username:service-account-password
```

Example 3 (unknown):
```unknown
request_start_ts
```

---

## Glossary

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/Glossary

**Contents:**
- Glossary#

An end-to-end data and analysis solution designed to support your entire studio. Analytics lets studios easily understand game performance and player behaviors.

Average revenue per daily active users for players in and not in the campaign by calendar date.

Players that are grouped by criteria such as player behavior or location. Audiences can be targeted to personalize their game journey.

Logical partitions for Unity Game Services that contain data associated with your project.

A key is used to integrate and configure the SDK. For Google you need a Firebase Service Account Key. For Apple you need an Apple Key.

Recorded when a notification is opened. Contains data on which campaign and cohort the user was in, and if the app was launched from the notification.

Recorded when a new token is registered on the client, containing the push token.

Percentage of notifications opened by players by calendar date.

A key is used to integrate and configure the SDK. For Google you need a Firebase Service Account Key. For Apple you need an Apple Key.

Purchase for players in and not in the campaign by calendar date

Push Notifications is a feature you can use to schedule rich push messages to a selection of chosen players. Currently this is available for Android and iOS only. Use Push Notifications to tell players about things that are happening in their game from outside the game. You can measure how many players have opened them and then started your game as a result.

Use Reporting to see the performance of your Push Notifications. To see specific information about your Push Notification, choose between metrics like Application Open and Purchases. Select the time frame since the send date, from 24 hours to 30 days.

Software developer kit, that adds functionality and features to your Unity project, such as the sending of events for analysis.

Choose to send a notification once.

Choose to set up a recurring notification.

A real-time 3D development platform and editor to make creative projects.

---

## Parties

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/parties

**Contents:**
- Parties#
- Requirements#
- High-level workflow#
- Concepts#
  - Parties#
  - Party leader#
  - Party member#
- Manage parties#
  - Create a party#
  - Assign another player as the party lead (as the party lead)#

Note: Parties uses the Unity Lobby service to group players together. As a result, the Lobby service is a requirement of Parties.

Parties shows how to create a party experience in your game. A party is a group of players, formed by players, that persists for a game session (from game launch to game exit). A party persists across multiple game # states, such as lobby, matchmaking, and gameplay. Unlike a friends list (which is a permanent grouping of players), a party only lasts for the duration of a single game session.

Before continuing, download and install the Unity Hub and a supported version of the Unity Editor. Parties supports the following Unity Editor versions:

Before getting started with Parties, you must meet the following requirements:

A typical party member’s journey using Parties is as follows:

A party is a group of players, formed by players, that persists for a game session (from game launch to game exit).

A party leader is the host of a party. They manage the party and can add and kick out players.

A party member is the player who is part of the party. Party members can add other players by sending an invite code.

Use the following Lobby code samples from the LobbyManager to carry out Party operations:

You need to create a method for sending invites to players. However, in lieu of the ability to send invites to players, players can share the LobbyCode via text communication.

Visit the Support page to learn how to contact the Unity Lobby support team.

**Examples:**

Example 1 (unknown):
```unknown
async Task<(bool success, Lobby lobby)> TryCreateLobbyAsync()
{
    try
    {
        var currentPlayer = new Unity.Services.Lobbies.Models.Player(AuthenticationService.Instance.PlayerId);
        var partyLobbyOptions = new CreateLobbyOptions()
        {
            IsPrivate = true,
            Player = currentPlayer,
        };

        Lobby lobby = await LobbyService.Instance.CreateLobbyAsync("new lobby",
            maxPlayers: 4,
            partyLobbyOptions);

        //... The party has been created and joined
        return (true, lobby);
    }
    catch (LobbyServiceException e)
    {
        Debug.LogException(e);
        return (false, null);
    }
}
```

Example 2 (unknown):
```unknown
async Task<(bool success, Lobby lobby)> TryCreateLobbyAsync()
{
    try
    {
        var currentPlayer = new Unity.Services.Lobbies.Models.Player(AuthenticationService.Instance.PlayerId);
        var partyLobbyOptions = new CreateLobbyOptions()
        {
            IsPrivate = true,
            Player = currentPlayer,
        };

        Lobby lobby = await LobbyService.Instance.CreateLobbyAsync("new lobby",
            maxPlayers: 4,
            partyLobbyOptions);

        //... The party has been created and joined
        return (true, lobby);
    }
    catch (LobbyServiceException e)
    {
        Debug.LogException(e);
        return (false, null);
    }
}
```

Example 3 (unknown):
```unknown
async Task<(bool success, Lobby lobby)> TrySetHostAsync(string newHostPlayerId, Lobby lobby)
{
    // Only the host can modify the host
    if (lobby.HostId != AuthenticationService.Instance.PlayerId)
        return (false, lobby);

    try
    {
        var setHostOptions = new UpdateLobbyOptions()
        {
            HostId = newHostPlayerId
        };

        return (true, await LobbyService.Instance.UpdateLobbyAsync(lobby.Id, setHostOptions));
    }
    catch (LobbyServiceException e)
    {
        Debug.LogException(e);
        return (false, lobby);
    }
}
```

Example 4 (unknown):
```unknown
async Task<(bool success, Lobby lobby)> TrySetHostAsync(string newHostPlayerId, Lobby lobby)
{
    // Only the host can modify the host
    if (lobby.HostId != AuthenticationService.Instance.PlayerId)
        return (false, lobby);

    try
    {
        var setHostOptions = new UpdateLobbyOptions()
        {
            HostId = newHostPlayerId
        };

        return (true, await LobbyService.Instance.UpdateLobbyAsync(lobby.Id, setHostOptions));
    }
    catch (LobbyServiceException e)
    {
        Debug.LogException(e);
        return (false, lobby);
    }
}
```

---

## Steam

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-steam

**Contents:**
- Steam#
- Set up a Steam account sign-in#
- Sign in a returning player or create new player#
- Update a player from anonymous to a Steam account#
- Sign in a returning player or create new player for Additional App IDs#
- Unlink Steam account#

Minimum SDK version: 2.0.0

This article guides you through the following scenarios in setting up authentication for players in your game with a Steam account:

To provide a steam sign-in option for the players in your game, create an app in the SteamWorks Partner Portal and install the Steamworks.Net SDK to sign in the user and get the session ticket.

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

Create your app and note down the app ID following the Steamworks documentation.

Create the Publisher Web API key following the Authentication using Web API Keys documentation.

Install the SteamWorks.Net SDK following instructions to install the SDK specifically for Unity.

Configure your ID provider to be Steam for Unity Authentication:

(Optional) Add Additional App IDs for Demo, PlayTest, Alpha builds. Still in the Authentication Settings.

Implement the Steam login using the sample code below. Refer to the documentation of GetAuthTicketForWebApi. Unity Authentication SDK accepts only Steam session tickets. Encrypted Application Tickets are not accepted.

Important: It's crucial to register to the OnAuthCallback provided by Steam SDK. It provides a proper auth ticket validation. More details can be found here. The code below is a good example of Steam authentication.

Important: Unity Player Authentication only accepts a string containing alphanumeric characters with a length between 5 and 30 as the identity field; make sure to request the ticket using the same string following the same requirements.

Note: The code example below assumes you already have the player's Steam session ticket using the GetAuthTicketForWebApi method and that you have passed the same identity parameter for issuing the ticket.

Use the SignInWithSteamAsync method to either:

If no Unity Authentication player in your project is associated with the credentials, SignInWithSteamAsync creates a new player. If a Unity Authentication player in your project is associated with the credentials, SignInWithSteamAsync signs into that player's account. This function doesn't consider the cached player, and SignInWithSteamAsync replaces the cached player.

After anonymous authentication set up, if the player wants to upgrade from being anonymous to create a Steam account and sign in using a Steam account, the game should prompt the player to trigger the Steam sign-in and get the session ticket from Steam. Then, call the LinkWithSteamAsync API to link the player to the Steam session ticket.

If a cached player exists on the SDK, you can link the cached player to the Steam Account.

For more information about cached players, refer to Sign In a Cached Player.

When the player triggers the Steam login by signing in or by creating a new player profile, and you have received the Steam access token using the same identity parameter, call the following API to authenticate the player.

Use the same SignInWithSteamAsync method to sign a player in to an Additional App ID, for example, Demo, PlayTest, Alpha.

Note: The code example below assumes you already have the player's Steam session ticket using the GetAuthTicketForWebApi method and that you have passed the same identity parameter for issuing the ticket.

Important: The player has the same Unity Authentication Player ID for all App IDs under the same project, so use your best judgement to set up different environments to keep the player data (for example, Economy, Cloud Save) scoped to each App ID and avoid mixing production data with non-prodution data.

Use the UnlinkSteamAsync API so your players can unlink their Steam account. Once unlinked, if their account isn’t linked to any additional identity, it transitions to an anonymous account.

**Examples:**

Example 1 (unknown):
```unknown
steam_appid.txt
```

Example 2 (unknown):
```unknown
Callback<GetTicketForWebApiResponse_t> m_AuthTicketForWebApiResponseCallback;
string m_SessionTicket;
string identity = "unityauthenticationservice";

void SignInWithSteam()
{
    // It's not necessary to add event handlers if they are
    // already hooked up.
    // Callback.Create return value must be assigned to a
    // member variable to prevent the GC from cleaning it up.
    // Create the callback to receive events when the session ticket
    // is ready to use in the web API.
    // See GetAuthSessionTicket document for details.
    m_AuthTicketForWebApiResponseCallback = Callback<GetTicketForWebApiResponse_t>.Create(OnAuthCallback);

    SteamUser.GetAuthTicketForWebApi(identity);
}

void OnAuthCallback(GetTicketForWebApiResponse_t callback)
{
    m_SessionTicket = BitConverter.ToString(callback.m_rgubTicket).Replace("-", string.Empty);
    m_AuthTicketForWebApiResponseCallback.Dispose();
    m_AuthTicketForWebApiResponseCallback = null;
    Debug.Log("Steam Login success. Session Ticket: " + m_SessionTicket);
    // Call Unity Authentication SDK to sign in or link with Steam, displayed in the following examples, using the same identity string and the m_SessionTicket.
}
```

Example 3 (unknown):
```unknown
Callback<GetTicketForWebApiResponse_t> m_AuthTicketForWebApiResponseCallback;
string m_SessionTicket;
string identity = "unityauthenticationservice";

void SignInWithSteam()
{
    // It's not necessary to add event handlers if they are
    // already hooked up.
    // Callback.Create return value must be assigned to a
    // member variable to prevent the GC from cleaning it up.
    // Create the callback to receive events when the session ticket
    // is ready to use in the web API.
    // See GetAuthSessionTicket document for details.
    m_AuthTicketForWebApiResponseCallback = Callback<GetTicketForWebApiResponse_t>.Create(OnAuthCallback);

    SteamUser.GetAuthTicketForWebApi(identity);
}

void OnAuthCallback(GetTicketForWebApiResponse_t callback)
{
    m_SessionTicket = BitConverter.ToString(callback.m_rgubTicket).Replace("-", string.Empty);
    m_AuthTicketForWebApiResponseCallback.Dispose();
    m_AuthTicketForWebApiResponseCallback = null;
    Debug.Log("Steam Login success. Session Ticket: " + m_SessionTicket);
    // Call Unity Authentication SDK to sign in or link with Steam, displayed in the following examples, using the same identity string and the m_SessionTicket.
}
```

Example 4 (unknown):
```unknown
GetAuthTicketForWebApi
```

---

## CCD support

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCD-support

**Contents:**
- CCD support#

If you ever have a question about our services or experience an issue, you have access to our dedicated support staff. The Cloud Content Delivery team is here to help with any feature or performance concerns.

There are several ways you can request help from the CCD team:

---

## Migrating from Perforce

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/migrating-from-p4

**Contents:**
- Migrating from Perforce#
- Workflow#
- CLI Usage#
  - Options#
- Import example#
- Recommentations#
- Limitations#
  - Known Issues - Pull#
  - Known Issues - Push#

Unity Version Control (UVCS) lets you migrate, and keep synchronized, a Perforce (P4) repository. The P4 Sync command can import metadata, data, and P4 branches in a bidirectional way.

The P4Sync command seeks new P4 changesets to import into UVCS, and vice versa. It scans the repositories for missing UVCS changesets to import into P4. When the search operation finds new changesets or changelists, the process synchronizes them.

You can use the same command to synchronize the data bidirectionally between the two version control systems, P4 and UVCS. You don't need to change the command syntax to pull from P4 or pull from UVCS; both operations take place simultaneously.

By default, when you run the sync command for the first time, all the P4 history for the given depot path syncs into the empty UVCS repository. The first P4 changelist is usually the most challenging, as many assets are typically added at the beginning of the P4 repository. Don't worry if you see the command stop at a changelist; it likely contains numerous changes, and the importer is processing it.

The sync command provides periodic updates on the ongoing process. You can enable the cm log file to view additional debug information. To learn how to do this, see https://www.plasticscm.com/documentation/technical-articles/kb-enabling-logging-for-plastic-scm-part-i

cm sync <repspec> p4multibranch <p4server> [--mainbranch=main_branch_folder] [--branchesfolder=branches_folder] --user=usr_name --pwd=password

Given the P4 repository structure below, where //depot/project/dev is the main branch folder, then //depot/project/release-01 and //depot/project/release-02 branch folders.

//depot/project/dev//depot/project/release-01//depot/project/release-02

The command to synchronize the entire structure from the very beginning of the P4 history would be:

cm sync MyRepoName@catacroquer@cloud p4multibranch p4Server:1666 --mainbranch=//depot/project/dev --branchesfolder=//depot/project --user=p4_read_user --pwd=password

If you don't want to import the P4 branches, do not specify the --branchesfolder= parameter. The tool will import just the main branch.

Moving a P4 repository involves a lot of data. The process might hit the overall machine performance by flooding the TMP directory. We recommend using the -tmpwkpath parameter and redefining the OS PATH variable for the import session. Stick to the P4 history you need to import. The --first parameter is handy to eliminate unneeded old history. Also, use the --excluded parameter to entirely skip P4 depot paths you won't need at the UVCS repository. cm sync p4multibranch uses the Perforce CLI tool (p4) to manage the P4 data and metadata. Ensure you have a p4 tool configured with the correct access to the depot at the OS Path env variable. P4 history can be a case sensitivity mess. You can find entries referring to the same item using different case. UVCS is case-sensitive, so to prevent issues and end up with duplicated entries, use the --caseinsensitive parameter.

The branches are always created in UVCS using the full content of the starting point. If only a subdirectory of //depot/project/main/...@24 is branched in P4, we will see the full content under //depot/project/main/... in UVCS. The P4 branches created from custom configurations don't keep this custom configuration in UVCS. A UVCS branch always starts from an existing and defined configuration (changeset). So, the importer will choose only one specified path@changelist configuration as the branch base. The net.parallel.max P4 setting must be set (to a value higher than 1) to enable parallel download of contents while syncing. However, in those scenarios where the user is not a super user, parallel processing won't be enabled by default as it requires to check a p4 variable and it will fail in this case. The workaround is asking a super user (usually a company admin) to set both variables: net.parallel.max and net.parallel.threads and these values will be used during the sync. You can also force the number of threads to download data from p4 by using the parameter --p4threads=X. You can only migrate one P4 path into a UVCS repository.

The sync operation ignores the P4 changelists that contain changes of different branches (or what we consider different branch folders) in the same changelist. When the P4 changelist used to create the branch (populate/integrate commands) only contains delete operations, we don’t use it as the branch base. In this scenario, we use the closest parent changelist with any change different than a delete as the starting point. The CLI progress while pulling content from P4 might display inconsistent data. For example, if the P4 depot contains 500 changelists, the CLI will display 500 changelist to pull. But the import might affect only 200 changelist, and then the 500 count is inaccurate. This works this way to avoid requesting all the P4 changelists at once at the beginning because it can be slow and error-prone. The sync operation can display there are new P4 changelists to pull, although it later pulls nothing. This happens if these changeslist were pushed from UVCS before or if new changelists in the depot apply to paths unrelated to what's being synchronized. The sync operation can leave some empty directories in UVCS. This is because p4 is not capable of versioning directories, so when all the content of a directory is removed the directory is left empty.

The sync report might show some skipped changes for the following reason: The path couldn't be deleted. This report is harmless. It will just keep a file loaded in p4 that shouldn't be there (in the worst scenario). Perforce doesn't support reusing a path in the same changelist. Therefore we cannot export these changes from UVCS to Perforce. In these cases, we do our best to keep the same structure on the Perforce side. The push ignores changes on empty directories since p4 doesn't handle directories.

**Examples:**

Example 1 (unknown):
```unknown
cm sync <repspec> p4multibranch <p4server> [--mainbranch=main_branch_folder] [--branchesfolder=branches_folder] --user=usr_name --pwd=password
```

Example 2 (unknown):
```unknown
skipplasticbranches
```

Example 3 (unknown):
```unknown
/main/Fix-5.4/SCM4767
```

Example 4 (unknown):
```unknown
/semanticmain/ReleaseSMT-0.9.40.0
```

---

## OpenID Connect

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/openid-connect

**Contents:**
- OpenID Connect#
- Set up custom OpenID Connect ID sign-in#
- Sign in a returning user or create new user#
- Updating a player from anonymous to a custom ID provider account#
- Unlink OpenID account#

A custom sign-in creates a new player for the game session with input from the player (for example, sign-in credentials like an email and password) and links a player to your custom ID provider account. Use custom ID providers to enable existing authentication systems account sign-ins in your game, such as PlayFab, Firebase, Epic Online Services, among others.

If the player signs in with a custom identity provider account, the SignInWith APIs are called to authenticate the players or create new players.

Minimum SDK version: 2.2.0

Check your SDK version; OIDC is supported from 2.2.0+.

This article guides you through the following scenarios to set up authentication for players in your game with a custom ID provider using OpenID Connect:

Important: To provide a custom ID provider sign-in option for the players in the game, follow the instructions given by your custom ID provider to get an ID token inside your Unity game.

Note: Unity Gaming Services does not provide the integration, and so you need to do the integration to the OIDC/OAuth2 server.

Note: The code example below assumes you've already set up a custom ID provider in the Unity Dashboard and already have a valid ID provider name and the player's ID Token. The integration exists only to link a third-party IdP credential with a UGS Player ID, and you're still expected to build the IdP integration yourself.

Below is a UML sequence diagram with a typical integration between the third party IdP, Unity Gaming Services, and the Unity app/game.

OpenID is an identity layer over the OAuth2.0 protocol. You can verify the identify of the player based on the authentication performed by an authorization server. Use OpenID to connect to clients such as web-based, JavaScript, and mobile clients, to get information on end users and authentication sessions.

Configure an OpenID Connect ID Provider for Unity Authentication:

You can use the SignInWithOpenIdConnectAsync method to either:

If no Unity Authentication player in your project is associated with the credentials, then SignInWithOpenIdConnectAsync will create a new player. If a Unity Authentication player in your project is associated with the credentials, then SignInWithOpenIdConnectAsync will sign into that player's account. This function doesn't take into consideration the cached player, and SignInWithOpenIdConnectAsync will replace the cached player.

After you’ve set up anonymous authentication, the player can upgrade from being anonymous to creating a custom ID provider account and sign in using it to get the ID token. Then, call the LinkWithOpenIdConnectAsync API to link the player to their account.

If a cached player exists on the SDK, then you have the option of linking the cached player to the Open ID Connect Account.

For more information about cached players, read the Sign In a Cached Player section.

When the player wants to sign-in using their account in your own custom ID provider, call the following API:

Use the UnlinkOpenIdConnectAsync API so your players can unlink their OpenID account. Once unlinked, if their account isn’t linked to any additional identity, it transitions to an anonymous account.

**Examples:**

Example 1 (unknown):
```unknown
https://cognito-idp.<Region>.amazonaws.com/<userPoolId>
```

Example 2 (unknown):
```unknown
https://<keycloak-domain>/realms/<realm>
```

Example 3 (unknown):
```unknown
https://securetoken.google.com/<projectId>
```

Example 4 (unknown):
```unknown
SignInWithOpenIdConnectAsync
```

---

## Record events with a custom user ID

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/custom-user-id-support

**Contents:**
- Record events with a custom user ID#

By default, Analytics SDK uses the UGS installation ID as the user ID for each event. This ID is different for each installation on each device which can make it difficult to track the same user across multiple devices, or to join data between the Analytics platform and your own internal sources.

To help with this situation, you can use the External User ID feature to set a specific user ID that you control.

You can set the external user ID to override the Analytics user ID at any point during the application lifecycle using this code:

Warning: Changing the user ID contributes a new user to metrics such as Monthly Active User counts, which might affect billing. For more information, see our billing page. To avoid this, ensure you set an external user ID before enabling data collection.

Even if you set an external user ID, the Analytics SDK still records the installation ID in the unityInstallationID parameter. Likewise, if the player has signed in using Unity Authentication, the authenticated player ID is included in the unityPlayerID parameter. These are not affected by the use of an external user ID.

Any events recorded after you set a custom user ID use the given value. Events recorded previously are not updated and retain the original value.

Note that the SDK doesn't save the external user ID value. If you want to keep a consistent custom ID for a given user over time, you need to save it manually (for example using PlayerPrefs) and set it each time your app starts.

You can revert to using the installation ID for the user ID by setting the ExternalUserId to a null or empty string:

If you are not sure what ID is current in use, you can call the AnalyticsService.Instance.GetAnalyticsUserID() method to retrieve the ID that the Analytics SDK is currently recording events against. It returns either the installation ID or the external user ID that you have set.

**Examples:**

Example 1 (unknown):
```unknown
using Unity.Services.Core;

void SetExternalUserId()
{
	UnityServices.ExternalUserId = "some-user-id";
}
```

Example 2 (unknown):
```unknown
using Unity.Services.Core;

void SetExternalUserId()
{
	UnityServices.ExternalUserId = "some-user-id";
}
```

Example 3 (unknown):
```unknown
unityInstallationID
```

Example 4 (unknown):
```unknown
unityPlayerID
```

---

## Merge conflicts

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/merge-conflicts

**Contents:**
- Merge conflicts#
- 3-way merge tracking#
- Manual merge conflict resolution#

Merge conflicts occur when you try to merge changes into a branch that has conflicting changes. For example, if you change a specific part of a file and someone else also changed that part of the file, then a version control system can’t determine which change takes precedence.

Unity Version control (UVCS) uses 3-way merge tracking, which shows three elements of a merge: the base, the source, and the destination.

The base is the common ancestor of the two changesets you want to merge. The base shows you the file before the changes, which allows UVCS to automatically resolve most merge conflicts. If you have two contributors, and only one modifies a line of code, UVCS compares the line of code with the base in order to keep the modified line in the merge.

For more information, refer to Navigate the Mergetool window

When the same line of code is modified in both the source and the destination, UVCS doesn’t know which modification you want to merge. This means you need to use the UVCS desktop client to manually resolve the merge conflict.

---

## Server files filters

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-files-filters

**Contents:**
- Server files filters#
- Filter files by date#
- Search for files#
- Preview a single file#
- Download a single file#

After you display the game server files for a specific server ID, you can narrow these results by using the provided filters.

Note: A maximum of 600 files are displayed at any one time in the table. To view more files, use the available filters to narrow down the results.

To filter server files by date:

The list of relevant files update automatically.

If you chose Custom as your date filter:

To preview an individual file, select the file name from the list of game server files. This action displays a condensed version of the file without downloading it.

Note: This feature is currently limited to .log filetypes.

To download a single file, select the Download icon at the end of a file's row.

---

## IOSTATS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/iostats

**Contents:**
- IOSTATS#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Available tests#
  - Examples#

Shows statistics about the hardware.

cm iostats [<repserverspec>] [<list_of_tests>[ ...]] [--nettotalmb=<value_mb>] [--networkiterations=<value_iter>] [--diskdatasize=<value_size>] [--disktestpath=<value_path>] [--systemdisplaytime=<value_time>] [--systemdisplaytimeinterval=<value_interval>]

This command requires an available server be used during the network speed tests ("serverUploadTest" and/or "serverDownloadTest").

The '--diskTestPath' must point to a path that belongs to the physical disk drive about to be tested. If no path is specified, the command tries to use the system default temp path. The disk drive of the specified path must have enough free space to execute the test.

During the command execution, the system can experience a degraded performance caused by the tests performed.

cm iostats MYSERVER:8087 --serveruploadtest --serverdownloadtest --nettotalmb=32

**Examples:**

Example 1 (unknown):
```unknown
cm iostats [<repserverspec>] [<list_of_tests>[ ...]] [--nettotalmb=<value_mb>] [--networkiterations=<value_iter>] [--diskdatasize=<value_size>] [--disktestpath=<value_path>] [--systemdisplaytime=<value_time>] [--systemdisplaytimeinterval=<value_interval>]
```

Example 2 (unknown):
```unknown
cm iostats MYSERVER:8087 --serveruploadtest --serverdownloadtest --nettotalmb=32
```

---

## Google Play Games

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-google-play-games

**Contents:**
- Google Play Games#
- Set up a Google Play Games sign-in#
- Sign in a returning player or create new player#
- Updating a player from anonymous to a Google Play Games account#
- Unlink Google Play account#

Minimum SDK version: 2.1.0

This article guides you through the following scenarios in setting up authentication for players in your game with a Google Play Games account:

Note: The code example below assumes you already have the player's one-time authorization code.

To provide a Google Play Games sign-in option for the players in your game, create your app in the Google Play Console and install Google Play Games plugin for Unity v11.01+ to sign in the user and get the one-time authorization code.

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

For plugin versions running v10.14 and earlier, follow the Google ID provider article.

Note: A Google Play Games sign-in is compatible with Android devices only.

Note: Google Play Games sign-in is supported by the Google Play Games plugin for Unity v11.01 and above which recommends using Play Games Services v2 SDK.

Download and import the Google Play Games Plugin for Unity.

Set up your app to enable Google sign-in. Follow Google’s documentation on how to configure your game for Google Login.

Configure your ID provider to be Google for Unity Authentication:

In the Unity Editor menu, go to Edit > Project Settings…, then select Services > Authentication from the navigation menu.

Set ID Providers to Google Play Services, then click Add.

Enter the Web App client ID in the Client ID text field.

Enter the Web App client secret in the Client Secret text field, then select Save.\

Note: You must set a Web App client ID in the plugin setup dialog to use the Authentication SDK.

Implement the Google Play Games sign-in following this sample code:

You can use the SignInWithGooglePlayGamesAsync method to either:

If no Unity Authentication player in your project is associated with the credentials, SignInWithGooglePlayGamesAsync creates a new player. If a Unity Authentication player in your project is associated with the credentials, SignInWithGooglePlayGamesAsync signs into that player's account. This function doesn't consider the cached player, and SignInWithGooglePlayGamesAsync replaces the cached player.

After you’ve set up anonymous authentication, if the player wants to upgrade from being anonymous to creating a Google Play Games account and sign in, your game should prompt the player to trigger the Google Play Games sign-in and get the one-time authorization code from Google. Then, call the LinkWithGooglePlayGamesAsync API to link the player.

If a cached player exists on the SDK, you can link the cached player to the Google Play Games Account.

For more information about cached players, refer to Sign In a Cached Player.

Use the UnlinkGooglePlayGamesAsync API so your players can unlink their Google Play Games account. Once unlinked, if their account isn’t linked to any additional identity, it transitions to an anonymous account.

**Examples:**

Example 1 (javascript):
```javascript
using GooglePlayGames;
using GooglePlayGames.BasicApi;
using UnityEngine;

public class GooglePlayGamesExampleScript : MonoBehaviour
{
    public string Token;
    public string Error;

    void Awake()
    {
        //Initialize PlayGamesPlatform
        PlayGamesPlatform.Activate();
        LoginGooglePlayGames();
    }

    public void LoginGooglePlayGames()
    {
        PlayGamesPlatform.Instance.Authenticate((success) =>
        {
            if (success == SignInStatus.Success)
            {
                Debug.Log("Login with Google Play games successful.");

                PlayGamesPlatform.Instance.RequestServerSideAccess(true, code =>
                {
                    Debug.Log("Authorization code: " + code);
                    Token = code;
// This token serves as an example to be used for SignInWithGooglePlayGames
                });
            }
            else
            {
                Error = "Failed to retrieve Google play games authorization code";
                Debug.Log("Login Unsuccessful");
            }
        });
    }
}
```

Example 2 (javascript):
```javascript
using GooglePlayGames;
using GooglePlayGames.BasicApi;
using UnityEngine;

public class GooglePlayGamesExampleScript : MonoBehaviour
{
    public string Token;
    public string Error;

    void Awake()
    {
        //Initialize PlayGamesPlatform
        PlayGamesPlatform.Activate();
        LoginGooglePlayGames();
    }

    public void LoginGooglePlayGames()
    {
        PlayGamesPlatform.Instance.Authenticate((success) =>
        {
            if (success == SignInStatus.Success)
            {
                Debug.Log("Login with Google Play games successful.");

                PlayGamesPlatform.Instance.RequestServerSideAccess(true, code =>
                {
                    Debug.Log("Authorization code: " + code);
                    Token = code;
// This token serves as an example to be used for SignInWithGooglePlayGames
                });
            }
            else
            {
                Error = "Failed to retrieve Google play games authorization code";
                Debug.Log("Login Unsuccessful");
            }
        });
    }
}
```

Example 3 (unknown):
```unknown
SignInWithGooglePlayGamesAsync
```

Example 4 (unknown):
```unknown
SignInWithGooglePlayGamesAsync
```

---

## Client timeouts

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/client-timeouts

**Contents:**
- Client timeouts#

Client timeouts, also called idle timeouts, occur when Relay disconnects a client from a Relay server due to inactivity. The default time to live (TTL) before Relay disconnects a client is 10 seconds. The disconnect TTL is 60 seconds when the host is alone (after the BIND message but before a peer connects to them with a CONNECT message).

A timeout (controlled by a TTL value) is a mechanism that limits the lifetime of idle connections to a Relay server. Relay uses a TTL to decide when a client times out from lack of network activity. Because some game types might have a low message rate, such as turn-based strategy games, you might need to configure the game client to send PING messages to the Relay server to keep the connection alive to prevent a timeout. The PING message resets the idle timeout for a player connection.

When an allocation expires through a client timeout, the Allocations service removes the allocation from the Relay server, which sends the client a timeout error message.

Note: If an allocation times out, the Relay server responds with an allocation ID not found error. It's common for allocation IDs to expire due to a lack of PING messages. Check out Keep a connection alive to learn how to prevent unintended timeouts.

**Examples:**

Example 1 (unknown):
```unknown
allocation ID not found
```

---

## Use anonymous sign-in

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/use-anon-sign-in

**Contents:**
- Use anonymous sign-in#

Anonymous sign-in creates a new player for the game session without any input from the player. It's a quick way for a player to get started with your game.

You cannot recover anonymous accounts that are not linked to a platform-specific account and if the session token is lost. For example, the player will not be able to log in to their anonymous account if they uninstall and then reinstall the game.

If a session token is cached on the SDK, then the SignInAnonymouslyAsync() method recovers the existing credentials of the cached player, regardless of whether they signed in anonymously or through a platform account. If there is no player sign-in information, this method creates a new anonymous player.

For more information about signing in returning players, refer to Sign In a Cached Player.

The following code sample shows how sign in to your game anonymously.

After implementing anonymous sign-in, it is recommended to integrate with at least one supported external identity provider to allow your players to continue their progress from another device or recover their account, if needed.

**Examples:**

Example 1 (unknown):
```unknown
SignInAnonymouslyAsync()
```

Example 2 (unknown):
```unknown
async Task SignUpAnonymouslyAsync()
{
    try
    {
        await AuthenticationService.Instance.SignInAnonymouslyAsync();
        Debug.Log("Sign in anonymously succeeded!");

        // Shows how to get the playerID
        Debug.Log($"PlayerID: {AuthenticationService.Instance.PlayerId}");

    }
    catch (AuthenticationException ex)
    {
        // Compare error code to AuthenticationErrorCodes
        // Notify the player with the proper error message
        Debug.LogException(ex);
    }
    catch (RequestFailedException ex)
    {
        // Compare error code to CommonErrorCodes
        // Notify the player with the proper error message
        Debug.LogException(ex);
     }
}
```

Example 3 (unknown):
```unknown
async Task SignUpAnonymouslyAsync()
{
    try
    {
        await AuthenticationService.Instance.SignInAnonymouslyAsync();
        Debug.Log("Sign in anonymously succeeded!");

        // Shows how to get the playerID
        Debug.Log($"PlayerID: {AuthenticationService.Instance.PlayerId}");

    }
    catch (AuthenticationException ex)
    {
        // Compare error code to AuthenticationErrorCodes
        // Notify the player with the proper error message
        Debug.LogException(ex);
    }
    catch (RequestFailedException ex)
    {
        // Compare error code to CommonErrorCodes
        // Notify the player with the proper error message
        Debug.LogException(ex);
     }
}
```

---

## Application size reduction with CCD

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDAppSizeReduction

**Contents:**
- Application size reduction with CCD#
- Reduce application size summary#
- Install required packages#
- Configure a bucket in CCD#
- Configure the Unity Editor#
- Prepare the scenes#
- Compare builds (optional)#
- Configure your script#
- Prepare AssetBundle for Dashboard upload#
- Upload to the Dashboard#

To entice players to download your game, a good practice is to keep the initial size of your application small, then have the players download files for new levels and assets as needed later.

This section uses an example project to take you through the process of reducing the size of your application by using CCD and Addressables together.

The following is a summary of the application reduction process. Each step is expanded upon later in the document.

To complete these steps, you need the following:

First, make sure you have installed the required Addressables and CCD Management packages.

The following steps show you how to create and configure a bucket in the Unity Dashboard.

Complete the CCD in the Unity Dashboard instructions to access buckets within CCD.

Complete the Buckets instructions to create a bucket.

Select Create to create the bucket.

Select the bucket from your list of buckets.

Select Upload Content, and upload any file from your computer.

This step is only to create and retrieve a URL for your bucket. You can delete this file once you create your initial release.

Refresh the page then create a release.

Select the release from the Releases tab.

Select Addressable Remote Path URLs.

Copy the Badge: This is the latest URL for use later in the Unity Editor.

Continue the app size reduction process by setting the following in the Unity Editor.

Next, prepare the scene or scenes to load through CCD. Make sure you have at least one scene that is different from the initial level.

Scene creation is outside the scope of this use case. See the Unity Manual: Scenes documentation for more information.

In the Unity Editor, find your scene among your assets in the Project tab.

In the Inspector tab, enable Addressable. Alternatively, drag the scene from the Project tab into the Addressables Groups tab’s Default Local Group.

Within the Addressables Groups tab, right-click on the asset and select Simplify Addressable Names for easier readability.

Select the Default Local Group.

Back in the Addressables Groups window, select Build > New Build > Default Build Script.

If you have previously already run a build, you can update it by selecting Build > Update a Previous Build, then selecting the build’s .bin file.

In this optional step, build the application once with the scene, and once without the scene to compare build sizes.

In the following examples of two test applications with the same number of files and folders, there is roughly a 30 MB difference. In larger applications with more levels and assets, the size savings would be greater.

An example of a release build with the scene and assets included:

An example of a release build without the scene:

In the main scene (the scene to be built with the project), make sure to add a button or an event within the game that loads the next level.

Be sure to exclude from your build any scenes that you are sending through CCD to avoid conflicts.

You can attach the following example script to a button in your game. Be sure to fill in the addressable name (sceneName in this example) in the Inspector.

Prepare your scene assets to upload to the Unity Dashboard by completing these steps:

Upload the recently built .hash and .bundle files that you generated from the previous step. If this is your first upload, select and upload all files.

You can test your build by clicking on the button or action that triggers loading the CCD scene. If everything went correctly, your CCD scene should load after a small delay. Your build should only contain the main scene and not the level you want to load through CCD, otherwise you haven’t reduced the size of your application.

**Examples:**

Example 1 (unknown):
```unknown
using UnityEngine;
using UnityEngine.EventSystems;
using UnityEngine.SceneManagement;
using UnityEngine.AddressableAssets;

public class LoadSceneCCD : MonoBehaviour
{
    public string sceneName = "";

    public void LoadTargetScene()
    {
        Addressables.LoadSceneAsync(sceneName, UnityEngine.SceneManagement.LoadSceneMode.Single, true);
    }
}
```

Example 2 (unknown):
```unknown
using UnityEngine;
using UnityEngine.EventSystems;
using UnityEngine.SceneManagement;
using UnityEngine.AddressableAssets;

public class LoadSceneCCD : MonoBehaviour
{
    public string sceneName = "";

    public void LoadTargetScene()
    {
        Addressables.LoadSceneAsync(sceneName, UnityEngine.SceneManagement.LoadSceneMode.Single, true);
    }
}
```

Example 3 (unknown):
```unknown
ServerData\StandaloneWindows64
```

---

## Session observability

**URL:** https://docs.unity.com/ugs/en-us/manual/session-observability/manual/overview

**Contents:**
- Session observability#
- Authentication#
- Session events#
- Sample session detail#

The Session observability service exposes key events that occurred in a multiplayer session. Currently, it supports Matchmaker events.

The Session observability API allows fetching of session details by ID or by the following filter criteria:

Session details are stored for 30 days from its creation.

The Session Observability service uses service account authentication. Service accounts that are granted the project-level Multiplayer Session Details Viewer role will be authorized to make requests to the API for that project.

Player IDs in session events are anonymized to Player 1, Player 2, etc. to comply with policies regarding retention of personal identifiable information. These anonymized IDs are consistent across one session only.

The following session events are currently supported:

The following is an example of a response received from the API of a session detail where backfill is not enabled.

**Examples:**

Example 1 (unknown):
```unknown
{
    "allocation": {
        "completedAt": "2024-03-19T22:12:48.237Z",
        "regionId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
        "requestedAt": "2024-03-19T22:12:47.981Z",
        "status": "Allocated"
    },
    "createdAt": "2024-03-19T22:12:47.847Z",
    "environmentId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
    "gameMode": {
        "poolId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
        "poolName": "default-pool",
        "queueId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
        "queueName": "default-queue"
    },
    "matchmakingStatus": "OpenNotBackfilling",
    "projectId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
    "sessionEvents": [
        {
            "appliedRules": [
                {
                    "context": "Team",
                    "teamId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
                    "name": "Blue Team",
                    "type": "Difference",
                    "source": "Players.CustomData.Skill",
                    "reference": 500,
                    "not": false,
                    "externalData": {}
                }
            ],
            "teams": [
                {
                    "id": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
                    "name": "Red Team",
                    "playerIds": [
                        "Player 1",
                        "Player 2",
                        "Player 3",
                    ]
                },
                {
                    "id": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
                    "name": "Blue Team",
                    "playerIds": [
                        "Player 4",
                        "Player 5",
                        "Player 6",
                    ]
                }
            ],
            "timestamp": "2024-03-19T22:12:47.847Z",
            "type": "match.created"
        },
        {
            "regionId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
            "timestamp": "2024-03-19T22:12:47.981Z",
            "type": "allocation.requested"
        },
        {
            "timestamp": "2024-03-19T22:12:48.237Z",
            "type": "allocation.succeeded"
        },
        {
            "assignmentStatus": "Found",
            "players": [
                {
                    "customData": {
                        "Skill": 2000
                    },
                    "id": "Player 3",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 1800
                    },
                    "id": "Player 4",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 2100
                    },
                    "id": "Player 5",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 1750
                    },
                    "id": "Player 6",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 1950
                    },
                    "id": "Player 1",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 1675
                    },
                    "id": "Player 2",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                }
            ],
            "timestamp": "2024-03-19T22:12:49.198Z",
            "type": "players.assigned"
        }
    ],
    "sessionId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
    "updatedAt": "2024-03-19T22:12:49.198Z"
}
```

Example 2 (unknown):
```unknown
{
    "allocation": {
        "completedAt": "2024-03-19T22:12:48.237Z",
        "regionId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
        "requestedAt": "2024-03-19T22:12:47.981Z",
        "status": "Allocated"
    },
    "createdAt": "2024-03-19T22:12:47.847Z",
    "environmentId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
    "gameMode": {
        "poolId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
        "poolName": "default-pool",
        "queueId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
        "queueName": "default-queue"
    },
    "matchmakingStatus": "OpenNotBackfilling",
    "projectId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
    "sessionEvents": [
        {
            "appliedRules": [
                {
                    "context": "Team",
                    "teamId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
                    "name": "Blue Team",
                    "type": "Difference",
                    "source": "Players.CustomData.Skill",
                    "reference": 500,
                    "not": false,
                    "externalData": {}
                }
            ],
            "teams": [
                {
                    "id": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
                    "name": "Red Team",
                    "playerIds": [
                        "Player 1",
                        "Player 2",
                        "Player 3",
                    ]
                },
                {
                    "id": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
                    "name": "Blue Team",
                    "playerIds": [
                        "Player 4",
                        "Player 5",
                        "Player 6",
                    ]
                }
            ],
            "timestamp": "2024-03-19T22:12:47.847Z",
            "type": "match.created"
        },
        {
            "regionId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
            "timestamp": "2024-03-19T22:12:47.981Z",
            "type": "allocation.requested"
        },
        {
            "timestamp": "2024-03-19T22:12:48.237Z",
            "type": "allocation.succeeded"
        },
        {
            "assignmentStatus": "Found",
            "players": [
                {
                    "customData": {
                        "Skill": 2000
                    },
                    "id": "Player 3",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 1800
                    },
                    "id": "Player 4",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 2100
                    },
                    "id": "Player 5",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 1750
                    },
                    "id": "Player 6",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 1950
                    },
                    "id": "Player 1",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                },
                {
                    "customData": {
                        "Skill": 1675
                    },
                    "id": "Player 2",
                    "qosResults": [],
                    "ticketId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5"
                }
            ],
            "timestamp": "2024-03-19T22:12:49.198Z",
            "type": "players.assigned"
        }
    ],
    "sessionId": "0e5a4f23-5e1a-4a82-80b0-a1bd80019bc5",
    "updatedAt": "2024-03-19T22:12:49.198Z"
}
```

---

## Get started with Leaderboards

**URL:** https://docs.unity.com/leaderboards/manual/install-leaderboard

**Contents:**
- Get started with Leaderboards#
- Unity Dashboard#
- Unity SDK installation and setup#
  - Install Leaderboards SDK#
  - Install Authentication SDK#
  - Link your Unity project#
  - Initialize the SDKs and authenticate the player#
  - Next steps#
- Leaderboards in the UGS CLI#
  - Deploy a Leaderboards configuration#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

The first step in using Leaderboards is to learn how to implement the feature. This section describes how to set up Leaderboards for your project.

You can set up and manage Leaderboards in the Unity Dashboard:

When you launch Leaderboards for the first time, this adds Leaderboards to the Shortcuts section on the sidebar and opens the Leaderboards Overview.

You can use the Unity Dashboard to create and manage your leaderboards and view their entries.

The Leaderboards SDK requires Unity 2020.3.0 or newer.

You can install the package in the Unity Editor.

Navigate to Window > Package Manager and select Unity Registry in the Packages dropdown on the top left. You can either:

There is a Samples section where you can import example code to your project to assist you calling the Leaderboards SDK from your game.

After installation, the Leaderboards SDK is available in Unity scripts from the Unity.Services.Leaderboards namespace:

The Leaderboards package relies on the Authentication package. The Unity Authentication service creates an account to persist player scores where you can use anoynymous sign-in or platform-specific authentication.

The Authentication package is installed as a dependency when you install the Leaderboards package. For information on installing packages manually, refer to Install a package from a registry.

After installation, the Authentication SDK is available in Unity scripts from the Unity.Services.Authentication namespace:

Once installed, the Authentication package prompts you to link your Unity project to a Unity Gaming Services Project ID. Follow the instructions in the prompt on the screen to link your project.

Alternatively, follow the steps to Link your project in the Unity Editor.

You must initialize the Leaderboards SDK and its dependencies from inside a Unity script lifecycle callback before use. The following example uses the Awake callback. This is done by initializing all installed services via the Core SDK by calling await UnityServices.InitializeAsync();, available from the Unity.Services.Core namespace.

After the SDK initialization is complete, the player is authenticated. The following example uses anonymous authentication to create an anonymous account for the player to persist their scores. Other methods of authentication are available as outlined in the Unity Authentication documentation.

After completing the above steps the Leaderboards SDK is now ready to use from the Unity.Services.Leaderboards namespace. Review the features, Unity SDK tutorial, and the SDK sample to find out more about the Leaderboards feature set and how to use them.

The Unity Gaming Services (UGS) command line interface provides a scalable and automatable alternative to the Unity Dashboard and improves your team's workflows and productivity. The CLI is used to manage, test and deploy your Leaderboards configuration.

See the documentation on how to install and use the CLI.

To make your Leaderboards configurations accessible to the game client, you must deploy the configuration to the Leaderboards service.

Refer to write configuration to learn more about script deployment.

To get started with the UGS CLI, perform the following steps:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Configure a Service Account with the required roles for Leaderboards and environments management. Refer to Get Authenticated.

Run the following command:

ugs deploy <path-to-configuration-file>

Developers that do not use Unity can access APIs via web endpoints or REST APIs. REST APIs provide more flexibility and allow you to automate your workflows by using your favorite language and game development engine.

The Leaderboards service provides the following REST APIs:

This module allows users to author, modify, and deploy Leaderboard configuration assets directly from the Unity Editor.

Leaderboards Authoring is only supported on Unity 2021.3 and above.

The Deployment Window is a core feature of the Deployment package.

The purpose of the Deployment Window is to allow all services to have a single cohesive interface for Deployment needs.

The Deployment Window provides a uniform deployment interface for all services. It allows you to upload cloud assets for your respective cloud service.

For more information, refer to the com.unity.services.deployment package documentation.

Use the right click menu in the Project window to create a Leaderboard asset.

The Deployment Window automatically detects these files to be deployed at a later time.

For more information on how to create and modify Leaderboards Assets, refer to Leaderboards assets.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.Leaderboards
```

Example 2 (unknown):
```unknown
using Unity.Services.Leaderboards;
```

Example 3 (unknown):
```unknown
using Unity.Services.Leaderboards;
```

Example 4 (unknown):
```unknown
Unity.Services.Authentication
```

---

## GETWORKSPACEINFO

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/getworkspaceinfo

**Contents:**
- GETWORKSPACEINFO#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Shows info about the workspace selector.

cm workspaceinfo | wi [<wk_path>]

The 'wi' command shows the working configuration of a workspace (repository, branch, and/or label).

**Examples:**

Example 1 (unknown):
```unknown
cm workspaceinfo | wi [<wk_path>]
```

Example 2 (unknown):
```unknown
cm wi c:\mywk
```

---

## Types of machines

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/machines

**Contents:**
- Types of machines#
- Bare metal machines#
- Cloud machines#

Game servers reside on machines of the following types:

Due to the innate differences between bare metal and cloud machines, Multiplay Hosting manages them differently. The primary difference between the two machine types is how to configure server density.

Bare metal machines (also called bare metal capacity) refer to physical machines that typically reside in a traditional data center and have their operating systems installed directly on the machine’s hardware.

Note: Bare metal is currently reserved for account-managed enterprise customers and must be ordered through our sales team. If your organization is interested in obtaining bare metal for your project, contact a Unity expert.

Cloud machines (also called cloud capacity) refer to virtual machines that exist in the cloud. Multiplay Hosting supports using cloud capacity from several major cloud providers. Cloud machines differ from bare metal machines in that they're typically virtual machines that the cloud provider manages and exposes through an API.

---

## Grow your game • Unity Grow • Unity Docs

**URL:** https://docs.unity.com/ads/en-us/manual/UnityAdsHome

**Contents:**
- Documentation
- Engine
- Services
- Grow
- Industry
- Support
- Engine
- Services
- Grow
- Industry

"Unity", Unity logos, and other Unity trademarks are trademarks or registered trademarks of Unity Technologies or its affiliates in the U.S and elsewhere (more info here). Other names or brands are trademarks of their respective owners.

---

## Provide a code review

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/provide-code-review

**Contents:**
- Provide a code review#
- Add comments#
- Ask questions and request changes#
- Change the review status#
- Additional resources#

You can add and reply to general comments in the Conversation tab.

In the Changed Files tab, you can add questions or change requests to specific sections of code:

When all change requests have been resolved, you can mark the code review as Reviewed.

To mark your code review as reviewed:

---

## Create branch

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/create-branch

**Contents:**
- Create branch#

You can create a new branch from an existing branch:

---

## Get started with Relay

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/get-started

**Contents:**
- Get started with Relay#
- Set up a Relay project#
- Prerequisites#
- Set up Relay#
- Link your Relay project in the Unity Editor#
- Install the Relay package#
- Relay with Netcode for Game Objects#
- Simple Relay sample#
  - Import the Simple Relay sample project#
  - Use the Simple Relay sample#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

Read the following sections to learn how to set up a Relay project and how to use the Relay sample project. If you haven’t already, visit Get started with UGS to learn how to work with the Unity Dashboard.

Note: Binding, and other interactions done through a Relay server, are handled using a networking solution such as UTP or NGO. NGO is higher level and uses UTP under the hood.

Relay is a PAYG (pay as you go) service with a free tier. If you exceed the free tier monthly usage limit, you must enter payment information to keep full access to Relay and any other services.

To get started with Relay, you need to do the following:

You can set up and manage Relay through the Unity Dashboard:

When you launch Relay for the first time, this adds Relay to the Shortcuts section on the sidebar and opens the Overview page.

Note: For most users, the unified Multiplayer Services package replaces the Relay standalone package, which is deprecated in Unity 6. Consider migrating to the unified package to facilitate a smooth transition. Visit the migration guide for a step-by-step transition process.

Check out the Simple Relay sample to learn how to interact with the sample project.

Using Relay with Netcode for GameObjects is a simple use case. Check out Relay with Netcode for GameObjects to learn more.

The Simple Relay sample is an example project that exercises the Relay SDK. The project provides a simple user interface (UI) with buttons, and is intended for manual testing of the SDK. To try the sample project, follow the steps below.

Note: The Simple Relay sample only demonstrates what the standalone Relay SDK does, which doesn't include binding to a server. The standalone Relay SDK makes HTTP API calls to the Relay backend service to create allocations and join codes, and it doesn't affect the client’s network connections.

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.multiplayer
```

Example 2 (unknown):
```unknown
com.unity.services.relay
```

Example 3 (unknown):
```unknown
Assets/Samples/Relay/1.0.1-pre.3/Simple Relay Sample
```

---

## Access the Moderation Platform

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/safety-moderator/access-sv

**Contents:**
- Access the Moderation Platform#

Requirements for accessing the Moderation Platform as a Moderator:

---

## Configure Gluon

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/configure-gluon

**Contents:**
- Configure Gluon#
- Connect to a cloud server#
- Connect to an on-premises server#

Connect your Gluon application to a server so that you can access your repositories.

Gluon installs with the Unity DevOps Version Control application. If you don't have the application, refer to download the desktop client.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-json

---

## Allocations service

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/allocations-service

**Contents:**
- Allocations service#

The Allocations service is the entry point for interacting with the Relay service and enables players to create and join game sessions powered by Relay servers.

The allocation flow, or the connection flow, is the process by which the Allocations service allocates a host player and any number of joining players to a game session.

Note: For details on API request and response bodies, check out the Relay SDK and the Relay allocations API.

---

## Allocating, binding, and joining

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/allocating-binding-joining

**Contents:**
- Allocating, binding, and joining#
- Allocating#
- Binding#
- Joining#

Allocating, binding, and joining are three distinct concepts in the Relay connection flow.

Note: Binding, and other interactions done through a Relay server, are handled using a networking solution such as UTP or NGO. NGO is higher level and uses UTP under the hood.

Allocating is when a host player tells the Allocations service about their intent to connect to a Relay server, and the Allocations service reserves slots on a Relay server. When the Allocations service reserves slots on a Relay server, it prepares the Relay server for players to bind (establish a network connection). The number of slots depends on the maximum number of connections specified in the allocation request.

Check out the following steps in the connection flow:

Binding is when the player establishes a connection with the Relay server that the Allocations service reserved for the player during the allocating process. After the player completes the binding process, the Relay server can discover the player’s IP address and exchange packets.

Note: The host player and joining players must bind to the Relay server before connecting to each other.

A BIND is a specific message sent via the Relay protocol from the game client to the Relay server to establish its connection to the Relay server.

Note: You typically send BIND messages after calling the allocate and join APIs, which retrieve the Relay server’s destination address for use with the BIND message.

Check out the following steps in the connection flow:

Joining is when a joining player joins the host player’s allocation on a Relay server. After the joining player completes the joining process, they can exchange messages with the host player. Allocating and joining are similar processes. The primary difference is that the join API response has the host connection data.

Note: A join is when a joining player (a non-host player) client joins the host client’s game session. Under the hood, it’s another allocate call to the Relay service.

Check out the following steps in the connection flow:

---

## Apple Game Center

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-apple-game-center

**Contents:**
- Apple Game Center#
- Set up an Apple Game Center sign-in#
- Sign in a returning player or create new player#
- Updating a player from anonymous to an Apple Game Center account#
- Unlink Apple Game Center account#

Minimum SDK version: 2.4.0

This article guides you through the following scenarios in setting up authentication for players in your game with an Apple Game Center player identifier:

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

To provide an Apple Game Center sign-in option for the players in your game, set up your app to enable sign-in with Apple Game Center.

You can add Apple Game Center either in the Unity Editor directly, or in the Unity Dashboard.

Set up and install the Apple Game Kit Unity plugin, found in the Apple Unity Plug-ins repository. The GameKit framework is used to implement Apple Game Center features including player identity.

Add Apple Game Center as an ID provider for Unity:

Important: For Unity Authentication, the timestamp input is only valid for 10 minutes for security reasons. Before calling SignInWithAppleGameCenterAsync or LinkWithAppleGameCenterAsync, please call Apple's FetchItems API to receive fresh inputs. After a single successful call to SignInWithAppleGameCenterAsync or LinkWithAppleGameCenterAsync, there is no need to call these APIs anymore.

After installing the required plugin and setting up the ID provider, you can use the following sample code to retrieve the parameters for identity verification:

If you see an error related to MissingMethodException from within the Apple.GameKit namespace, it is likely due to relevant code being stripped during compilation. That can be addressed by using Link XML to ensure the offending code is preserved. Alternatively the code stripping option in Player Settings can be set to "Minimal" which may resolve the issue, but be aware that this may increase the size of the final binary.

You can use the SignInWithAppleGameCenterAsync method to either:

If no Unity Authentication player in your project is associated with the credentials, SignInWithAppleGameCenterAsync creates a new player. If a Unity Authentication player in your project is associated with the credentials, SignInWithAppleCenterAsync signs into that player's account. This function doesn't consider the cached player, and SignInWithAppleGameCenterAsync replaces the cached player.

For more information about cached players, refer to Sign In a Cached Player.

After you’ve set up anonymous authentication, if the player wants to upgrade from being anonymous to creating an Apple Game Center account and sign in using Apple Game Center, your game should prompt the player to trigger the Apple Game Center sign-in and get the ID verification parameters from GameKit. Then, call the LinkWithAppleGameCenterAsync API to link the player to the Apple Game Center teamPlayerID.

If a cached player exists on the SDK, you can link the cached player to the Apple Game Center Account.

For more information about cached players, refer to Sign In a Cached Player.

Use the UnlinkAppleGameCenterAsync API so your players can unlink their Apple Game Center account. Once unlinked, if their account isn’t linked to any additional identity, it transitions to an anonymous account.

**Examples:**

Example 1 (unknown):
```unknown
SignInWithAppleGameCenterAsync
```

Example 2 (unknown):
```unknown
LinkWithAppleGameCenterAsync
```

Example 3 (unknown):
```unknown
SignInWithAppleGameCenterAsync
```

Example 4 (unknown):
```unknown
LinkWithAppleGameCenterAsync
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/apple-privacy-manifest

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for IAP is available from version 4.11.0.

The following code sample displays the contents of the PrivacyInfo.xcprivacy manifest file for Authentication. This file is also available in the SDK.

To identify the data that this SDK collects, refer to the following key:

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
		<dict>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>C617.1</string>
			</array>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategoryFileTimestamp</string>
		</dict>
	</array>
	<key>NSPrivacyCollectedDataTypes</key>
	<array/>
	<key>NSPrivacyTracking</key>
	<false/>
</dict>
</plist>
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
		<dict>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>C617.1</string>
			</array>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategoryFileTimestamp</string>
		</dict>
	</array>
	<key>NSPrivacyCollectedDataTypes</key>
	<array/>
	<key>NSPrivacyTracking</key>
	<false/>
</dict>
</plist>
```

---

## Idle clicker game

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/IdleClickerGame

**Contents:**
- Idle clicker game#
- Prerequisites#
- Overview#
  - Functionality#
    - Placing Wells#
    - Real-time resource updates#
    - Virtual purchases#
- Setup#
  - Requirements#
  - Unity Cloud services configuration#

In real-time idle clicker and social games, such as farming or city-building games, common considerations include:

This sample use case shows how to solve both challenges while limiting calls to Unity Gaming Services, which can cause throttling issues or increased costs.

In this sample, the player uses a resource (Water) to purchase Wells, which each produce 1 unit of Water per second.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

To see this use case in action, open the samples menu and navigate to Idle Clicker Game. To open this scene directly and interact with the use case:

The IdleClickerSceneManager.cs script performs the following initialization tasks in its Start function:

Initializes Unity Gaming Services.

Signs in the player anonymously using the Authentication service. If you’ve previously initialized any of the other sample scenes, Authentication will use your cached Player ID instead of creating a new one.

Retrieves and updates the player's currency balances from the Economy service.

Retrieves or creates the current game state.

Note: If the game is already in progress, this step grants Water based on the quantity produced by all Wells since the last time the game state was updated.

Enables button-click functionality for the available tiles in the play field.

You can click any open tile in the play field to place a Well in exchange for 500 Water. Cloud Code validates whether you’re attempting to place a Well in an empty tile. When you click a tile, the following occurs:

If the Virtual Purchase fails, Cloud Code throws an exception back to the client that then displays a pop-up message explaining what happened.

Between moves, while the player is viewing the game scene but not interacting, the client simulates Water production and updates the Currency HUD accordingly. Each Well produces one Water per second. Because this sample game is intended to be real-time, whenever the client calls Cloud Code, it checks the current time and calculates how much cumulative Water has been produced by each Well since its last production cycle. Every time the game loads, or the player attempts to place a Well, the following occurs:

Note: Because the Water quantity displayed in the currency HUD is simulated by the client and not actually in sync with the server until the scene is reloaded or the player attempts to place a Well, its server-side values will often appear inaccurate.

This sample illustrates how virtual purchases occur through the Economy service. In this case, the virtual purchase for a Well costs 500 Water, but, unlike most virtual purchases, the purchase itself does not actually grant anything. Instead, the virtual purchase consumes the transaction cost (500 Water) and updates the game state with a new Well in the corresponding tile. Cloud Save stores the full game state, including the locations of Wells and obstacles.

Note: The service only attempts the transaction after confirming that the space is empty.

To replicate this use case, you'll need the following Unity packages in your project:

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys all the necessary items.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Publish the following scripts in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resource in the Unity Dashboard:

In addition, configure the following virtual purchase for the battle pass:

* The Well itself is not granted by the virtual purchase; Cloud Code adds it to the game state directly upon a successful transaction.

**Examples:**

Example 1 (unknown):
```unknown
IdleClickerSample.unity
```

Example 2 (unknown):
```unknown
IdleClickerSceneManager.cs
```

Example 3 (unknown):
```unknown
IdleClicker_PlaceWell.js
```

Example 4 (unknown):
```unknown
Idle Clicker Game
```

---

## Configuring User Reporting

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/UserReporting/ConfiguringUserReporting

**Contents:**
- Configuring User Reporting#
- Create and sending Reports#
- Add metadata#
- Log events#
- Add sampling metrics#
- Add screenshots#
- Add attachments#
- Organize report dimensions#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

The default settings for User Reporting are suitable for normal use, but as your project develops you might want to make changes for specific needs. You might build your own UI that matches your application to introduce custom fields or change the appearance of a user report form. The sample provided in the package is functional, but acts as a starting point.

User reports contain useful information such as metadata, events, sampled metrics, screenshots, and file attachments. For example, you could attach a user’s game save files to their report, or log an event every time the player performs a certain action. You can also sample performance metrics in performance-intensive gameplay situations.

Use the API to configure maximum values of each data type in your report. The UserReportExample file (found in the sample imported into your Unity project) provides a demonstration of the different means of adding data to reports.

For example, you might customize the following settings to limit the maximum of specific data types in a report:

There are no limits to these settings, but if you set higher values the collected data affects the size of your reports. In particular, large high resolution screenshots can quickly increase the size of the report.

To configure User report settings, call the UserReportingService.Instance..Configure(UserReportingClientConfiguration configuration) method:

To create a report, call UserReportingService.Instance.UserReporting.CreateNewUserReport();.

To send a report, call UserReportingService.Instance.SendUserReport(Action<float> progressUpdate, Action<bool> result).

Observe the sample example to best understand action parameters. Sending a report is not required but recommended.

Use metadata to collect specific data for your game which appears with the device metadata included in User Reports by default.

To add custom metadata, call the UserReportingService.Instance.AddMetadata(string name, string value) method.

Adding metadata has negligible impact on performance.

To log custom events, call the UserReportingService.Instance.LogEvent(UserReportEventLevel level, string message) method.

Logging events has a negligible impact on performance.

To add custom sampling metrics, call the UserReportingService.Instance.SampleMetric(string name, double value) method.

The SampleMetric method is designed for you to call every frame with a little impact on performance. However, if you call the above method for every frame, each distinct name can add significant size to the report.

To add screenshots to your report, call the UserReportingService.Instance.TakeScreenshot(int maximumWidth, int maximumHeight) method. Screenshots are viewed as part of the report in the Dashboard.

Optionally you might specify a source for the screenshot, such as a Camera or RenderTexture using UserReportingService.Instance.TakeScreenshot(int maximumWidth, int maximumHeight, object source).

The image is scaled down until it fits within the size defined by the maximumWidth and maximumHeight parameters regardless of source.

When you select a maximum width and maximum height, user reports must be less than 10MB. The last screenshot taken serves as the thumbnail for the report in the Dashboard.

Note: Taking screenshots has an impact on performance. To avoid adverse effects for your users, take screenshots when performance isn't critical, for example if the player is idle.

Add attachments such as video and scene graphs.

Attachments are encoded as Base64 objects.

Use UserReportingService.Instance.AddAttachmentToReport(string title, string filename, byte[] data) to add attachments.

Use dimensions to filter user reports on the Unity Dashboard. You can add dimensions and metrics to your report before sending it by adding items to a dimensions property. Each dimension or metric has a name and a value. You can add a new dimension to your report by calling:

UserReportingService.Instance.AddDimensionValue(string dimension, string value);

For example, see three reports with the following dimensions:

See the following filtering options on the Dashboard:

You can also add different dimensions to different reports. For example, you might only want to add SystemLanguage as a dimension for localized reports.

Users can also add a single hash tag to a report summary. This hashtag appears as a dimension.

For example, the summary "I fell through the floor #FloorBug" appears as:

**Examples:**

Example 1 (unknown):
```unknown
FramesPerMeasure
```

Example 2 (unknown):
```unknown
MaximumMeasureCount
```

Example 3 (unknown):
```unknown
MaximumEventCount
```

Example 4 (unknown):
```unknown
MaximumScreenshotCount
```

---

## Uploading symbol files

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/DebuggingSymbols/UploadingSymbolFiles

**Contents:**
- Uploading symbol files#
  - Finding and uploading missing iOS/OSX application symbols#
  - iOS, Bitcode, and the App Store#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Native crash reports might contain missing symbols. If your project contains missing symbols, you can manually add application symbol files to your project. This will help you to better diagnose and fix problems.

If your crash and exception reports contain missing symbols, add application symbol files from the Cloud Diagnostics Dashboard.

When you upload new symbols, there is a short period between the upload and when they are available for use. Wait at least five minutes before submitting a new crash. When they have been processed, any new reports should be generated with the proper symbolication.

When you build your application using Xcode, iOS/OSX places the symbols in a dSYM folder with a name similar to the following:

A dSYM file is an ELF file that contains DWARF (debugging with attributed record formats) debug information for your application. DWARF is a debugging file format that supports source-level debugging.

To verify that the dSYM contains the correct UUID, run the dwarfdump command, and replace appname with the name of your application’s dSYM:

The following shows sample output from dwarfdump:

UUID: 5EEDCCD2-38E7-3E52-81EC-B90C7BCD6D91 (armv7) appname.dSYM/Contents/Resources/DWARF/appname

UUID: 583173FD-6697-3E3C-90DC-EA9147563A5B (arm64) appname.dSYM/Contents/Resources/DWARF/appname

Note: Dwarfdump is an application that prints DWARF information in a human-readable format. The output of dwarfdump reports the UUID in upper-case and with dashes. UUIDs are often displayed as all lower-case with no dashes. Either format can represent a UUID. For example, 5EEDCCD2-38E7-3E52-81EC-B90C7BCD6D91 and 5eedccd238e73e5281ecb90c7bcd6d91 represent the same UUID.

After locating the correct dSYM folder, zip the entire folder and upload it to the Cloud Diagnostics service using the Debugging Symbols tab on the Unity Dashboard.

When you build your iOS app with Bitcode enabled and submit it to the App Store, Apple post-processes your build and creates a new binary. The new binary has a new UUID and a new corresponding dSYM. In this case, you must download the dSYM from iTunes Connect. It’s available in iTunes Connect at My Apps > Activity > All Builds > (choose your build).

When you upload your app to the App Store, check Include bitcode for iOS content and Upload your app’s symbols to receive symbolicated reports from Apple to enable the App Store to generate a new dSYM with the correct symbols:

After downloading the new dSYM, verify that the UUID is correct using dwarfdump. Zip the file and upload it to the Cloud Diagnostics service through the Debugging Symbols tab.

For more information on symbolication, see Symbolicating Crash Reports on the Apple Developer website.

Note: When you upload a new dSYM lD, reports are not re-symbolicated. You must submit a new crash to generate a report using the new symbols.

**Examples:**

Example 1 (unknown):
```unknown
~/Library/Developer/Xcode/DerivedData/<build id>;/Build/Products/<build type>/appname.dSYM
```

Example 2 (unknown):
```unknown
~/Library/Developer/Xcode/DerivedData/<build id>;/Build/Products/<build type>/appname.dSYM
```

Example 3 (unknown):
```unknown
dwarfdump -u appname.dSYM/Contents/Resources/DWARF/appname
```

Example 4 (unknown):
```unknown
dwarfdump -u appname.dSYM/Contents/Resources/DWARF/appname
```

---

## FILEINFO

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/fileinfo

**Contents:**
- FILEINFO#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Revision head changeset#
    - Output format parameters (--format option)#
    - The output parameters of this command are the following#
  - Examples#

Retrieves detailed information about the items in the workspace.

cm fileinfo <item_path>[ ...] [--fields=<field_value>[,...]] [[--xml | -x [=<output_file>]] | [--format=<str_format>]] [--symlink] [--encoding=<name>]

This command prints a detailed list of attributes for each selected item. Each attribute is printed on a new line by default.

The attribute list can be modified to display only the attributes the user needs. This can be achieved using the '--fields=<field_list>' which accepts a string of comma-separated attribute names. This way, only those arguments whose name has been indicated are shown.

This option is disabled by default. Please note that retrieving this attribute is significantly slower than the rest of them, so we advise users to group together as many items as possible. This will improve execution times by avoiding many separate 'cm fileinfo' executions. Also, this feature is not currently available for controlled directories.

You can find below the complete list of available attribute names. Names marked with an asterisk ('*') will not be shown by default:

This command accepts a format string to show the output.

Please note that '--format' and '--xml' options are mutually exclusive, so they can't be used at the same time.

cm fileinfo file1.txt file2.txt dir/

cm fileinfo "New Project.csproj" --xml

cm fileinfo assets.art --fields=ServerPath,Size,IsLocked,LockedBy

cm fileinfo proj_specs.docx --fields=ServerPath,RevisionChangeset --xml

cm fileinfo samples.ogg --format="{ServerPath}[{Owner}] -> {Size}"

**Examples:**

Example 1 (unknown):
```unknown
cm fileinfo <item_path>[ ...] [--fields=<field_value>[,...]] [[--xml | -x [=<output_file>]] | [--format=<str_format>]] [--symlink] [--encoding=<name>]
```

Example 2 (unknown):
```unknown
cm fileinfo file1.txt file2.txt dir/
```

Example 3 (unknown):
```unknown
cm fileinfo "New Project.csproj" --xml
```

Example 4 (unknown):
```unknown
cm fileinfo assets.art --fields=ServerPath,Size,IsLocked,LockedBy
```

---

## Back up tools

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/backups/backup-tools

**Contents:**
- Back up tools#

Learn about different back up tools you can use.

You can perform the back up and restore operations manually or with a back up tool. The following tools are tested with Unity Version Control (UVCS) on Windows and Linux:

**Examples:**

Example 1 (unknown):
```unknown
rsync -a -e ssh source/ username@remotemachine.com:/path/to/destination/
```

Example 2 (unknown):
```unknown
Rdiff-backup
```

---

## Get started with Lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/get-started

**Contents:**
- Get started with Lobby#
- Prerequisites#
- Set up Lobby#
- Link your Lobby project in the Unity Editor#
- Install the latest Lobby package for Unity#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

Read the following sections to learn how to set up a Lobby project and how to use the Lobby Game sample project.

To get started with Lobby, you need to do the following:

You can set up and manage Lobby through the Unity Dashboard:

When you launch Lobby for the first time, this adds Lobby to the Shortcuts section on the sidebar and opens the Overview page.

Note: For most users, the unified Multiplayer Services package replaces the Lobby standalone package, which is deprecated in Unity 6. Consider migrating to the unified package to facilitate a smooth transition. Visit the migration guide for a step-by-step transition process.

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.multiplayer
```

Example 2 (unknown):
```unknown
com.unity.services.lobby
```

---

## Use value matching pattern files

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/filter-pattern-values

**Contents:**
- Use value matching pattern files#
- Value filter pattern files in UVCS#
- Rule types#
  - Extension rules#
    - compression.conf example#
  - Path rules#
    - eolconversion.conf example#
  - Name rules#
    - filetypes.conf example#
  - Wildcard rules#

Use value matching filter pattern rules to set up specific client configuration files.

A value matching pattern file assigns a value to items that match specified patterns. These files contain one pattern per line. Unity Version Control (UVCS) uses the path of each item to check whether it matches any of the rules and then returns the assigned value.

UVCS has the following value matching pattern files:

Each line in these files contains rule/value pairs. The filetypes.conf file uses the : character as a separator, but the files compression.conf and eolconversion.conf use whitespaces as the rule/value separator.

To comment a line, start the line with a # character.

There are four types of patterns you can use with value matching pattern files.

For more information on which rule types take precedence when you use multiple, refer to pattern hierarchy.

Extension rules define the exact extension of the files to match. These apply to the characters after the last . character in the file name. This means that values such as .in.html or .en.rex don’t match any files.

In the following example, a file such as /theme/images/background.png doesn’t use compression, but a file such as /src/client/main.cpp uses gzip compression.

Path rules compare the full path of an item and if they match, apply the rule value to that item.

In the following example, you use automatic EOL conversion for /src/main.c uses, and for /lib/core/Calculator.cs, you convert all of its EOL sequences to CR + LF:

Name rules exactly match the item name.

In the following example, you set a file such as /my-app/wwwroot/img/header.png as binary, but set files such as /README.md or /src/doc/README.md as text:

You can enhance path rules with wildcard sequences:

If you apply this compression filter, files such as the following don’t use compression:

Files such as the following use gzip compression:

UVCS uses the patterns in a file to match the path of an item. Some pattern formats take precedence over others. The following shows the hierarchy of pattern formats:

In the following example, /src/main/bootstrap/compile.exe is binary because path rules take precedence. Any other compile.exe file, such as /build/release/compile.exe because of the name rule.

In the following example, you convert the EOL sequences to LF for any file under /src/java/<subdir>/, such as /src/java/<subdir>/. But because an extension rule takes precedence over a wildcard rule, you use automatic EOL conversion for any .java files inside /src/java/<subdir>/, such as /src/java/test/complex/ExtremelyRareScenarioTest.java.

**Examples:**

Example 1 (unknown):
```unknown
compression.conf
```

Example 2 (unknown):
```unknown
eolconversion.conf
```

Example 3 (unknown):
```unknown
filetypes.conf
```

Example 4 (unknown):
```unknown
filetypes.conf
```

---

## Players

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/players

**Contents:**
- Players#
- The host player#
- Joining players#
- Maximum connections#

A player is an end-user who is using a game client and wants to play in a game session. Because players can only communicate with other players within the same session, there are no globally unique player identifiers.

There are two types of players:

Host players are players who create a game session and then generate a join code to share with other players. There is only one host player per session. A host player receives its connection data after making an allocation request, which is then used to author a BIND message.

Joining players are players who receive the join code from the host player and then use the join code to join the game match. Joining players receive their own connection data, and the host's connection data, after making a join request using the join code. These connection data are used to request a connection to the host through the Relay server.

The maximum number of players that can join and connect to the host in a session depends on the maximum number of connections configured by the host when they make the allocation request.

Players can leave at any time by sending a DISCONNECT message. Additional players can join the Relay server and connect to the host, as long as the number of connected players remains under the maximum allowed connections.

---

## SDKs for Lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/lobby-unity-sdk-landing

**Contents:**
- SDKs for Lobby#

Find the right Lobby SDK for your version of Unity.

Note: For most users, the unified Multiplayer Services package replaces the Lobby standalone package, which is deprecated in Unity 6. Consider migrating to the unified package to facilitate a smooth transition. Visit the migration guide for a step-by-step transition process.

The following SDKs have all the functionality necessary to use Lobby services in your game.

---

## Windows keyboard shortcuts

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/keyboard-shortcuts

**Contents:**
- Windows keyboard shortcuts#
- Main actions#
- Items#
- Branches#
- Differences#
- 3 way merge#
- Diff window#
- Text diff panel in the Diff window#
  - Clipboard, undo, and edit actions#
  - Delete edit actions#

Use keyboard shortcuts in the Unity Version Control (UVCS) desktop application.

Select a specific item to use the following shortcuts.

Navigate the 3 wway merge tool.

Navigate the diff tool window.

Use the text diff panel and edit the contents.

---

## Support

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/support

**Contents:**
- Support#

You can contact the Lobby Support team using one of the following methods:

---

## Query protocols

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/query-protocols

**Contents:**
- Query protocols#

A server query protocol is a protocol that facilitates querying information from a server. Multiplay Hosting requires all builds to implement a server query protocol.

Note: Although you implement the query protocol in the build, you specify the query protocol in the build configuration.

Multiplay Hosting uses the information supplied by the server query protocol to:

The analytic data is available per fleet and per server. The query protocol type might include concurrently connected players (CCU), players per platform, total available server slots, and current map.

The recommended protocol is SQP, which integrates well with Multiplay Hosting. It's supported by both the Unity and Unreal Engine SDKs.

Multiplay Hosting supports A2S. This might be beneficial if you're already using a library providing A2S, such as the Steam SDK. In future, this might not have feature parity with SQP.

Tip: Refer to go-svrquery for an example implementation of SQP. go-svrquery is a Golang client or talking to game servers using various query protocols, including SQP.

---

## SHELVESET DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/shelveset-delete

**Contents:**
- SHELVESET DELETE#
- Description#
  - Usage#
- Help#
  - Examples#

cm shelveset delete | rm <sh_spec>

The 'shelveset delete' command deletes a shelveset.

cm shelveset delete sh:3

(Removes a stored shelveset.)

**Examples:**

Example 1 (unknown):
```unknown
cm shelveset delete | rm <sh_spec>
```

Example 2 (unknown):
```unknown
cm shelveset delete sh:3
```

---

## View changes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/view-changes

**Contents:**
- View changes#

You can compare your local changes with the files in your source control repository:

This opens a window with a text-only differences view.

Note: If you have already checked in the changes you want to view, you can view a changeset diff to view those changes.

---

## Availability buffer

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/availability-buffer

**Contents:**
- Availability buffer#

An available server buffer, or availability buffer, is a specific number of online and unallocated servers that must exist in a fleet region. You define the target number of available servers with a region’s scaling settings. Depending on the current server density, a region might sometimes exceed its target.

If the number of available servers goes below or above the buffer value, it serves as a signal for the scaling system to increase or decrease the number of available servers. Multiplay Hosting calculates the number of available servers by subtracting the number of allocated servers from the total number of servers.

If the number of available servers is below the target number, it adds more servers until the number of available servers matches the target number. Likewise, if the number of available servers is above the target number, it adjusts the number of servers.

---

## Debugging

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/debugging

**Contents:**
- Debugging#
- Logging#
- Files#
- Core dump access#

With Multiplay Hosting's Debugging feature, you can investigate issues you might have with your servers.

Debugging offers you the following tools:

Logging provides a way to view, search, and download logs from the Unity Dashboard without setting up a custom integration with a third-party service.

Note: Multiplay Hosting Logging is in closed beta. Unity is collecting as much feedback as possible to improve the feature. Please share any issues, thoughts, or feedback with the engineering team.

Game server files provide a list of files present on a server instance. You can optionally download these files.

Note: Before Multiplay Hosting can surface your files through the Unity Dashboard, you must specify the location of your files through your build configuration launch parameters.

A core dump is a file which contains a process's address space (memory) when it terminates unexpectedly. This file provides a snapshot of what happened when a process crashed.

Note: Before Multiplay Hosting can generate core dumps, you must configure the core dump storage settings.

---

## CHECKSELECTORSYNTAX

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/checkselectorsyntax

**Contents:**
- CHECKSELECTORSYNTAX#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Checks the syntax of a selector.

cm checkselectorsyntax | css --file=<selector_file>

(Checks the selector file syntax.)

cat <selector_file> | cm checkselectorsyntax | css -

(Unix. Checks selector file from standard input.)

type <selector_file> | cm checkselectorsyntax | css -

(Windows. Checks selector file from standard input.)

This command reads a selector on either a file or standard input, and checks it for valid syntax. If the syntax check fails, the reason is printed on standard output.

cm checkselectorsyntax --file=myselector.txt

(Checks the syntax of 'myselector.txt' file.)

cat myselector.txt | cm checkselectorsyntax

(Checks the syntax of 'myselector.txt' from standard input.)

**Examples:**

Example 1 (unknown):
```unknown
cm checkselectorsyntax | css --file=<selector_file>
```

Example 2 (unknown):
```unknown
cat <selector_file> | cm checkselectorsyntax | css -
```

Example 3 (unknown):
```unknown
type <selector_file> | cm checkselectorsyntax | css -
```

Example 4 (unknown):
```unknown
cm checkselectorsyntax --file=myselector.txt
```

---

## Google Play Data safety section for Analytics

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/google-data-safety

**Contents:**
- Google Play Data safety section for Analytics#
- Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Analytics. For your convenience, Analytics provides information on its data collection practices below.

Warning: The data disclosures below are for the Analytics SDK only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

* Analytics offers an SDK for customers to add into their game allowing them to track their players' actions. The events being tracked can then be analyzed in a variety of tools in the Unity Dashboard. There are standard events that the SDK automatically collects such as gameStarted, gameEnded, etc., and users can also create their own custom events to track additional events that are specific to their game. When Analytics is used with Game Overrides users are able to use Analytics data to target a particular override at a segment of their playerbase. In order to do this, Analytics compares the user profile (composed of installationID and other metrics collected) against a set criteria to determine if they would be a member of the audience.

Unity Analytics collects data specified and controlled by the developer, and can include any of the data designated with an asterisk (*). The developer should make a determination for whether they collect and/or share those data types, and whether that data is processed ephemerally, is required to be collected, and why that data is collected.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

** A randomly generated installation ID (or developer-generated ID) is used to identify the player.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

** The IAP plugin forwards transaction events for users to be able to analyze their transactions.

*** Required but developers can disable IAP plugin and the transaction events will no longer be sent.

* Developers can record whatever data they desire, we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Developers can record whatever data they desire; we are not the data controller in this circumstance.

* Installation ID, IDFV, and IDFA.

**Examples:**

Example 1 (unknown):
```unknown
gameStarted
```

Example 2 (unknown):
```unknown
installationID
```

---

## TRIGGER

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/trigger

**Contents:**
- TRIGGER#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to manage triggers.

cm trigger | tr <command> [options]

cm trigger <command> --usage

cm trigger <command> --help

cm tr mk before-mklabel new "/path/to/script" --server=myserver:8084

cm tr edit before-mklabel 7 --position=4 --server=myserver:8084

cm tr ls before-mkbranch --server=myserver:8084

cm tr rm after-setselector 4

**Examples:**

Example 1 (unknown):
```unknown
cm trigger | tr <command> [options]
```

Example 2 (unknown):
```unknown
cm trigger <command> --usage
```

Example 3 (unknown):
```unknown
cm trigger <command> --help
```

Example 4 (unknown):
```unknown
cm tr mk before-mklabel new "/path/to/script" --server=myserver:8084
```

---

## PARTIAL UPDATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-update

**Contents:**
- PARTIAL UPDATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Updates the partial workspace and downloads latest changes.

cm partial update [<item_path>[ ...]] [--changeset=<number>] [--silent | --report] [--dontmerge] [--xml[=<output_file>]] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

The 'partial update' command updates the out-of-date files.

The command assumes recursive operation.

If all the specified paths are files inside the same Xlink when using the '--changeset' option, then the versions to download are searched in the specified changeset of the Xlinked repository.

(Updates all in the current partial workspace.)

(Updates all current directory children items.)

cm partial update backgroud-blue.png

(Updates 'backgroud-blue.png' item.)

cm partial update soft_black.png soft-grey.png

(Updates 'soft_black.png' and 'soft-grey.png' items.)

cm partial update src --report

(Updates all 'src' directory children items, printing the applied changes list at the end.)

cm partial update src --changeset=4

(Updates all 'src' directory children items to the content they loaded in the changeset 4.)

cm partial update xlink/first.png --changeset=4

(Updates 'xlink/first.png' item to the content it loaded in the changeset 4 of the Xlinked repository.)

cm partial update . --changeset=2 --xml=output.xml 2>errors.txt

(Updates all current directory children items to the content they loaded in the changeset 2, reporting the result in XML format. The output is stored in a file named 'output.xml' and errors are redirected to the file 'errors.txt'. NOTE: redirection syntax rely on the shell.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial update [<item_path>[ ...]] [--changeset=<number>] [--silent | --report] [--dontmerge] [--xml[=<output_file>]] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
cm partial update
```

Example 3 (unknown):
```unknown
cm partial update .
```

Example 4 (unknown):
```unknown
cm partial update backgroud-blue.png
```

---

## Integrate using Blueprints

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/unreal-engine-sdk/integrate-using-blueprints

**Contents:**
- Integrate using Blueprints#
  - Install the Matchmaker SDK plugin#
  - Matchmaker Client Blueprint API#
    - CreateTicket#
    - DeleteTicket#
    - GetTicketStatus#
  - Matchmaker Server Blueprint API#
      - CreateBackfillTicket#
      - ApproveBackfillTicket#
      - UpdateBackfillTicket#

The following section shows how to integrate with the Matchmaker SDK using Blueprints in the Unreal Engine.

The two Matchmaker interfaces you can interact with within the Unity Gaming Services SDK are the:

Before continuing, add the MatchmakerSDK as a public dependency of your module, then include the plugin header files in your classes as shown below.

Add MatchmakerServer and MatchmakerClient to your module's dependencies to your Unreal project build file (YourProjectName.Build.cs):

The Matchmaker client subsystem controls the client portion of matchmaking and finding matches. This includes creating, deleting, and polling matchmaking tickets.

Use the static functions from UMatchmakerClientBlueprintApi to interact with the Matchmaker client subsystem through the following Blueprints:

To use CreateTicket, place a Create Ticket node in your blueprint. Populate the Players and Options fields for the inputs to create a ticket.

The following example shows how to pass in a single player and a queue name to create a ticket. It also shows an event that handles the response to get an FString output for the TicketId.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the event's Response struct pin and select Split Struct Pin to access all the individual values in CreateTicketResponse.

Use the DeleteTicket blueprint to issue a delete ticket call, passing in the TicketId to delete.

Below is a simple example demonstrating how to use Delete Ticket and how to handle the response.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the event's Response struct pin and select Split Struct Pin to access all the individual values in DeleteTicketResponse.

Use GetTicketStatus to poll the matchmaker for a match using the TicketId retrieved from the CreateTicket blueprint.

After polling completes either successfully or not, or if the user wishes to manually cancel matchmaking, use the DeleteTicket blueprint to stop considering the player(s) for matchmaking.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the event's Response struct pin and select Split Struct Pin to access all the individual values in GetTicketStatusResponse].

The image above shows an example of polling a matchmaking ticket with the Set Timer by Event node. When the looping condition is true, this node triggers its event continuously in the frequency that is set in the Time variable. In this case, Time is set to 5; therefore this event occurs every five seconds until the timer handler is canceled. The return value is the timer handler which you can use to cancel the timer using a Clear and Invalidate Timer by Handle.

The Timer handle gets passed from the Set Timer by Event node to the Clear and Invalidate Timer by Handle node. You should have some conditional logic to trigger Clear and Invalidate Timer by Handle. You must make most consecutive calls to GetTicketStatus before a match is returned. After the status no longer returns as InProgress, it's safe to stop polling and delete the ticket.

The following image shows a basic example of how to handle a polling response and trigger a Clear and Invalidate Timer.

The Matchmaker Server Subsystem controls the server portion of matchmaking. This includes creating, approving, deleting, and updating backfill tickets.

You can use the UMatchmakerServerBlueprintApi to:

You need to create a new backfill ticket after a player (or players) leaves a full match, and the server needs to fill the empty slots. Use the Create Backfill Ticket blueprint to create a new backfill ticket for the server.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the events Response struct pin and select Split Struct Pin to access all the individual values in CreateBackfillTicketResponse.

Use the Approve Backfill Ticket blueprint to periodically approve your backfill ticket to let new players into the server.

It's recommended to approve backfill tickets no faster than once a second. If a ticket goes for 20 seconds without approval, the Matchmaker service deletes it.

In the example above, approval runs in a loop every second. Be sure to use a Clear and Invalidate Timer by Handle node after deleting the backfill ticket.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the events Response struct pin and select Split Struct Pin to access all the individual values in ApproveBackfillTicketResponse.

Unity recommends caching the values from the response and using them to build the BackfillTicket in UpdateBackfillTicket.

Update the backfill ticket whenever:

This can include but isn't limited to party invites, direct connections, and friend invites.

Use the Update Backfill Ticket blueprint to update a server's current backfill ticket.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the events Response struct pin and select Split Struct Pin to access all the individual values in UpdateBackfillTicketResponse.

You should call this no more than once every three seconds or after ApproveBackfillTicket sees a change in the backfill ticket to guarantee a matchmaking cycle has passed.

Important: Updating a backfill ticket too often can cause players to never backfill into the match. See Matchmaking Logic Sample to learn more.

Unity recommends calling ApproveBackfillTicket first and using the BackfillTicket returned from ApproveBackfillTicket to modify as needed and pass into the UpdateBackfillTicket.

You can delete a backfill ticket after a match becomes full and the server no longer needs to accept new players. You should also do this after a match ends.

Use the Delete Backfill Ticket blueprint to stop backfill on a server.

You can set up a custom event for the response handler and right-click (macOS: Ctrl+click) the events Response struct pin and select Split Struct Pin to access all the individual values in DeleteBackfillTicketResponse.

Due to limitations in Blueprints, JSON data types (such as FJsonObject and FJsonValue) are not natively compatible and don’t support direct manipulation. The SDK implements a set of utility functions that allow you to manage JSON data as part of the API:

MatchmakerCore is included as a dependency when adding MatchmakerClient or MatchmakerServer.

In the MatchmakerClient module there is MatchmakerClientBlueprintUtil with

You can use this blueprint to add a string data field to a player’s CustomData object.

This returns true if the data is set successfully; otherwise, it returns false.

You can use this blueprint to add a number data field to a player's CustomData object.

This returns true if the data is set successfully; otherwise, it returns false.

You can use this blueprint to remove a data field from a player’s CustomData object.

This returns true if the player’s CustomData contains a Key and it was removed. It returns false if a Key wasn't found.

In the MatchmakerClient module there is MatchmakerClientBlueprintUtil with

Use this blueprint to add a string-based attribute to a CreateTicketOptions object. This returns true if the attribute is set successfully, and false otherwise.

Use this blueprint to add a number-based attribute to a CreateTicketOptions object. This returns true if the attribute is set successfully, and false otherwise.

Use this blueprint to remove an attribute from a CreateTicketOptions object.

This returns true if CreateTicketOptions contains the attribute and it was removed. If the attribute wasn't found, it returns false.

In the MatchmakerServer module, there’s MatchmakerServerBlueprintUtil with

You can use this blueprint to add a string-based attribute to a CreateBackfillTicketOptions object. This returns true if the attribute is set successfully, and false otherwise.

This blueprint is used to add a number-based attribute to a CreateBackfillTicketOptions object.

This returns true if the attribute is set successfully, and false otherwise.

Use this blueprint to remove an attribute from a CreateBackfillTicketOptions object. This returns true if CreateBackfillTicketOptions contains the attribute and it was removed, and false if the attribute wasn't found.

**Examples:**

Example 1 (unknown):
```unknown
MatchmakerSDK
```

Example 2 (unknown):
```unknown
MatchmakerServer
```

Example 3 (unknown):
```unknown
MatchmakerClient
```

Example 4 (unknown):
```unknown
YourProjectName.Build.cs
```

---

## Player list

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/player-list

**Contents:**
- Player list#
- Player search#
- Filters#

The player list lets you review all the players that have been part of an incident in the Moderation service.

All the players listed along with their reputation score from Safe Text if you have enabled that service.

The list contains the number of resolved and unresolved incidents for each player in the Open Incidents column. By selecting a badge, either Unresolved or Resolved, the Moderation Queue opens, filtered for this specific player.

The Actions column displays past actions taken against the player, indicating how many are active, and how many have expired.

For more details about each player, select the player name, which opens the Player History panel.

Search for players by their UAS ID in the search bar. Note that players aren't searchable by their player name, only their UAS ID.

If you use external identifiers to authenticate players, you can search by any of those other IDs by using the Find Player button.

You can filter the player list page by their reputation. All players that have a Safe Text reputation score matching the selected value are shown in the list after selecting a reputation to filter by.

---

## Unity Player Accounts

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/unity-player-accounts

**Contents:**
- Unity Player Accounts#
- Overview#
- Get started#
  - Set up the Unity Player Accounts ID provider#
  - Before you publish your game#
  - Unity Player Accounts sample#
- Sign in a returning player or create new player#
- Link a returning player to Unity Player Accounts#
- Unlink Unity Player Accounts#
- Sign out from Unity Player Accounts#

Unity Player Accounts is Unity's comprehensive sign-in solution that supports persistence across games, devices and platforms. It's an end-to-end account system that includes a user flow UX, email and password, social sign-in options, and data access and deletion flows.

Unity Player Accounts is an external identity provider which is natively integrated with Unity Gaming Services and the Authentication SDK. It has multiple benefits such as SSO, organization-level player pool, and cross-game, cross-device or cross-platform gameplay.

To get started you must first install the Authentication package, and then configure a Unity Player Accounts ID provider in the Unity Dashboard.

The C# methods required for interacting with Unity Player Accounts are included within the Authentication package in the dedicated PlayerAccountService namespace.

You can set up Unity Player Accounts directly in the Unity Dashboard.

Note: For the sign-in flow to work in the Unity Editor Play mode, include the PC platform.

Note: The authentication flow works without the need for configuring the redirect URI, as long as the registered URIs follow the prescribed format:

Review Unity's compliance and branding guidelines:

The Authentication package includes a sample scene which is fully integrated with Unity Player Accounts. Use this sample to try out the flow after completing the configuration steps above.

To import the sample, follow these steps:

Open the sample scene under Assets > Samples > Authentication > [Package-Version] > UI Example > UnityPlayerAccountsUIExample.

Use the PlayerAccountService.Instance.StartSignInAsync method to start the player sign-in flow for Unity Player Accounts. This opens the system browser to https://player-login.unity.com, prompts the player to sign in, and then returns them to the application with their Unity Player Accounts credentials.

When they have signed in to Unity Player Accounts and returned to your application with their credentials, use the AuthenticationService.Instance.SignInWithUnityAsync method to either:

The PlayerAccountService.Instance.SignedIn event will let us know when the browser-based Unity Player Accounts sign in has succeeded and we can proceed with signing in to Unity Authentication.

The credentials required to sign in to Unity Authentication are the access token available on PlayerAccountService.Instance.AccessToken.

If you have an existing player who is signed in already, either anonymous or using a different external ID provider, you can allow them to link with Unity Player Accounts. Your game should prompt the player to trigger the Unity Player Accounts sign-in flow. Then, call the LinkWithUnityAsync API to link the player using the Unity Player Accounts access token.

For linking to be successful, the player must be signed in to Unity Authentication. For more information on Unity Authentication session lifecycle, refer to Unity Authentication sessions.

Use the AuthenticationService.Instance.UnlinkUnityAsync API so your players can unlink their Unity Player account. Once unlinked, if their account isn't linked to any additional identity, it transitions to an anonymous account.

The PlayerAccountService.Instance tracks if the player has signed in to their Unity Player Account. This is separate from tracking if the player is signed in to Unity Authentication, as done by AuthenticationService.Instance. This gives individual control over signing out from Unity Authentication and Unity Player Accounts.

Use PlayerAccountService.Instance.SignOut to sign the player out of Unity Player Accounts on the device.

Because the PlayerAccountService.Instance doesn't persist a session token on the device, there is no option to clear the session token.

**Examples:**

Example 1 (unknown):
```unknown
PlayerAccountService
```

Example 2 (unknown):
```unknown
http://localhost/callback
```

Example 3 (unknown):
```unknown
unitydl://com.unityplayeraccounts.{unity-project-id}
```

Example 4 (unknown):
```unknown
https://player-account.unity.com/delete-account
```

---

## Manage incidents

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/manage-incidents

**Contents:**
- Manage incidents#
- Additional resources#

Incidents represent instances of detected or reported behavior within your game. They're the central feature of the Moderation Platform from which Safety Moderators will be able to review evidence and take actions against problematic players.

All incidents are listed on the Moderation queue page in the Unity Dashboard. These incidents are broken down into Unresolved incidents and Resolved incidents and populated with evidence from Safe Text. Safety Moderators and Admins have the ability to resolve and manage incidents.

The types of incidents including in the Moderation queue depends on which safety services your game is using.

With Safe Text you will have:

For more information on the differences between incidents types refer to Incidents.

---

## Set up a workspace

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/create-workspace

**Contents:**
- Set up a workspace#
- Create a workspace in the GUI#
- Create a workspace in the CLI#
- Additional resources#

To work in Unity Version Control (UVCS), you need a repository. Inside your repository, you can create a workspace, which is a local copy of a project.

Because a workspace is a local copy, you need to set up your workspace through the desktop application or the command line.

Note: If you work on Windows and you have a large amount of files, you might want to enable dynamic workspaces so that you don't have to download every file.

You can create a workspace when you create a repository, or you can create a workspace for an existing repository.

To create a new workspace, use the cm workspace create command:

Go to your newly created directory:

By default, the workspace uses the main branch.

To check the latest changeset on the branch, run cm status --head:

Run update to update to the latest changeset:

The command provides information about the copied files until you’re up to date with the latest changeset.

**Examples:**

Example 1 (unknown):
```unknown
cm workspace create
```

Example 2 (unknown):
```unknown
>cm workspace create quakewk quake_path --repository=quake@localhost:6060
Workspace quakewk has been correctly created
```

Example 3 (unknown):
```unknown
>cm workspace create quakewk quake_path --repository=quake@localhost:6060
Workspace quakewk has been correctly created
```

Example 4 (unknown):
```unknown
>cd quake_path
>cm status
/main@quake@localhost:6060 (cs:0 - head)
```

---

## Support alternative connections to a server

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/alternative-connections

**Contents:**
- Support alternative connections to a server#
- Configure the server aliases file#
- Example server alias file#

Use Unity Version Control (UVCS) to connect to the same server with different IP addresses and protocols. For example, if you connect to localserver.office-network.com:8084 at your office, but want to go home and connect through the public SSL-protected IP ssl://plastic.external-network.com:8090, you can tell the client that server:8084 and ssl://externalserver:8085 are aliases of each other.

Use the serveralias.conf file to enable this feature on your UVCS client so that the client knows which connection to use and can switch from one server URL to the other transparently.

Create the serveralias.conf file under one of the following directories: * On Linux or macOS: $HOME/.plastic4 * On Windows: C:\Users\user\AppData\Local\plastic4 * In the plastic-global-config repository to give all clients the same settings by default. * Under the client folder in the UVCS installation directory.

The serveralias.conf file contains a pair of connections that are aliases of each other:

To resolve the example in the first paragraph, you can use the following serveralias.conf file:

Note: The file can jump to a different URL and a different protocol (in this case from regular TCP to SSL).

**Examples:**

Example 1 (unknown):
```unknown
localserver.office-network.com:8084
```

Example 2 (unknown):
```unknown
ssl://plastic.external-network.com:8090
```

Example 3 (unknown):
```unknown
server:8084
```

Example 4 (unknown):
```unknown
ssl://externalserver:8085
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/unreal-engine-sdk/overview

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-density

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/attribute-create

---

## Common errors

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/common-errors

**Contents:**
- Common errors#
- SDK error codes#
- API error responses#
- Android-specific errors#

This section describes common errors that may be returned by the Authentication service.

ClientInvalidUserState Returned when the player is not in the expected state. For example, calling SignOut when the player is already signed out will result in this error.

ClientNoActiveSession Returned when trying to sign in with a session token while there is no cached session token. Refer to the Session management and PlayerPrefs sections for more information on how and where a session token is saved.

ClientUnlinkExternalIdNotFound Returned when a player tries to unlink a social account but no external ID for that provider is found for the account. This could be because the player info has not been loaded.

ClientInvalidProfile Returned when a player tries to switch profile but the profile name is invalid. Refer to the Profile management section for more information.

InvalidParameters Returned when a parameter is missing or not in the right format.

AccountAlreadyLinked Returned when a player tries to link a social account that is already linked with another player.

AccountLimitExceeded Returned when a player tries to link a social account but this player has already reached the limit of links for that account type. Social platform account linking is typically limited to one link per platform type per player.

InvalidSessionToken Returned when the session token is invalid.

BannedUser Returned when the request was understood but the user has been banned from logging in.

EnvironmentMismatch Returned when there is a mismatch between the requested environment and the one configured.

Any errors returned by the service API are in the RFC 7807 format. For more details, refer to the RFC 7807 documentation.

When using the SDK, these errors will be logged to the console and can provide additional insights for debugging.

For error code paths, only determine the subsequent action using the status or title fields. Do not use the detail field to determine subsequent code paths.

If the status is in the 400-499 range, it is likely the error is on the client and most likely there are steps you can take to rectify the issue, be it in the API calls to Unity Authentication or in the authentication via Platform specific providers. Please check the API inputs to make sure they are correct.

By looking at the detail field you can find further description at the issue at hand. Below you can find the most common errors by description and the steps you can take to try and fix them.

Description: These errors indicate that the token is not valid at this current moment, whether it’s because the token was issued for a time period later or earlier than now.

Description: This usually applies to ID Token based authentication. It indicates there is a mismatch between the application or client ID you registered with Unity Authentication and the application ID listed on the token, which is usually in the audience field.

Note: Sometimes the ID Provider provides multiple application ids in different formats, and inputting the incorrect type will lead to this error.

Description: These errors indicate that the ID token was not issued by the expected source.

Description: This indicates there was some issue with the token input.

Android Network Error SSL CA certificate Error. Only TLS version 1.2 and above are supported for Android devices. TLS 1.2 is supported by Android API levels 16+ and enabled by default on 20+.

**Examples:**

Example 1 (unknown):
```unknown
ClientInvalidUserState
```

Example 2 (unknown):
```unknown
ClientNoActiveSession
```

Example 3 (unknown):
```unknown
ClientUnlinkExternalIdNotFound
```

Example 4 (unknown):
```unknown
ClientInvalidProfile
```

---

## Glossary

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/glossary

**Contents:**
- Glossary#

A/B testing is a Unity Dashboard feature within Game Overrides that splits your Override into variants that you set to see what impact they make on your game. For example, you might believe starting players are given too many coins and are progressing through your game too quickly or stop playing too early, missing IAP (in-app purchases) opportunities. You’d set two (or more) starting balances: the control, and the variant.

An end-to-end data and analysis solution designed to support your entire studio. Analytics lets studios easily understand game performance and player behaviors.

Anonymous sign-in creates a new player for the game session without any input from the player.

Unity Authentication provides anonymous and platform-specific authentication solutions for supported platforms, including mobile and PC.

Access to exclusive in-game content for an additional cost, often as part of a tiered system.

By using Unity's Cloud Code to write stateless server-side code on a fully managed infrastructure, you can focus more on developing your game logic. Cloud Code automatically provisions server capacity based on load so you can ensure that your players receive a good experience without any lag or downtime.

Cloud Content Delivery

Cloud Content Delivery (CCD) is Unity's managed cloud service that hosts and delivers content to your application’s players worldwide without having to reinstall a new version of the application.

Use Unity's Cloud Save service to save persistent player data (such as game progress) from a game into the cloud, making it independent of device. Because it's cloud-based, players can access their data anywhere and across devices, mitigating data loss when a player changes devices or re-installs a game.

The Unity Dashboard provides an easy-to-use interface to manage your Unity Gaming Services, including Analytics, Game Overrides, and Cloud Content Delivery.

Unity’s Economy service provides a way to create, manage and publish an economy system to be used in your game. Includes Currency, Inventory Item, Configuration, and Publication.

Console gaming includes Nintendo Switch™, PlayStation®4, PlayStation®5, and Xbox®.

In-app purchases are items in-game that are bought with real money, such as gems, lives, or weapons.

Unity Authentication supports authenticating players anonymously as well as through external identity providers that include Google Play Games, Facebook, Apple, Steam, OpenID connect and console-specific logins.

Lobby connects players before or during a game session with public or private lobbies. You can use the Lobby service to group players together in a lobby before starting a game session or prevent connection loss if a host player becomes unavailable.

In addition to running game clients and game servers, multiplayer games can optionally implement a matchmaking component, which is the action of grouping players together for a game session. Players running a multiplayer game need their game client to connect to a game server so they can play a game session.

OpenID Connect lets players authenticate through a custom ID provider.

The Package Manager in the Unity Editor adds a software package in-game in Authentication, which contains code that lets you track events.

Used to identify returning and new players on different devices and external providers.

A platform sign-in creates a new player for the game session with input from the player (for example, sign-in credentials like a username and password) and is a sure way to link a player to a platform account. This is done by using external ID providers to enable platform account sign-ins in your game, such as Google Play Games, Apple, Facebook, and Steam.

A class that stores Player preferences between game sessions after logging in. It can store string, float and integer values into the player's platform registry.

Players can use profiles to sign in to multiple accounts on a single device. Profiles add a level of isolation to the values saved to the PlayerPrefs.

A game in the Unity Editor, that is linked to UGS.

Unity Relay offers a way for game developers to securely provide increased connectivity between players by using a join code style workflow without needing to invest in a third-party solution, maintain dedicated game servers (DGS), or worry about the network complexities of a peer-to-peer game.

Remote Config is a cloud service that you can use to tune your game design without deploying new versions of your application. It consists of a set of namespaced Key-Value parameters, and you can optionally define a set of values that override or add to these parameters.

A representational state transfer application programming interface that follows the REST architectural style, allowing communication between RESTful web services.

Software Development Kit, which can be installed into your Unity project to add functionality, such as the sending of events for analysis.

Events that are time-based, such as a Christmas season that runs for 12 days.

When a player signs in using a session token, the token used will be invalidated. A new token will be created and stored in PlayerPrefs. This session token can be used to authorize the player in the future using either anonymous or session login.

When a new or returning player returns to your game, the following tokens are generated:

Unity Gaming Services is a suite of products designed to enhance and develop your games, providing a better experience for players.

A real-time 3D development platform and editor to make creative projects.

Unity’s voice and text chat service, for multiplayer communication, offers a voice chat and direct message text service with a managed hosted solution.

---

## Work in version control

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/work-version-control

**Contents:**
- Work in version control#

Learn to use Gluon for a version control workflow.

---

## ACL

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/acl

**Contents:**
- ACL#
- Description#
  - Usage#
  - Options#
  - Special usage for secured paths#
- Help#
  - Remarks#
    - Server path permissions (a.k.a. secured paths)#
  - Examples#
  - Secured path examples#

Sets permissions on an object.

cm acl (--user=<usr_name> | --group=<group_name>) (-allowed|-denied|-overrideallowed|-overridedenied=+|-<permission>[,...])[,...] <objectspec>

cm acl [(--user=<usr_name> | --group=<group_name>) (-allowed|-denied|-overrideallowed|-overridedenied=+|-<permission>[,...])[,...]] [--delete] [--branches=[+ | -]<branch>[,...]] <spec>

Configuring permissions requires understanding how UVCS security works. Check the Security Guide to learn how permissions work:

https://www.plasticscm.com/download/help/securityguide

This command sets permissions for a user or group on the specified objects, repositories, branches, labels and/or server paths.

Object specs: (Use 'cm help objectspec' to learn how to specify objects.) The 'acl' command uses a special type of spec: secured paths.

Secured paths specs: path:server_path[#tag] Examples:

Permission action: Use -allowed and -denied to specify what permissions to set. Use -overrideallowed and -overridedenied arguments to specify what permissions to override.

Each action requires a permission list separated by commas.

Permission names: Each permission name is preceded by + or - symbol. The + symbol sets the permission and the - symbol clears it. To see the permissions of an object, use the 'cm showacl' command.

Overridden permissions: Overriding a permission using -overrideallowed and -overridedenied allows you to bypass inheritance. It is helpful to bypass permissions set at the repository or server level. Example:

cm acl --user=vio -allowed=+ci -overrideallowed=+ci br:qa@test

(Allows user 'vio' to checkin on the branch 'qa' on repo 'test' even if she has the permission denied at the repo level.)

The permissions that can be defined for a secured path are the following:

'ci', 'change', 'add', 'move', 'rm', 'read'

If the permissions check is not successful for any of the involved items, the checkin operation will be rolled back.

To set secured path permissions to a group of branches, use the --branches option. Example:

cm acl --user=jo -denied=+ci path:/src#rule0 --branches=main,main/rel0

To edit the ACL associated to the secured path, the tag is useful. Example:

cm acl --user=jo -denied=+rm path:/src#rule0

(Without the tag, the list of branches would need to be specified again.)

The list of branches of the secured path can be edited. Example:

cm acl path:/src#rule0 --branches=-main,+main/rel1

(Removes 'main' from the list and adds 'main/rel1'.)

To remove a secured path, use the --delete argument. Example:

cm acl --user=jo --delete path:/src#rule0

Inheritance: Inheritance is an option that comes from the days of Plastic SCM 3.0. It is advanced, but almost deprecated. It lets an object inherit its permissions from any other object, overriding the default inheritance relationships.

Use the option -cut to cut the inheritance chain. Use the option -cutncpy to cut and copy the current inherited permissions. (This is inspired on the Windows filesystem permissions where you can cut inheritance but retain the actual permissions.)

The -inherit option allows the user to inherit from an object spec. Example: '-inherit=object_spec'

cm acl --user=danipen -denied=+ci rep:core

(Denies checkin for user 'danipen' on repo 'core'.)

cm acl --group=developers -allowed=+view,-read -denied=+chgperm br:main

(The command grants view permission, clears read permission, and denies chgperm permission to 'developers' group in 'main' branch.)

cm acl --group=devs -denied=+ci path:/server#rel --branches=main,main/2.0

(The command denies the checkin permission to 'devs' group for any path that matches '/server' in the branches 'main' and 'main/2.0'. The tag '#rel' is created to be able to refer to it later.)

cm acl path:/server#rel --branches=-/main,+/main/Rel2.1

(Updates the secured path '/server' whose tag is 'rel', removing the 'main' branch and adding the branch 'main/Rel2.1' to the branch group the secured path applies to. Considering the previous example, now the branches list will contain 'main/Rel2.1' and 'main/2.0'.)

cm acl --user=vsanchezm -allowed=-read -overrideallowed=+read path:/doc

(Removes 'read' permission to 'vsanchezm' overriding it in '/doc' path.)

**Examples:**

Example 1 (unknown):
```unknown
cm acl (--user=<usr_name> | --group=<group_name>) (-allowed|-denied|-overrideallowed|-overridedenied=+|-<permission>[,...])[,...] <objectspec>
```

Example 2 (unknown):
```unknown
cm acl [(--user=<usr_name> | --group=<group_name>) (-allowed|-denied|-overrideallowed|-overridedenied=+|-<permission>[,...])[,...]] [--delete] [--branches=[+ | -]<branch>[,...]] <spec>
```

Example 3 (unknown):
```unknown
cm acl --user=vio -allowed=+ci -overrideallowed=+ci br:qa@test
```

Example 4 (unknown):
```unknown
cm acl --user=jo -denied=+ci path:/src#rule0 --branches=main,main/rel0
```

---

## DevOps pricing

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/pricing-for-unity-devops

**Contents:**
- DevOps pricing#
- Upgrade plan#
- Cancel your DevOps subscription#
- Additional resources#

If you exceed the DevOps usage allotted in the free plan, you can upgrade your DevOps plan to a consumption-based pricing billing model, which means you only pay for what you use.

DevOps then sends you a bill at the end of each billing cycle that provides a sum of your Unity DevOps charges.

For the specific pricing model, refer to the official pricing page. You can use the consumption examples to preview how much DevOps costs for different project sizes.

The first bill is $0, but this commits you to automatically pay for any usage that exceeds the amount allotted in the free plan at the end of the month.

To remove your Unity DevOps subscription:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/resolve-merge-conflicts

---

## Collect evidence

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/evidence

**Contents:**
- Collect evidence#
- Text evidence from Safe Text#
  - Context analysis#

Evidence is supplementary information that helps moderators make actioning decisions on reports. Evidence can be event logs, channel information, or recorded audio. To incorporate evidence into your reports, you must use Vivox Safe Text in your application.

Once Safe Text is enabled, evidence from that services is attached to incidents.

Text evidence management is an optional feature you can add to a Vivox instance that contributes textual context to player reports.

Once you have Vivox Text Chat with Text evidence activated in a project, channel transcripts will be automatically included in player reports where the reporter and offender are both present.

For evidence from Text evidence to be accessible to moderators, they must have the role of Safety Moderator in User Roles settings.

Context analysis is an optional feature you can add to receive automated AI based analysis on text-based messages for additional textual context. Context analysis detects specific toxicity types by analyzing the conversation to help provide a complete picture of text interactions.

Once Context analysis is in a project, text messages are analyzed for inappropriate content and highlighted within player reports and incidents.

---

## A/B testing

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/ABTest

**Contents:**
- A/B testing#
- Prerequisites#
- Overview#
  - Initialization#
  - Functionality#
    - Gain XP#
    - Sign In As New Player#
    - Back button#
- Setup#
  - Requirements#

A/B testing is a powerful tool to test different variables on various user segments in parallel to see which variable has the most impact on your game. A/B tests can be very useful for fine-tuning retention, monetization, or balancing mechanics. This sample simulates an A/B test to evaluate how much experience it should take to gain a level.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

To see this use case in action, open the samples menu and navigate to AB Test Level Difficulty. To open this scene directly and interact with the use case:

When a player signs in, the screen displays their level and an XP meter that tracks their current XP and the total amount of XP required to level up. In this case, the amount of total XP to level up is either 100, 80, 60, 50, or 30, depending on which test group the player is randomly assigned. For diagnostic purposes, the player's test group is also displayed (A, B, C, D, or E).

The ABTestLevelDifficultySceneManager.cs script performs the following initialization tasks in its Start function:

All of this updated data is displayed in the scene, and the Gain XP button becomes interactive.

When you click the Gain XP button, the simulated player gains 10 XP. When the XP bar is full (according to the test group threshold), the simulated player levels up and receives currency. The following occurs:

The button’s OnClick method sends an ActionButtonPressed custom event to the Analytics service and makes a call to the Cloud Code GainXPAndLevelIfReady.js script.

This server-authoritative call fetches the player's information from the Cloud Save and Remote Config services, increases the XP by the amount specified by Remote Config (in this case, 10), then tests whether the new player XP total equals or exceeds the level-up threshold.

The client code opens a level-up dialog and updates the relevant data in the scene UI. Note that this step provides an opportunity to show players different art based on their segmentation, and a convenient way to retrieve additional data for a specific currency at runtime.

Note: In this example, a cross-reference dictionary located in Remote Config and initialized at start-up converts the rewarded currency ID (in this case, COIN) to an Addressables address, which you can use to display the sprite (in this case, Sprites/Currency/Coin). A simpler approach to displaying different art according to a player’s segmentation is to attach additional information to the custom data associated with Currencies in the Economy configuration data. However, here the data was added to the Campaigns to demonstrate the flexibility of the Remote Config service.

Click Sign In As New Player to simulate a new player with a new randomly assigned test group that starts with 0 XP. The following occurs:

If you press the back button (the arrow in the top-left corner of the scene) to return to the "Start Here" or samples menu scene, it triggers a SceneSessionLength custom Analytics event, which captures the amount of time spent in this scene.

To replicate this use case, you'll need the following Unity packages in your project:

Note: Although it is listed as a package and requires separate dashboard configuration, Game Overrides doesn't actually have an SDK to install from Package Manager. It is a server-side offering that affects values returned from other services.

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys the following items:

The Deployment package doesn't support the following items:

To configure them, refer to Using the Unity Dashboard.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Important: This sample demonstrates the code that is needed to trigger Analytics events. However, additional code might be necessary to meet legal requirements such as GDPR, CCPA, and PIPL. For more information, see the documentation on managing data privacy.

Configure and enable the following custom Analytics events:

Configure the following custom parameters to support your custom events:

Note: This extended list of potential parameters allows for a more flexible analysis of different parameter groupings in the Data Explorer in the Unity Dashboard. Alternatively, you can send only the ungrouped parameters (for example, buttonName or sceneName) and perform any kind of grouped analysis you want by using the Data Export feature within the Data Explorer.

Publish the following script in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resource in the Unity Dashboard:

Set up the following config values in the Unity Dashboard:

Configure the following Overrides in the Unity Dashboard:

Select Choose content type > Config Overrides.

Enter override values for the following keys for variant 1:

Enter override values for the following keys for variant 2:

Enter override values for the following keys for variant 3:

Enter override values for the following keys for variant 4:

Enter override values for the following keys for variant 5:

Set the following start and end dates:

After finishing creating the Game Override, click Enable.

**Examples:**

Example 1 (unknown):
```unknown
ABTestLevelDifficultySample.unity
```

Example 2 (unknown):
```unknown
ABTestLevelDifficultySceneManager.cs
```

Example 3 (unknown):
```unknown
SceneOpened
```

Example 4 (unknown):
```unknown
SceneSessionLength
```

---

## CHANGESET DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/changeset-delete

**Contents:**
- CHANGESET DELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Deletes a changeset from the repository.

cm changeset delete | rm <csetspec>

cm changeset rm cs:4525@myrepo@myserver

cm changeset delete cs:cb11ecdb-1aa9-4f11-8698-dcab14e5885a

**Examples:**

Example 1 (unknown):
```unknown
cm changeset delete | rm <csetspec>
```

Example 2 (unknown):
```unknown
cm changeset rm cs:4525@myrepo@myserver
```

Example 3 (unknown):
```unknown
cm changeset delete cs:cb11ecdb-1aa9-4f11-8698-dcab14e5885a
```

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/unreal-engine-sdk/get-started

**Contents:**
- Get started#
  - What's included#
  - Understand the requirements#
- Download the Matchmaker SDK#
  - From the Unreal Engine Marketplace website#
  - From the Epic Games Launcher#
  - Configure the Matchmaker SDK#
    - Configure backfill#
- What's next ?#

Use the following instructions to learn how to install and configure the Unity Gaming Services SDK plugin. After you’ve installed and configured the Unity Gaming Services SDK for your project, you can use C++ or Blueprints for Unity Matchmaker.

The Unity Gaming Services SDK includes three of Unity’s services built into one plugin:

The Matchmaker SDK plug-in for Unreal Engine supports the Unreal Engine versions 4.27 to 5.3.

>Important: Currently, the Unity Matchmaker only supports matchmaking players into dedicated servers hosted using Unity Multiplay Hosting. Multiplay Hosting may incur costs. For pricing details, see Pricing.

>Important: Unity Matchmaker uses a protocol called Centrifuge to handle events on the server. This is contained in the plugin module MatchmakerServer. Centrifuge is not supported on non-PC platforms. Exclude the MatchmakerServer module from Client builds using Multiple Game Modules and TargetAllowList in the .uproject file.

Sign in to the Unreal Engine Marketplace.

Access the Unity Gaming Services SDK for Unreal Engine Marketplace page.

Select Open in Launcher.

Skip to Step 4 in From the Epic Games Launcher.

>Note: If you use a version of the engine built from sources then you can access your Marketplace folder by doing the following:

Unity Matchmaker relies on the Unity Authentication service, which is included in the Unity Gaming Services SDK.

Before you start calling the Matchmaker APIs and start allocating players using the Matchmaker, configure your Unity Matchmaker settings on the Unity Dashboard. Otherwise, all matchmaking requests fail. Unity Matchmaker requires a minimum of one queue with a default pool.

Backfill enables you to place players into an existing match that’s below the maximum player count. See backfill documentation to learn more.

Before using backfill, ensure you enable backfill on the Unity Dashboard for your queue.

Proceed with either integrations:

**Examples:**

Example 1 (unknown):
```unknown
MatchmakerServer
```

Example 2 (unknown):
```unknown
MatchmakerServer
```

Example 3 (unknown):
```unknown
TargetAllowList
```

Example 4 (unknown):
```unknown
C:\Program Files\Epic Games\UE_5.3\Engine\Plugins\Marketplace
```

---

## WORKSPACE MOVE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/workspace-move

**Contents:**
- WORKSPACE MOVE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

cm workspace | wk move | mv [<wkspec>] <new_path>

This command allows users to move a workspace to another location on disk.

cm workspace move myWorkspace \new\workspaceDirectory

(Moves 'myWorkspace' to the specified location.)

cm wk mv c:\users\maria\wkspaces\newlocation

(Moves the current workspace to the new location.)

**Examples:**

Example 1 (unknown):
```unknown
cm workspace | wk move | mv [<wkspec>] <new_path>
```

Example 2 (unknown):
```unknown
cm workspace move myWorkspace \new\workspaceDirectory
```

Example 3 (unknown):
```unknown
cm wk mv c:\users\maria\wkspaces\newlocation
```

---

## Record ad impression events

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/record-ad-impression-events

**Contents:**
- Record ad impression events#

Use the adImpression event to track what happens when you show an ad to a player.

The adImpression event is a standard event with a predefined schema you must match to process and track the event. A special AdImpressionParameters object is provided by the Analytics SDK to help you fulfil the schema when recording an ad impression.

Use the following code to record a minimal adImpression event:

Some of these fields need to be populated with values that come from your ad mediation SDK, while others are specific to your game. See the breakdown:

The AdImpressionEvent object contains a number of other fields that are less important, which you can also populate if you want and have the data available.

**Examples:**

Example 1 (unknown):
```unknown
adImpression
```

Example 2 (unknown):
```unknown
adImpression
```

Example 3 (unknown):
```unknown
AdImpressionParameters
```

Example 4 (unknown):
```unknown
adImpression
```

---

## Reservations

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/beta/reservations

**Contents:**
- Reservations#
  - Active build bonfiguration#

Warning: This feature is in closed beta and accessible by permission only.

A reservation is a request to the Multiplay Hosting API to reserve a specific server for a game session. Reservation requests are part of the reservation system Multiplay Hosting offers. The reservation system works the best for games that don’t use a matchmaker to group players together for a game session but use a server-select flow. A server-select flow is a method of connecting game clients to a game server where the player selects the specific game server they want to join.

Contrary to allocations, fleets using reservations-based matchmaking only operate using a single active build configuration. When the game client reserves a game server, the active build configuration is what the game server executes for that game session.

To determine and set the active build configuration for a reservations fleet, a request to the Multiplay Hosting API must be made.

When switching an active build configuration for a fleet, the graceful flag set on the fleet is used to determine how the system interacts with game servers as they are being switched to the new build configuration.

---

## Multiplay Hosting SDK for Unreal Engine

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/sdk/unreal-engine-sdk/overview

**Contents:**
- Multiplay Hosting SDK for Unreal Engine#

The Multiplay Hosting SDK for Unreal Engine includes all the functionality necessary to leverage Multiplay scaling and game server services in your game.

For more information about using Unity Gaming Services products with Unreal Engine, refer to Multiplay Hosting SDK for the Unreal Engine, which contains Multiplay Hosting, Matchmaker and Authentication in one convenient package.

Refer to Get started (UGS for the Unreal Engine) to download and install the SDK.

Note: Refer to Multiplay Hosting SDK for Unity if you’re using the Unity Engine to develop your game.

Important: The Multiplay Hosting SDK for Unreal Engine is incompatible because it's now included in the UGS SDK. If you're already using the Multiplay Hosting SDK for Unreal Engine, delete it to resolve the migration. No code change is required.

---

## Filters

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/filters

**Contents:**
- Filters#
- Filter by repository#
- Filter syntax#

You can use filters to create triggers that only execute when specified fields match the repository, object, or path involved in the operation that triggers the execution.

The system checks every particular filter for each type of trigger.

If the trigger receives data from the standard input, then the filter applies to each line of this input before the trigger executes. At least one filter must match with a line in the standard input for the trigger to execute, but it's not mandatory that all lines in the standard input match with the specified filters.

Note: Each trigger type accepts different filter elements.

You can filter by repository (rep:) in all types of triggers. For example:

--filter="rep:myrepo".

Filters are a comma-separated list, and admit regular expressions. If you need to use a comma character inside a filter, remember to scape it: \,.

For example, you can filter by an exact name for a repository, object or path:

--filter="rep:code,BL101"

Filters also support wildcards:

**Examples:**

Example 1 (unknown):
```unknown
--filter="rep:myrepo"
```

Example 2 (unknown):
```unknown
--filter="rep:code,BL101"
```

Example 3 (unknown):
```unknown
--filter="STATUS,br*"
```

Example 4 (unknown):
```unknown
--filter="rep:test*"
```

---

## Get started with Leaderboards

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/sdk-install-setup

**Contents:**
- Get started with Leaderboards#
- Unity Dashboard#
- Unity SDK installation and setup#
  - Install Leaderboards SDK#
  - Install Authentication SDK#
  - Link your Unity project#
  - Initialize the SDKs and authenticate the player#
  - Next steps#
- Leaderboards in the UGS CLI#
  - Deploy a Leaderboards configuration#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

The first step in using Leaderboards is to learn how to implement the feature. This section describes how to set up Leaderboards for your project.

You can set up and manage Leaderboards in the Unity Dashboard:

When you launch Leaderboards for the first time, this adds Leaderboards to the Shortcuts section on the sidebar and opens the Leaderboards Overview.

You can use the Unity Dashboard to create and manage your leaderboards and view their entries.

The Leaderboards SDK requires Unity 2020.3.0 or newer.

You can install the package in the Unity Editor.

Navigate to Window > Package Manager and select Unity Registry in the Packages dropdown on the top left. You can either:

There is a Samples section where you can import example code to your project to assist you calling the Leaderboards SDK from your game.

After installation, the Leaderboards SDK is available in Unity scripts from the Unity.Services.Leaderboards namespace:

The Leaderboards package relies on the Authentication package. The Unity Authentication service creates an account to persist player scores where you can use anoynymous sign-in or platform-specific authentication.

The Authentication package is installed as a dependency when you install the Leaderboards package. For information on installing packages manually, refer to Install a package from a registry.

After installation, the Authentication SDK is available in Unity scripts from the Unity.Services.Authentication namespace:

Once installed, the Authentication package prompts you to link your Unity project to a Unity Gaming Services Project ID. Follow the instructions in the prompt on the screen to link your project.

Alternatively, follow the steps to Link your project in the Unity Editor.

You must initialize the Leaderboards SDK and its dependencies from inside a Unity script lifecycle callback before use. The following example uses the Awake callback. This is done by initializing all installed services via the Core SDK by calling await UnityServices.InitializeAsync();, available from the Unity.Services.Core namespace.

After the SDK initialization is complete, the player is authenticated. The following example uses anonymous authentication to create an anonymous account for the player to persist their scores. Other methods of authentication are available as outlined in the Unity Authentication documentation.

After completing the above steps the Leaderboards SDK is now ready to use from the Unity.Services.Leaderboards namespace. Review the features, Unity SDK tutorial, and the SDK sample to find out more about the Leaderboards feature set and how to use them.

The Unity Gaming Services (UGS) command line interface provides a scalable and automatable alternative to the Unity Dashboard and improves your team's workflows and productivity. The CLI is used to manage, test and deploy your Leaderboards configuration.

See the documentation on how to install and use the CLI.

To make your Leaderboards configurations accessible to the game client, you must deploy the configuration to the Leaderboards service.

Refer to write configuration to learn more about script deployment.

To get started with the UGS CLI, perform the following steps:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Configure a Service Account with the required roles for Leaderboards and environments management. Refer to Get Authenticated.

Run the following command:

ugs deploy <path-to-configuration-file>

Developers that do not use Unity can access APIs via web endpoints or REST APIs. REST APIs provide more flexibility and allow you to automate your workflows by using your favorite language and game development engine.

The Leaderboards service provides the following REST APIs:

This module allows users to author, modify, and deploy Leaderboard configuration assets directly from the Unity Editor.

Leaderboards Authoring is only supported on Unity 2021.3 and above.

The Deployment Window is a core feature of the Deployment package.

The purpose of the Deployment Window is to allow all services to have a single cohesive interface for Deployment needs.

The Deployment Window provides a uniform deployment interface for all services. It allows you to upload cloud assets for your respective cloud service.

For more information, refer to the com.unity.services.deployment package documentation.

Use the right click menu in the Project window to create a Leaderboard asset.

The Deployment Window automatically detects these files to be deployed at a later time.

For more information on how to create and modify Leaderboards Assets, refer to Leaderboards assets.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.Leaderboards
```

Example 2 (unknown):
```unknown
using Unity.Services.Leaderboards;
```

Example 3 (unknown):
```unknown
using Unity.Services.Leaderboards;
```

Example 4 (unknown):
```unknown
Unity.Services.Authentication
```

---

## Check in changes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/merging

**Contents:**
- Check in changes#
- Check in changes in the Unity Dashboard#
- Check in changes in the GUI#
- Check in changes in the CLI#
  - Check in all changes#
  - Check in changes in a given path#
  - Additional options#
- Additional resources#

You can merge changes that you make into a destination branch. Whether you can merge depends on the merge rules in place.

Merge conflicts can prevent you from merging changes. You can resolve merge conflicts in the Unity Version Control desktop client.

You can manually merge branches and changesets in the DevOps Unity Dashboard:

Note: For information on how to automatically merge changes and check for merge conflicts, refer to Mergebots.

You can select changed files in the Pending Changes tab and check them in as a changeset.

If you’ve made any changes to a file in your workspace, you can run cm status to retrieve a list of your changed files.

To check in all of your pending changes, run ci –all:

The --all modifier means every file that’s changed, deleted, or moved. To include private files, you can use ci –all –private.

To check in changes on a specific path, specify the path in your cm ci command. For example:

**Examples:**

Example 1 (unknown):
```unknown
>cm ci --all
The selected items are about to be checked in. Please wait ...
Assembling checkin data
Validating checkin data
Uploading file data
Uploaded 0 bytes of 2.77 KB (0%)
Confirming checkin operation
Modified c:\Users\pablo\wkspaces\quake_path\code
Modified c:\Users\pablo\wkspaces\quake_path\code\lib
Modified and moved from c:\Users\pablo\wkspaces\quake_path\code\FileSystem-renamed.cs to c:\Users\pablo\wkspaces\quake_path\code\lib\FileSystem.cs
Created changeset cs:575@br:/main/fix-1342@quake@localhost:6060 (mount:'/')
```

Example 2 (unknown):
```unknown
>cm ci --all
The selected items are about to be checked in. Please wait ...
Assembling checkin data
Validating checkin data
Uploading file data
Uploaded 0 bytes of 2.77 KB (0%)
Confirming checkin operation
Modified c:\Users\pablo\wkspaces\quake_path\code
Modified c:\Users\pablo\wkspaces\quake_path\code\lib
Modified and moved from c:\Users\pablo\wkspaces\quake_path\code\FileSystem-renamed.cs to c:\Users\pablo\wkspaces\quake_path\code\lib\FileSystem.cs
Created changeset cs:575@br:/main/fix-1342@quake@localhost:6060 (mount:'/')
```

Example 3 (unknown):
```unknown
ci –all –private
```

Example 4 (unknown):
```unknown
cm ci task001\alpha\* -c “alpha files checked in” –all
```

---

## Custom actions

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/custom-actions

**Contents:**
- Custom actions#
- Create a custom action#
  - Custom action settings#
- Cloud Code script#
- Use a custom action#

On top of the built-in actions moderators can take, you can craft custom actions to fit your game. These actions can be anything from banning a user from a specific game mode or removing points or currency from an account.

There are two steps to creating a custom action:

To create the custom action, navigate to the Moderation actions page in the Unity Dashboard: Vivox > Safe Text > Moderation action.

The custom action you created will appear with the listed actions on the Moderation actions page.

When creating or editing a custom action, you can change multiple conditions of the action:

You can also toggle event settings from the editing page or whether the action is enabled or disabled.

You can edit a custom action after it’s been created.

To have an action take effect in your game's backend, you must set up a Cloud Code Script to execute any necessary actions For example, if you want a player banned from Competitive mode, you need to establish this action within the script to hit your game’s webhooks which would carry out the ban.

There is a default template script available from Cloud Code. The Moderation actions page directs you to this default template in the Cloud Code dashboard. Update the script with the desired behavior of your custom actions. Define each custom action you create in one script file.

Important: The Cloud Code script must be published before being added.

This script uses events to trigger specific actions through Cloud Code. You need to define a JSON parameter called ‘event’ in the script. You can do this from the Cloud Code product page under the Scripts section. Then select the Details tab of the script you are using and select Add.

Fill in the parameter fields with:

Set the script on the Moderation action page. When Moderators use the customize action the script will trigger.

Learn more about Cloud Code and script templates in the Cloud Code documentation.

Select the custom action from the list of actions when responding to an incident.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-checkin

---

## Audit configuration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/webadmin/audit-config

**Contents:**
- Audit configuration#
- Audit log levels#
- Audit log files#
  - Example audit log file#

Set up the Unity Version Control (UVCS) audit level and the audit log file name in the server administration console.

By default, the audit log is active and set to log level one in the audit.log file. You can find the audit log file in the UVCS server installation directory.

There are file audit levels:

Note: Each audit level includes any previous levels.

An audit log file includes a line for any logged operation with the following structure:

Note: To collect hashes regularly, you can schedule the tail command. For example, tail -n 1 audit.log |mail admin@myorg.com.

**Examples:**

Example 1 (unknown):
```unknown
<HASH> <user> (<machine>) <timestamp> [<repository>]: <operation>
```

Example 2 (unknown):
```unknown
<HASH> <user> (<machine>) <timestamp> [<repository>]: <operation>
```

Example 3 (unknown):
```unknown
MHXET08/RpZQaJWXLlU/v7ovDPugjEOBSG9/74HFgD8= maria (HERMES) 6/23/2017 5:11:31 PM [doom3src]: Branch deleted: scm15478 (7991)
ZDSSKBGFy6SRg/O38WiyJzHbhqmUCq7SMoMp3Eqfiuc= maria (HERMES) 6/23/2017 5:44:06 PM [doom3src]: Deleted '/README.txt' (changeset 8375)
dhZG9IWM10FoHTGF+amMEeErFmHkZ2KIIL1t/uwxtYI= sue (HERMES) 6/23/2017 5:49:46 PM [doom3src]: Access denied to object 'rep:10', operation 'view'
q23jnDUDPZAicF2bYWZOWihMbXRn3/JLYSJDqOW1xJ4= maria (HERMES) 6/23/2017 5:56:14 PM [doom3src]: New label: BL064 (8408) applied to changeset 8398
k2L9HjEMqktYo7tDZQuo9PghlHgs+BMH+q3oFspRm/8= maria (HERMES) 6/23/2017 5:58:04 PM [doom3src]: Comment changed on '8408' from '' to 'Label audit test'
u84wRigufEZTKUcQrwJSjcLIxyV9b3LjwyyuX8pLUII= maria (HERMES) 6/23/2017 5:58:25 PM [doom3src]: New attribute: 'review' (8409)
AJSY/4c4QeuHU8GKIYzIdI92k6JiZoa5/ye73YIzolI= maria (HERMES) 6/23/2017 6:04:49 PM [rep03]: New branch: /main (3)
e7Mb3A49LcohQWzOCk9pAnT6Pvz5JgWNIuqthgh69BA= maria (HERMES) 6/23/2017 6:04:49 PM [rep03]: New repository: rep03 (577)
3B4jcQwNsgpi7NueKwV6rFU7vgfH1rAAQ6t+hQyXZ6U= maria (HERMES) 6/23/2017 6:17:45 PM [doom3src]: Attribute 'review' renamed to 'reviewed' (8409)
/BKLej1sb66/FlqJ/9Hr/8oiV/R50nP/oR5UEwCmbO4= maria (HERMES) 6/23/2017 6:19:58 PM [doom3src]: Comment changed on '8425' from 'Renamed' to 'File renamed'
jvck2dfnGSosVXSeLYkSzNOaFZZY1Z8AcEJtWoSx59w= maria (HERMES) 6/23/2017 6:31:10 PM [doom3src]: Downloaded revision 2276
2YqWTWGEw+UbuZRYfo2ZiDEKYRMBZyGc+Tc+myQqtPc= maria (HERMES) 6/23/2017 6:31:10 PM [doom3src]: Downloaded revision 7343
WrA0T9Pq276DqFxDLhoVI1gnfdWzKNEo69refw8q640= maria (HERMES) 6/23/2017 6:31:10 PM [doom3src]: Downloaded revision 8016
FxFNosrb4XuAOyzwsOsiOsISgdy5S7kY5wXxPKyP/5E= maria (HERMES) 6/23/2017 6:31:10 PM [doom3src]: Downloaded revision 8320
```

Example 4 (unknown):
```unknown
MHXET08/RpZQaJWXLlU/v7ovDPugjEOBSG9/74HFgD8= maria (HERMES) 6/23/2017 5:11:31 PM [doom3src]: Branch deleted: scm15478 (7991)
ZDSSKBGFy6SRg/O38WiyJzHbhqmUCq7SMoMp3Eqfiuc= maria (HERMES) 6/23/2017 5:44:06 PM [doom3src]: Deleted '/README.txt' (changeset 8375)
dhZG9IWM10FoHTGF+amMEeErFmHkZ2KIIL1t/uwxtYI= sue (HERMES) 6/23/2017 5:49:46 PM [doom3src]: Access denied to object 'rep:10', operation 'view'
q23jnDUDPZAicF2bYWZOWihMbXRn3/JLYSJDqOW1xJ4= maria (HERMES) 6/23/2017 5:56:14 PM [doom3src]: New label: BL064 (8408) applied to changeset 8398
k2L9HjEMqktYo7tDZQuo9PghlHgs+BMH+q3oFspRm/8= maria (HERMES) 6/23/2017 5:58:04 PM [doom3src]: Comment changed on '8408' from '' to 'Label audit test'
u84wRigufEZTKUcQrwJSjcLIxyV9b3LjwyyuX8pLUII= maria (HERMES) 6/23/2017 5:58:25 PM [doom3src]: New attribute: 'review' (8409)
AJSY/4c4QeuHU8GKIYzIdI92k6JiZoa5/ye73YIzolI= maria (HERMES) 6/23/2017 6:04:49 PM [rep03]: New branch: /main (3)
e7Mb3A49LcohQWzOCk9pAnT6Pvz5JgWNIuqthgh69BA= maria (HERMES) 6/23/2017 6:04:49 PM [rep03]: New repository: rep03 (577)
3B4jcQwNsgpi7NueKwV6rFU7vgfH1rAAQ6t+hQyXZ6U= maria (HERMES) 6/23/2017 6:17:45 PM [doom3src]: Attribute 'review' renamed to 'reviewed' (8409)
/BKLej1sb66/FlqJ/9Hr/8oiV/R50nP/oR5UEwCmbO4= maria (HERMES) 6/23/2017 6:19:58 PM [doom3src]: Comment changed on '8425' from 'Renamed' to 'File renamed'
jvck2dfnGSosVXSeLYkSzNOaFZZY1Z8AcEJtWoSx59w= maria (HERMES) 6/23/2017 6:31:10 PM [doom3src]: Downloaded revision 2276
2YqWTWGEw+UbuZRYfo2ZiDEKYRMBZyGc+Tc+myQqtPc= maria (HERMES) 6/23/2017 6:31:10 PM [doom3src]: Downloaded revision 7343
WrA0T9Pq276DqFxDLhoVI1gnfdWzKNEo69refw8q640= maria (HERMES) 6/23/2017 6:31:10 PM [doom3src]: Downloaded revision 8016
FxFNosrb4XuAOyzwsOsiOsISgdy5S7kY5wXxPKyP/5E= maria (HERMES) 6/23/2017 6:31:10 PM [doom3src]: Downloaded revision 8320
```

---

## Transfer a Unity Cloud project to a different Unity organization

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/how-to-clone-repositories-before-transferring-project

**Contents:**
- Transfer a Unity Cloud project to a different Unity organization#
- Step 1. Clone Repositories Before Transferring#
  - Prerequisites#
  - Cloning the Repositories#
- Step 2: Transfer the Project#

You can transfer a Unity Cloud project to a different Unity organization. This process is useful if you need to consolidate projects under a single organization or move a project to another organization.

Important: All UVCS repositories associated with the project will be deleted during the transfer. Be sure to clone any repositories you wish to retain before transferring the project.

To keep the UVCS repositories, clone them to a Unity Cloud project within the destination organization before initiating the transfer.

For each repository, run the following command in your terminal:

Replace placeholders as follows:

Once you've successfully cloned all repositories, you may proceed with transferring the Unity Cloud project to the destination organization.

**Examples:**

Example 1 (unknown):
```unknown
cm clone <source-project>/<target-repository>@<source-organization>@unity <destination-project>/<target-repository>@<destination-organization>@unity
```

Example 2 (unknown):
```unknown
cm clone <source-project>/<target-repository>@<source-organization>@unity <destination-project>/<target-repository>@<destination-organization>@unity
```

Example 3 (unknown):
```unknown
<source-project>
```

Example 4 (unknown):
```unknown
<repository-name>
```

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal data collected about app users/game-players#
    - Developer defines#
- Relationship under privacy laws#
- Legal basis for processing#
- Consent#
- Data subject requests#
  - Access#
  - Deletion#
- Data retention#

The Relay service exposes a way for game developers to securely offer increased connectivity between players by using a join code style workflow without needing to invest in a third-party solution, maintain dedicated game servers (DGS), or worry about the network complexities of a peer-to-peer game. Instead of using DGS, the Relay service provides connectivity through a universal Relay server acting as a proxy.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default personal data collected (always collected in order for product to work)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they must implement it client-side in a way determined by the developer.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Relay support team with the Player ID of the end user that requested access.

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Relay support team with the Player ID of the end user that requested access.

Please note: This functionality only applies to this service. If you are using other services which collect app user personal data you will need to review that service's documentation for how it handles data deletion requests. To delete the Player ID created by the Unity Authentication SDK (if enabled), please use the Authentication API.

Personal data is retained for 30 days.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## Queues and pools

**URL:** https://docs.unity.com/ugs/manual/matchmaker/manual/advanced-topics-queues-pools

**Contents:**
- Queues and pools#
- Queues#
  - Default queue#
- Pools#
  - Default pool#
  - Filters#
    - Examples of filters#

A queue contains a mutually exclusive set of tickets that you can match together. Tickets in a queue will not be matched with tickets found in another queue. This behavior is useful when building a game with discrete game modes that don't overlap, such as Team Deathmatch, Free-For-All, and Capture the Flag. It’s also useful in a game where the type of game is different, such as a competitive game with Ranked and Unranked modes.

The default queue serves as a fallback queue if the ticket created does not specify the name of the queue. This fallback method allows you to dynamically switch to the default queue after the game goes live without changing the game client.

This ability to fall back to the default queue also supports legacy versions of Matchmaker where the game clients do not specify queue names. Therefore you do not need to update your game client to include a queue name when migrating your services.

A pool represents a dynamic separation of tickets within a queue. Pools contain filters that indicate which tickets the pool will process. The matchmaker assigns tickets that do not match the filters of a pool to a subsequent pool. If the ticket is not compatible with any of the pools, it uses the default pool of that queue.

For each pool, it is possible to specify hosting information as well as the matchmaking logic to use when building matches with the tickets within the pool.

In this way, you can separate pools by platform by using filters to target the specific platforms, such as a console or Windows. You can also use pools to target regions, such as North America, the European Union, or Asia.

Similarly to queues, the default pool serves as a fallback to make sure you can still process tickets that are not compatible with any other pool. If we take our example with pools for each region, the default pool would be used to put players in a fallback region.

A filter is a way for pools to decide which tickets it will process. When a client creates a matchmaking ticket, custom values can be added under the Attributes section. These attribute values are the ones used in pool filters.

The matchmaker supports two types of values: text and numbers and the filters currently support four operations =, !=, <, and >.

If a pool contains multiple filters, all the filters must pass in order for a ticket to be accepted in this pool.

Here's an example of a pool that matches tickets only on a Windows platform:

**Examples:**

Example 1 (unknown):
```unknown
var attributes = new Dictionary<string, object>
{
    { "platform", "Windows" }
};
```

Example 2 (unknown):
```unknown
var attributes = new Dictionary<string, object>
{
    { "platform", "Windows" }
};
```

Example 3 (unknown):
```unknown
"attributes":[{
        "platform":"Windows"
    }
]
```

Example 4 (unknown):
```unknown
"attributes":[{
        "platform":"Windows"
    }
]
```

---

## Unity Dashboard

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/logging/tutorials/retrieve-logs/unity-dashboard

**Contents:**
- Unity Dashboard#

The Unity Dashboard provides a graphical interface for displaying and filtering log entries.

From the Unity Dashboard, open Cloud Code and select Logs.

The page allows you to filter logs by time range, as well as by a boolean query expression. Refer to Filter logs for more information.

Log entries can be expanded by clicking on the arrow toggle on the left, revealing the full structured log entry.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/remove-private

---

## WORKSPACE LIST

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/workspace-list

**Contents:**
- WORKSPACE LIST#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Output format parameters (--format option)#
  - Examples#

cm workspace | wk [list | ls] [--format=<str_format>]

This command accepts a format string to show the output. The output parameters of this command are the following:

(Lists all workspaces.)

cm workspace list --format={0}#{3,40}

cm workspace list --format={wkname}#{wkid,40}

(Lists all workspaces and shows the workspace name, a # symbol and the workspace GUID field in 40 spaces, aligned to left.)

cm wk --format="Workspace {0} in path {2}"

cm wk --format="Workspace {wkname} in path {path}"

(Lists all workspaces and shows result as formatted strings.)

**Examples:**

Example 1 (unknown):
```unknown
cm workspace | wk [list | ls] [--format=<str_format>]
```

Example 2 (unknown):
```unknown
cm workspace list --format={0}#{3,40}
```

Example 3 (unknown):
```unknown
cm workspace list --format={wkname}#{wkid,40}
```

Example 4 (unknown):
```unknown
cm wk --format="Workspace {0} in path {2}"
```

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/privacy-overview

**Contents:**
- Privacy overview#
- Product Overview#
- Personal Data Collected about App Users/Game Players#
  - Developer Defines#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent#
- Data Subject Requests#
  - Access#
  - Deletion#

Multiplay Hosting is a battle-tested solution that helps you run game servers at scale, across the world.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, refer to the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected (always collected in order for the product to work)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they must implement it client-side in a way determined by the developer.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. If your game server stores IP addresses in its logs, you may either download them from your game servers (we offer an API and a UI for that) or through our logging solution.

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. If your game server stores IP addresses in its logs, you may delete the logs by scaling down the servers through our UI or API. The server will eventually get deleted after a couple of hours, depending on your server TTL. Our logging solution automatically deletes any log older than 7 days.

This product has no dependencies on other Unity products.

By default, IP addresses are retained by Multiplay Hosting systems and game server logs for up to 30 days.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

Unity DPA applies to the transfer of data for this product.

---

## Install lifecycle

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/install-lifecycle

**Contents:**
- Install lifecycle#
  - Progressive rollout lifecycle#
  - Forced rollout lifecycle#

The install lifecycle is the series of states or statuses a server transitions through when you roll out a release for a build. When you update a build and roll out a new release, the servers using the build go through the install lifecycle. There are six possible states in the install lifecycle: allocated, deallocated, installing, offline, online, and ready, many of which overlap with the server lifecycle.

The install lifecycle varies slightly depending on whether the rollout is a forced rollout or a progressive rollout.

A progressive rollout is a method of deploying a build update where you update servers only when they're empty. If there are any players connected to a server, Multiplay Hosting performs the update on servers as soon as they're available.

If you release an update as a progressive rollout, Multiplay Hosting waits for you to deallocate each server before triggering the installation. As a result, the state flow of a server during a progressive rollout is allocated → deallocated → installing → offline → online.

Note: The deallocated state exists but doesn't appear in the Unity Dashboard.

A forced rollout is a method of deploying a build update where you force servers to update even if there are players connected. If players are connected when you start a forced rollout, Multiplay Hosting stops the server, breaking the connection with those players.

If you release an update as a forced rollout, Multiplay Hosting triggers the installation irrespective of the server’s allocation status. As a result, the state flow of a server during a forced rollout is allocated → installing → offline → online.

---

## REPOSITORY

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/repository

**Contents:**
- REPOSITORY#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to manage repositories.

cm repository | repo <command> [options]

cm repository <command> --usage

cm repository <command> --help

cm repository newrepo

cm repository create newrepo

cm repository rename oldname newname

cm repository add C:\repo\

**Examples:**

Example 1 (unknown):
```unknown
cm repository | repo <command> [options]
```

Example 2 (unknown):
```unknown
cm repository <command> --usage
```

Example 3 (unknown):
```unknown
cm repository <command> --help
```

Example 4 (unknown):
```unknown
cm repository
```

---

## License for Unity Player Accounts

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/license-player-accounts

**Contents:**
- License for Unity Player Accounts#
- Copyright (c) 2014-present Matt Zabriskie & Collaborators#

This package contains third-party software components governed by the license(s) indicated below:

Component Name: Emotion

Copyright (c) Emotion team and other contributors

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: Fontsource

Copyright (c) 2023 Ayuhito

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: Google Cloud Secret Manager

TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

"License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.

"Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.

"Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.

"You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.

"Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.

"Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.

"Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).

"Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.

"Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."

"Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.

Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.

Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.

Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:

(a) You must give any other recipients of the Work or Derivative Works a copy of this License; and

(b) You must cause any modified files to carry prominent notices stating that You changed the files; and

(c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and

(d) If the Work includes a "NOTICE" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.

You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.

Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.

Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.

Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.

Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.

Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.

END OF TERMS AND CONDITIONS

APPENDIX: How to apply the Apache License to your work.

Copyright [yyyy] [name of copyright owner]

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.

Copyright (c) 2017 VERTEX SYSTEMS

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: Sentry

Copyright (c) 2019 Sentry (https://sentry.io) and individual contributors. All rights reserved.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: TanStack

Copyright (c) 2021-present Tanner Linsley

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: zxcvbn

Copyright (c) 2012-2016 Dan Wheeler and Dropbox, Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: Amplitude

Copyright (c) 2014 Amplitude Analytics

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: Sharp

Copyright (c) 2014 Amplitude Analytics

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: Phosphor

Copyright (c) 2020 Phosphor Icons

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: Stylis

Copyright (c) 2016-present Sultan Tarimo

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Component Name: Axios

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

The MIT License (MIT)

Copyright (c) 2023 Vercel, Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: Next-auth

Copyright (c) 2022-2023, Balázs Orbán

Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

Component Name: Prom-client

TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

"License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.

"Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.

"Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.

"You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.

"Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.

"Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.

"Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).

"Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.

"Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."

"Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.

Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.

Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.

Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:

(a) You must give any other recipients of the Work or Derivative Works a copy of this License; and

(b) You must cause any modified files to carry prominent notices stating that You changed the files; and

(c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and

(d) If the Work includes a "NOTICE" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.

You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.

Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.

Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.

Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.

Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.

Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability.

END OF TERMS AND CONDITIONS

APPENDIX: How to apply the Apache License to your work.

Copyright 2015 Simon Nyberg

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.

Component Name: Prop-types

Copyright (c) 2013-present, Facebook, Inc.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

Component Name: React

Copyright (c) Meta Platforms, Inc. and affiliates.

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

**Examples:**

Example 1 (unknown):
```unknown
Apache License
                       Version 2.0, January 2004
                    http://www.apache.org/licenses/
```

Example 2 (unknown):
```unknown
Apache License
                       Version 2.0, January 2004
                    http://www.apache.org/licenses/
```

Example 3 (unknown):
```unknown
To apply the Apache License to your work, attach the following
  boilerplate notice, with the fields enclosed by brackets "[]"
  replaced with your own identifying information. (Don't include
  the brackets!)  The text should be enclosed in the appropriate
  comment syntax for the file format. We also recommend that a
  file or class name and description of purpose be included on the
  same "printed page" as the copyright notice for easier
  identification within third-party archives.
```

Example 4 (unknown):
```unknown
To apply the Apache License to your work, attach the following
  boilerplate notice, with the fields enclosed by brackets "[]"
  replaced with your own identifying information. (Don't include
  the brackets!)  The text should be enclosed in the appropriate
  comment syntax for the file format. We also recommend that a
  file or class name and description of purpose be included on the
  same "printed page" as the copyright notice for easier
  identification within third-party archives.
```

---

## Relay integration

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/relay-integration

**Contents:**
- Relay integration#

Using the Relay service isn't a requirement for using the Lobby service, but if you're using Relay, you can set Relay-related properties on a lobby to enable synchronized disconnects between Relay and Lobby. If you register a player's Relay information with the lobby, and that player disconnects or is disconnected from the Relay server they're connected to, the Relay service sends a notification to the Lobby service so that the disconnected player is removed from that lobby. Refer to the Relay documentation for more information about Relay and the Lobby config options for more details about configuring player disconnects.

To enable Relay integration with the Lobby service, set the AllocationID for each player whenever a player is in a lobby and is using a Relay server. The AllocationID for the player who sets up the allocation (most likely the lobby host) should be the allocation ID returned by the CreateAllocationAsync API call. All other players in the lobby who join that allocation should instead use the allocation ID returned by their respective JoinAllocationAsync API calls.

You can use the Game Lobby Sample, which demonstrates how to use the Lobby and Relay packages to create a typical game lobby experience.

Note: When you are using relay integration and the relay host disconnects from the relay, the host is removed from the lobby. Other players are also disconnected from the relay at this time (because the host is gone), but they are not disconnected from the lobby. For more information, see Host migration.

Check out the Lobby and Relay demo overview to learn about how you can use Lobby and Relay together to create a game that facilitates multiplayer game sessions without dedicated game servers.

---

## PULL

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/pull

**Contents:**
- PULL#
- Description#
  - Usage#
  - Options#
  - Translate options#
    - Mode#
    - Specifics if mode is set to "table"#
  - Authentication options#
    - Authentication data can be specified using one of the two following modes#
    - Using authentication parameters#

Pulls a branch from another repo.

cm pull <src_br_spec> <dst_rep_spec> [--preview] [--nodata] [TranslateOptions] [--user=<usr_name> [--password=<pwd>] | AuthOptions]

(Direct server-to-server replication. Pulls a branch from a repository.)

cm pull <dst_rep_spec> --package=<pack_file> [AuthOptions]

(Package based replication. Imports the package in the destination repository.)

cm pull hydrate <dst_br_spec> [<src_rep_spec>] [--user=<usr_name> [--password=<pwd>] | AuthOptions]

(Introduces the missing data for all the changesets of a branch previously replicated with '--nodata'. If a repo to obtain the data is not specified, UVCS tries to use the "replication source" (origin of the replicated branch)).

cm pull hydrate <dst_cs_spec> [<src_rep_spec>] [--user=<usr_name> [--password=<pwd>] | AuthOptions]

(Introduces the missing data for a changeset previously replicated with '--nodata'. If a repo to obtain the data is not specified, UVCS tries to use the "replication source").

--trmode=(copy|name|table --trtable=<translation_table_file>)

The source and destination repositories may use different authentication modes. The '--trmode' option specifies how to translate the user names from the source to the destination. The '--trmode' must be one of the following values:

--trtable=<translation_table_file>

If the translation mode is 'table', a translation table is a file containing lines in the form <oldname;newname> (one per line). When the branch is written to the destination repository, the objects created by a user identified by "oldname" in the source repository will be set to the user with "newname" on the destination.

--authmode=<mode> --authdata=<data>

Where --authmode can take one of the following values

The '--authdata' line is the content of the <SecurityConfig> entry in the client.conf file and the profiles.conf file. The profiles.conf file can be easily generated from the UVCS GUI in the replication profiles tab under Preferences.

--authmode=UPWorkingMode --user=<user> --password=<psw>

It's possible to have a different file for each server you connect to, with the credentials for that server and --authfile=<authentication_file> where the authentication_file must be formed by the following 2 lines:

The 'pull' command is able to replicate branches (along with their changesets) between a source repository and a destination repository. The repositories can be located at different servers.

There are two replication operations: 'push' and 'pull'.

A 'pull' operation means that the replication operation will demand data from the source repository to be stored into the destination repository. The client will connect to the destination repository and, from that host, it will establish a connection to the source repository to retrieve the targeted data. During pull it is the destination server which will be connected to the source.

Although in a typical distributed scenario a developer pushes data from his local server to the main server, the developer might want to pull the latest repository updates from the main server, too.

Replication can resolve situations where concurrent changes have been made on the same branch on two replicated repositories:

Keep in mind that pull replication works in an indirect way. When executed, the command asks the destination repository to connect to the source and obtain the selected branch.

However, this can be done directly by using the push command. This will make the command replicate the selected branch from source to destination.

cm pull br:/main@project1@remoteserver:8084 projectx@myserver:8084

(Pulls the 'main' branch from 'remoteserver' to 'myserver'. In this case, both servers are configured with the same authentication mode.)

cm pull br:/main@project1@remoteserver:8084 projectx@myserver:8084 --authmode=LDAPWorkingMode --authdata=::0:dave:fPBea2rPsQaagEW3pKNveA

(Pulls the same branch as before, but now the remote server is configured to authenticate users with Active Directory. For instance, I am connecting from a Linux machine to a Windows server configured to use Active Directory integrated mode. I will specify my Active Directory user and cyphered password and pass it as LDAP to the server.)

cm pull br:/main@project1@remoteserver:8084 projectx@myserver:8084 --authmode=UPWorkingMode --user=dave --password=mysecret

(Pulls the same branch, but now users are authenticated on the remote server, taking advantage of the user/password database included in UVCS.)

cm pull br:/main@project1@remoteserver:8084 projectx@myserver:8084 --nodata

(Replicates the 'main' branch from 'remoteserver' to 'myserver' without data.)

cm pull hydrate br:/main@projectx@myserver:8084 projectx@remoteserver:8084

(Hydrates all the changesets in the 'main' branch obtaining the data from the remote server.)

cm pull hydrate cs:122169@projectx@myserver:8084 projectx@remoteserver:8084

(Hydrates changeset 122169 in 'myserver' obtaining the data from the remote server.)

**Examples:**

Example 1 (unknown):
```unknown
cm pull <src_br_spec> <dst_rep_spec> [--preview] [--nodata] [TranslateOptions] [--user=<usr_name> [--password=<pwd>] | AuthOptions]
```

Example 2 (unknown):
```unknown
cm pull <dst_rep_spec> --package=<pack_file> [AuthOptions]
```

Example 3 (unknown):
```unknown
cm pull hydrate <dst_br_spec> [<src_rep_spec>] [--user=<usr_name> [--password=<pwd>] | AuthOptions]
```

Example 4 (unknown):
```unknown
cm pull hydrate <dst_cs_spec> [<src_rep_spec>] [--user=<usr_name> [--password=<pwd>] | AuthOptions]
```

---

## Blueprint Integration

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/unreal-engine-sdk/blueprint-integration

**Contents:**
- Blueprint Integration#
  - Add the Authentication SDK as a dependency#
  - Get User Info#
  - Delete User#
  - Register State Changed Callback#
  - Sign Out#
  - Switch Profile#
  - Profile Exists#
  - Get Current Profile Name#
  - Get Profile Names#

Before you continue with the following blueprint demonstrations, make sure you’ve successfully installed the Authentication SDK plugin and can view Authentication-related functions in a Blueprint’s event graph or function under Unity Gaming Services > Authentication.

Use Sign In Anonymously to anonymously authenticate. This is a quick way to authenticate without any user information, and requires no interaction with external providers. If successful, this populates the current player profile with the retrieved credentials returned from the Unity Authentication servers.

Sign In Anonymously takes an FAuthenticationSignInOptions struct as a parameter that changes the way a sign-in is performed. More information about these parameters can be found on the official Unity API services documentation page.

The response from the SDK can be handled in a custom event, which needs to take in an Authentication Response as an output pin. To isolate response variables, right-click the response body output pin and select Split Pin.

Use Get User Info to retrieve information about the currently authenticated user. This includes their user Id, authentication timestamps, and any external Identity providers that are linked to their session.

The response from the SDK can be handled in a custom event, which needs to take in an Authentication User Response as an output pin, representing the user response from the Authentication SDK. To isolate response variables, right-click the response body output pin and select Split Pin.

Use Delete User to delete all information related to the currently authenticated player. This function also signs out the player, and deletes all player preferences and profiles connected to the player.

The response from the SDK can be handled in a custom event, which needs to take in a Boolean as an output pin, representing whether the deletion was a success.

Use Register State Changed Callback to assign a callback function that invokes upon the state of the subsystem changing. For instance, the assigned function executes when a player has successfully authenticated and the subsystem state has changed to Authorized.

The response from the SDK can be handled in a custom event, which needs to take in an Authentication State Changed Response as an output pin, representing the response from the Authentication SDK. To isolate response variables, right-click the response body output pin and select Split Pin.

Use Sign Out to sign-out of the currently authenticated player profile. This removes the current player profile and switches to the default profile. This function also has an optional parameter to remove any stored credentials associated with this player.

Note: If Sign Out is used while using the default profile, then the profile information is cleared and the profile stays intact.

This function returns a Boolean representing whether the operation was a success.

Use Switch Profile to switch to, or create, a player profile.

Note: Switch Profile can only be called while signed-out. If a profile switch is invoked while authenticated, a warning is logged and nothing happens.

Use Profile Exists to check if a given profile exists in the current session.

Note: Profile Exists cannot detect profiles from previous sessions that have not been re-created in the current session.

This function returns a Boolean representing whether the given profile name exists in the current list of player profiles.

Use Get Current Profile Name to retrieve the name of the current player profile.

This function returns a String representing the name of the current player profile being used by the Authentication subsystem.

Use Get Current Profile Names to retrieve a list of all player profile names being used in the current session.

This function returns a String Array representing all the names of the player profiles being used by the Authentication subsystem.

Use Register Profile Changed Callback to assign a callback function that invokes when a player profile changes. For instance, the assigned function executes when Switch Profile has executed successfully.

The response from the SDK can be handled in a custom event, which needs to take in an Authentication Player Profile Changed Response as an output pin. To isolate response variables, right-click the response body output pin and select Split Pin.

Use the Register Profile Changed Callback function to assign a callback function that invokes when a player profile is removed from the current session. For instance, the assigned function executes when Sign Out has executed successfully.

The response from the SDK can be handled in a custom event, which needs to take in an [Authentication Player Profile] Authentication Player Profile Deleted Response as an output pin. To isolate response variables, right-click the response body output pin and select Split Pin.

Use Is Signed In to check whether the current player profile is signed-in. Being “Signed-In” is defined as being either Authorized or Expired.

This function returns a Boolean representing whether the current player profile is signed-in.

Use Is Anonymous to check whether the current player profile is signed-in anonymously. This should return true after executing Sign In Anonymously successfully.

This function returns a Boolean representing whether the current player profile is signed-in anonymously. If the last sign-in was anonymous, this returns true even if the session has expired.

Use Is Authorized to check whether the current player profile is signed-in and currently authorized.

This function returns a Boolean representing whether the current player profile is signed-in and has been authorized successfully. This should return true after executing any sign-in function while the expiration time has not yet passed.

Use Is Expired to check whether the current player profile’s session has expired.

This function returns a Boolean representing whether the current player profile’s session has gone past the returned expiry time from its initial Authentication Response.

Use Session Token Exists to check whether a session token exists in player preferences for the current player profile.

This function returns a Boolean representing whether the session token exists.

Use Get Unity Project Id to retrieve the Unity Project Id associated with the current authentication session.

This function returns a Guid representing the current Project Id in use.

Use Get Unity Environment Name to retrieve the name of the Unity Environment Name associated with the current authentication session.

This function returns a String representing the current Environment in use.

Use Get Access Token to retrieve the access token for the current session. If none exists, this returns an empty string.

Use Get Session Token to retrieve the session token for the current session. If none exists, this returns an empty string.

Use the Get User Id function to retrieve the user Id for the current session.

Note: This is different from the player profile name. The user Id is the unique user identifier returned from the Unity Authentication System.

This function returns a String representing the current player profile’s user Id. If none exists, this returns an empty string.

Use the Get State function to retrieve the current state of the authentication session.

This function returns an Enum representing the state of the subsystem.

Use Set Unity Project Id to set the Unity Project Id for the current authentication session. This function takes a Guid.

Note: This overrides the Unity Project Id configured in Project Settings.

Use Set Unity Environment Name to set the Unity Environment Name for the current authentication session. This function takes a String.

Note: This overrides the Unity Environment Name configured in Project Settings.

**Examples:**

Example 1 (unknown):
```unknown
Sign In Anonymously
```

Example 2 (unknown):
```unknown
Sign In Anonymously
```

Example 3 (unknown):
```unknown
FAuthenticationSignInOptions
```

Example 4 (unknown):
```unknown
Get User Info
```

---

## ATTRIBUTE DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/attribute-delete

**Contents:**
- ATTRIBUTE DELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Deletes one or more attributes.

cm attribute | att delete | rm <att_spec>[ ...]

This command removes one or more attributes.

cm attribute delete att:status

(Deletes the attribute 'status'.)

cm att rm status att:integrated@reptest@server2:8084

(Deletes the attributes 'status' and 'integrated'.)

**Examples:**

Example 1 (unknown):
```unknown
cm attribute | att delete | rm <att_spec>[ ...]
```

Example 2 (unknown):
```unknown
cm attribute delete att:status
```

Example 3 (unknown):
```unknown
cm att rm status att:integrated@reptest@server2:8084
```

---

## A2S Query protocol

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/a2s

**Contents:**
- A2S Query protocol#

A2S is a UDP-based game server query protocol that Valve Software keeps as a part of the Steam SDK. Many game engines support A2S natively, but if yours doesn’t, you can add support for A2S manually by using one of the A2S libraries for your preferred language (for example, go-a2s for Golang, QueryMaster for C#).

Visit the Valve Software wiki page for server queries to learn more about the technical details of the A2S protocol, including the protocol specification, response body format, and a list of implementations in various languages.

To integrate a manual A2S implementation with Multiplay Hosting, you must configure at least the following variables:

It’s important to make sure the values reported for Players and Max Players in A2S_INFO responses are correct. Multiplay Hosting uses these values to calculate and watch resource usages on the machine. If the values are inaccurate or in the wrong format, Multiplay Hosting won’t be able to manage resources, which can cause errors, game server crashes, or sub-optimal performance. The recommended best practice is to include correct map type data, which enables Multiplay Hosting to report crashes by map type.

Note: A2S is a legacy protocol. Unity’s SQP protocol is newer and integrates more easily into the Unity ecosystem.

**Examples:**

Example 1 (unknown):
```unknown
Max Players
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unreal-plugin

---

## BRANCH RENAME

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/branch-rename

**Contents:**
- BRANCH RENAME#
- Description#
  - Usage#
- Help#
  - Remarks#
  - Examples#

cm branch | br rename <brspec> <new_name>

This command renames a branch.

cm branch rename /main/task0 task1

(Renames branch '/main/task0' to '/main/task1'.)

cm br rename br:/main@reptest@server2:8084 secondary

(Renames the 'main' branch of repository 'reptest' to 'secondary'.)

**Examples:**

Example 1 (unknown):
```unknown
cm branch | br rename <brspec> <new_name>
```

Example 2 (unknown):
```unknown
cm branch rename /main/task0 task1
```

Example 3 (unknown):
```unknown
cm br rename br:/main@reptest@server2:8084 secondary
```

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/get-started

**Contents:**
- Get started#
- Prerequisites#
- Configure your hosting#
- Install the Matchmaker SDK#
- Set up Matchmaker#
- Create a queue and a pool#
- Create a matchmaking ticket#
- Poll ticket status#
- Matchmaking Results#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

This guide walks you through the different steps required to install the Matchmaker SDK, enable Matchmaker, create the first matchmaking ticket and create a Multiplay Hosting allocation.

To get started with Matchmaker, you need to do the following:

Before enabling Matchmaker, either initialize Multiplay Hosting or a client-hosted solution provided by Unity. Refer to Get Started with Multiplay Hosting, Get Started with Relay, and the Distributed Authority Quickstart.

To install the latest Matchmaker package for Unity:

Note: For most users, the unified Multiplayer Services package replaces the Matchmaker standalone package, which is deprecated in Unity 6. Consider migrating to the unified package to facilitate a smooth transition. Visit the migration guide for a step-by-step transition process.

You can set up and manage Matchmaker through the Unity Dashboard:

When you launch Matchmaker for the first time, this adds Matchmaker to the Shortcuts section on the sidebar and opens the Overview page.

Define the rules used to define the matches created when sending ticket to that queue and pool. Select JSON and copy/paste the following block of code:

This creates matches of one team with a minimum of one player and a maximum of five players.

Matchmaker is now configured. You can check the Queue and Pool that were created by clicking on Queues in the menu under the Matchmaker section.

Now that the matchmaker is configured we can create and send a ticket to request a Multiplay Hosting allocation:

> Note: Player Ids must be different to be matched together.

https://services.docs.unity.com/matchmaker/v2/index.html#tag/Tickets/operation/createTicket

Once the ticket is created, the client polls to get the status of the ticket using the ticket ID returned when creating the ticket.

When the ticket is assigned to a match and a server is allocated, Matchmaker adds the server information to the ticket status response.

https://services.docs.unity.com/matchmaker/v2/index.html#tag/Tickets/operation/getTicketStatus

On the server side, when the server is allocated it is possible to fetch the Matchmaking Results about the match made using the Payload Allocation.

Matchmaking results give the server information about the different players that are supposed to be in the match, their data as well as their distribution in the different teams.

This code only works on the server allocated by Multiplay Hosting.

Note: Use the server.json file to get a server’s allocation UUID.

You will need to install the Multiplay Hosting SDK to access the matchmaking results

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.multiplayer
```

Example 2 (unknown):
```unknown
com.unity.services.matchmaker
```

Example 3 (unknown):
```unknown
{
  "Name": "Test",
  "MatchDefinition": {
    "Teams": [
      {
        "Name": "Main team",
        "TeamCount": {
          "Min": 1,
          "Max": 1
        },
        "PlayerCount": {
          "Min": 1,
          "Max": 5
        }
      }
    ],
    "MatchRules": []
  },
  "BackfillEnabled": false
}
```

Example 4 (unknown):
```unknown
{
  "Name": "Test",
  "MatchDefinition": {
    "Teams": [
      {
        "Name": "Main team",
        "TeamCount": {
          "Min": 1,
          "Max": 1
        },
        "PlayerCount": {
          "Min": 1,
          "Max": 5
        }
      }
    ],
    "MatchRules": []
  },
  "BackfillEnabled": false
}
```

---

## Record transaction events

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/record-transaction-events

**Contents:**
- Record transaction events#
- Send events manually#
  - Record automatically using the IAP plug-in#
  - Report successful purchases#
  - Report failed purchases#
- Validate transactions#
  - Apple Store#
  - Google Play#

Use the transaction event to track successful in-app purchases via the revenue KPIs in the dashboard. This event contains arrays and some special Product objects to capture multiple items and currencies spent or bought in a single transaction.

You might be developing an RPG where the player can buy and receive heroes, gear and resources from multiple points such as the shop, popup offers, and a daily reward system. The transaction event has parameters to help register most of the information about your transactions.

Unsuccessful transactions are tracked under a dedicated transactionFailed event, containing details regarding the purchase transaction and the reason for its failure. This doesn't contribute to the revenue metrics in the dashboards.

You can send the transaction and transactionFailed events manually via the SDK or REST API. If you're using Unity IAP version 4.2 or higher, it automatically sends these events for you.

Important: Sending transactions manually to Analytics while also using the IAP plug-in counts them twice and reports inflated revenue.

Important: Transaction events received from Apple and Google sandbox purchases can be reviewed in the Analytics > SQL Data Explorer tool, but they don't contribute towards dashboard Revenue reports.

The Analytics SDK provides the TransactionEvent and TransactionFailedEvent classes to help you record these events successfully.

If you are using the REST API, you can refer to their schemas in the Event Manager.

Transactions made by the Unity IAP are automatically forwarded to Analytics using the same transaction event schema as when you send the events manually. The transaction event contributes to the revenue KPIs available in Analytics. Unsuccessful transactions are also automatically tracked by the IAP plug-in using the transactionFailed event. If you are using Unity IAP, you don't need to record transactions manually.

In the following example, the transaction event records the player spending $4.99 of real US dollars to purchase a treasure chest which contains virtual currency and multiple items.

Use the following code to create the transaction event:

The transactionFailed event captures unsuccessful in-app purchases. Purchases can fail for a number of reasons, including network failure, payment failure, or device settings.

In the following example the transactionFailed event records the player's attempt to spend $4.99 of real US dollars to purchase a treasure chest that contains virtual currency and multiple items, where the user cancels the purchase.

Use the following code to create the transactionFailed event:

Transaction validation checks to see if a transaction is a legitimate purchase.

The platform can undertake transaction receipt validation with iOS and Android stores in order to ensure that any revenue displayed in your dashboards is genuine revenue and not the result of a hacked or jailbroken game.

To use transaction validation you'll need to:

The transaction event contains a revenueValidated parameter, used by IAP receipt validation services, which is populated automatically if you're using revenue validation. The available values are:

Analytics automatically attempts receipt validation on iOS transactions. Add the following to iOS transactions to validate the receipt:

The transactionReceipt is the base-64 encoded receipt data returned from Apple. Refer to the Apple developer website for details on Apple Receipt Validation.

You must provide the Google public key. To update the Google key go to Project Settings > In-app purchase (IAP) settings and populate the Google License Key.

Add the following to the transaction event to Android transactions to validate the receipt:

Important: Since the transaction receipt and a private key generates the transactionReceiptSignature, in order to validate the receipt it must be the exact string provided by Google and passed as a string, not a nested JSON object.

**Examples:**

Example 1 (unknown):
```unknown
transaction
```

Example 2 (unknown):
```unknown
transaction
```

Example 3 (unknown):
```unknown
transactionFailed
```

Example 4 (unknown):
```unknown
transaction
```

---

## Google Play data safety for Vivox

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/privacy/google-data-safety

**Contents:**
- Google Play data safety for Vivox#
- Data collection survey#
  - Data types#

Starting April 2022, Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Vivox. For your convenience, Vivox provides information on its data collection practices below.

Important: The data disclosures below are for the Vivox SDK only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

*Voice data is not encrypted, but the signaling is. Voice data is encoded (not encrypted), and gets decoded by the SDK/client side. The purpose of this is for app functionality and analytics.

---

## Manage profiles

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/profile-management

**Contents:**
- Manage profiles#
  - Switch profiles#
  - Current profile#
  - Default profile#
  - Set the profile at initialization#

Players can use profiles to sign in to multiple accounts on a single device. Profiles add a level of isolation to the values saved to the PlayerPrefs. Profiles are not automatically persisted; it’s up to developers to determine how to manage them.

Players must be signed out to switch the current profile. Use AuthenticationService.Instance.SwitchProfile(profileName). The profile name only supports alphanumeric values, `-`, `_` and has a maximum length of 30 characters.

If a player is not signed out, SwitchProfile throws an AuthenticationException with the error code AuthenticationErrorCodes.ClientInvalidUserState.

If an invalid name is used, SwitchProfile throws an AuthenticationException with the error code AuthenticationErrorCodes.ClientInvalidProfile

To view the current profile, use AuthenticationService.Instance.Profile.

If no profile is provided in the initialization options, the value default is used.

Optionally, you can set the profile when initializing UnityServices. The AuthenticationService uses the value default if no profile is provided.

**Examples:**

Example 1 (unknown):
```unknown
PlayerPrefs
```

Example 2 (unknown):
```unknown
AuthenticationService.Instance.SwitchProfile(profileName)
```

Example 3 (unknown):
```unknown
SwitchProfile
```

Example 4 (unknown):
```unknown
AuthenticationException
```

---

## Launch parameters

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/launch-parameters

**Contents:**
- Launch parameters#
- Server variables#
- Default launch parameters#
  - Unity#
  - Unreal#

Launch parameters are variables passed to a game server at the time of start-up. These variables load before any other configuration variables and are separate from configuration variables and the server.json file. Launch parameters are best suited for loading information that the server needs access to immediately after starting.

You might want to use a launch parameter instead of a configuration variable in the following scenarios:

However, it makes more sense to use configuration variables instead of launch parameters in most cases.

You must encase each launch parameter variable in dollar symbols ($$), two on each side. For example, a launch parameter named port converts to $$port$$. The following code snippet has example launch parameters.

Like build configuration variables, you can use the following server-specific variables in your launch parameters. The following table has example server variables, each with a type, description, and example value.

The following sections display the default launch parameters for games made with Unity and games made with Unreal.

Note: Build configuration variables are encased in double dollar symbols ($$).

The default launch parameters for games made with Unity include -nographics, -batchmode, and -logFile.

Tip: The recommended best practice is to use sessions to integrate Multiplay Hosting into your Unity game. Refer to Unity Editor command line arguments to learn more about the different flags you can use.

Depending on the game, the launch parameters might also include the query port (queryPort) and query protocol (queryType).

The default launch parameters for games made with Unreal include -log, and -port.

Tip: Refer to Unreal Engine command line arguments to learn more about the different flags you can use.

Depending on the game and SDK you’re using, the launch parameters might include the query port (queryPort) and query protocol (queryType).

**Examples:**

Example 1 (unknown):
```unknown
server.json
```

Example 2 (unknown):
```unknown
-port $$port$$ -queryport $$query_port$$ -log $$log_dir$$
```

Example 3 (unknown):
```unknown
-port $$port$$ -queryport $$query_port$$ -log $$log_dir$$
```

Example 4 (unknown):
```unknown
$$commandline$$
```

---

## Unity Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/overview

**Contents:**
- Unity Authentication#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users in the unlikely event that Unity takes an action which impacts those end users under the DSA. To comply with this end user notification requirement, we developed a new notification API. If you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you need to integrate the new notification API by the effective date of the DSA, February 17, 2024. The following API is ready for adoption in late January 2024. Please refer to our DSA compliance efforts. Refer to DSA notifications to make your game compliant.

Apps typically need to know player identities to provide features and services to game developers and players that ensure security, consistency, and safety with every interaction.

Unity Authentication offers robust cross-platform account and authentication solutions that support cross-play and progression across all major devices and platforms. You can authenticate your players with anonymous, platform-specific, or custom sign-in solutions, making it easy for games with custom identity solutions to unlock the full power of UGS.

---

## Server files

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-files

**Contents:**
- Server files#

Game developers configure their server applications to output many different forms of information to files, ranging from performance data captured by a profiler to reports or logs generated when an error or crash occurs. Multiplay Hosting surfaces these files (including logs) from your build executable through the Unity Dashboard.

Note: Before Multiplay Hosting can surface your files through the Unity Dashboard, you must specify the location of your files by setting the $$file_dir$$ variable in your build configuration launch parameters.

There are two methods to access these files:

To access server files through the Debugging interface:

To access server files through the Servers interface:

From there, you can use filters to sort through the results.

If your log files aren't displayed in the Unity Dashboard, refer to Troubleshooting logs.

**Examples:**

Example 1 (unknown):
```unknown
$$file_dir$$
```

---

## Checkin samples

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/tutorials/checkin-sample

**Contents:**
- Checkin samples#
- Apply a code beautifier to .java files#
  - Sample trigger creation command (on Windows):#
- Apply a modifying action to items in block#
  - Sample trigger creation command (on Windows):#
- Ensure that there are check in comments#
  - Sample trigger creation command:#

There are multiple ways that you can use triggers that apply before a contributor checks in any changes. Refer to the following sections for examples:

This sample is a Ruby script that processes all java files through a code beautifier. This example uses Ruby, but you can use any tool.

Note: This example runs cm cat individually for each affected file, runs jindent on it, creates a shelf for the changed file, and then deletes it from the disk. To improve performance, refer to Apply a modifying action to items in block.

To create the trigger that applies the code beautifier before checkin, you can use the following command:

cm trigger create before-checkin "apply jindent" "ruby c:\triggers\jindent.rb"

This is the same example as above, except that this example runs cm cat and shelves the files in block, which greatly improves performance.

cm trigger create before-checkin "apply block jindent" "ruby c:\triggers\jindent.rb"

You can use a trigger to ensure that any contributor who checks in changes provides comments.

The following sample ruby script checks the PLASTIC_COMMENT environment variable:

If the PLASTIC_COMMENT environment variable is empty and there is no comment, this script exits with a status code of 1 and the command fails. As a before-checkin trigger, UVCS throws an exception that aborts the check in operation and notifies the user.

cm trigger create before-checkin "comment required" "ruby c:\triggers\check-comments.rb"

**Examples:**

Example 1 (unknown):
```unknown
#!/usr/bin/env ruby

# temp file that will be used for jindent
tmpfile = "c:\\tmp\\triggers\\trigger-validate.java"

# Process each line of stdin
STDIN.readlines.each_with_index do |line, index|

  # split into item, revspec and wkspec
  splitted = line.split(';')

  # pick item name from item spec
  filename = splitted[0].split('#')[0]

  # if it is a .java file, apply jindent
  if (filename =~ /\.java$/) then

    # revspec is after the first ;
    revspec = splitted[1];

    # extract revision content from repository to temp file
    res = system("cm cat #{revspec} --file=\"#{tmpfile}\"")

    # execute jindent on temp file (jindent should be on path)
    if (res) then res = system("jindent \"#{tmpfile}\"") end

    # if jindent failed, signal the trigger failed too
    if (!res || $? != 0) then exit(1) end

    # store the re-formatted file on Plastic repository
    if (res) then system("cm shelveset #{revspec} --file=\"#{tmpfile}\"") end

    # delete the temp file
    if (res) then system("del \"#{tmpfile}\"") end

  end  #if

end  #each
```

Example 2 (unknown):
```unknown
#!/usr/bin/env ruby

# temp file that will be used for jindent
tmpfile = "c:\\tmp\\triggers\\trigger-validate.java"

# Process each line of stdin
STDIN.readlines.each_with_index do |line, index|

  # split into item, revspec and wkspec
  splitted = line.split(';')

  # pick item name from item spec
  filename = splitted[0].split('#')[0]

  # if it is a .java file, apply jindent
  if (filename =~ /\.java$/) then

    # revspec is after the first ;
    revspec = splitted[1];

    # extract revision content from repository to temp file
    res = system("cm cat #{revspec} --file=\"#{tmpfile}\"")

    # execute jindent on temp file (jindent should be on path)
    if (res) then res = system("jindent \"#{tmpfile}\"") end

    # if jindent failed, signal the trigger failed too
    if (!res || $? != 0) then exit(1) end

    # store the re-formatted file on Plastic repository
    if (res) then system("cm shelveset #{revspec} --file=\"#{tmpfile}\"") end

    # delete the temp file
    if (res) then system("del \"#{tmpfile}\"") end

  end  #if

end  #each
```

Example 3 (unknown):
```unknown
cm trigger create before-checkin "apply jindent" "ruby c:\triggers\jindent.rb"
```

Example 4 (python):
```python
#!/usr/bin/ruby
tmpdir = 'c:\\tmp\\triggers\\'

$files = []
$cat_shelve_specs = []

# Apply command sending revision info
def commandOnSpecs(cmd)
  IO.popen(cmd, "w") do |io|
    $cat_shelve_specs.each do |spec|
      puts 'catting ' + spec
      io.puts spec
    end
  end
end

# Process stdin
STDIN.readlines.each do |line|
  itemspec, revspec, wkspec = line.split(';')
  filename, branchspec, revno = itemspec.split('#')

  # this may have problems with long paths
  filename.gsub!(/\//, '_') # replace / with _ in filenames
  filename = tmpdir + filename  # add tmpdir

  $files << filename
  $cat_shelve_specs << "#{revspec};#{filename}"
end

# cat files on temp directory
commandOnSpecs("cm cat -")

# Apply action on files
$files.each { |file| system("jindent \"#{file}\"") }

# shelve files
commandOnSpecs("cm shelveset -")

# remove temp files
$files.each { |file| File.delete file }
```

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/get-started

**Contents:**
- Get started#
- Sign up#
- Link your project#
- Install the SDK#
- Initialize the Unity Services SDK#
  - Register authentication events#

To use Authentication, you need to:

If you don't have a Unity account, create one and create a new project to sign up for Unity Gaming Services.

Important: Only Organization Owners can sign up for Authentication.

Link your project to a Unity Cloud project in the Unity Editor through a project ID. Follow these steps to get your project ID.

Now you can find your project ID from the Settings tab in the Services window.

To install the latest Authentication package for Unity:

Refer to the Package Manager documentation for more information.

To implement Unity Authentication in your game, initialize all the Unity Services SDKs included in the project following this code snippet:

To receive updates about the status of your player, register a function to the SignedIn, SignInFailed and SignedOut event handlers.

**Examples:**

Example 1 (unknown):
```unknown
using System;
using Unity.Services.Core;
using UnityEngine;

public class InitializationExample : MonoBehaviour
{
	async void Awake()
	{
		try
		{
			await UnityServices.InitializeAsync();
		}
		catch (Exception e)
		{
			Debug.LogException(e);
		}
	}
}
```

Example 2 (unknown):
```unknown
using System;
using Unity.Services.Core;
using UnityEngine;

public class InitializationExample : MonoBehaviour
{
	async void Awake()
	{
		try
		{
			await UnityServices.InitializeAsync();
		}
		catch (Exception e)
		{
			Debug.LogException(e);
		}
	}
}
```

Example 3 (unknown):
```unknown
SignInFailed
```

Example 4 (javascript):
```javascript
// Setup authentication event handlers if desired
void SetupEvents() {
  AuthenticationService.Instance.SignedIn += () => {
    // Shows how to get a playerID
    Debug.Log($"PlayerID: {AuthenticationService.Instance.PlayerId}");

    // Shows how to get an access token
    Debug.Log($"Access Token: {AuthenticationService.Instance.AccessToken}");

  };

  AuthenticationService.Instance.SignInFailed += (err) => {
    Debug.LogError(err);
  };

  AuthenticationService.Instance.SignedOut += () => {
    Debug.Log("Player signed out.");
  };

  AuthenticationService.Instance.Expired += () =>
    {
        Debug.Log("Player session could not be refreshed and expired.");
    };
}
```

---

## Unity Player Accounts

**URL:** https://docs.unity.com/authentication/en-us/manual/unity-player-accounts

**Contents:**
- Unity Player Accounts#
- Overview#
- Get started#
  - Set up the Unity Player Accounts ID provider#
  - Before you publish your game#
  - Unity Player Accounts sample#
- Sign in a returning player or create new player#
- Link a returning player to Unity Player Accounts#
- Unlink Unity Player Accounts#
- Sign out from Unity Player Accounts#

Unity Player Accounts is Unity's comprehensive sign-in solution that supports persistence across games, devices and platforms. It's an end-to-end account system that includes a user flow UX, email and password, social sign-in options, and data access and deletion flows.

Unity Player Accounts is an external identity provider which is natively integrated with Unity Gaming Services and the Authentication SDK. It has multiple benefits such as SSO, organization-level player pool, and cross-game, cross-device or cross-platform gameplay.

To get started you must first install the Authentication package, and then configure a Unity Player Accounts ID provider in the Unity Dashboard.

The C# methods required for interacting with Unity Player Accounts are included within the Authentication package in the dedicated PlayerAccountService namespace.

You can set up Unity Player Accounts directly in the Unity Dashboard.

Note: For the sign-in flow to work in the Unity Editor Play mode, include the PC platform.

Note: The authentication flow works without the need for configuring the redirect URI, as long as the registered URIs follow the prescribed format:

Review Unity's compliance and branding guidelines:

The Authentication package includes a sample scene which is fully integrated with Unity Player Accounts. Use this sample to try out the flow after completing the configuration steps above.

To import the sample, follow these steps:

Open the sample scene under Assets > Samples > Authentication > [Package-Version] > UI Example > UnityPlayerAccountsUIExample.

Use the PlayerAccountService.Instance.StartSignInAsync method to start the player sign-in flow for Unity Player Accounts. This opens the system browser to https://player-login.unity.com, prompts the player to sign in, and then returns them to the application with their Unity Player Accounts credentials.

When they have signed in to Unity Player Accounts and returned to your application with their credentials, use the AuthenticationService.Instance.SignInWithUnityAsync method to either:

The PlayerAccountService.Instance.SignedIn event will let us know when the browser-based Unity Player Accounts sign in has succeeded and we can proceed with signing in to Unity Authentication.

The credentials required to sign in to Unity Authentication are the access token available on PlayerAccountService.Instance.AccessToken.

If you have an existing player who is signed in already, either anonymous or using a different external ID provider, you can allow them to link with Unity Player Accounts. Your game should prompt the player to trigger the Unity Player Accounts sign-in flow. Then, call the LinkWithUnityAsync API to link the player using the Unity Player Accounts access token.

For linking to be successful, the player must be signed in to Unity Authentication. For more information on Unity Authentication session lifecycle, refer to Unity Authentication sessions.

Use the AuthenticationService.Instance.UnlinkUnityAsync API so your players can unlink their Unity Player account. Once unlinked, if their account isn't linked to any additional identity, it transitions to an anonymous account.

The PlayerAccountService.Instance tracks if the player has signed in to their Unity Player Account. This is separate from tracking if the player is signed in to Unity Authentication, as done by AuthenticationService.Instance. This gives individual control over signing out from Unity Authentication and Unity Player Accounts.

Use PlayerAccountService.Instance.SignOut to sign the player out of Unity Player Accounts on the device.

Because the PlayerAccountService.Instance doesn't persist a session token on the device, there is no option to clear the session token.

**Examples:**

Example 1 (unknown):
```unknown
PlayerAccountService
```

Example 2 (unknown):
```unknown
http://localhost/callback
```

Example 3 (unknown):
```unknown
unitydl://com.unityplayeraccounts.{unity-project-id}
```

Example 4 (unknown):
```unknown
https://player-account.unity.com/delete-account
```

---

## Event Manager

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/event-manager

**Contents:**
- Event Manager#

Use the Event Manager feature in Analytics to explore standard events, enable and disable events, and create and edit custom events and parameters. All the events that are available for you to record are shown in the Events table. For active Events, Event Manager displays the total number of valid and invalid events received in the past 24 hours.

For more information about events and what they're suited for, refer to Events.

Note: Standard events cannot be edited.

For information about how to create custom events, refer to Create a custom event. Once you have the data required for each of your events, refer to Record an event to start sending them from your game.

Use the environment switcher to see your event and parameter definitions in other environments.

You can also copy events to other environments from this page. Refer to the tutorial on copying custom events to another environment.

---

## PURGE HISTORY

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/purge-history

**Contents:**
- PURGE HISTORY#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Allows the user to check the state of all the purges registed in the server at some point.

Also, it is useful to get information about them that are preserved for query purposes, such as the author, the date of execution or the storage size and the types affected by the purge.

cm purge history [--verbose | --server=<server>] [--sort=(desc|asc)] [--skip=<skip> | --limit=<limit>]

(Shows the ID and status for all purges ever registered in the server).

cm purge history --server=stoltz@cloud

(You can override the server to use different one if needed).

cm purge history --verbose

(Includes more detailed data associated to the shown purges).

cm purge history --sort=asc

(Shows the history starting from the oldest purges).

cm purge history --skip=0 --limit=20 cm purge history --skip=20 --limit=20 cm purge history --skip=40 --limit=20 (Instead of showing everything at once, you can paginate results).

**Examples:**

Example 1 (unknown):
```unknown
cm purge history [--verbose | --server=<server>] [--sort=(desc|asc)] [--skip=<skip> | --limit=<limit>]
```

Example 2 (unknown):
```unknown
cm purge history
```

Example 3 (unknown):
```unknown
cm purge history --server=stoltz@cloud
```

Example 4 (unknown):
```unknown
cm purge history --verbose
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/matchmaking-rules-rules

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/session-management

---

## Navigate code reviews

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/navigate-code-reviews

**Contents:**
- Navigate code reviews#
- View files#
  - Filter files#
  - Enter focus mode#
  - Change comparison method#
- View comments#

In the Changed Files tab, you can view either a list of files or a list of comments. To switch between the two lists, select either the Files or Comments button above the file window.

There are multiple ways to navigate the files in the Changed Files tab:

You can move through files using the arrow buttons next to the Files button in the toolbar.

On the top navigation bar of the Unity Dashboard, select the expand Enter focus mode icon. This collapses both left-hand navigation bars for a more focused view. To exit focus mode, select the expand icon again.

You can change the way diffs are displayed to suit your reviewing needs.

To change how you view diffs, select the gear icon. The following are the diff display options:

You can view all comments on the code review in the Conversation tab.

You can also view change requests and questions from the Changed Files tab in order to see them in context:

---

## Supported UGS events

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/concepts/supported-ugs-events

**Contents:**
- Supported UGS events#
- Authentication#
  - Signed up#
  - Signed in#
- Leaderboards#
  - Reset#
  - Score submitted#
- Cloud Save#
  - Key saved#
- Moderation#

Unity Gaming Services emit events that can provide you with information about player activity and game state. Use these events to trigger Cloud Code scripts or modules by creating a trigger configuration with the corresponding event type.

Refer to Trigger structure to check how an event is matched to the trigger configuration.

Note: This page covers events emitted from UGS. The Scheduler service also emits events you can use to trigger Cloud Code scripts or modules. Refer to Schedule events for guidelines on how to create schedule configurations.

Refer to the table below for a list of events emitted by Unity Gaming Services:

The Authentication service provides events that can help you drive engagement for new players, provide sign-in bonuses, and reward returning players.

If you are authenticating players from Unity Runtime, the events are fired before the player authentication flow is completed.

The signed up event is emitted when a player is created in the Authentication service. A created player is also signed in, emitting a Signed in event.

Event type: com.unity.services.player-auth.signed-up.v1

Refer to the table below for the event payload:

Obtain the full player information by calling the Get Player endpoint with the playerId in the event.

Refer to Use case sample: Initialize newly signed-up players with default configuration values for an example of how to use this event.

The signed in event is emitted when a player signs into the Authentication service, or refreshes their token.

Event type: com.unity.services.player-auth.signed-in.v1

Refer to the table below for the event payload:

Obtain the full player information by calling the Get Player endpoint with the playerId in the event.

The Leaderboard service provides events that can help you drive engagement.

The reset event is emitted when a leaderboard is reset.

Event type: com.unity.services.leaderboards.reset.v1

Refer to the table below for the event payload:

You could use this event to reward top players on a leaderboard, or promote and demote players to different tiers.

Refer to Use case sample: Reward top players with in-game currency at the end of season for an example of how to use this event.

The Leaderboards service emits the score submitted event when a player submits a score to a leaderboard.

Event type: com.unity.services.leaderboards.score-submitted.v1

Refer to the table below for the event payload:

You can use this event to drive engagement. For example, you can notify players when they are outperformed on a leaderboard, or reward players for reaching a certain rank.

Refer to Use case sample: Send a push message to the player whose score was beaten) for an example of how to use this event.

The Cloud Save service provides an event that can help you drive engagement by notifying players when their item is updated.

The key saved event is emitted when an item of a player or an entity in Cloud Save is saved.

Event type: com.unity.services.cloud-save.key-saved.v1

Refer to the table below for the event payload:

You could use this event to drive engagement by notifying players when their item updates.

The Moderation service provides events that can help you manage player behavior. You can define custom actions in Cloud Code to execute when a player action is moderated through the Moderation service. For example, you can define a custom action in Cloud Code to ban a player from a specific game mode when the event is emitted.

Note: Moderation type Cloud Code scripts enable a workflow to manage custom actions and provide you with a template to get started. By default, you can't run these scripts from a game client. For more information, refer to Script types.

The player action event is emitted when a player action is moderated.

Event type: com.unity.services.moderation.player-action-event.v1.

Refer to the table below for the event payload:

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.player-auth.signed-up.v1
```

Example 2 (unknown):
```unknown
com.unity.services.player-auth.signed-in.v1
```

Example 3 (unknown):
```unknown
lastLoginAt
```

Example 4 (unknown):
```unknown
previousLoginAt
```

---

## Standard audiences

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/standard-audiences

**Contents:**
- Standard audiences#

This is the list of standard audiences that are included in every project. Standard audiences cannot be edited, but you can create custom audiences to suit your own needs. See the custom audiences tutorial.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/player-name-management

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/add-real-money-purchase

---

## Smart Locks

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/smart-locks

**Contents:**
- Smart Locks#
- Smart Lock behavior#
- Lock rules#
- Retained locks#
- Destination branch#
- Smart Locks workflow#
  - Create the Lock#
  - Remove the lock#
- Technical considerations#

You can use Smart Locks, also known as exclusive check outs, in Unity Version Control (UVCS) to help you collaborate on projects. When you check out a file, you can lock it to prevent anyone else from modifying the file to avoid conflicts. For example, you can lock non-mergeable assets, such as 3D models, images, or audio files.

For more information, refer to Use Smart Locks.

When you check out a file you have two options: Checkout or Lock and checkout. If a file has existing lock rules, then the normal check out locks the file according to those rules regardless. If there are no existing lock rules and you select Lock and checkout, then UVCS prompts you to create a new lock rule for that context.

A locked file displays a lock icon to indicate that it’s locked. If you try to check out a locked file, a dialog informs you that the file is locked. You can't check out, check in, or merge any files that are locked by another user; whoever has the file locked is the only person who can update it. This prevents multiple users from changing the same file in parallel and ensures that only the latest revision is modified.

To avoid any loss of work, Smart Locks keep track of your repository to ensure that only the latest revision of a file can be locked. This lets you know if the latest revision of a file is on another branch and prevents you from checking out an outdated revision.

The following types of lock rule are available:

For more information, refer to Create lock rules.

When you check in a locked file on a branch that isn't the destination branch, the file status is set to Retained. To unlock the file, you need to merge the change to the destination branch.

If you try to check out a file with a retained lock, Unity Version Control informs you that there is a newer version of the file on another branch. Since retained locks are not held by the specific user who created the lock, any user can check out the latest revision of a file with a retained status.​ To remove the retained status, you can either check out the file from that branch and merge it to the destination branch, or you can contact the lock owner or an admin to remove the lock.

The destination branch is the source of truth when creating a new lock. The default destination branch is /main. If no current revision has the retained status, the revision loaded in the destination branch is considered the latest revision.

You can also set multiple destination branches so that you can lock the same files on different branches at the same time. For example, if the different or unrelated branches need to diverge or specialize:

First, you check out the file and create a lock from the latest revision of a file. The latest revision is either the version in the destination branch or a version with a retained status.

If you don’t make the lock from the latest revision of the file, the checkout operation fails and UVCS displays a message to inform you.

When you complete your changes, either check in the file or merge the changes to the destination branch to release the lock.

If the file was exclusively checked out in a different branch, when you check in the file the lock transitions from Locked to Retained status. You must then merge to the destination branch to remove the lock. While in the Retained status, any user can check out the file and make new changes, as this is now considered the latest revision.

Alternatively, lock owners or admins can manually release or remove the lock.

---

## Unity SDK sample

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/unity-sdk-sample

**Contents:**
- Unity SDK sample#

This sample (with additional methods) is found as part of the Leaderboards SDK package by checking the box to include Samples when installing from the package manager.

The following example presumes the existence of a leaderboard with the ID my-first-leaderboard. You can create this from the Unity Dashboard.

The sample then initializes the Unity services and uses anonymous authentication to sign-in the player in the Awake lifecycle callback (see SDK Installation & Setup) and then uses the SDK to provide methods for interacting with the leaderboard data and printing it to the console.

**Examples:**

Example 1 (unknown):
```unknown
my-first-leaderboard
```

Example 2 (javascript):
```javascript
using System.Collections.Generic;
using System.Threading.Tasks;
using Newtonsoft.Json;
using Unity.Services.Authentication;
using Unity.Services.Core;
using Unity.Services.Leaderboards;
using UnityEngine;

public class LeaderboardsSample : MonoBehaviour
{
    // Create a leaderboard with this ID in the Unity Dashboard
    const string LeaderboardId = "my-first-leaderboard";

    string VersionId { get; set; }
    int Offset { get; set; }
    int Limit { get; set; }
    int RangeLimit { get; set; }
    List<string> FriendIds { get; set; }

    async void Awake()
    {
        await UnityServices.InitializeAsync();

        await SignInAnonymously();
    }

    async Task SignInAnonymously()
    {
        AuthenticationService.Instance.SignedIn += () =>
        {
            Debug.Log("Signed in as: " + AuthenticationService.Instance.PlayerId);
        };
        AuthenticationService.Instance.SignInFailed += s =>
        {
            // Take some action here...
            Debug.Log(s);
        };

        await AuthenticationService.Instance.SignInAnonymouslyAsync();
    }

    public async void AddScore()
    {
        var scoreResponse = await LeaderboardsService.Instance.AddPlayerScoreAsync(LeaderboardId, 102);
        Debug.Log(JsonConvert.SerializeObject(scoreResponse));
    }

    public async void GetScores()
    {
        var scoresResponse =
            await LeaderboardsService.Instance.GetScoresAsync(LeaderboardId);
        Debug.Log(JsonConvert.SerializeObject(scoresResponse));
    }

    public async void GetPaginatedScores()
    {
        Offset = 10;
        Limit = 10;
        var scoresResponse =
            await LeaderboardsService.Instance.GetScoresAsync(LeaderboardId, new GetScoresOptions{Offset = Offset, Limit = Limit});
        Debug.Log(JsonConvert.SerializeObject(scoresResponse));
    }

    public async void GetPlayerScore()
    {
        var scoreResponse =
            await LeaderboardsService.Instance.GetPlayerScoreAsync(LeaderboardId);
        Debug.Log(JsonConvert.SerializeObject(scoreResponse));
    }

    public async void GetVersionScores()
    {
        var versionScoresResponse =
            await LeaderboardsService.Instance.GetVersionScoresAsync(LeaderboardId, VersionId);
    Debug.Log(JsonConvert.SerializeObject(versionScoresResponse));
    }
}
```

Example 3 (javascript):
```javascript
using System.Collections.Generic;
using System.Threading.Tasks;
using Newtonsoft.Json;
using Unity.Services.Authentication;
using Unity.Services.Core;
using Unity.Services.Leaderboards;
using UnityEngine;

public class LeaderboardsSample : MonoBehaviour
{
    // Create a leaderboard with this ID in the Unity Dashboard
    const string LeaderboardId = "my-first-leaderboard";

    string VersionId { get; set; }
    int Offset { get; set; }
    int Limit { get; set; }
    int RangeLimit { get; set; }
    List<string> FriendIds { get; set; }

    async void Awake()
    {
        await UnityServices.InitializeAsync();

        await SignInAnonymously();
    }

    async Task SignInAnonymously()
    {
        AuthenticationService.Instance.SignedIn += () =>
        {
            Debug.Log("Signed in as: " + AuthenticationService.Instance.PlayerId);
        };
        AuthenticationService.Instance.SignInFailed += s =>
        {
            // Take some action here...
            Debug.Log(s);
        };

        await AuthenticationService.Instance.SignInAnonymouslyAsync();
    }

    public async void AddScore()
    {
        var scoreResponse = await LeaderboardsService.Instance.AddPlayerScoreAsync(LeaderboardId, 102);
        Debug.Log(JsonConvert.SerializeObject(scoreResponse));
    }

    public async void GetScores()
    {
        var scoresResponse =
            await LeaderboardsService.Instance.GetScoresAsync(LeaderboardId);
        Debug.Log(JsonConvert.SerializeObject(scoresResponse));
    }

    public async void GetPaginatedScores()
    {
        Offset = 10;
        Limit = 10;
        var scoresResponse =
            await LeaderboardsService.Instance.GetScoresAsync(LeaderboardId, new GetScoresOptions{Offset = Offset, Limit = Limit});
        Debug.Log(JsonConvert.SerializeObject(scoresResponse));
    }

    public async void GetPlayerScore()
    {
        var scoreResponse =
            await LeaderboardsService.Instance.GetPlayerScoreAsync(LeaderboardId);
        Debug.Log(JsonConvert.SerializeObject(scoreResponse));
    }

    public async void GetVersionScores()
    {
        var versionScoresResponse =
            await LeaderboardsService.Instance.GetVersionScoresAsync(LeaderboardId, VersionId);
    Debug.Log(JsonConvert.SerializeObject(versionScoresResponse));
    }
}
```

---

## Player evidence report HTTP response

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/text-evidence/player-evidence-report-response

**Contents:**
- Player evidence report HTTP response#

The following code is an example of a player evidence response:

The next field is used for pagination and represents the player’s most recent activity in the next conversation returned. This value will be null if there are no more pages of results to return. Use the next value as the end_ts in a subsequent request to retrieve the next page of results. The request_start_ts is also used for pagination and represents the timestamp of the initial request. This value maintains consistency in paging results if the player is active during review. The request_start_ts is required when using the next value to request subsequent pages of results.

The conversation objects in the response contain the following fields:

Returned conversation results are in order of the player’s most recent activity.

**Examples:**

Example 1 (unknown):
```unknown
{
   "request_start_ts": 1706203970429807,
   "next": 1704400836045162,
   "conversations": [
       {
           "message_count": 2,
           "last_activity": 1704400939799491,
           "conversation_uri": "sip:confctl-g-your-issuer.test-channel-1@youvivoxdomainname.vivox.com"
       },
       {
           "message_count": 1,
           "last_activity": 1704400878101904,
           "conversation_uri": "sip:your-issuer.doe@yourvivoxdomainname.vivox.com"
       }
   ]
}
```

Example 2 (unknown):
```unknown
{
   "request_start_ts": 1706203970429807,
   "next": 1704400836045162,
   "conversations": [
       {
           "message_count": 2,
           "last_activity": 1704400939799491,
           "conversation_uri": "sip:confctl-g-your-issuer.test-channel-1@youvivoxdomainname.vivox.com"
       },
       {
           "message_count": 1,
           "last_activity": 1704400878101904,
           "conversation_uri": "sip:your-issuer.doe@yourvivoxdomainname.vivox.com"
       }
   ]
}
```

Example 3 (unknown):
```unknown
request_start_ts
```

Example 4 (unknown):
```unknown
request_start_ts
```

---

## GETWORKSPACEFROMPATH

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/getworkspacefrompath

**Contents:**
- GETWORKSPACEFROMPATH#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - The output parameters of this command are the following#
  - Examples#

Gets workspace info from a path.

cm getworkspacefrompath | gwp <item_path> [--format=<str_format>] [--extended]

This command shows information about the workspace that is located in path.

Output format parameters (--format option): This command accepts a format string to show the output.

cm getworkspacefrompath c:\myworkspace\code\file1.cpp --format="Workspace name: {wkname}"

cm gwp . --format="Name: {wkname} | Type: {type}, {dynamic}"

**Examples:**

Example 1 (unknown):
```unknown
cm getworkspacefrompath | gwp <item_path> [--format=<str_format>] [--extended]
```

Example 2 (unknown):
```unknown
cm getworkspacefrompath c:\myworkspace\code\file1.cpp --format="Workspace name: {wkname}"
```

Example 3 (unknown):
```unknown
cm gwp . --format="Name: {wkname} | Type: {type}, {dynamic}"
```

---

## Manage lobbies

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/manage-lobbies

**Contents:**
- Manage lobbies#
- Public lobby#
- Private lobby#
- Password-protected lobby#

Explore the following links to learn how to manage lobbies:

Lobby provides two main flows using public lobbies and private lobbies for players to create and find game sessions. The following are each of their features:

Note: You can use both types of lobbies within a single game title.

A public lobby lets your players create, browse, and join public lobbies that fit their search parameters.

A private lobby lets your players invite other players by sending them a lobby code.

A password-protected lobby can be private or public but always requires a password to join.

---

## Privacy and consent for Lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/privacy-and-consent

**Contents:**
- Privacy and consent for Lobby#
- Privacy overview#
- Apple privacy manifest#
- Google Play data safety#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## Manage data privacy with the SDK

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/manage-data-privacy

**Contents:**
- Manage data privacy with the SDK#
- Unity 6.2 and later with Analytics SDK 6.1 and later#
  - Start data collection#
  - Data deletion#
- Unity 6.1 and earlier, or Analytics SDK 6.0 and earlier#
  - Start data collection#
  - Data deletion#
- Privacy URL#

Important: Unity Analytics requires you to implement a privacy solution separate from Unity Ads. If you're using both Unity Ads and Analytics, the Unity Ads opt-out mechanism does NOT apply to both services.

Analytics collects data to help you improve the player experience in your game. Some of that data includes personal data regulated under data privacy laws.

Some regions might require consent to collect personal data by law, while others might require end-user notice and the opportunity to opt-out. However, consent and opt-out requirements extend beyond these use cases and must be applied in any region that requires it. By using these functions, you take responsibility for providing this consent correctly and for all regions.

When a user does not consent to, or opts out of personal data collection and processing under a data privacy regulation (for example GDPR, CCPA, or PIPL), this prevents personal data from being collected about your users and may impact your analytics and key metrics.

For a full breakdown of your responsibilities, refer to the Privacy overview.

In Unity 6.2 and later, the Developer Data framework's EndUserConsent API controls the Analytics SDK. To start or stop data collection, use this API to set the AnalyticsIntent consent to Granted or Revoked.

For specific information about granting consent with the EndUserConsent API, refer to Developer Data framework.

Call AnalyticsService.Instance.RequestDataDeletion() to request personal data deletion, which triggers a purge of user data from the server. In order to make a data deletion request, you must first deny consent using the EndUserConsent API.

If there is no internet connection when this request is made, the SDK reattempts the request at regular intervals until it is successful. It will remember this across application restarts using Unity's PlayerPrefs system, so be aware that using PlayerPrefs.DeleteAll() may disrupt this process.

Important: This functionality only applies to Analytics and the Push Notification service. If you are using other services which collect application user personal data you will need to review those services' documentation for how they handle data deletion requests. To delete the player ID created by the Unity Authentication SDK (if enabled), use the Authentication API.

Important: The Analytics SDK does not manage data privacy compliance in any way. You, the developer, are responsible for determining what data privacy legislation applies to the player and what consent is required before activating the SDK.

As of version 5.0.0, the Analytics SDK does not collect any personal data by default. The SDK initializes in a dormant state, in which it ignores all events. You are responsible for determining what data privacy legislation affects the player and when it is appropriate for you to enable data collection by the SDK (i.e. have the player’s consent for an opt-in legislation, or that the player has not denied consent for an opt-out legislation). If you are not using SDK version 5.0.0 or greater, it is strongly recommended that you upgrade as soon as possible.

Only once you've confirmed that you have the player's consent to collect data, you can activate the SDK by calling AnalyticsService.Instance.StartDataCollection().

If the player has denied or revoked their consent, you can avoid calling StartDataCollection and so leave the SDK inactive.

For specific information about how to start data collection in compliance with the two major kinds of legislation, see these pages:

The following diagrams display the methods that the SDK offers to manage consent and privacy scenarios:

If the user wants to opt out after data collection has been started, use the AnalyticsService.Instance.StopDataCollection() method.

Call AnalyticsService.Instance.RequestDataDeletion() to request personal data deletion, which triggers a purge of user data from the server. This will also stop data collection if it has not already been stopped.

If there is no internet connection when this request is made, the SDK reattempts the request at regular intervals until it is successful. It will remember this across application restarts using Unity's PlayerPrefs system, so be aware that using PlayerPrefs.DeleteAll() may disrupt this process.

Important: This functionality only applies to Analytics and the Push Notification service. If you are using other services which collect application user personal data you will need to review those services' documentation for how they handle data deletion requests. To delete the player ID created by the Unity Authentication SDK (if enabled), use the Authentication API.

If you need to present the user with Unity's privacy policy, the privacy URL is available in the SDK as the AnalyticsService.Instance.PrivacyUrl property. Use the following code to open a browser window with Unity's privacy policy:

**Examples:**

Example 1 (unknown):
```unknown
EndUserConsent
```

Example 2 (unknown):
```unknown
AnalyticsIntent
```

Example 3 (unknown):
```unknown
EndUserConsent
```

Example 4 (unknown):
```unknown
AnalyticsService.Instance.RequestDataDeletion()
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/ApplePrivacySurvey

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/migration-path

---

## Apple

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-apple

**Contents:**
- Apple#
- Set up an Apple sign-in#
- Sign in a returning player or create new player#
- Update a player from anonymous to an Apple account#
- Unlink Apple account#

Minimum SDK version: 2.0.0

This article guides you through the following scenarios in setting up authentication for players in your game with an Apple account:

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

Important: The sign-in with Apple support in the Unity Authentication SDK only works with a single Bundle ID with the ID token from the iOS platform. It doesn't support Apple sign-in for players using Service ID and auth code from the Android platform.

To provide an Apple sign-in option for the players in your game, set up your app to enable sign-in with Apple.

Note: The code example below assumes you already have the player's Apple ID Token.

You can use the SignInWithAppleAsync method to either:

If no Unity Authentication player in your project is associated with the credentials, SignInWithAppleAsync creates a new player. If a Unity Authentication player in your project is associated with the credentials, SignInWithAppleAsync signs into that player's account. This function doesn't consider the cached player, and SignInWithAppleAsync replaces the cached player.

After you’ve set up anonymous authentication, if an anonymous player wants to upgrade to creating an Apple account, then sign in using Apple, your game should prompt the player to trigger the Apple sign-in and get the ID token from Apple. Then, call the LinkWithAppleAsync API to link the player to the Apple ID token.

If a cached player exists on the SDK, you can link the cached player to the Apple Account.

For more information about cached players, refer to Sign In a Cached Player.

Use the UnlinkAppleAsync API so your players can unlink their Apple account. Once unlinked, if their account isn’t linked to any additional identity, it transitions to an anonymous account.

**Examples:**

Example 1 (javascript):
```javascript
using System.Text;
using UnityEngine;

// External dependencies
using AppleAuth;
using AppleAuth.Enums;
using AppleAuth.Interfaces;
using AppleAuth.Native;

public class AppleExampleScript : MonoBehaviour
{
    IAppleAuthManager m_AppleAuthManager;
    public string Token { get; private set; }
    public string Error { get; private set; }

    public void Initialize()
    {
        var deserializer = new PayloadDeserializer();
        m_AppleAuthManager = new AppleAuthManager(deserializer);
    }

   public void Update()
   {
      if (m_AppleAuthManager != null)
      {
         m_AppleAuthManager.Update();
      }
   }

    public void LoginToApple()
    {
        // Initialize the Apple Auth Manager
        if (m_AppleAuthManager == null)
        {
            Initialize();
        }

        // Set the login arguments
        var loginArgs = new AppleAuthLoginArgs(LoginOptions.IncludeEmail | LoginOptions.IncludeFullName);

        // Perform the login
        m_AppleAuthManager.LoginWithAppleId(
            loginArgs,
            credential =>
            {
                var appleIDCredential = credential as IAppleIDCredential;
                if (appleIDCredential != null)
                {
                    var idToken = Encoding.UTF8.GetString(
                        appleIDCredential.IdentityToken,
                        0,
                        appleIDCredential.IdentityToken.Length);
                    Debug.Log("Sign-in with Apple successfully done. IDToken: " + idToken);
                    Token = idToken;
                }
                else
                {
                    Debug.Log("Sign-in with Apple error. Message: appleIDCredential is null");
                    Error = "Retrieving Apple Id Token failed.";
                }
            },
            error =>
            {
                Debug.Log("Sign-in with Apple error. Message: " + error);
                Error = "Retrieving Apple Id Token failed.";
            }
        );
    }
}
```

Example 2 (javascript):
```javascript
using System.Text;
using UnityEngine;

// External dependencies
using AppleAuth;
using AppleAuth.Enums;
using AppleAuth.Interfaces;
using AppleAuth.Native;

public class AppleExampleScript : MonoBehaviour
{
    IAppleAuthManager m_AppleAuthManager;
    public string Token { get; private set; }
    public string Error { get; private set; }

    public void Initialize()
    {
        var deserializer = new PayloadDeserializer();
        m_AppleAuthManager = new AppleAuthManager(deserializer);
    }

   public void Update()
   {
      if (m_AppleAuthManager != null)
      {
         m_AppleAuthManager.Update();
      }
   }

    public void LoginToApple()
    {
        // Initialize the Apple Auth Manager
        if (m_AppleAuthManager == null)
        {
            Initialize();
        }

        // Set the login arguments
        var loginArgs = new AppleAuthLoginArgs(LoginOptions.IncludeEmail | LoginOptions.IncludeFullName);

        // Perform the login
        m_AppleAuthManager.LoginWithAppleId(
            loginArgs,
            credential =>
            {
                var appleIDCredential = credential as IAppleIDCredential;
                if (appleIDCredential != null)
                {
                    var idToken = Encoding.UTF8.GetString(
                        appleIDCredential.IdentityToken,
                        0,
                        appleIDCredential.IdentityToken.Length);
                    Debug.Log("Sign-in with Apple successfully done. IDToken: " + idToken);
                    Token = idToken;
                }
                else
                {
                    Debug.Log("Sign-in with Apple error. Message: appleIDCredential is null");
                    Error = "Retrieving Apple Id Token failed.";
                }
            },
            error =>
            {
                Debug.Log("Sign-in with Apple error. Message: " + error);
                Error = "Retrieving Apple Id Token failed.";
            }
        );
    }
}
```

Example 3 (unknown):
```unknown
SignInWithAppleAsync
```

Example 4 (unknown):
```unknown
SignInWithAppleAsync
```

---

## Workflows and partial replicas

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/partial-replicas

**Contents:**
- Workflows and partial replicas#
- Centralized workflow#
- Distributed workflow#
  - Nodata replicas#
    - Hydrating replicas for offline work#
  - Use Xlinks to structure projects#

Unlike distributed systems that require a full local clone of the repository, Unity Version Control (UVCS) allows you to connect a local workspace directly to the central server. This workflow has the following advantages:

This workflow can be helpful for artists or other team members that don’t require the full version history.

If you prefer a distributed workflow with a local repository, Unity Version Control (UVCS) provides features to manage repository size. For example, you can use nodata replicas, or xlinks.

To manage repository size in a distributed workflow, you can create a nodata replica of the repository. A nodata replica is a clone that contains all the repository's metadata but none of its actual file data (blobs):

This setup results in a very small local repository.

When you access a file, the data is retrieved on-demand from the server. You can browse history, diff files, and change branches without locally stored file data. Any new checkins you create add data to your local repository. You can then push the checkins to the central server.

For more information on how to create and manage nodata replicas, refer to Use a nodata replica.

A nodata replica needs a connection to the central server to fetch file data. With the hydrate command, you can selectively download data for offline use.

Hydrating is the process that occurs when you download the actual file data from the original server and store it in your local nodata replica. A common workflow is to create a nodata replica of the main branch and hydrate only the latest changeset. This workflow provides a complete working copy for development without downloading the data for the entire project history.

For more information on how to hydrate a nodata replica, refer to Hydrate a replica for offline use.

UVCS supports Xlinks, which allow you to split a large project into several smaller, more manageable repositories. For example, you can fully replicate the code repository with data for main development, while using a nodata replica for a large art asset repository. Alternatively, you can use an Xlink that points directly to a centralized art repository to avoid needing a local clone of the repository entirely.

---

## Pipe commands

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/pipe

**Contents:**
- Pipe commands#
- Commands that accept piped paths#
- Pipe examples#
  - Pipe from the Windows dir command#
  - Checkout files recursively into piped directory arguments#

The UVCS command line can read arguments from standard input (stdin) one by one if you use the - option.

For example, you can add three files at the same time:

This allows you to pipe output from other commands into cm. For example, you can combine commands to create automations such as to add all files under a specific directory tree:

find /path/to/dir | cm add -

The following commands accept piped paths:

The following example pipes from the Windows dir command to remove files that match a specific pattern from a workspace:

**Examples:**

Example 1 (unknown):
```unknown
>cm add -
a.txt
b.txt
c.txt

The selected items are about to be added. Please wait ...
Item c:\Users\pablo\wkspaces\mcga\a.txt was correctly added
Item c:\Users\pablo\wkspaces\mcga\b.txt was correctly added
Item c:\Users\pablo\wkspaces\mcga\c.txt was correctly added
```

Example 2 (unknown):
```unknown
>cm add -
a.txt
b.txt
c.txt

The selected items are about to be added. Please wait ...
Item c:\Users\pablo\wkspaces\mcga\a.txt was correctly added
Item c:\Users\pablo\wkspaces\mcga\b.txt was correctly added
Item c:\Users\pablo\wkspaces\mcga\c.txt was correctly added
```

Example 3 (unknown):
```unknown
find /path/to/dir | cm add -
```

Example 4 (unknown):
```unknown
applylocalchanges
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/google-play-data-safety

---

## Rate limits

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/rate-limits

**Contents:**
- Rate limits#

The Relay service uses rate limiting to help control network traffic by restricting the number of requests received by the API within any given second. The following table shows the rate limit for each of the Relay service’s request types. The rate limit applies to each authenticated player.

---

## Organizations

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/unity-vcs-organizations

**Contents:**
- Organizations#
- Permission management#

Unity organization owners and managers can assign seats and manage settings. Unity Version Control (UVCS) leverages Unity organization and project access management, which you can access through the Administration section of your Unity Dashboard.

If you add a user to a Unity organization, they can view all of the projects and repositories in that organization. If you add a user to a Unity Cloud project, they can only view repositories within that project. Users need a DevOps seat to get write access to all of the repositories they have access to, otherwise they have read-only access.

For documentation on how to manage Unity organizations and Unity Cloud projects, refer to the following pages:

Control repository permissions at the Unity organization and Unity Cloud project levels.

For more information, refer to the documentation on how to assign DevOps seats and manage members.

---

## Common objects

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/SDK-common-objects

**Contents:**
- Common objects#
- Economy date#
- Write lock#

An EconomyDate object is a wrapper for modified and created dates from the economy service. It currently has one parameter as shown below:

The write lock is used to implement optimistic concurrency. It is optional.

A writeLock is returned for each balance or inventory item instance when they are fetched, added or updated. The user can then pass the writeLock value back to the SDK when updating a currency balance or inventory instance. If it matches, the request is successful and will update. If it doesn't, then an error is returned.

The writeLock can be any string value.

For a code example, see the method UpdatePlayersInventoryItemUsingWriteLock in the InventoriesBasicExample sample.

**Examples:**

Example 1 (unknown):
```unknown
EconomyDate
```

Example 2 (unknown):
```unknown
UpdatePlayersInventoryItemUsingWriteLock
```

Example 3 (unknown):
```unknown
InventoriesBasicExample
```

---

## Server configuration files

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/server-configuration

**Contents:**
- Server configuration files#

Find or create the following configuration files in your Unity Version Control (UVCS) server installation directory.

**Examples:**

Example 1 (unknown):
```unknown
cryptedservers.conf
```

Example 2 (unknown):
```unknown
externaldata.conf
```

Example 3 (unknown):
```unknown
gitserver.conf
```

Example 4 (unknown):
```unknown
groups.conf
```

---

## Set up User Reporting

**URL:** https://docs.unity.com/cloud-diagnostics/en/manual/UserReporting/SettingupUserReporting

**Contents:**
- Set up User Reporting#
- Set up notifications for new reports#
- Test reports and notifications#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Integrate the User Reporting SDK with your app to set up user reports. Once integrated, you can use the built-in user report prefab, or create your own custom user reports without the prefab.

Note: Before you integrate User reports with your project, make sure you set up your project for Unity Services. Your project must be in the Editor to the Dashboard with a project ID. See Setting up your project for Unity Services.

To add the built-in example User Reporting Prefab to your project:

User Reporting supports new report notifications via Integrations so you can connect your development workflow to non-Unity tools. Receive a notification via third-party integrations such as email, Slack, Discord, Trello, and more.

To set up notifications:

The sample scene is an effective tool for confirming whether or not your User Reporting has been set up correctly. In this example, we’ll optionally include a test of the email notification integration for new reports.

To set up email notifications (optional):

To test that reports are received:

---

## Check in changes to the server

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/check-in-changes

**Contents:**
- Check in changes to the server#
- Keep files locked#

Check in changes you make to the server to make the changes available for other users in your repository.

When you edit your files with an external tool and save them, Gluon detects these changes. When you refresh your workspace view, the status of any edited files changes from Checked-out (unchanged) to Checked-out (changed).

The Checked-out (changed) status means that the changes to the locked files are saved locally but not on the server. To unlock the file and allow other users to access the changes, you need to check in the changes:

The Checkin changes tab also displays the differences of any file that you select to show you the changes made.

After you check in your changes, the status of the file in the Explore workspace tab returns to Controlled. The changeset is also available in the details view.

Note: To check in changes via the command line, run the command cm partial checkin.

You can check in your files so that the changes are available on the server, but keep the file locked so that you can continue work on the file later.

Before you select Checkin, select the Keep items locked checkbox.

Note: To keep an item locked from the command line, run the command cm partial checkin and add the--keeplock option.

**Examples:**

Example 1 (unknown):
```unknown
cm partial checkin
```

Example 2 (unknown):
```unknown
cm partial checkin
```

---

## Get started

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/sdk/unreal-engine-sdk/get-started

**Contents:**
- Get started#
- Understand the requirements#
  - Build the Engine from Source#
- Download the Multiplay Hosting SDK#
  - From the Unreal Engine Marketplace website#
  - From the Epic Games Launcher#
  - Building the project including the SDK#
  - Configure the Multiplay Game Server SDK#
- What's next ?#

The following instructions teach you how to install and configure the Multiplay Game Server SDK plug-in. After you’ve installed and configured the Multiplay Game Server SDK for your project, you can use the C++ or Blueprints integration.

The Multiplay Game Server SDK plug-in for Unreal Engine supports the Unreal Engine versions 4.27 to 5.3.

Unreal Engine requires you to use a source build to set up a dedicated server. Refer to Setting Up Dedicated Servers (Unreal Engine).

Perform the following steps to build the Unreal Engine from source:

At this point, you should have an Unreal Engine binary.

Refer to Building Plugins (Unreal Engine)

Multiplay generates the server.json file from information about the game server instance, such as the IP address, port number, and server ID. It also includes any configuration variables from the active build configuration.

The Multiplay Game Server SDK uses the server.json file to access the server query port variable ($$query_port$$) and the server ID variable ($$serverid$$).

To configure the server.json file in the Unity Dashboard, access Multiplay Hosting, then select Build Configurations.

You must include at least the queryPort and the serverID in the server.json file for your project. Refer to the following example server.json file.

Note: Refer to the server.json documentation.

Proceed with either integrations:

**Examples:**

Example 1 (unknown):
```unknown
Unity Gaming Services SDK for Unreal Engine
```

Example 2 (unknown):
```unknown
C:\Program Files\Epic Games\UE_5.3\Engine\Plugins\Marketplace
```

Example 3 (unknown):
```unknown
UnityGamingServicesSDK
```

Example 4 (unknown):
```unknown
MultiplayGameServerSDK
```

---

## Create a custom event

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/custom-event

**Contents:**
- Create a custom event#
- Create a custom event through the Unity Dashboard#
- Create a matching Event class in your game#

Unity Analytics comes with standard events that work without the need for additional configuration. However, you can create custom events to record player actions that are unique to your game. These must be created on the Unity Dashboard and then implemented in your game code.

Go to the Event Manager and select Add New > Custom Event.

Enter an event name and description.

Select Assign Parameter to add parameters to your event. You can add existing parameters or create new ones here by selecting Assign Parameter > Create New Parameter. A parameter needs a name, description and data type.

Ensure your event is set to Enabled.

To copy this event to another environment, refer to Copy custom events to another environment.

Note: Once created, you can enable or disable your custom event, but you can't delete it.

Note: Parameters can be edited but not deleted. You can add up to 1,500 parameters to the environment.

Note: You can create parameters from the main Event Manager page by selecting Add New > Custom Parameter.

Note: These API methods changed in version 5.1.0 of the SDK. Ensure that you have the latest version of the SDK installed.

The Analytics SDK is designed to help you match your game code with your event schemas as defined in the Unity Dashboard. While we provide helper classes for all of the standard events that you might encounter, you must make your own helper classes to support the custom events that are unique to your game. This is done through making sub-classes of the abstract Event class, giving you type safety when working with the same event across multiple locations, and can help you to prevent validation errors when the events are uploaded.

The following code is an example of how to make a sub-class of Event, for an event called myEvent that has individual parameters of each of the four available types:

The Event base class provides the SetParameter(...) methods, which take in the string parameter name from your event schema and a value type. Wrapping this in write-only properties or type-safe methods ensures that repeated uses of the same event are less likely to introduce mistakes, and that changes to the underlying schema or the way you populate events can be made with the benefit of refactoring tools. Since the names of parameters in events are case sensitive, and their values must match the types defined in the Event Manager, this gives you one place to manage the mapping between what the game can supply and what is expected by the Analytics back-end.

Note: Parameter values must be one of the following primitive types: string, int, long, float, double or bool. This restriction is enforced by the SetParameter(...) methods provided by the Event base class.

Once you have created your event schema and helper class and activated the SDK, you can use the AnalyticsService.Instance.Record(...) method to record an event. For more information, refer to Record event.

**Examples:**

Example 1 (unknown):
```unknown
public class MyEvent : Unity.Services.Analytics.Event
{
	public MyEvent() : base("myEvent")
	{
	}

	public string FabulousString { set { SetParameter("fabulousString", value); } }
	public int SparklingInt { set { SetParameter("sparklingInt", value); } }
	public float SpectacularFloat { set { SetParameter("spectacularFloat", value); } }
	public bool PeculiarBool { set { SetParameter("peculiarBool", value); } }
}
```

Example 2 (unknown):
```unknown
public class MyEvent : Unity.Services.Analytics.Event
{
	public MyEvent() : base("myEvent")
	{
	}

	public string FabulousString { set { SetParameter("fabulousString", value); } }
	public int SparklingInt { set { SetParameter("sparklingInt", value); } }
	public float SpectacularFloat { set { SetParameter("spectacularFloat", value); } }
	public bool PeculiarBool { set { SetParameter("peculiarBool", value); } }
}
```

Example 3 (unknown):
```unknown
SetParameter(...)
```

Example 4 (unknown):
```unknown
SetParameter(...)
```

---

## Quest system

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/modules/use-cases/quest-system

**Contents:**
- Quest system#
- Overview#
- Set up quests#
- Set up Cloud Code#
  - Restrict access to Cloud Save#
  - Set up Quest service#
  - Data classes#
  - Dependency setup#
  - Quest controller#
- Assign quests to players#

The quest system sample demonstrates how to use Cloud Code to implement a quest sample with the Remote Config and Cloud Save services. The sample covers server authoritative anti-cheat, the caching of other UGS service responses, and the modification of players' Cloud Save data. The sample uses Push messages to notify a player when they complete a quest.

The quest system allows players to call a Cloud Code module to issue them a quest. To provide players with quests, Cloud Code can do the following:

The player can perform actions that count toward the quest progress.

Cloud Code checks when the player last made progress, and either permits or denies the action from contributing to their progress dependent on the following limits:

This acts as a simple anti-cheat method by limiting the rate at which the player can receive quest progress point.

Once the player completes the quest, Cloud Save deletes the quest data and notifies the player via Push messages.

You need to define your quests in the Remote Config service:

The configuration acts as the active quest database.

The quest structure is as follows:

For instance, the Chop Trees quest can only be completed in five minutes, assuming the player is performing the action at the end of each one minute cooldown.

Set up a Cloud Code module called QuestSystem to handle the quest system.

To add a layer of security to your Cloud Save data, you can use Access Control to create a resource policy.

To prevent users from cheating by modifying their own Cloud Save data, you need to create a resource policy for UGS.

Create a file called cloud-save-resource-policy.json and paste the following:

You can deploy it using the UGS CLI:

To learn more about resource policies, refer to Access Control, and an example policy to restrict writes to common LiveOps services can be viewed on the Control Access to Services page.

Create a file called QuestService.cs.

The Quest Service fetches the quests from Remote Config and caches them for a set period of time.

Create a file called DataClasses.cs to store the data classes. You can use data classes to deserialize the responses that Cloud Code receives from Remote Config and Cloud Save. Create a file called DataClasses.cs to store the data classes.

To learn more about custom serialization, refer to Custom serialization.

To wire up the Cloud Code module, you need to set up the QuestService, GameApiClient, and PushClient:

The ICloudCodeSetup interface allows you to manage the dependencies of your modules. Learn more about it in the Dependency Injection documentation.

Create the QuestControllerclass to act as the main class and an entrypoint of user traffic to the service.

You can call the AssignQuest function to assign a quest to a player. This function:

If the player already has a quest in progress, the function responds accordingly.

You can call the PerformAction function to progress a quest. To update the progress, call this function each time the player performs an action that counts towards the quest progress.

To validate the changes to Cloud Save data, you can inspect the player's Cloud Save data in the Unity Dashboard.

To confirm your push notifications work, refer to Push messages.

**Examples:**

Example 1 (unknown):
```unknown
[
  {
    "id": 1,
    "name": "Chop Trees",
    "progress_required": 5,
    "progress_per_minute": 1,
    "reward": 5
  },
  {
    "id": 2,
    "name": "Mine Gold",
    "progress_required": 5,
    "progress_per_minute": 1,
    "reward": 10
  }
]
```

Example 2 (unknown):
```unknown
[
  {
    "id": 1,
    "name": "Chop Trees",
    "progress_required": 5,
    "progress_per_minute": 1,
    "reward": 5
  },
  {
    "id": 2,
    "name": "Mine Gold",
    "progress_required": 5,
    "progress_per_minute": 1,
    "reward": 10
  }
]
```

Example 3 (unknown):
```unknown
progress_required
```

Example 4 (unknown):
```unknown
progress_per_minute
```

---

## Evidence report HTTP response example

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/text-evidence/evidence-report-http-response

**Contents:**
- Evidence report HTTP response example#

The top level of the response contains a results object with individual message objects, and a next field containing the Unix timestamp (integer) of the next message if there are more messages in the channel. The next field is returned as null if there are no more messages to return. Use the next value as the start_ts in a subsequent request to retrieve the next page of results. Each message object contains a message_id, sender_id, and an array of message_versions.

The message_versions field contains a timestamp, the message body, and an optional unsafe_message field if filtering is applied.

The messages displays in ascending order with the oldest message in the results first. Message versions display in descending order with the most recent message version first and the oldest message version last.

Below is an example Text Evidence Management response:

**Examples:**

Example 1 (unknown):
```unknown
message_versions
```

Example 2 (unknown):
```unknown
message_versions
```

Example 3 (unknown):
```unknown
unsafe_message
```

Example 4 (unknown):
```unknown
{
   "results": [
       {
           "sender_id": "sip:your-issuer.username1.1234.@yourdomainname.vivox.com",
           "message_versions": [
               {
                   "unsafe_message": "Message 1: Edit 2: testing the fucking filter",
                   "timestamp": 1697117082123458,
                   "body": "Message 1: Edit 2: testing the **** filter"
               },
               {
                   "timestamp": 1697117040123457,
                   "body": "Message 1: Edit 1"
               },
               {
                   "timestamp": 1697117012123456,
                   "body": "Message 1"
               }
           ],
           "message_id": "434461955301228290"
       },
       {
           "sender_id": "sip:your-issuer.username2.1234.@yourdomainname.vivox.com",
           "message_versions": [
               {
                   "timestamp": 1697117091123459,
                   "body": "Message 2"
               }
           ],
           "message_id": "434461975538075906"
       },
       {
           "sender_id": "sip:your-issuer.username1.1234.@yourdomainname.vivox.com",
           "message_versions": [
               {
                   "timestamp": 1697117217124567,
                   "body": "Message 3"
               }
           ],
           "message_id": "434462007728276226"
       },
       {
           "sender_id": "sip:your-issuer.username2.1234.@yourdomainname.vivox.com",
           "message_versions": [
               {
                   "timestamp": 1697117224124568,
                   "body": "Message 4"
               }
           ],
           "message_id": "434462009596678402"
       }
   ],
   "next": null
}
```

---

## Incident types

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/incident-types

**Contents:**
- Incident types#
- Moderation incident types#
  - Player reports#
- Safe Text incident types#
  - Proactive text detections#

Incidents from Safe Text appear in the Moderation queue.

Player submitted reports. The Moderation queue differentiates between reports submitted by players and automated reports triggered by behaviours. Player reports will automatically contain Safe Text related data if they're present in your project.

Safe Text reviews text messages sent between players.

When Safe Text detects toxic or disruptive behavior in text messages, it treats the offending messages as an incident, without a player having to report it themselves. Those incidents show up in the Moderation queue.

If a player does report the messages the text detections are attached to the submitted player report.

For more information on text detections refer to Context analysis.

---

## Keep a connection alive

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/keep-connection-alive

**Contents:**
- Keep a connection alive#

Note: Netcode for GameObjects (NGO) automatically keeps connections alive. Check out Using Relay with NGO.

Relay servers automatically disconnect clients after a period of inactivity. The default time to live (TTL) before Relay disconnects a client is 10 seconds. The disconnect TTL is 60 seconds when the host in alone (after the BIND message but before a peer connects to them with a CONNECT message). Any message received by the Relay server involving this client, either as a sender or receiver, resets this timeout.

For games with a lower message frequency, it’s important to keep the connection alive with a method that you regularly call, such as in the Update() loop. If you’re using Relay with NGO, the network manager (NetworkManager) keeps the connection alive automatically. However, it will only do so after you’ve successfully called StartClient or StartHost.

If you’re using Relay with UTP, UTP keeps the connection alive automatically as long as you regularly schedule updates to the NetworkDriver for both host and joining players. You normally do this anyway to accept new connections and receive messages. The following code sample demonstrates code that will keep the connection alive.

**Examples:**

Example 1 (unknown):
```unknown
NetworkManager
```

Example 2 (unknown):
```unknown
StartClient
```

Example 3 (unknown):
```unknown
NetworkDriver
```

Example 4 (unknown):
```unknown
//Call the below regularly, e.g., in Monobehaviour.Update()
void Example_KeepingConnectionAlive()
{
    // Update the NetworkDrivers regularly to ensure the host/player is kept online.
    if (HostDriver.IsCreated && isRelayServerConnected)
    {
        HostDriver.ScheduleUpdate().Complete();

        //Accept incoming client connections
        while (HostDriver.Accept() != default(NetworkConnection))
        {
            Debug.Log("Accepted an incoming connection.");
        }
    }

    if (PlayerDriver.IsCreated && clientConnection.IsCreated)
    {
        PlayerDriver.ScheduleUpdate().Complete();

        //Resolve event queue
        NetworkEvent.Type eventType;
        while ((eventType = clientConnection.PopEvent(PlayerDriver, out _)) != NetworkEvent.Type.Empty)
        {
            if (eventType == NetworkEvent.Type.Connect)
            {
                Debug.Log("Client connected to the server");
            }
            else if (eventType == NetworkEvent.Type.Disconnect)
            {
                Debug.Log("Client got disconnected from server");
                clientConnection = default(NetworkConnection);
            }
        }
    }
}
```

---

## Clients

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/clients

**Contents:**
- Clients#

Clients, or game clients, are executable programs that players or end-users use to play a game. In multiplayer games, clients allow the player to connect to other players to participate in a game session .

In the scope of Relay, there are two types of clients:

---

## FASTEXPORT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/fastexport

**Contents:**
- FASTEXPORT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Exports a repository in fast-export format.

cm fast-export | fe <repspec> <fast-export-file> [--import-marks=<marks_file>] [--export-marks=<marks_file>] [--branchseparator=<chr_separator>] [--nodata] [--from=<changesetid>] [--to=<changesetid>]

cat repo.fe.00 | git fast-import --export-marks=marks.git --import-marks=marks.git

cm fast-export repo@localhost:8087 repo.fe.00 --import-marks=marks.cm --export-marks=marks.cm

(Exports the repository 'repo' in the local server into the 'repo.fe.00' file in Git fast-export format and creates the marks files to perform incremental exports later.)

cm fast-export repo@localhost:8087 repo.fe.00 --from=20

(Exports the repository 'repo' in the local server into the 'repo.fe.00' file in Git fast-export format from changeset '20'.)

**Examples:**

Example 1 (unknown):
```unknown
cm fast-export | fe <repspec> <fast-export-file> [--import-marks=<marks_file>] [--export-marks=<marks_file>] [--branchseparator=<chr_separator>] [--nodata] [--from=<changesetid>] [--to=<changesetid>]
```

Example 2 (unknown):
```unknown
cm fast-export repo@localhost:8087 repo.fe.00 --import-marks=marks.cm --export-marks=marks.cm
```

Example 3 (unknown):
```unknown
cm fast-export repo@localhost:8087 repo.fe.00 --from=20
```

---

## Player balances

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/SDK-player-balances

**Contents:**
- Player balances#
- GetBalancesAsync#
  - GetBalancesOptions#
  - GetBalancesResult#
- SetBalanceAsync#
  - SetBalanceOptions#
- IncrementBalanceAsync#
  - IncrementBalanceOptions#
- DecrementBalanceAsync#
  - DecrementBalanceOptions#

The PlayerBalances namespace contains all the methods for fetching and updating a player's currency balances.

These methods will return the balances for the currently signed in player from the Authentication SDK.

All the methods in this namespace can throw an EconomyException.

Retrieve the currency balances for the current user. Takes an optional GetBalancesOptions.

When getting balances, you can use the GetBalancesOptions to set a limit on the number of balances to fetch (between 1 and 100 inclusive). This is to help with pagination. The default number is 20.

The following sample code retrieves the first five balances for the current user, and then retrieves the next five, including those for currencies that have since been deleted from the configuration.

These methods return a GetBalancesResult. See GetBalancesResult.

The options object for a GetBalancesAsync call. It has the following field:

A GetBalancesResult provides paginated access to the list of balances retrieved. It has the following fields:

It has the following methods:

Sets the balance of the specified currency to the specified value.

This method optionally takes a SetBalancesOptions object used to set the write lock. If provided, an exception is thrown unless the writeLock matches the writeLock received by a previous read, in order to provide optimistic concurrency. If not provided, the transaction proceeds regardless of any existing writeLock in the data.

This method returns the current balance after the update has been applied, if the operation is successful.

The options object for a SetBalanceAsync call. It has the following field:

Increments the balance of the specified currency by the specified value.

This method optionally takes a IncrementBalancesOptions object used to set the write lock. If provided, then an exception is thrown unless the writeLock matches the writeLock received by a previous read, in order to provide optimistic concurrency. If not provided, the transaction proceeds regardless of any existing writeLock in the data.

This method returns the current balance after the update is applied, if the operation is successful.

The options object for a IncrementBalanceAsync call. It has the following field:

Decrements the balance of the specified currency by the specified value.

This method optionally takes a DecrementBalanceOptions object used to set the write lock. If provided, then an exception is thrown unless the writeLock matches the writeLock received by a previous read, in order to provide optimistic concurrency. If not provided, the transaction proceeds regardless of any existing writeLock in the data.

This method returns the current balance after the update is applied, if the operation is successful.

The options object for a DecrementBalanceAsync call. It has the following fields:

A player balance represents a single currency balance for a player. It has the following fields:

It also has the following helper methods:

This is a convenience method to get the currency definition for the currency associated with this balance. It returns a CurrencyDefinition.

This event can be subscribed to in order to be notified when the SDK updates the balance of a particular currency. The subscriber is passed the currency ID of the balance that was updated.

This event is be called for SDK initiated actions (for example, updating player's balances, making purchases). It is not called for any updates from other devices / service side changes.

**Examples:**

Example 1 (unknown):
```unknown
PlayerBalances
```

Example 2 (unknown):
```unknown
GetBalancesOptions
```

Example 3 (unknown):
```unknown
GetBalancesOptions
```

Example 4 (unknown):
```unknown
// Optional, defaults to 20
GetBalancesOptions options = new GetBalancesOptions
{
    ItemsPerFetch = 5
};

GetBalancesResult getBalancesResult = await EconomyService.Instance.PlayerBalances.GetBalancesAsync(options);
List<PlayerBalance> firstFiveBalances = getBalancesResult.Balances;
// do something with your balances

if (getBalancesResult.HasNext) {
    getBalancesResult = await getBalancesResult.GetNextAsync(options.ItemsPerFetch);
    List<PlayerBalance> nextFiveBalances = getBalancesResult.Balances;
    // do something with your balances
}
```

---

## Set up integrations

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/integrations

**Contents:**
- Set up integrations#
- Slack#
- Discord#
- WebHook#

As an administrator, you can create Version Control integrations in the Unity Dashboard to notify users of certain events.

To set up an integration in the Unity Dashboard, select DevOps > Version Control > Settings > Integrations.

UVCS and Slack come together to help you set up notifications to your team’s Slack channel.

To create a new Slack integration in the Integrations tab:

To create a new Discord integration in the Integrations tab:

To create a new Webhook integration in the Integrations tab:

---

## Unity Version Control 8.x Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/8

**Contents:**
- Unity Version Control 8.x Release Notes#
- 8.0.16.4054#
  - New#
    - [code]cm ls[/code] is now about 20 times faster!#
  - Bug#
    - After switching to a branch in an empty workspace…#
    - When moving the mouse really close to the top, ov…#
- 8.0.16.4048#
  - New#
    - We added a new subcommand called [code]conns[/cod…#

This document contains all release notes for Unity Version Control major version 8.x, organized from newest to oldest.

All platforms - Command line client: cm ls is now about 20 times faster!

The command was retrieving the branches where each item was modified for the last time one by one. Now it batches requests.

In our internal tests, retrieving the biggest tree we have goes down from 190 seconds to just 10 (19 times faster!).

All platforms - Gluon: After switching to a branch in an empty workspace using Gluon, if the workspace had xlinks, when trying to download a single file failed with an unexpected error. Now it's fixed.

Windows - Plastic: When moving the mouse really close to the top, over the comments bar in the CodeReview window, sometimes the following error appeared:

All platforms - Server: We added a new subcommand called conns to the plastid shell command. It displays all the network connections for a specific Plastic SCM server instance.

All platforms - Server: The user management command line tool, umtool, is now available as a subcommand of plasticd shell.

To manage your users and groups, you can now run:

The arguments to umtool remain unchanged. You can learn more about the umtool command line options in the online documentation.

All platforms - Server: We added detailed shutdown times of each component and better logs to the activity scheduler.

We added new logs to have more precise tracking while improving tests performance, but we think they are good logs to stay.

We also added logs to track scheduled activities as follows:

All platforms - All clients: We added trace information when a workspace returns to cs:0.

When a workspace gets resetted (it points again to cs:0 and all files appear as private), Plastic SCM clients will now leave a trace of what happened in the workspace .plastic directory as new log files (without needing any extra log configuration).

This applies to all clients (Plastic, Command Line Client, Gluon, Visual Studio Package, Shell Extension, etc) so regardless of which one of them resets the workspace, it will leave detailed log of what and why happened.

The names of these log files look like wkcorruption.2020.02.02.13.15.26.352.log & wkmismatch.2020.02.02.13.15.26.352.log, where the numbers are a timestamp.

All platforms - all products (logging): We added a daily rolling file appender. It does what you expect by its name - a new log file for each day's logs. You can also set a maximum number of files to keep on disk.

To configure this log appender, add something like the following to your "log.conf" files.

This will generate files like: 2020-02-27-cm.debug.log.txt, 2020-02-28-cm.debug.log.txt and so on.

Parameter maxFileCount is the maximum number of files to keep on disk. The oldest log files in the directory will be deleted to maintain this limit.

All platforms - Plastic: we improved the text of the merge resolution menu options to make what's going on clearer. In particular, the options for a "merge to..." operation no longer mention the workspace (because there is no workspace involved in a "merge to" operation!).

All platforms - Plastic: In some scenarios, the combo to select a Plastic SCM repository when creating a workspace in the Welcome screen could be duplicated. Now it's fixed.

Windows - Gluon: When using the "Search files" functionality in the "Explore workspace" view, if there was activity on disk in the workspcace folder, Gluon was not able to correctly focus the selected file. Now it's fixed (special thanks to Greg Koreman for reporting this!).

Windows - Plastic: Sometimes the GUI lost the expanded and selected nodes in the Workspace Explorer if you clicked the refresh button repeatedly. Now it's fixed.

All platforms - .NET Core Server: Our brand new, .NET Core-based Plastic SCM server received new superpowers! Now it has the WebAdmin and WebUI available - and DevOps (mergebots)! (Unless you run it on macOS, where we still didn't enable the mergebots).

You can learn more about the .NET Core-based Plastic SCM server and how to install it in this blogpost.

All Platforms - Server: You can now run the Plastic proxy as a subcommand "proxy" of plasticd.

What is the Plastic proxy? See here: https://www.plasticscm.com/documentation/administration/plastic-scm-version-control-administrator-guide#Chapter4:Usingaproxyserver

The arguments to "plasticd proxy" are exactly the same as for "plasticcached":

Windows - Plastic: The Plastic client periodically checks the license on the server, and if doesn't find any license, it shows an appropriate warning message in the notification area. Sadly, failing to connect to the server would also produce the same message, even if a license did exist, which was confusing.

We fixed this. Now, if the client can't connect to the server, it tells you it can't connect. If it connects and finds that there is no license, well, it tells you that you have no license.

macOS - Plastic: The new Code Review system for macOS is no longer an experimental feature! We removed the warning panel in the top of the Window saying that. However, the feature is still recent, so do not hesitate to report any possible problem to support at codicesoftware dot com.

All platforms - Plastic, Gluon (Cloud Edition): This release has a known bug that causes repositories to appear duplicated during the configuration steps. This bug is not critical, is just a graphical nuissance when selecting the repository you want to join. It will be fixed in the upcoming releases.

All platforms - .NET Core Server: Great news! We just published the Plastic SCM server built on .NET Core, the cross-platform, rock-solid, super-fast and officially supported framework.

The new servers are available for Linux, macOS and Windows since version 8.0.16.4017.

The new servers are fully compatible with your current installation but as of 8.0.16.4017 they still don't include WebAdmin, WebUI and mergebots. We'll release a new version packaging those soon.

The Linux servers are available as tar.gz and also regular packages.

Windows and macOS servers are only available as zip and tar.gz at this point. We'll make them full regular installers soon.

You can read more about the brand new .NET Core server in this blogpost.

All platforms - Server: We introduced a buffer pool for the network buffering.

Now Plastic Protocol takes advantage of a buffer pool and larger buffers (2MB) when reading from and writing to the network, which speeds up operations when sending lots of metadata.

All platforms - Server: We added extra logs and a list of active connections.

Added a new log to Plastic Proto (only when it runs standalone without remoting) to track socket accepts:

Also, added a new command (conns) to plasticd --console shell and extra info to the ServerStats log that prints the active connections:

Total connections is redundant with the former:

The counter shows all the open socket connections, whether they are waiting or actively used.

Also, added an extra security setting: If SSL stays being negotiated more than 10 secs, the conn will be aborted.

All platforms - Server: We added a new shell that lets you interact with locally running plasticd processes. Yes! This is particularly useful when the Plastic SCM Server is running as a daemon, in which case you couldn't interact with it.

Probably best explained with some examples:

Of course, if there were only one, it would have connected to it directly.

To see the list of available commands:

Switch to my other server, and shut it down:

All platforms - Plastic, Gluon (Cloud Edition): This release has a known bug that causes repositories to appear duplicated during the configuration steps. This bug is not critical, is just a graphical nuissance when selecting the repository you want to join. It will be fixed in the upcoming releases.

Windows - Plastic: When editing the path permissions for a repository that is not the workspace active one, the dialog allowed to choose folders for the currently active repository instead of the one that was selected. That was wrong and now it's fixed.

Windows - Plastic: After refreshing the Repository browser view (the view that shows the files in a branch, label or changeset), the expanded and selected nodes were lost. Now it's fixed.

Command line client: updated the "cm undo" inline help to explain the current limitation regarding reverting file deletions. Namely, to undo a deletion, you must either specify the full path of the item, or specify the containing directory and use the recursive ("-r") flag.

(Does NOT undo deletions in the current directory.)

(Undoes all deletions (and other changes) in the current directory recursively.)

$ cm undo src/file.txt

(Undoes deletion (or other change) of src/file.txt.)

All platforms - Gluon: Perhaps you noticed that private items you chose to add in the Workspace Explorer turned into controlled for a short while, then eventually they appeared as Added (as one would expect). This happened in big repositories, since the GUI takes longer to calculate the status and size information.

Right after refresh, the tree could only know whether an item was private or not. That's why you saw added items displayed as controlled. It's kind of confusing, though; that's why it's fixed now!

All platforms - Plastic: We improved the search buttons behavior in the branch explorer. Previously, those didn't focus any matching changeset, label or branch -even if they were visible- when you toggled the "Only relevant" option. Now it's fixed.

Windows - VSPackage: Visual Studio crashed after checking-in files from the Pending Changes view. Now it's fixed.

Linux - Server: Fixed a wrong message during server shutdown.

Often we saw a wrong message during server shutdown like this:

Hopefully it won't happen again.

All platforms - Gluon: Gluon now properly handles file system permissions (r-xr-xr-x). This was available only in the Plastic client until today!

The client will set the permissions on disk during the update and configure operations. Also, the checkin operation will save the changes you might do to them.

This improvement applies to 'cm partial' commands as well.

All platforms - Plastic: The Incoming Changes feature doesn't support the sub-branches. Before these changes, you weren't explicitly notified about this scenario. Now, Plastic will detect this situation and it will let you know that you need to perform a merge to get the head changes.

What is a sub-branch, then? We call "sub-branches" the situation that happens when a single branch has more than one line of changesets evolving in parallel. This scenario is often seen when working on distributed mode. Let's say there are 2 developers, John and Kate, who have workspaces pointing to the same branch. They checkin new changes each one in their server, and eventually, John pulls Kate's changes. They'll end up having something like this:

All platforms - Plastic: The Incoming Changes feature doesn't support workspace with transformer rules. Before these changes, you weren't explicitly notified about this scenario. Now, Plastic detects this situation and it lets you know the steps you need to do to get the head changes.

All platforms - Plastic: The Incoming Changes feature doesn't support a writable Xlink edited to point to a previous changeset. Before these changes, you weren't explicitly notified about this scenario. Now, Plastic detects this situation and it lets you know the steps you need to do to get the head changes.

Windows - Gluon: Incoming changes: The incoming changes view now allows you to check the items to update/resolve instead of obtaining all incoming changes.

All platforms - Command line client: calling cm workspace with the wrong number of arguments now shows the help for the workspace command, rather than the workspace create subcommand.

All platforms - Server: We optimized the performance checking the security of a query or a branch explorer.

Checking the security of 13000 branches:

Before: It took 2300 ms.

After: It takes 110 ms

The problem was that the server read the administrator over and over for each object that needed a security check. Now, it's only read once for all the objects to check.

This only improves Jet backend performance, since the sql-based backends already used an internal cache for the server administrator.

All platforms - Server: The security checks were slower after the first operation that a user runs after a server restart. It happened due to some internal cache clearing. This will not happen anymore.

All platforms - Server: Fixed the log that prints enqueued requests.

The log did not print the line "Max threads have been reached. No new thread is created. Waiting for a free thread." since we allowed to create several new threads in chunks a few months ago.

All platforms - Server: We improved the message when the client abruptly disconnects.

We were sometimes printing "end of file" in the logs when in reality the client side was closing the socket.

All platforms - Gluon: Improved the way the Incoming Changes deals with files that are locally changed in the workspace, out of date and are configured to use exclusive locking.

The local changes done in these files cannot be merged with the server changes since they were configured to use the exclusive checkout.

This scenario should be avoided by the user by locking (checking-out) the file before doing any change in it. Anyway, Gluon helped nothing once it occurred.

Now, Gluon gives a better feedback to the user in two ways:

The "Explore workspace" view shows the 'Cannot merge' status for the files under the previous circumstances.

The "Incoming changes" view reports that these changes cannot be applied with a proper explanation:

"Cannot checkout '/game/art/texture.bin' because you don't have the latest version. You will need to undo your changes to update to latest and lock. If you really need to preserve your changes, backup them manually. Please remember to lock this file in the future before making changes."

Plastic SCM Wwise Plugin: we improved the way we handle resources during potentially long operations like add, checkin, update and undo. Now, the GUI remains responsive during long operations, and you can cancel operations at any point.

Plastic SCM WWise Plugin: We now check the Plastic client version when you click "Test Connection" in the configuration dialog.

Note: the current minimum Plastic client version to use the Wwise plugin is 8.0.16.3876.

All platforms - Plastic, Gluon: We updated the pending changes in all our GUIs (or Checkin views, as you Gluon users may know them) to include a "Check/Clear all" checkbox right above the changes tree. This was already present in Windows, so now the remaining platforms have one less reason to be jealous. This new control is quite useful when you have a lot of changes, or they're distributed more than one category.

Linux - Plastic, Gluon: We've enhanced the pending changes tree. You'll notice that categories will display an intermediate state when some but not all changes inside them are checked. This provides better visual feedback when you have a lot of changes in a category, especially when you have checked items inside it but the scroll position doesn't have them on display.

Please note that not all GTK themes show this intermediate state. In that case, you'll only see it checked or unchecked.

Visual Studio Package: Our Visual Studio Package now supports the Incoming Changes.

You can find more info about Incoming Changes here

All platforms - Server: you can now configure the server by running plasticd configure.

The "configure" subcommand takes the same arguments as the deprecated clconfigureserver.exe.

Where previously you would have run

All platforms - Server: Servers that use a floating license wrongly included unauthenticated users in the Users Monitor. Now it will only list valid (i.e. authenticated) users.

These unauthenticated users come from calls from wrongly configured clients or connection profiles. These users cannot access the server, but they were still wrongly included on the Users monitor.

See an example: John has a local client & server, and he has its client configured with the user 'John'. When he tries to connect against the central server, the call fails and asks for valid user credentials.

Remarks: This was NOT a security issue. Unauthenticated users were not able to access the server. The problem was that wrong and valid users were listed all together in the Users Monitor.

All platforms - Proxy server: The download operation failed if the path to the cached storage files was incomplete, i.e. there were missing directories in the path, not just a missing file. This could happen if a client requested dehydrated revisions (i.e. replicated with --nodata) through a proxy. Those revisions don't get written to files, so the cache wasn't able to handle the missing directories in the path.

macOS - Server: We fixed an uncommon scenario in which the checkin operation could fail. The bug affects only servers running on newer macOS versions and using a SQL database backend (such as SQLite).

The issue was a zlib compress output buffer smaller than required. We could only reproduce this issue while checking in specific trees - and only when the server had just started. So, you've probably never encountered this, and now never will! Let's thank our automated test suite for finding this one, as otherwise it well could have gone unnoticed for years.

All platforms - Server: We fixed an issue with Active Method Calls that reported calls mistakenly.

We saw logs like these on our internal servers:

And we suspected that some requests were 'hanged' somehow. But it wasn't true.

The problem was that when some requests failed due to network issues, we were not tracking that the request exited, so it looked like it was there already, but it wasn't true.

All platforms - Command line client: cm pull hydrate now lets you hydrate a changeset specified by GUID. Previously it accepted changeset ids, but failed for changeset GUIDs if you did not choose to specify the source branch.

...will now hydrate the specified changeset.

macOS - Plastic: The code review window reported index out of range errors when:

a) you opened a code review window whose first change is a changed file with semantic support

b) the semantic diff failed

c) the diff fell back correctly to text mode

d) you clicked the "toggle comments" button in the toolbar - the one that hides and shows the list of comments for the diffed file

This happened because the review comments didn't load after the error and the toggle button logic didn't consider the possibility of an uninitialized comments list.

We protected that scenario so that toggle button will check whether it can operate and also fallback text diffs will properly load the list of comments.

All platforms - Command line client: cm remove private now gives the correct output if you try to remove a file which does not exist.

a)Before this release:

All platforms - Plastic, Gluon, Command line client: the new connection timeout didn't work with server aliases.

We introduced an issue with the new connection timeout we created back in version 8.0.16.3819: when a connection timed out, the alias system was not triggered. This is now fixed!

We also modified the internal network code so when a socket gets a timeout (it can be due to several reasons), the calls are not repeated and it fails fast.

Windows - Installer: We have detected a situation in which the workspace could be corrupted if you upgraded Plastic to version 8.0.16.3960 or higher with Office Plugin installed and any Word/Excel/PowerPoint instances opened.

Now, during a upgrade installation, when the Office Plugin is installed, the installer checks for any running instance of Word, Excel or PowerPoint. You need to close them before continuing with the upgrade installation.

All platforms - Command line client: cm find review command improved. Now it is possible to find reviews filtering by human-readable status strings. Valid string values are: under review, reviewed and rework required (case insensitive).

Plastic SCM Plugin for Wwise: We are pleased to announce the first release of the Plastic SCM Plugin for Wwise. Wwise users can get Plastic source control functionality from within the application.

To use the Plastic SCM Plugin for Wwise, you have to copy the plugin dll from your Plastic SCM client install directory to the following location in your Wwise install:

Where <Wwise install directory> is usually something like C:\Program Files (x86)\Audiokinetic\Wwise 2019.1.X.YYYY.

In “Project” menu, open “Project Settings…”.

In the “General” tab, “Workgroup” -> “Plug-in” combo, select “Plastic SCM”.

Here you can set the path to the cm.exe. If left blank it will pick up any cm on the system %PATH%.

Click “Test connection” to check the setup.

If the cm path is correct AND the project is in a Plastic workspace, you should see the message “Test connection executed successfully”.

If you see “No workspace found for project”, check that the project is in a workspace.

If you see “Failed to start Plastic SCM Shell Process.” Check the cm path.

Here are some screenshots:

All platforms - Server: Experimental Lz4 decompression could enter into a death loop.

This is not a critical issue since we didn't enable Lz4 network compression by default yet.

We detected that when the client (using Lz4) closed the socket, the server side could enter into a tight loop trying to continue reading bytes and burning CPU (empty loop trying to read again and again). That's now fixed!

Windows - Plastic: We increased the initial width of the Repository Explorer dialog so its controls don't overlap. This dialog allows you to select the target repository in the "New workspace" dialog.

All platforms - Proxy server: The proxy server didn't handle revisions with missing data right. This is a common scenario if you replicate branches to a repository using the --nodata flag (which we call "dehydrated replica").

In this case, the proxy server didn't do anything special during download. It considered those revision data to be already downloaded but the expected cache didn't exist on disk... so the proxy server thought that the missing files weren't there because a cache cleanup and retried the download three times. This meant an unnecessary delay of 1.5 seconds in total.

The proxy server will now know about this scenario and return quickly so the client can talk directly to the server.

Command line client: We edited the explanation of the cm attribute edit command to show you how to specify a default list of values for an attribute. We also included an example to be clearer.

All platforms - Server: Improved the ChannelCall log with more details:

Added mt (method time) to plasticproto, it was always zero before.

Changed prt (process time, basically request time) in remoting to measure the entire request, now it is comparable to plasticproto.

Added precise tracking to network times (millisecond precision) and lz4 compression/decompression

Plastic Protocol and Remoting calls are now easier to compare - they are properly aligned!

All platforms - Server: Serialization in Plastic protocol improved even more.

We are working on performance to boost Plastic Protocol performance as much as we can. Starting from this release, Plastic Protocol will serialize data (big trees) faster than remoting. We still need to add a buffer pool but this will come soon.

All platforms - Server: We optimized the Plastic Protocol serialization performance.

We use a binary protocol for network serialization that we called Plastic Protocol. We still have an ancient one called Remoting. We found out that remoting was serializing trees (and metadata in general) faster, due to the way we serialize in Plastic Protocol.

The problem was an intermediate buffer we used to group metadata before sending it to the network. Writing to it was slow and it was killing performance.

We fixed it and now serialization time in Plastic Protocol is as good as Remoting. It means that Plastic Protocol calls (the defaults) are now consistently faster than Remoting.

With the test trees we used:

Before: Remoting needed 31-47 ms to serialize a 5MB tree. Plasticproto needed 87-113.

After: Plasticproto is now 40-50 ms. We still have some room for improvement. But, since remoting sends more data (less effective protocol), Plasticproto should be consistently faster now.

All platforms - Server, Plastic, Command line client: We changed a message for when SSL negotiation fails.

And it will print extra info if possible.

We found this while debugging some unit tests that failed sporadically, and we thought it would be good in production too.

macOS - Plastic: Great news! You'll notice that branch code reviews now allow you to review changeset by changeset! There is a new switcher in the upper left corner of the window that enables you to switch back and forth between this new mode and the already supported "entire branch" review.

Selecting a changeset in the list will recalculate the changes you see in the upper right panel so you can diff any of them. This provides a quick way to go through all changes in the branch you're reviewing.

We're really excited about this, as we encourage our users to review their peers changeset by changeset. This provides a better insight about what the developer had in their mind and their thought process.

You can see it in action in this video we recorded for you. We hope you'll like this as much as we do!

All platforms - Plastic: Workspaces pointing to Cloud repositories did not support Global Configuration. There were invalid characters in the name of the workspace pointing to the global configuration (the @ bit). That's fixed now! You can create and use your plastic-global-config repository in the Cloud.

You can read more about Global Configuration in the documentation

All platforms - Plastic: The Pending Changes view did not show cloaked controlled changes (e.g. after performing a merge operation that involved them). It is fixed now!

Windows - Plastic: Closing a Plastic view while loading its content could break the workspace metadata under very specific concurrency circumstances. That left the workspace pointing to the changeset 0 and created files plastic.wktree.bak and plastic.changes.bak inside the workspace metadata folder ($workspace_root/.plastic).

Using different Plastic clients concurrently (e.g. Plastic GUI, cm CLI, Visual Studio Plugin or Unreal plugin) increased the chances of hitting this issue.

This happened because we handled the abort exception as an actual problem reading the workspace tree. Now it's fixed.

macOS - Plastic: The new Code Review system now allows you to visualize comments located in revisions that aren't loaded in the code review window. For example, this happens when you checked in new changes to apply revision comments. That creates new revisions for those files in the same branch, which don't match the commented revisions. When this happens, we display a panel with three actions:

Diff revision with comments: Compares the commented revision (right side) with the base one (left side).

Last in branch: Compares the last revision in the branch (right side) with the base one (left side). This is what selecting a file in the changes tree does.

Diff with head: Compares the last revision in the branch (right side) with the commented revision (right side).

Please remember that the Code Review feature is still beta in macOS. Feel free to share your feedback with us!

Windows, macOS - Plastic: Checking in your changes will refresh the branch diff in opened code review windows now. This allows you to have the current information in your code review windows. Nobody likes stale data, right?

Windows - Gluon: The Checkin view didn't recalculate the diffs of the selected file after refresh. Now it does!

All platforms - WebAdmin: there were some aesthetic issues in the Performance section. When browsing with Firefox, the numbers were cut out. Now it's fixed!

All platforms - Command line client: We edited the 'cm pull hydrate' example explanation. It now highlights that this command introduces the missing data for all the changesets in a branch. Also, the 'cm pull' command now includes an example of how to hydrate a changeset.

All platforms - Server, Command line client, Plastic, Gluon, Unity3D plugin, Proxy server: We improved how Plastic (client and server) manages memory buffers. Our new changes will prevent Plastic from getting out of resources in its pools, also improving the response times under heavy load.

All platforms - Gluon: The Checkin view menu has a new item: "Checkout"! It will put locally changed items under explicit version control. For instance, if you right-click a locally changed item and select "Checkout", that item will checked-out from that moment on. Private files will become Added, etc. This menu item behaves like the one with the same name in the Pending Changes view of Plastic.

Windows - Plastic: The Branch Explorer highlights search results in yellow, with the focused result in orange. Because of a bug, the focused search result was losing its orange color after a refresh. Now it's fixed.

macOS, Linux - Plastic, Gluon, Command line client: Under some circumstances, move detection did not always work on *NIX systems. We could only reproduce this issue in Virtual Machines where the guest is one of these OSs, so you probably never encountered it - rest your mind knowing that it is fixed. Now let's dive into the details:

Let's say that you have the following workspace configuration:

Now you move fileA.txt to fileE.txt. We will have this scenario:

We want to know if fileA.txt is actually fileD.txt or fileE.txt (or even neither of those), so we need to compare [A <> D] and [A <> E] to determine that. Once we determine through comparisons that A and E are the same file with different name, we have enough information to have this scenario:

...and in an ideal world is that easy. But now imagine that we have thousands of private files. We can't compare A with those thousands of files to determine the local move operation fast enough. So, in order to reduce the number of files we need to compare against, one of the filters we apply is the timestamp of the file. And if we lose timestamp precision because of the underlying File System in any of the operations involved, move detection breaks! Now, it is fixed.

All platforms - Server: ChannelCall incorrectly printed sec:none after the first method call with SSL.

In the ChannelCall log, after a connection attended the first request, next ones printed this:

The sec:none bit was not correct because they were indeed SSL calls. Now it is fixed!

(This was NOT a security issue, just a log issue!)

Windows - Gluon: Added the embedded diff viewer in the "Checkin changes" view.

When you select a file in the "Checkin changes" view, the differences appear in a panel at the bottom of the window (or the file content, when it's an added / moved / deleted file).

These are the file formats supported by the viewers:

Semantic diffs for supported languages

Binary diffs (we display the file metadata).

Windows - Plastic: When there is no item selected in the pending changes view, we display the following improved empty state:

All platforms - Command line client: We changed the usage of the "cm update" and "cm partial update" commands to make clearer which arguments are optional (i.e. those that can be omitted).

All platforms - Command line client: Now you can just run "cm update" to update the full workspace. The workspace root path is no longer needed. You don't need lines like "cm update $wk_root_path" or "cm update ." anymore.

All platforms - Plastic: We improved how the merge operation solves multiple directory conflicts. Before these changes, any conflict that Plastic SCM couldn't apply caused the operation to stop. Now, the merge will continue solving any remaining conflicts.

Additionally, the operation retries all failed conflicts at the end. Directory conflict resolution might fail because it depends on another conflict resolution. That's why it makes sense to try again, so Plastic can smoothly apply it at the end.

This merge has 2 conflicts:

Move evil twin conflict: /Windows/settings/Center.xml

Move/Deleted conflict: /Windows/settings/Center.xml

Before this improvement, first you needed to resolve the Move/Deleted conflict in order to choose source as resolution for both. Now you can resolve both conflicts at the same time.

All platforms - Server: We noticed that our trunkbot kept notifying that there is no CI system configured if you skipped that step during setup. This happened for every processed branch. That's annoying! You don't really need to know that something did not run if you explicitly configured it that way, right? Well, we fixed it!

All platforms - Plastic, Command line client: Some complex merge cases failed, showing errors like the following: The item '/bdwgc/cord/tests/de_cmds.h' cannot be restored because it had changes in it when it was deleted. Please undo the pending changes and repeat the merge without pending changes or with another conflict resolution.. This happened even though there were no pending changes before starting the merge. Now it's working.

This is a sample scenario that reproduced the issue:

The error appeared when you chose to keep the source contributor for all directory conflicts.

All platforms - Plastic, Command line client: Some complex merge cases failed, showing errors like the following: The following merge operations cannot be applied: M "c:/tmp/SCM14918/boehmgc/cord/tests/middle.c" "c:/tmp/SCM14918/bdwgc/cord/tests/middle.c" - Error: "Item cannot be moved because it cannot be found."

We fixed that. This is an scenario that reproduced the issue:

The error appeared when you chose to keep the source contributor for all directory conflicts.

All platforms - Server: Some complex merge-to cases failed, showing errors like the following: Can't add an entry with the same name. Duplicated child [head.png]. Parent [art]. Now it's fixed.

The error appeared during the merge-to resolution when you chose to keep the source contributor for all directory conflicts.

Windows - Plastic: After resizing the Plastic window, sometimes the diff scroll was unable to reach the textbox botton, due to a scrollbar metrics issue. Now it's fixed.

Command line client: have you ever wanted to see the status of your cloaked items using the CLI? Of course you have. And now you can! Use the new "--cloaked" flag of "cm status".

The normal status output denotes cloaked items with Cloaked. The machine readable output denotes this items with CL.

Command line client: We added a new code, "HC", to the machine-readable output of "cm status". It denotes files or directories included in the hidden_changes.conf filter.

All platforms - Plastic: Diff failed with no-data replicated branches.

You replicate a branch with no-data and then the diff failed because it wasn't able to locate the original data.

Back in 8.0.16.3046 we made improvements in the diff to avoid showing "empty contents". It was a concurrency problem. Unfortunately, we broke the diff for nodata (data not downloaded to the repo, only metadata) and it refused to show the diffs loading missing contents from the original server.

Windows - Plastic: After disabling and re-enabling a button in the GUI, the icon color could denote that the button was still disabled. This color remained until an application restart. Now it's fixed!

Windows - Plastic: If you tried to close the Sync view while it is loading, it could make Plastic to crash and close. Now it's fixed.

Windows - Gluon: Incoming changes: The tool now converts pending changes into checkouts before calculating the incoming changes. This allows detecting the files in conflict with your current changes.

Unity 3D plugin - Gluon: Incoming changes: the 'Incoming changes" view is now complete! It allows you to solve file conflicts when there are new changes in conflict.

The "Resolve Conflicts..." context menu is now enabled. Now it is possible to resolve conflicts in assets individually.

An asset will be in "conflict" state when you have local changes in an asset, and somebody else created a new revision of the same asset in the repository on the same branch you are working on.

REMARK: Only available in Gluon mode!

This feature is experimental. You need to manually activate it by adding the following line to the client.conf configuration file.

On Windows, it is at %LocalAppData%\plastic4\client.conf:

Command line client: Improved the cm find examples by adding some missing double-quotes to avoid errors when running the command on macOS and Linux.

All platforms - Plastic: The Incoming Changes operation sometimes left writable Xlinks as checked-out. This issue affected only Xlinks that pointed to a different changeset but without changes inside.

How did it happen? Let's assume that our workspace is loading the cs:5 with and we have a xlink at /doc.

Add the new file /doc/new.c and check it in (cs:6).

Remove the file /doc/new.c and check it in (cs:7).

Switch to the original changeset cs:5.

Run the Incoming Changes operation to update the workspace to cs:7. Then, the xlink /doc appears as checked-out without changes.

All platforms - Plastic, Command line client: Fixed the order in some checkin steps that caused issues when a before-checkin trigger modified files in the workspace.

If this before-checkin trigger modified files in the workspace, these files were incorrectly detected as modified only AFTER the checkin.

This is because the workspace metadata got calculated before trigger execution, when it should be done just after it, in order to consider possible content changes.

macOS - Plastic: The Code Review is finally available for macOS users!

We still have some things to implement, but you can start using it in your day to day.

You can access the code reviews from the sidebar.

Creating a code review is as easy as one-two-three. Just right click a branch, and select "New Code Review for this branch...". It also works for changesets, both from the Branch Explorer and from the Query views.

Once you open a new code review, you will see the following warning in the window:

It reminds you that the feature is still in beta (so be patient if you find some rough edges!). Clicking the link redirects you to a blogpost where we keep an updated list of the Code Review restrictions in macOS - a list we hope to shorten fast.

Learn all about Code Reviews for macOS here: Code Review now available for macOS.

All platforms - Plastic: A few releases back, we changed the default path of the Branch Explorer configuration file. It is now inside the .plastic directory, and it's name is plastic.branchexplorer (to match the naming of the rest of the files already there).

Now that the Branch Explorer configuration exists per workspace (instead of a unique file affecting all the workspaces in your machine), it is time for the global Branch Explorer configuration to be per repository server, and then per repository (instead of a unique file affecting all the workspaces in your machine!)

You see, until now the global BrEx configuration gets loaded only from the allrepos directory in your default repository server's Global Configuration. This made sense when said configuration affected all of your workspaces - you wouldn't want BrEx configuration coming from other repository server different than your default one (what a mess!) But now it is natural (and possible) to design global configuration per repository.

Bear in mind that in the global BrEx configuration you can only define Filters and Conditional format rules. These filters and format rules are merged with your local ones when the global configuration gets downloaded. You can't still distinguish the origin of each rule though (global or local configuration), so there is still room for improvement.

The search path for the Global BrEx configuration is as follows (to support the legacy location, and the new possibilities). The first configuration file found is the one that will merge with the local one.

Until this release, the client looked for the file only in 3.2 and then 3.3.

We recommend using the new name plastic.branchexplorer!

With an specific example, imagine that your current workspace is pointing to awesomeproject@remoteserver:9095, but your client is configured against localhost:8087. When opening the workspace in a GUI, the Branch Explorer global configuration file search path will be as follows:

Windows - Gluon: Incoming changes: we improved the check to determine if there are new changes available in order to show the notification bar only when there is any change that can be applied (e.g: the moves which cannot be applied are now filtered).

Windows - Plastic: Fixed two issues in the new Code Review System:

.NET files (C#/VB.NET): When navigating to a comment, if the source file had code regions, they were collapsed by default. When this happened, the selected comment was lost.

.NET files (C#/VB.NET): Sometimes, when navigating to a comment, the source file was not correctly scrolled to the line the comment was inserted. Now it's fixed.

All platforms - Command line client: The Incoming Changes displayed the message "Merging file 1 of 1: README.txt" twice for each merged file. The second message should be the merge result, so we changed it accordingly.

If the merge is complete, you'll see this:

If you cancel the merge (i.e. exit without saving), you'll see this instead:

All platforms - Gluon: The update operation could wrongly load a file/directory from a xlink inside its parent xlink. For this to happen, some kind of Plastic internal ids matching was needed (the item id of the revisions loaded by the xlinks should match)

Let's see an example of what could happen.

Having the following structure in the server tree:

After the workspace update, the file 'texture_A.01' would be loaded under the parent xlink '/game' instead of under the proper xlink '/game/content/textures'.

All platforms - Gluon: The updade operation didn't download the new items when they were located directly under the xlink and the xlink was changed. Fixed.

All platforms - Plastic, Gluon, Server, command line: Now the socket connect has a default timeout of 3 seconds, to avoid waiting forever on unreachable servers.

Timeouts are good to avoid waiting forever when you have network issues.

Now, if you try to reach an unreachable server that has a valid address, instead of waiting for 20 seconds (on Windows) it will throw an error in 3 secs:

== How to configure ==

Default is 3 seconds, but you can configure it in several ways.

For plasticprotocol (the default) just edit client.conf and/or server.conf (only if you have timeouts during push/pull) and add a new integer value with the following key:

The value is in milliseconds. If you set it to 0, it will be an infinite timeout.

In case you are using remoting, edit your remoting.conf file (valid for client and server) and add timeoutMilliseconds="4000" as follows:

All platforms - Server and all clients: Improved DNS name resolution during socket creation.

We've been working on introducing timeouts during socket connect. After doing that, we detected some issues during internal testing, where some connections timed out when they didn't before.

This was because the BeginConnect we use to do the async is internally doing some wrong stuff with name to IP resolution. Framework code that sometimes doesn't work as expected. Anyway, we introduced some fixes so we now avoid unneeded translations when the name is already an IP, and we also cache resolutions (not needed normally, but when the underlying network has some glitches, and we saw it with VMWares we use, it can happen).

Windows - Gluon: Incoming changes: the notification bar for the new 'Incoming changes' view is now available.

When you are working in a single branch with other people, it is common to find they have checked in new changes.

When this happens, Gluon will notify you on the top-right area of the window.

Scenario 1: You have no pending changes and new changes from other users appear. Gluon will show you a green notification in order to allow you to see the changes in the Incoming Changes view, and update to them.

Scenario 2: You have pending changes. New changes from other users appear, but they don't affect any of the files you have changed. Gluon again will show you the green notification for the same purpose.

Scenario 3: You have pending changes. New changes from other users appear, and there are changes in files that you have also changed. In this case you need to merge these changes. Gluon will show you a red notification in order to allow you to see the conflicts in the Incoming Changes view, and resolve them.

This is how the Scenarios 1 and 2 look like:

And this is how the Scenario 3 looks like:

You can see it working here:

This feature is experimental. You need to manually activate it by adding the following line to the client.conf configuration file.

On Windows, it is at %LocalAppData%/plastic4 folder:

Windows - Plastic: Workspace Explorer navigation was slow because every key hit triggered a network call.

Each time you selected a file in the Workspace Explorer, with the mouse or the keys, it wrongly triggered a network call to retrieve the global config and find external actions to add to the context menu.

It happened for branches, labels and changesets too.

We fixed it and now the external tools are only loaded when you switch workspaces, so navigation with keys is smooth again.

All platforms - Command line client is now able to do Incoming Changes both with cm update and cm checkin.

== How it looks like during update ==

== What if there is a directory conflict ==

== During cm ci --update ==

Remember, the Incoming Changes is an experimental feature. It allows you to get the latest changes from the server, rebasing your pending changes on the process. You can see how it works at: Single branch workflow improvements: announcing Incoming Changes

To enable this feature, simply add the following line to your client.conf configuration file:

Command line client: cm update was failing to show the animated progress bar when the selector was pointed at a branch rather than a changeset. For example, when updating a freshly created workspace for an existing repository. This is now fixed.

All platforms - Server: Fixed a null error during the exclusive checkout (lock) operation. It happened under not very clear conditions when the working branch was not valid (it doesn't appear on the branches view nor in the Branch Explorer).

Windows - Plastic: Views that for whatever reason failed to load left the GUI in an inconsistent state. It prevented you to open any other views. You had to restart the GUI and hope that the view initialization error didn't appear again. That's gone for good!

Windows - Plastic: Sometimes you got an warning message telling you that the view state coudln't be saved in guivisualstate.xml. That usually happened when any of the views failed to load on startup. We protected that issue: views that failed to load simply won't have their status saved.

Windows - Plastic: The "Recent workspaces" menu (the one that appears in the top left corner) used to contain the current workspace. That's not really useful, is it? We changed the menu so it will never contain the current workspace. Less noise to worry about!

Windows - Plastic: Improved Pending Changes UX. After deleting a file, the view was refreshed and the selection was lost. Now, when a file is deleted, Plastic selects the closest file in the list.

All platforms - CLI, Plastic: The update operation couldn't download files when there was a directory in the target path. Likewise, the operation wasn't able to create directories when files existed in the target paths. Now it's fixed.

Windows - Plastic: The new Code Review now sorts changesets by date when reviewing changeset by changeset. Before this fix, the changesets were sorted by their Changeset Id. This lead to an incongruent changeset list under scenarios involving replication.

When replicating changesets, an older one can have a Changeset Id higher than a newer one. This is because the Id is not replicated - the server assigns the Ids in a "first-in, first-served" fashion. Using the old sorting method, an old changeset could appear after a newer one, making review difficult.

Windows - Plastic: The comment text in the code review window never displayed the vertical scroll bars. This was problematic because you wouldn't know you could scroll down unless you tried it out. Now you'll see those scroll bars in the comment text box when the comment text is too long to be displayed in the text box.

All platforms - server: The bundled mergebots couldn't handle submodules. You know, repos named like mainProject/assets or newGame/tools/releaseBuilder. URIs with encoded parameters (e.g. http://my.plastic.server.net/api/v1/repos/mainProject%2Fassets/branches/main) aren't allowed by default in .NET Framework 4.0 or older, so the mergebots couldn't retrieve the information they need from the server. We had to walk around that. It's all good now!

Windows - Plastic: Fixed merge-to diff menus that we broke in 8.0.16.3749.

Back in 8.0.16.3749 we broke the diff context menus when doing a merge-to.

We also cleaned up the old code, and made sure when you do diff src and dst in merge-to, the dst stays on the right, like you would expect. It went to the left before.

All platforms - Plastic: Merge-to does not checkout local changes incorrectly anymore.

When we released 3673 we made merge calculation to apply local changes (a.k.a. checkout). But we incorrectly did it for merge-to, which doesn't make sense because your local changes are not involved at all in the merge.

Windows, Linux - Plastic: We made the server combo box on the repository (and Cloud) view wider, so it shows long server address without truncating.

All platforms - Plastic: Did you run into some cryptic error messages such as "find is not supported for object '19'" or "The method CreateCodeReviewComment is not supported"? It's likely coming from your outdated server! It doesn't support the new code review comment, but your shiny, up-to-date client does. We improved that so the client will output readable messages to let you that you need to upgrade your server.

Windows - Gluon: Incoming changes: the context menu for the new 'Incoming changes" view is now available.

It allows you to perform the following operations:

Merge selected conflicts.

Merge selected files keeping source.

Merge selected files keeping destination.

Diffs yours with incoming.

Diff incoming changes.

This feature is experimental. You need to manually activate it by adding the following line to the client.conf configuration file.

On Windows, you can find it in %LocalAppData%\plastic4\client.conf:

All platforms, Server: We made the server more robust by fixing a couple of potential problems when timeouts happen.

Now, if the server detects a timeout while reading a request, it will close the connection. Before this change it kept the connection open and continued reading - which could lead to strange readings and logs. Not critical, but it is better now.

The server could abandon connections that could stay idle until the client closed them. Now this is fixed. We are not sure this was ever find in production.

All platforms - Plastic & Gluon: Diffing files with an external tool is now faster. This applies to diffing 2 revisions of a file from the item history, file conflicts during a merge…

This boost in performance comes from optimizing server calls. There was one in particular that could take even a few seconds when working with big trees (i.e. more than 100k items) in a server that uses a SQL-based backend. The server doesn't execute those calls anymore in this scenario.

By the way, we recommend you to migrate your SQL backend to our Jet backend! It's really faster and our recommended choice. Take a look at 'The story of Jet: Plastic's super-fast repo storage'.

Windows - Plastic: We improved the 2D revision tree for revisions added in merge sources. Those displayed blank diagrams, not very useful. They'll now load the added revision and its related changes, just like any other revision in the merge!

All platforms - Server: Socket receive timeout now defaults to 10 seconds.

In case you need to change it: edit remoting.conf configuration file located in the server directory and make sure your line looks like this:

To increase to 15 seconds: socketReceiveTimeout="15000"

To make it wait forever: socketReceiveTimeout="-1"

We added this to make the server more robust in case of connection problems.

All platforms - Plastic & Gluon: The embedded diff/content view in the Pending Changes View sometimes failed with the error Cannot download revision XXX from server: Data cannot read/write to Plastic Cloud. There was an authentication issue.... The error appeared when you changed the selected change, which triggered the diff/content refresh. It happened if your workspace pointed to a cloud repository and you kept open the Pending Changes View for 1 day or longer.

Windows - Plastic Proxy: When you upgrade the Proxy using the installer, it removes the old version before copying the new one. But it was removing configuration files by mistake too! In particular, plasticcached.conf, plasticcached.remoting.conf, and plasticcached.remoting.conf . This caused losing settings such as the cache size or directory. It is now fixed!

All platforms - Server. SQL backends: Checkin operations could fail with the error The object is currently locked.... It appeared when you or another user interrupted a checkin operation previously (e.g. killing the Plastic client) in the middle of the confirm step. This happened because the server couldn't detect the original operation as abandoned. Now it's fixed.

The same problem could also affect replication operations.

Oh, and by the way, this error only affects server versions 8.0.16.3766 or higher.

Windows - Plastic: We disabled the two history-related items in the workspace explorer context menu, applying only to added items. It doesn't make a lot of sense to display the history of items you are about to add, right?

Windows - Plastic: Improved how we draw the selected comments in the new Code Review system.

Now, when you select a comment, the textbox draws a selection mark around the commented lines. Note that at the moment we only support single-line comments, but we'll support multi-line comments soon.

Command line client: we improved the warning message when an operation can't run because another operation already locked the workspace - it now tells you which operation is locking the workspace.

This is the old message:

And this is the new one:

Windows - Gluon: Incoming changes: the new 'Incoming changes" view is now complete, so it allows you to preview, download and solve file conflicts when there are new changes.

This feature is experimental. You need to manually activate it by adding the following line to the client.conf configuration file.

On Windows, it is at %LocalAppData%\plastic4 folder:

All platforms - Server: We added some new extensions to the default lock rules. We also tweaked a little bit the WebAdmin's Lock Rules webpage to better explain how global lock rules apply to repositories.

Windows - Plastic: Did you notice that you couldn't display the contents of added/deleted items in a merge preview? Well, this update will put that inconvenience in your rearview mirror. You'll notice that the "Diff ancestor with source contributor" item is now enabled in the merge view for those added/deleted source conflicts. Clicking them will display the revision contents in a new window.

This applies to the Incoming Changes view, too. The menu item title changes: it's "Diff incoming changes" instead.

Windows - Plastic: Some customers asked for a way to show the old code review window when opening a code review. This is now possible by adding a --oldcodereview argument to the Plastic GUI application:

Windows - Gluon: The History and Undelete panel tables didn't have the appropriate styles applied to them. Fixed!

All platforms - Client: We fixed the error "Can't add an entry with the same name" that could happen in operations that apply local changes. That might be the checkin, undo changes, or explicitly apply the local changes (convert local uncontrolled changes in checkouts).

The issue happened when you locally moved a directory with one of their children checked out, and you locally moved another controlled file in the new destination of that checked out file.

Let's see an example. Add the following structure, each file having different contents:

Now, checkout file /dirA/file3.txt:

Then, rename dirA to dirB outside Plastic. If you're using the Windows command prompt, this is what you'd type:

After that, take the controlled file /file.txt and move it (using the shell or Explorer, not Plastic) to overwrite /dirB/file3.txt (which used to be /dirA/file3.txt and is checked out):

Finally, run a global undo operation:

At this point, the command above failed with the mentioned error "Can't add an entry with the same name".

Please note that this issue happened while the command tried to apply the local changes to convert them to controlled ones. So, the same thing could happen if you right-clicked these changes in the Pending Changes view and clicked "Checkout" in the popup menu.

All platforms - SCC Plugin: Good news! Our SCC plugin now supports logging the checkin results in your configured issue tracker.

This was detected by a customer using PowerBuilder, so we can now proudly say that PB can log the checkins through SCC :-)

Windows - Plastic: increased the default width of the code review window. This way the controls aren't drawn on top of each other.

Windows - Plastic: fixed the vertical alignment of the label of the filter on the code review window.

Windows - Plastic: fixed "unable to cast object" error that appeared when choosing "Only relevant" on the 2D history view.

Windows, Linux - Proxy: Added a few extra protections to the code to avoid deadlocking while downloading data.

We increased the size of the buffer pool we use to download data, because we suspect it can be creating a deadlock. We are not 100% sure but we saw a proxy stalled and so far this is the only reason we can think of.

Windows - Visual Studio Package: Checkin failed when there are NuGet packages outside the solution directory. This could happen with Visual Studio 2019. Now it's fixed.

Linux, Windows - Proxy: Protected the new timers controlling cache clean up from unexpected exceptions.

We detected a bug in our internal proxy when one of the new timers (introduced a few releases ago to support auto-cleanup) threw an exception.

We are more used to threads than timers, and we didn't protect them correctly.

Unity 3D plugin: The plugin now propertly deletes local, private assets.

If you want to know more about this: the underlying Version Control needs to delete private/local assets starting on Unity Editor 2019.X. Older Editor versions are still compatible with this plugin version.

Windows - Plastic: We improved the look and feel of the comment icons in the Code Review bar. Hovered or selected comments weren't visible enough. Now you'll notice how comment icons change when you select them or you hover the mouse cursor over them: they'll grow larger and get a thicker, double-lined border.

This is the aspect it has:

As you can see, you can disable this starting Plastic GUI with the --cr-disable-high-contrast-colors flag:

Windows - Gluon: Incoming changes: There's a new view called "Incoming Changes". It previews what Gluon needs to download.

This new view will eventually allow you to preview, download, and solve file conflicts when there are new changes.

Right now this feature only does the first stage: previewing. To see its power in action, stay tuned for upcoming releases!

This feature is experimental. You need to manually activate it by adding the following line to the client.conf configuration file. On Windows, it is at %LocalAppData%\plastic4 folder:

Windows - Plastic: The discarded Change Requests in a code review no longer appear in the "Close change requested in review" combo-box in the Pending Changes view.

All platforms - Gluon: The update operation handles better the moved changes in the following ways:

Mark has the file /action/member.c checked-out in the workspace.

Steffy moves the file from /action/member.c to /animation/member.c and check it in.

Mark runs an update and Plastic properly applies the movement, so he has /animation/member.c checked-out now.

Steffy moves in her workspace the file /action/member.c to /animation/member.c but she doesn't check it in.

Mark modifies the file /action/member.c and checks it in.

Steffy runs an update and the new revision of member.c is updated at her moved location /animation/member.c.

Before this improvement, the update just showed an error saying that Plastic can't apply the operation and updated nothing in the workspace. Now, it just makes it :)

All platforms - Server: Fixed a deadlock issue using an SQL backend. This deadlock happened on really corner scenarios under heavy load.

Windows - Plastic: Sometimes, in the new Code Review system, the 'Review Comments Summary' appeared empty even though there were comments in the review. Now it's fixed!

Windows - Gluon: Some buttons ellipsized their captions if the text was long enough. This issue particularly hit those who use Gluon with Japanese localization. The GUI didn't calculate the button width correctly because the default font in Japanese is different from the one used in Western languages. Now it's fixed! A special shout out to our friend Hiroaki Nakano for letting us know about this problem.

All platforms - Server: Fixed an issue with trigger filters where it was necessary to append '*' to the filter for it to work with repositories.

For example, the trigger...:

...is now equivalent to...:

...without the ",*" at the end.

macOS - Plastic: The annotate view didn't disable the navigation buttons while the navigation operation ran. This left the door open to null reference errors if you clicked the navigation buttons quick enough. Not anymore!

Linux - Plastic: The annotate view didn't disable the navigation buttons while the navigation operation ran. It does now, so it's consistent with the general behavior of the GUI when any operation runs.

All platforms - Server (Jet backend): The server will now upgrade any outdated repository database on its startup stage.

This could happen in the following scenario:

Create a backup of a repository database.

Upgrade the Plastic Server to a newer version.

Finally, replace the repository database with the backup.

All platforms - Server (Jet backend): Now the server upgrades any repository database added using cm repository add command.

Before this release, the Plastic Server couldn't use an added repository when it was out of date.

All platforms - Server: We added triggers for object removal events!

The goal is that you can set-up scripts to run automatically before and/or after objects are deleted. The objects handled are branches, changesets, labels and attributes. This is the complete list of new triggers:

The Plastic trigger mechanism sets environment variables whose values you can use in your script.

For branch deletions, use the trigger type rmbranch. It sets the following:

PLASTIC_BRANCH_NAME: The name of the branch

PLASTIC_FULL_BRANCH_NAME: Name including parent

For changeset deletions, use the trigger type rmchangeset. It sets the following:

PLASTIC_BRANCH_NAME: The name of the branch

PLASTIC_CHANGESET_NUMBER: Number of the deleted changeset

PLASTIC_CHANGESET_OWNER: Owner of the changeset

For label deletions, use the trigger type rmlabel. It sets the following:

PLASTIC_BRANCH_NAME: The name of the branch

PLASTIC_CHANGESET_NUMBER: Number of the labelled changeset

PLASTIC_CHANGESET_OWNER: Owner of the labelled changeset

PLASTIC_LABEL_NAME: The name of the label

For attribute deletions, use the trigger type rmattribute. It sets the following:

Additionally, all the new trigger types set the following variables:

PLASTIC_USER: The current user name

PLASTIC_CLIENTMACHINE: The machine name

PLASTIC_SERVER: Server address

PLASTIC_REPOSITORY_ID: The repository id

PLASTIC_REPOSITORY_NAME: The repository name

PLASTIC_COMMENT: The object's comment

Windows, macOS - Plastic: We improved how the Merge View displays the controlled errors. Before it did so using modal alerts. Now the errors are in a text view.

macOS - Plastic: This release (8.0.16.3760) has a known bug in the Plastic GUI client for macOS.

When annotating a file, the annotate history navigation buttons are always enabled, even if they shouldn't.

This causes an exception when navigating before the first annotate, or after the last one.

If you encounter this issue, to close the annotate sub-view just launch a new annotate or browse the history of any file.

This issue will be addressed in the next public release.

macOS - Plastic: If there was an error refreshing the Pending Changes or the Merge views, it appeared over and over. Now it's fixed!

Windows - Plastic: The Merge View's error messages had a wrong background color. Now it's fixed!

Windows - Plastic (Cloud Edition): The Welcome dialog didn't look good in screens with DPI scaling enabled. Now it's fixed!

Windows - Plastic: When there are no comments to show in a Code Review, we showed a message... that was not in perfect English. Now it's fixed!

All platforms - Plastic: The Incoming Changes notification didn't appear if you had pending merge conflicts to resolve. Now it's fixed!

Imagine the following scenario:

You are working with other teammates in the same branch.

You changed two files: foo.c and bar.c. The Incoming changes notification will appear, warning about conflicts in those two files.

You open the Incoming Changes view and resolve only one file. Then you close the Plastic GUI.

When you reopen Plastic, you can't see the Incoming Changes notification. Now it's fixed!

Linux - Plastic: Fixed an issue where navigating rapidly through the annotations of an item and its parents could cause an unexpected error.

All platforms - trunkbot: We felt that your life would be easier if the trunkbot could define the expected status attribute values as the list of default values. So, we did that! The trunkbot will write a new line defining that list of default values when it creates the status attribute. Remember: this only happens if the status attribute doesn't exist on bot startup. The trunkbot won't update comments of existing attributes.

All platforms - multilinerbot: Just as we did with the trunkbot, we improved the multilinerbot so it write the list of expected status attribute values as the list of default values for the status attribute. Remember: this only happens if the status attribute doesn't exist on bot startup. The multilinerbot won't update comments of existing attributes. Oh, and this just applies to the status attribute, not the one to define the merge destination branches!

All platforms - Command line client: We improved the update command startup time. Empty or small updates are now 14% faster than before.

All platforms - Command line client: We added the option '--skipchangedcheck' to the update command. The update checks for pending changes before starting. This option skips looking for locally changed files. This way you will save time using this option if you always checkout the files before you change them.

Windows - Plastic: the focus is now correctly set on the server field of the configuration panel when launched using "plastic --configure"

macOS, Linux - Plastic, Gluon: We unified the contextual menus in the Pending Changes view as much as possible - both for Plastic and Gluon. Now finding the features you use the most is easier when switching applications.

But this change brings other goodies too! For example, now you can check a file's history, and annotate it, right from the Pending Changes. We also added support to change cloaked.conf in Plastic, and hidden_changes.conf in Gluon.

Remember that Gluon and partial workspaces don't consider cloaked.conf file. That's why you can't configure it from Gluon.

macOS - Plastic: The Incoming Changes is now available for macOS! Check the "Announcing Incoming Changes" blogpost!

macOS - Plastic: The GUI now shows a notification in the toolbar when the changeset you are working on no longer exists. This can happen if a colleague deletes that changeset.

This helps users returning to a valid configuration by updating the workspace. The notification looks like this - click on "Update" and you are good to go!

macOS - Plastic: We improved the message for the Incoming Changes view. It now explains that you only need to update the workspace to synchronize the metadata when your changes match the ones in the new head of the branch.

macOS - Plastic: We added a tooltip in the notification bar for the incoming changes to explain the current scenario.

The available scenarios are:

There are new changes in the branch that you can preview and download.

There are new changesets that conflict with your current changes.

The changeset you were working on no longer exists. Click the "Update" button to return to a valid configuration.

All platforms - Gluon: removed "Show hidden files" from the check-in options, since it is only relevant to Plastic.

All platforms - Plastic, Gluon: The Similarity Percentage slider (in Pending changes -> Options -> Move detection) now correctly disables when the Find Moved option is deselected.

All platforms - Server: On-premises servers now support global lock rules! Bear in mind that global lock rules will be used for all repositories unless there are repository-specific rules that apply to them. They aren't merged, but replaced!

So, if you'd like to override the global lock rules for one of your repos, simply create lock rules for it. If you leave them empty, no rules will apply.

All platforms - WebAdmin: We added a new block to store the global rules. And now you'll have auto-complete features to enter the repository names for repository-specific rules! Isn't that nice?

All platforms - Proxy server: We added the caller IP and user name in the log line after the GetObjectsData call. You can now see who's causing trouble!

Now the log is as follows:

Windows - Plastic: The annotate pane could end up misaligned with the code pane by up to a line due to the way we were synchronising the two panes. We changed the way we do this, and now we have pixel-perfect alignment.

Windows - Plastic: fixed a bug in Cloud Edition where issue tracker settings were not being saved correctly.

All platforms – Proxy Server, Client: Fixed an issue downloading data from the cloud that impacts the performance. The issue was introduced on the release 8.0.16.3725. If you are using the release 8.0.16.3725, please upgrade.

All platforms - Client, Server: The Incoming Changes operation sometimes left writable Xlinks as pending changes. This issue only affected Xlinks with more than one expansion rule. It took place when the server changes contained the first changes in the current branch under the Xlink.

All platforms - Plastic, Command line client: The client didn't detect Xlink deleted-changed conflicts in some merge scenarios. This happened when the current user had pending changes under a Xlink in their workspace. Additionally, the source contributor had deleted it. Now the Plastic clients do detect the conflict.

All platforms - Plastic, Command line client: The merge operation failed in a complex scenario. It involves merges whose source changes modify the Xlink path. At the same time, the merging user has pending changes in their workspace under that Xlink.

This is an example scenario that reproduced the issue:

First, Alice is working in branch '/main'. She renames the '/physics' directory to '/effects' and adds a writable Xlink. She checks in these changes.

Then, Beth checks out the file '/physics/water.cs' in her current workspace.

Finally, using the same workspace, Beth starts a merge from '/main' into her current branch.

At this point, the merge operation failed with this error message: "Item 55 could not be found...".

All platforms - Server: The Incoming Changes operation left the previous version as deleted when you replaced a Xlink in the server. Now it's fixed.

All platforms - Proxy: It is now able to monitor free space on disk and clean up the cache to avoid running out of disk.

You'll see something as follows in the log when it runs out of disk:

And, if there is enough room (twice the size of the cache) then something as follows:

All platforms - Plastic Proxy: Implemented a disk cache limit.

Now the proxy can limit the size of its on-disk cache.

== How to configure ==

Very easy: last use the new MaxCacheSizeInGb in the plasticcached.conf file.

And the Proxy will make sure its cache size doesn't exceed 20.5 Gb.

A value of 0 means the clean is disabled.

The Proxy maintains a LRU (Least Recently Used list) and updates it on every data access.

Every 10 minutes, it checks if the total cache size is bigger than the value configured. If the maximum size is exceeded, the Proxy retrieves the least recently used entries and removes them from disk.

Every 3 minutes the Proxy saves the LRU info to disk. The LRU data is written to proxy-data-path/proxy-lru.dat. The data is also written on shutdown.

On startup and then every 8 hours, the Proxy checks if it needs to walk the entire cache directory to rebuild the LRU and recover from possible inconsistencies. While the check runs every 8 hours, a rebuild will only happen once every 3 days. The date of the last rebuild is stored under proxy-data-path/proxy-last-cache-walk.dat.

proxy-data-path is the directory where you configured the proxy to store the cache.

For existing Proxy installations, the new version will rebuild the cache on the fly.

During the startup of the Proxy you'll see:

You can see how the Proxy skips the rebuild and how it loaded 107k entries to the LRU.

Then, every 3 minutes, and during shutdown:

And during a clean up:

DevOps: ConflictsBot was useless with MergeRules enabled (they are available since release 8.0.16.3433).

From now on, ConflictsBot will be able to report merge conflicts again at earlier stages. (The fix is to skip the MergeRules check in the underlying dry-run merge operation the ConflictsBot runs).

All platforms - Plastic, Command line client: in the debug log for an update, the metadata download and processing times were incorrectly calculated. This has been fixed.

All platforms - Checkin & Update: Multi-thread checkin and update enabled by default now.

Plastic can be super-fast, but historically we were to shy enabling the full power by default. But, smart defaults are key for usability, because nobody wants to dig into config files. So, that's what we are doing now.

Plastic uses a pipeline to checkin as fast as possible. There are 3 phases:

By default, each phase uses one thread, so the checkin is always multi-thread.

But, using fast disks (typically SSD and beyond), everything can be done faster using more threads in each phase.

The new defaults are:

Read from disk. Controlled by UploadReadPoolSize in client.conf = 2

Compress data. Configured by UploadCompressionSize in client.conf = 2

Send data. Configured by Upload_SendDataThreadCount in client.conf = 3

Remark: The old defaults are written to client.conf on all installations out there, so this version will consider 1 as not configured, and will set the new values. In case you really want to force 1 thread, set these 3 values to zero. Yes, it is confusing, but we need to bypass the defaults, we'll remove this weird thing in one year or so when everyone is upgraded.

Update uses 1 thread to download and write. The setting is controlled by UploadReadPoolSize in client.conf and was set to zero by default. The default will be now 2.

All platforms – Proxy Server, Client: Added support to cache data from Plastic Cloud.

This is one of the long-awaited features for the Proxy: the ability to cache data from the Cloud.

And it is finally there. No changes required, just install a proxy (and your client too if you use encrypted data in the Cloud) and start caching data.

All platforms - Server: Replica data transfer can be 3 times faster now on fast networks.

In our tests, pushing 18Gb from a repo in Denmark to one in Oregon, went down from 30 minutes to 9. This is quite an speed up!

The key is using the multi-thread capabilities to make sure Plastic reaches the maximum network potential.

To enable multiple threads, set the ReplicaDataTransferThreads in server.conf. The actual number will depend on your environment. In ours, we saw an incredible speed up going from 1 (the default) to 8.

The process distributes the size of data to send evenly among the available threads, and that's the key to achieve a consistent improvement.

WARNING: do not use this with SQL backends, it is only safe to use with Jet.

REMARK: push/pull to Cloud was already multi-thread and is not affected by this task.

Here is sample output before and after:

Before: 2180860 ms = 36.34 min

After: 534750 ms = 8.9 min

All platforms - Plastic, Gluon: changes to the diff window comparison method {"Ignore EOL", "Ignore whitespaces", "Ignore EOL and whitespaces", "Recognize all"} are now persisted.

It used to be a bit annoying that when you changed the comparison method, that change would be forgotten as soon as you closed the diff, and you would have to change it again next time. That happened because we initialise the diff view with the global setting from Preferences -> Diff and merge. Now, changing the option in the diff window updates the global setting, so next time you open a diff you get your previously selected option.

Windows - Plastic: after failing to save an attribute value change, due to permissions for example, the GUI would be left displaying the wrong value. it now updated to show the correct attribute value in this case.

macOS, Linux - Command line client: we fixed an issue where the mutli-line progress for replication (clone, push & pull) would draw each frame of animation on a new line, rather than maintaining a fixed position in the console window.

Windows - Plastic: Incoming Changes. It failed when updating the filesystem protection of a file or directory. In the case of a file, it didn't fail if the content of the file was also changed. This filesystem protection change would come from a checkin in a Linux / macOs platform. Fixed.

The filesystem protection changes are skipped by the Incoming Changes at the moment. This will be supported in further releases.

Windows - Plastic: The counter labels in Merge and Incoming Changes views appeared cut in high DPI screens. Now they look fine!

Windows - Plastic: Some customers reported an error that prevent them from creating branches from the GUI. It seems Plastic can't access a file in the "Theme" folder. Now it's fixed.

All platforms - Plastic: We detected that working concurrently against the same workspace using different plastic clients (e.g. Plastic GUI, Visual Studio Plugin, Unreal plugin) could potentially break the workspace metadata under certain circumstances. That left the workspace pointing to the changeset 0 and created files plastic.wktree.bak and plastic.changes.bak inside the workspace metadata folder ($workspace_root/.plastic). Now it's fixed.

All platforms - Proxy: It is now able to monitor free space on disk and clean up the cache to avoid running out of disk.

You'll see something as follows in the log when it runs out of disk:

And, if there is enough room (twice the size of the cache) then something as follows:

All platforms - Plastic Proxy: Implemented a disk cache limit.

Now the proxy can limit the size of its on-disk cache.

== How to configure ==

Very easy: last use the new MaxCacheSizeInGb in the plasticcached.conf file.

And the Proxy will make sure its cache size doesn't exceed 20.5 Gb.

A value of 0 means the clean is disabled.

The Proxy maintains an LRU (Least Recently Used list) and updates it on every data access.

Every 10 minutes, it checks if the total cache size is bigger than the value configured. If the maximum size is exceeded, the Proxy retrieves the least recently used entries and removes them from disk.

Every 3 minutes the Proxy saves the LRU info to disk, to proxy-data-path/proxy-lru.dat. The Proxy also writes data on shutdown.

On startup and then every 8 hours, the Proxy checks if it needs to walk the entire cache directory to rebuild the LRU and recover from possible inconsistencies. While the check runs every 8 hours, a rebuild only happens once every 3 days. The Proxy stores the date of the last rebuild under proxy-data-path/proxy-last-cache-walk.dat.

proxy-data-path is the directory where you configured the proxy to store the cache.

For existing Proxy installations, the new version will rebuild the cache on the fly.

During the startup of the Proxy you'll see:

You can see how the Proxy skips the rebuild and how it loaded 107k entries to the LRU.

Then, every 3 minutes, and during shutdown:

And during a clean up:

DevOps: ConflictsBot was useless with MergeRules enabled (they are available since release 8.0.16.3433).

Now, ConflictsBot can report merge conflicts again at earlier stages!

The fix is skipping the MergeRules check in the underlying dry-run merge operation the ConflictsBot runs.

All platforms - Plastic, Command line client: Metadata download and processing times in the update debug log were not correct. This is now fixed.

All platforms - Checkin & Update: Multi-thread checkin and update enabled by default now.

Plastic can be super-fast, but historically we were shy enabling the full power by default. But smart defaults are key for usability, because nobody wants to dig into config files. So, that's what we are doing now.

Plastic uses a pipeline to checkin as fast as possible. There are 3 phases:

By default, each phase uses one thread, so the checkin is always multi-thread.

But when using fast disks (typically SSD and beyond) everything can be faster using more threads in each phase.

The new defaults are as follows. These configuration keys belong at client.conf file:

Read from disk. Controlled by UploadReadPoolSize. Default value is 2.

Compress data. Configured by UploadCompressionSize. Default value is 2.

Send data. Configured by Upload_SendDataThreadCount. Default value is 3.

Remark: The old defaults are written to client.conf on all installations out there, so this version will consider 1 as not configured, and will set the new values. In case you really want to force 1 thread, set these 3 values to zero. Yes, it is confusing, but we need to bypass the defaults, we'll remove this weird thing in one year or so when everyone is upgraded.

Update uses 1 thread to download and write. The setting is controlled by UploadReadPoolSize in client.conf and was zero by default. The default will be now 2.

All platforms – Proxy Server, Client: Added support to cache data from Plastic Cloud.

This is one of the long-awaited features for the Proxy: the ability to cache data from the Cloud.

And it is finally here! No changes required, just install a Proxy (and your client too if you use encrypted data in the Cloud) and start caching data.

All platforms - Server: Replica data transfer can be 3 times faster now on fast networks.

In our tests, pushing 18Gb from a repo in Denmark to one in Oregon, went down from 30 minutes to 9. This is quite a speed up!

The key is using the multi-thread capabilities to make sure Plastic reaches the maximum network potential.

To enable multiple threads, set the ReplicaDataTransferThreads key in server.conf to the number of threads you wish to use.

The actual number will depend on your environment. In ours, we saw an incredible speed up going from 1 (the default) to 8.

The process distributes the size of data to send evenly among the available threads, and that's the key to achieve a consistent improvement.

WARNING: do not use this with SQL backends, it is only safe to use with Jet.

REMARK: push/pull to Cloud was already multi-thread and is not affected by this task.

Here is sample output before and after:

Before: 2180860 ms = 36.34 min

After: 534750 ms = 8.9 min

All platforms - Plastic, Gluon: changes to the diff window comparison method {"Ignore EOL", "Ignore whitespaces", "Ignore EOL and whitespaces", "Recognize all"} now persist.

Before this change, you lost comparison method changes when closing the diff - you would need to change them again next time. That happened because the diff view loaded the global setting from Preferences -> Diff and merge. Now, changing the option in the diff window updates those global settings, so the next time you open a diff you get your previously selected option.

Windows - Plastic: The GUI displayed the wrong value for an attribute if it failed to save a value change (due to lack of permissions, for example). In this case, now the GUI recovers and shows the right value for the attribute, along with the error message.

macOS, Linux - Command line client: We fixed an issue with the mutli-line progress for replication (clone, push & pull). Sometimes, it would draw each frame of the progress animation on a new line, rather than maintaining a fixed position in the console window.

Windows - Plastic: The Incoming Changes failed when updating the filesystem protection of a file or directory. In the case of a file, it didn't fail if the content of the file was also changed. This filesystem protection change might come from a checkin in a Linux / macOS platform. Fixed.

The filesystem protection changes are skipped by the Incoming Changes now. This will be supported in further releases.

Windows - Plastic: The counter labels in Merge and Incoming Changes views appeared cut in high DPI screens. Now they look fine!

Windows - Plastic: Some customers reported an error that prevent them from creating branches from the GUI. It seems Plastic couldn't access a file in the "Theme" folder. Now it's fixed.

All platforms - Plastic: We detected that working concurrently against the same workspace using different Plastic clients (e.g. Plastic GUI, Visual Studio Plugin, Unreal plugin) could potentially break the workspace metadata under certain circumstances. That left the workspace pointing to the changeset 0 and created files named plastic.wktree.bak and plastic.changes.bak inside the workspace metadata folder ($workspace_root/.plastic). Now it's fixed.

Windows - Plastic: Happy to announce that we enabled the new Code Review system by default!

You can find all the information about it in the following blogpost: Improving the new Plastic Code Review system (Part I and

All platforms - Plastic, Gluon: A lot of users find the contextual help in the Plastic and Gluon UIs very useful. But for our more advanced users the help panel was getting in the way without providing any real benefit. Now, each help item will appear at most once a day. The GUI will only show more help than that when it detects that you might be having difficulty with the tool. Also, the help panel will hide after a few minutes if it opened itself (instead of by clicking the help button).

By the way, if you select "Got it, don't show me again" on the help panel, that help item won't appear ever again!

macOS, Linux - Plastic: Say hello to the new Attributes View! It allows you to list and manage the existing attributes in a repository. You'll be able to create new attributes, edit existing ones or simply delete them. This view was really necessary since we introduced the ability to define a list of default values in the attribute comments!

Here it goes on macOS:

And this is how it looks like on Linux:

We also fixed attribute definition in macOS with multiple predefined values: before if you defined default:one, two, "and three" the third value didn't show up in combos as "and three" but as two values. It is now fixed.

All platforms - Plastic, Command line client: the merge now checks for locked files and directories before applying changes.

Files and directories locked by third-party applications is a very common source of issues during a merge (Unreal users might be well aware of this!). Plastic might try to remove a file or a directory from your workspace, but because there is an application locking it, the operation fails - potentially leaving the workspace in an inconsistent state that is not obvious to recover.

We have just fixed this by checking that the files and directories involved in a merge are not locked before applying a merge (and this affects the upcoming Incoming Changes that will be the default way to update changes in a workspace when working on a single branch).

= How the detection looks like =

Suppose Notepad.exe is locking a file you are trying to merge. You'll get a message that looks like this:

And this is the message you get if what's locked is a directory:

= Going under the hood =

How do we detect locked files and directories on each platform?

Windows and macOS: we open each file involved and try to move each directory involved to a temporary location.

Linux: nothing, since Linux FS are quite friendly when it comes to applying changes to disk, so we don't have to worry about aborted operations by locked files or directories.

= Performance impact =

Since we now check every file involved in a merge prior to really combine the files and apply changes, we can expect a performance impact.

These are some numbers we grabbed so you can get an idea: checking if 50000 files are locked by another program takes 3 seconds.

Windows - Plastic: We are making a series of improvements to the single branch working workflow.

When you are working in a single branch with other people, it is common to find they have checked in new changes.

When this happens, Plastic will notify you on the top-right area of the window.

You have no pending changes and new changesets from other users appear. Plastic will show you a green notification in order to allow you to see the changes in the Incoming Changes view, and update to them.

You have pending changes. New changesets from other users appear, but they don't affect any of the files you have changed. Plastic again will show you a green notification in order to allow you to see the changes in the Incoming Changes view, and update to them.

You have pending changes. New changesets from other users appear, and there are changes in files that you have also changed. In this case you need a merge. Plastic will show you a red notification in order to allow you to see the conflicts in the Incoming Changes view, and resolve them.

This is how the Scenarios 1 and 2 look like:

And this is how the Scenario 3 looks like:

You can see it working here:

This feature is experimental.

To activate it, add the following line in the client.conf configuration file you can find at %LOCALAPPDATA%\plastic4\client.conf:

All platforms - Proxy: Added support for Plastic Protocol.

The Plastic Proxy (a.k.a. cache server) now can handle requests using Plastic Protocol instead of just "remoting".

The Proxy was already reaching remote servers using Plastic Proto, but it handled requests from clients using only remoting.

Plastic Protocol is a binary protocol we developed a few years ago. On the other hand, remoting is the older, slightly less efficient protocol we used for years. Our goal is to stick to Plastic Protocol and deprecate remoting later on this year.

All platforms - Plastic: Sometimes things are too easy. Like deleting a repository in Plastic. Two clicks and you can irreversibly delete your whole repository. We redesigned the "delete repository" dialog to eliminate accidental deletions.

Now, the dialog initially looks like this…:

…and the 'OK' button only activates when you enter the required text:

The functionality is the same of Mac and Linux:

Unity 3D plugin: The Unity plugin now deletes files in batches. It means when it has to delete thousands of files, it is much faster than before.

Using a project with 1.000 files the delete time is:

After: 10 s (reduction of 84,6%)

Jenkins plugin: The log output encoding is now hard-coded to be "utf-8".

macOS - Plastic: We implemented the Incoming Changes notification.

When you are working in a single branch with other people, it is common to find they have checked in new changes.

When this happens, Plastic will notify you on the top-right area of the window.

Scenario 1. You have no pending changes and new changesets from other users appear. Plastic will show you a green notification in order to allow you to see the changes in the Incoming Changes view, and update to them.

Scenario 2. You have pending changes. New changesets from other users appear, but they don't affect any of the files you have changed. Plastic again will show you a green notification in order to allow you to see the changes in the Incoming Changes view, and update to them.

Scenario 3. You have pending changes. New changesets from other users appear, and there are changes in files that you have also changed. In this case you need a merge. Plastic will show you a red notification in order to allow you to see the conflicts in the Incoming Changes view, and resolve them.

This is how the Scenarios 1 and 2 look like:

And this is how the Scenario 3 looks like:

You can see it working here:

This feature is still experimental. You need to manually activate it, adding the following line in the client.conf configuration file located at $HOME/.plastic4/client.conf:

Windows - Plastic: The GUI now shows a notification in the toolbar when the changeset you are working on no longer exists. This can happen if a colleague deletes that changeset.

This helps users returning to a valid configuration by updating the workspace. The notification looks like this - click on "Update" and you are good to go!

Windows - Plastic: We improved the message for the Incoming Changes view. It now explains that you only need to update the workspace to synchronize the metadata when your changes match the ones in the new head of the branch.

All platforms - Plastic, Command line client: We added the repository name to the error message you get when you try to create a child branch and you don't have that permission. This is useful when you have a merge involving xlinked repositories, because now you can we which repository is causing the problem.

Windows - Plastic: We added a tooltip in the notification bar for the incoming changes to explain the current scenario.

The available scenarios are:

There are new changes in the branch that you can preview and download.

There are new changesets that conflict with your current changes.

The changeset you were working on no longer exists. Click the "Update" button to return to a valid configuration.

macOS - Plastic: A "Cannot access a disposed object" error showed up when closing a merge that displayed a help panel. This could also happen when switching workspaces. Now it's fixed.

This bug was critical on macOS - it forced you to exit the application doing a "force quit". It also affected Linux, but it was not critical there (just an error message). This doesn't affect Windows.

To prevent further issues because of this bug, we unpublished the following releases:

8.0.16.3685 (10/30/2019)

8.0.16.3691 (10/31/2019)

8.0.16.3694 (11/04/2019)

Windows - Plastic: A few releases earlier we introduced new color filters for the Branch Explorer. But there was a bug on Windows! As you know, when there is more than one label in a changeset, we draw a split crown. When searching, the entire crown gets colored - even if only one of the labels matches the search. But none of the pieces got colored if a color filter matched another label different than the first one. That's now fixed. Thanks to forum user Wolfram for noticing and reporting this!

All platforms - Server: We detected some scenarios where the 'mergeto' endpoint of the server REST API failed. This happened if the merge contained a multi-file conflict and changes under an Xlink, too. As a side note, the main consumers of this endpoint are our mergebots. It's now fixed.

Windows, Linux - DevOps: The Jira plug couldn't connect to some Atlassian Cloud servers because of the lack of support for TLS 1.2. Not it's fixed.

Windows - Plastic: The GUI did not re-enable the buttons in the Pending Changes view after an error during the checkin. This prevented you from using it again unless you restarted the application. Now it's fixed.

Windows - Plastic: The update workspace operation failed from the incoming changes view when it took more than one minute to process. The view refreshed incorrectly before the operation finished.

Windows - Plastic: We noticed a visual issue in the list views (branches, changesets, labels, etc.). The text of the first column overflows the column bounds if you scroll to the right. The GUI didn't calculate the text width correctly! It's now fixed.

Unity 3D plugin: The Unity plugin now deletes files in batches. It means when it has to delete thousands of files, it is much faster than before.

Using a project with 1.000 files the delete time is:

After: 10 s (reduction of 84,6%)

All platforms - Plastic: Sometimes things are too easy. Like deleting a repository in Plastic. Two clicks and you can delete your whole repository forever. We have redesigned the delete repository dialog to help preventing accidental deletions.

Now, the dialog looks like this:

And the 'OK' button activates only when you enter the required text:

Functionality is the same for macOS and GNU/Linux:

Windows - Plastic: The GUI did not re-enable the buttons in the Pending Changes view after an error during the checkin. This prevented you from using it again unless you restarted the application. Now it's fixed.

Windows - Plastic: Happy to announce that the new Code Review system is enabled by default.

You can find all the information about it in this blogpost: "Improving the new Plastic Code Review system" (Part I and Part II).

Windows - Plastic: Incoming Changes. The following limitations described in the "Announcing Incoming Changes" blogpost don't apply anymore:

Not optimized after creating a new workspace. The Incoming Changes notification shows up when you create a new workspace saying there are tons of new changesets. This is because workspaces are created empty and pointing to the changeset zero of the main branch. Incoming Changes works well here, but it is more efficient to just launch a regular update. We'll get this one fixed asap.

Incoming Changes is not refreshed after undoing local changes, which is not correct. We are working to fix it.

Incoming Changes is closed when the update/conflict resolution finishes, but it is also closed incorrectly if a file is locked and the update can't happen.

Plastic still doesn't launch Incoming Changes instead of a regular merge when invoked from the Update in Workspace Explore and there are conflicting changes in the workspace (behaves differently than Pending Changes and the new notification area).

Plastic doesn't hide the new changes notification bar when switching workspace, which can create issues if you switch and click before it updates the status.

The workspace status is not correctly updated. You are on cset 100, use Incoming to move to head (cset 200), but the status area still shows cset 100 incorrectly.

DevOps: Jira plug was not able to connect to some jira cloud server instances, because the jira plug didn't have support for TLS 1.2. Fixed.

Windows - Plastic: Incoming Changes, the new way to work on a single branch, is finally here.

The feature is so important that we wrote a blogpost to explain it:

Incoming Changes feature explained

Write this in your client.conf:

Windows - Plastic: We are making a series of improvements to the single branch working workflow.

When you are working in a single branch with other people, it is common to find they have checked in new changes.

When this happens, Plastic will notify you on the top-right area of the window.

Scenario 1. You have no pending changes and new changesets from other users appear. Plastic will show you a green notification in order to allow you to see the changes in the Incoming Changes view, and update to them.

Scenario 2. You have pending changes. New changesets from other users appear, but they don't affect any of the files you have changed. Plastic again will show you a green notification in order to allow you to see the changes in the Incoming Changes view, and update to them.

Scenario 3. You have pending changes. New changesets from other users appear, and there are changes in files that you have also changed. In this case you need a merge. Plastic will show you a red notification in order to allow you to see the conflicts in the Incoming Changes view, and resolve them.

This is how the Scenarios 1 and 2 look like:

And this is how the Scenario 3 looks like:

You can see it working here:

This feature is still experimental. You need to manually activate it, adding the following line in the client.conf configuration file, that is located at %AppData%Localplastic4 folder:

All platforms - Plastic, Command line client: the merge now checks for locked files and directories before applying changes.

Files and directories locked by third-party applications is a very common source of issues during a merge (Unreal users might be well aware of this!). Plastic might try to remove a file or a directory from your workspace, but because there is an application locking it, the operation fails - potentially leaving the workspace in an inconsistent state that is not obvious to recover.

We have just fixed this by checking that the files and directories involved in a merge are not locked before applying a merge (and this affects the upcoming Incoming Changes that will be the default way to update changes in a workspace when working on a single branch).

= How the detection looks like =

Suppose Notepad.exe is locking a file you are trying to merge. You'll get a message that looks like this:

And this is the message you get if what's locked is a directory:

= Going under the hood =

How do we detect locked files and directories on each platform?

Windows and macOS: we open each file involved and try to move each directory involved to a temporary location.

Linux: nothing, since Linux FS are quite friendly when it comes to applying changes to disk, so we don't have to worry about aborted operations by locked files or directories.

= Performance impact =

Since we now check every file involved in a merge prior to really combine the files and apply changes, we can expect a performance impact.

These are some numbers we grabbed so you can get an idea: checking if 50000 files are locked by another program takes 3 seconds.

macOS, Linux - Plastic: Say hello to the new Attributes View! It will allow you to list and manage the existing attributes in a repository. You'll be able to create new attributes, edit existing ones or simply delete them. This view was really necessary since we introduced the ability to define a list of default values in the attribute comments!

This is how it looks like on Linux:

We also fixed attribute definition in macOS with multiple predefined values: before if you defined default:one, two, "and three" the third value didn't show up in combos as "and three" but as two values. It is now fixed.

All platforms - Plastic, Gluon: A lot of users have found the contextual help in the Plastic and Gluon UIs very useful. But for our more advanced users the help panel was getting in the way without providing any real benefit. Now, each help item will only be shown at most once a day, and we will only show more help than that when we detect you are having difficulty with the tool. Also, if the help panel opened automatically, rather than by pressing the help button, it will hide itself out of the way again after a few minutes.

By the way, if you select "Got it, don't show me again" on the help panel, that help item won't appear ever again!

All platforms - Proxy: Added support for Plastic Protocol.

The Plastic Proxy (a.k.a. cache server) now can handle requests using Plastic Protocol instead of just "remoting".

The Proxy was already reaching remote servers using Plastic Proto, but it handled requests from clients using only remoting.

Plastic Proto is a new binary protocol we developed a few years ago, and remoting is the older protocol we used for years, that is slightly less efficient, that's why our goal is to stick to Plastic Proto and deprecate remoting later on this year.

Windows - Plastic: A few releases earlier we introduced new color filters for the Branch Explorer. But there was a bug on Windows! As you know, when there is more than one label in a changeset, we draw a split crown. When searching, all of the pieces of the crown get colored even if only one of the labels matches the search - however, none of the pieces got colored if the filter matched another label different than the first one. That's fixed now. Thanks to forum user Wolfram for noticing and reporting this!

All platforms - server: We detected some scenarios where the 'mergeto' endpoint of the server REST API failed. This happened if the merge contained a multi-file conflict and changes under an Xlink, too. As a side note, the main consumers of this endpoint are our mergebots. Now it's fixed.

All platforms – Pending changes are now converted into checkouts before calculating merges.

This is a very important change to improve usability, but it might be surprising for Plastic long-term users.

Suppose you have foo.c modified in your workspace and then you merge from main/task001 where foo.c was also modified.

The merge didn't show foo.c as a conflict because the merge only considers the checkouts.

If you checkout foo.c then the merge preview showed the conflict.

The merge was still correct because changes were "promoted to checkouts" during the merge.

But, let's see a different example now: suppose you moved art/ into game-art/ locally and there were changes inside art/ in main/task001. The merge didn't consider your local changes and it would end up causing trouble.

We changed all this by simply "applying changes" before calculating the merge. This means any local "changed" will be converted into "checkout" and also that local moves, local deletes, will be put under control too (checkout for short).

It is an important change to ensure consistency and avoid corner cases.

== What are checkouts exactly ==

Plastic supports two ways of working:

You can directly modify foo.c, then go to Pending Changes and checkin.

Or you can checkout foo.c first, then modify, then checkin.

Checkouts are just a way to say Plastic "hey, I modified this file", or "hey, I moved this file this way", so it doesn't have to "guess" what happened. Plastic is very good guessing what you did by looking into the workspace and detecting changes, but it is even faster if it doesn't have to guess because "it knows" a change or a move happened.

Checkouts are not locks. You can checkout foo.c and it won't be locked at all. In fact, checkouts are stored locally and don't impose any performance hit at all.

Checkouts only lock files (a.k.a. exclusive checkouts) when the files are configured to be locked. This way, you can say all .png files must be locked on checkout, and when you checkout game.png it will be locked. Locks are stored on the server, although the performance hit is minimal.

Note for former Perforce users: Plastic checkouts are similar to p4 edit but without the performance hit.

Note for former Git users: Plastic checkouts are like adding something to the Git index.

When you launch a merge, before actually calculating the merge in the server, your local changes will be converted to "controlled changes" a.k.a. checkouts.

Windows, Linux - DevOps: A new built-in mergebot has just born! Its name: multiliner-bot.

The purpose of this mergebot is to be able to automatically merge a branch to several destination branches dynamically.

The merge is confirmed following an "all-or-nothing" policy. This is: if there are any merge conflicts, or the Continuous Integration system reports a build failure, the branch is rejected, and no merges will be written on any destination branch, even if some merges report no conflicts or CI builds success.

To define which destination branches a branch should be merged to, the multiliner-bot allows us to specify a plastic attribute name for this matter. Then, define a value for this attribute on a source branch (a comma separated list of destination branch names).

Find below a diagram explaining the basics of this multiliner-bot:

The multiliner-bot requires Plastic Server 8.0.16.3673 or higher to work.

No labeling support: to avoid label name collisions with several destination branches, this mergebot declines any labeling responsibility.

The mergebot configuration still requires a 'status' attribute to define when a branch is 'ready', when it 'fails', or when it is 'merged'.

If you specify several destination branches, and any of the merges fail (due to manual conflicts, or CI plan build), the bot rejects the source branch and marks it as 'failed'.

If you specify several destination branches, the CI plan for each destination branch triggers sequentially. We will consider adding support for parallel plan triggering in the future.

This mergebot allows triggering a CI plan after a branch successfully merges to several destination branches. But, if this post-checkin plan fails, it does NOT undo already confirmed merges. You just receive a notification about the post-checkin plan failing (if any notification plug is configured for this mergebot).

You can configure several notifier plugs with this mergebot. All of them are optional. So far, there are up to two notification plugs in the mergebot configuration template.

If any of the specified destination branches do not exist, the branch being processed by this mergebot is marked as 'failed'.

Windows, Linux - DevOps: Server and Jenkins Plug: Added support to specify a Jenkins job inside a Jenkins folder as the plan to execute by a mergebot (e.g. trunk-bot). Only top-level plan names were available before this release.

Now, you can specify a Jenkins job inside a folder in your favorite mergebot as the plan to build. Example:

Your Jenkins server has a folder named "projects"

Inside that folder, there is a job named "pipeline-debug".

You can type "projects/pipeline-debug" in the "Continuous Integration" section, having a Jenkins plug available for it.

Internally, he Jenkins plug will try to access to the config.xml file that defines the job on the following Uri path as an example: job/projects/job/pipeline-debug/config.xml.

Make sure this Uri is available on your Jenkins server. Otherwise, contact support [at] codicesoftware [dot] com and we will provide a custom Jenkins plug that fits your needs.

All platforms - Plastic: Merge now has file download progress! And it is ready for Linux, Windows, and macOS.

An image is worth a thousand words:

Why is this important? Well, during merges involving tons of big files, the UX was not good because the GUI didn't say much. So, users usually thought the app was not responding while it was downloading gigabytes of data. This is now finally solved!

This scenario is even more common for teams working on a single branch (game studios, for instance). Now the GUI shows download information while updating to the latest changes before a checkin.

This is part of the ongoing Incoming Changes effort, a much better way to work on a single branch.

All platforms - Triggers: When you run an update there are two client-side triggers: before-update and after-update. Now you have extra environment variables in both of them, we hope you find them useful for your scripts!

PLASTIC_INITIAL_CHANGESET: the ID of the changeset your workspace is (or was) pointing at when the update begins.

PLASTIC_FINAL_CHANGESET: the ID of the changeset your workspace is (or will be) pointing at when the update finishes.

So, with an example, let's say that your workspace is pointing to changeset 254, and you switch to branch /main. The head of /main is changeset 260.

The PLASTIC_INITIAL_CHANGESET will be 254, and the PLASTIC_FINAL_CHANGESET will be 260, for both the before-update and after-update triggers.

Bear in mind that we do not have "source" and "destination" changesets in partial and fast updates. When updating from Gluon, "cm partial update" command, or running a fast update from the GUI, the new environment variables will be -1.

You will notice that the update triggers run often for the plastic-global-config repository. Use filters to fine-tune in which repositories the trigger should run.

All platforms - Plastic, Gluon: A few releases earlier we introduced the "Location" column in the workspaces list. That column indicates the current object the workspace is pointing at. It included the full repository spec with the repository server, which is not useful, as it has a column of its own. Now, the location column shows the object spec without the repository. Check how it looks!

Windows - Plastic: Rejoice! We fixed the tab order of the "Other options" preferences panel.

All platforms - Server: A wrong SSL configuration won't prevent the server to startup correctly.

We changed how the server starts up, so a wrong SSL configuration won't prevent the server to startup. The server will listen on the other ports and will ignore the failing SSL one.

This is helpful when you wrongly configure a SSL port from the WebAdmin, because now you can go again to the WebAdmin and reconfigure instead of having to go to the command line.

Before, the server simply refused to start if it had a wrong SSL cert password setup.

All platforms - Plastic: we improved the usability of the Create Xlink dialog. Let me explain to you how: a xlink can be either "read-only" (Xlink) or "writable" (wXlink). Xlinks always point to the same changeset in the target repository, but wXlinks change according to the expansion rules. This means that expansion rules are useless for Xlinks - they only work for wXlinks. Yet when creating and editing Xlinks from the GUI, the expansion rules' list and buttons were enabled, which is confusing. No more! When creating or editing Xlinks, you can not create nor edit expansion rules.

Windows - Plastic: In the new Code Review system, when a requested change was applied, if you double-clicked it, it navigated to the changeset where it was applied. But you couldn't navigate to the comment itself anymore.

We changed that behavior so that, if you double-click the comment, you navigate to it. And, if the requested change is applied, you can navigate to the changeset where it was applied by clicking on its status.

Remember, right now, you need to launch the application with "plastic --codereview" to enjoy the new feature.

All platforms - Proxy Server: Made some improvements as part of the effort of modernizing the proxy.

Now a Proxy server with the log configured to INFO (logger Proxy) can give quite meaningful info as follows:

cache => full cache hit, everything read from cache.

downl => everything read remotely.

mixed => some from network, some from cache.

You can add this to your plasticcached.log.conf to see this log:

The log is called ServerStats and looks like this (just a fragment):

All platforms - Proxy Server: We disabled a thread abort code that was potentially causing problems and could make the proxy unstable and stop responding requests.

The Proxy has a safety code to kill a request if it detects that the client aborted the connection. This typically happens when you CTRL-C a command line. When that happens, the Proxy aborts the thread handling the request, and under some circumstances this could make the server very unstable.

We removed the abort code now.

All platforms - Server: We detected that the server initialized and shut down its internal services several times. This scenario was under control and it didn't affect functionality or performance. Its downside was that it polluted log files. That's fixed now.

macOS - Plastic: In the Branch Explorer the "dynamic date filter" was reset to "A given date" when changing a display option, even if you didn't change the start date filter there! That's fixed now.

All platforms - Plastic, Gluon: We fixed the search text entries in the Plastic toolbar and Gluon search dialog to properly protect regex-like characters. Before this fix, filenames such as 'file (new).txt' or 'file+15.txt' were really difficult to find because search patterns like '(new' or '+15.txt' wouldn't match anything.

Windows - Plastic: a null exception was thrown in the new Code Review system when you tried to navigate to an applied change and the changeset where the change was applied didn't contain the file where the change was requested. Now it's fixed.

Windows, Linux - Server (DevOps): There was a small issue while configuring a new mergebot. The WebAdmin page did not reload the configuration template when changing mergebot type. Unless you tweaked the URL, you could not configure a mergebot different than the first one on the list. That's now fixed!

All platforms - Plastic: We're improving the Branch Explorer layout! Until now, every developer would see the same chart when they open the Branch Explorer view. That's not entirely helpful because not everyone pays attention to the same things at the same time. That's why we decided to reorder the branches according to the current workspace status.

Your current workspace branch (as well as their parents and children) will always appear at the top of the chart -this allows you to remove clutter and see your current branch in a more meaningful context.

Integrated branches will sink to the bottom of the chart. Since those branches are already merged into main, they aren't likely to be active anymore.

Finally, all branches will be sorted according to these criteria:

Branches that are higher up in the hierarchy will also be up in the chart

Branches with a more recent activity will appear at the top

Branches with a longer life span will appear at the top

To try out this new layout, simply add the following property in your client.conf file:

We'd really appreciate your feedback! Let us know what would you want the Branch Explorer layout to look like in the forum thread.

All platforms - Plastic: Branch Explorer now stores configuration per workspace!

This is a huge change in usability, and something we should have done eons ago.

This affects the GUIs in all platforms: Windows, Linux and macOS.

Now every workspace remembers its Branch Explorer configuration, instead of it being global to all workspaces.

This is a huge change and worth an upgrade :-) Let me tell you about the details if you are interested!

Branch Explorer configuration used to be stored in the standard application configuration folder. Typically, this is "%LOCALAPPDATA%\plastic4\branchexplorer.cfg" on Windows, "$HOME/.plastic4/branchexplorer.conf" on GNU/Linux and macOS.

But now, it will be stored in ".plastic/plastic.branchexplorer" in the workspace root.

The branch explorer settings that are affected are the date filters, the “Only relevant” flag, all the “Display Options” and everything under “Filters and conditional format”.

The upgrade will happen as follows: after upgrading, when you open the branch explorer, its configuration will be read from the old configuration file, but from that point onwards it will be written and read from the new configuration file.

All platforms - Server triggers: the before-mklabel and after-mklabel have two new environment variables available: PLASTIC_CHANGESET_NUMBER and PLASTIC_CHANGESET_OWNER. The former indicates the number of the labeled changeset. The latter, the owner of that changeset. We hope you find it useful in your triggers!

DevOps: trunk-bot will pass a new property to the underlying Continuous Integration system to clearly identify whether the CI job is triggered in the 'Plan for build & test a branch' stage or 'Plan to run after checking-in a branch' stage, if any. This is useful when the same CI job is used for both stages, but we need to identify which stage launched the job to perform different build actions.

Example with Jenkins: when mergebot triggers a job in Jenkins, it will pass a new parameter to the Jenkins job called PLASTICSCM_MERGEBOT_STAGE. Its possible values are:

pre -> the job was triggered in the 'Plan for build & test a branch' stage.

post -> the job was triggered in the 'Plan to run after checking-in a branch' stage.

DevOps: We added a new configuration check to trunk-bot before it starts processing branches: If the 'Resolved' value for the Plastic status attribute is the same as the 'Merged' value, the trunk-bot won't start and it will log the error in the appropriate log file. We implemented this to prevent trunk-bot to enter in an infinite loop of branch polling, overloading plastic server's CPU.

The same restriction applies to the 'Resolved' and 'Failed' values.

All platforms - DevOps: The Jenkins mergebot plugin failed to build plans if the Jenkins worskpace path contained whitespaces. This is fixed now!

Windows - Plastic: We removed the now unnecessary "Run fast update" option from Preferences > Other options.

We need to do some rework on fast-update, and while it continues working, we consider it is best to simply hide it, so users don't select it without really knowing what it is about.

All platforms - Plastic: We improved the Undo Checkout operation when executed from the Workspace Explorer. Now:

You can undo changed files when you're working on a label.

When the operation fails, the item is not left checked out anymore.

You can undo a changed file under a readonly Xlink.

All platforms - Server: Sometimes concurrent check-in operations that affected the same branch weren't aware of each other. This resulted in a two-headed branch. It happened in the following scenario:

Liam and Emma are working on branch /main/task1.

Liam is working out of date on changeset 4.

Emma is working on changeset 5, the branch head.

Liam merged his changes with the head changes and checks everything in.

At the same time, Emma checks in her changes (she doesn't need a merge since she's working on the branch head).

The simultaneous check-in wasn't properly handled, leaving the branch with two head changesets.

Now the server detects the concurrent check-in. One of them will fail, letting the user know that the branch is currently locked.

Merge: Solved an issue in merge and locked files.

Let's better explain it with an example:

We have 2 file conflicts to resolve during a merge.

The first file is merged correctly.

The second one fails because the file is being used by another process (locked).

Then, the first file shows up again as pending to be merged.

Windows - Plastic: Your preferred maximized toolbar width was lost if you closed the application with the toolbar minimized. We fixed it! The state is now correctly restored on application startup. We also increased the default toolbar width slightly, so that the main actions all fit on single lines.

Windows - Plastic: When you select a file with no changes in the new Code Review window, you get "An unexpected error has occurred". Now it's fixed.

All platforms - Client core: Fixed some issues to deal with failing proxy servers.

When a client is using a Proxy Server (a.k.a. cache server) and the proxy suddenly becomes unreachable, the client was unable to disable it and kept trying to reach it on every data call, making the resulting experience slow.

We changed that, so that now proxies are properly disabled in each client session after the client detects the first failure.

We also removed a retry in the calls to the proxies: to disable a proxy (that was not even working) 5 calls needed to fail. This was very old code that was not even needed anymore because now the network code can handle retries (more on this later).

Finally, the proxies only support remoting protocol instead of plasticproto, but every single connection was trying to use plasticproto first, slowing down the whole thing.

A note on retries: suppose you were successfully downloading data from a proxy, and a second later the proxy is no longer reachable. Then, the client will try to reconnect (provided there was a recent successful connection) up to 10 times as follows in the next log. It can take up to 30 seconds to complete.

macOS, Linux - Plastic: Update Workspace will now correctly update to latest when you have pending changes.

Previously it would not allow the update if you had the "Allow to merge with pending changes" setting disabled. This setting ought not to have applied in this scenario, where the new changesets are on the current branch.

All platforms - Plastic, Gluon, Command line client: now the before-clientcheckout and after-clientcheckout triggers won't run when undoing local changes. These triggers were being executed because of the way Plastic SCM undoes local changes - in order to do so, first local changes must be converted into controlled ones through the checkout operation (in order to apply not only modifications, but also to know which files were renamed, moved, or deleted). It really didn't make sense to get notified of checkouts that were going to be immediately undone, so we removed trigger execution in this scenario.

This change affects CLI commands such as "unco --all" and "undo", but also operations such as "undo" and "undo unchanged" operations through the GUIs.

All platforms - Command line client: Use the --automaticresolution option to choose whether the source or the destination contributor should be automatically selected to resolve the conflict.

For example, imagine that you have to merge branch /main/task257. And you want "eviltwin" and "movedelete" conflicts to resolve automatically, but following these rules: the merge operation must resolve the "eviltwin" conflicts by keeping the source contributor and the "movedelete" conflicts by keeping the destination contributor:

Windows - Plastic: Incoming changes: As you may have already noticed, we are making a series of improvements in the single branch working workflow. One of these improvements is the "Incoming Changes" view.

The "Incoming Changes" view allows the developer to update your workspace to the latest changes in the working branch. You can launch the "Incoming Changes" view in two ways:

This feature is experimental yet. You need to manually activate it, adding the following line in the client.conf configuration file, that is located at %LOCALAPPDATA%\plastic4 folder:

macOS - Plastic, Gluon: In old macOS version such as 10.9.5, several unexpected error messages popped up when running both GUIs, Plastic and Gluon. The way we try to get macOS appearance (Light/Dark) failed. Now it's protected.

Windows - Gluon: Under some circumstances, the "Explore Workspace" view didn't focus a file after using the search files dialog. Now it's fixed.

macOS - Plastic: Merge view - Greatly improved UX!

We've done a UX review and decided to change texts and explanations. We also removed some outdated icons to save vertical space.

We updated the "Process all merges" button caption to make it a bit more descriptive:

If there are file conflicts pending to resolve, the caption is set to "Resolve conflicts". By clicking this button, the merge view will merge the pending file conflicts in batch (it will preserve the file conflict resolution of the already resolved conflicts). Note that all directory conflicts need to be resolved before clicking this button!

If there aren't any file conflicts, it means the merge just needs to apply changes done in the source contributor (and selected directory conflict resolutions, if any). So, the button text is set to "Apply changes". Screenshot:

Detailed description of changes done on different merge view tabs:

"Directory conflicts" tab:

Now the first directory conflict is automatically selected.

There is a red counter telling the user the number of pending directory conflicts to resolve vs total directory conflicts.

The "Resolve directory conflict" button for the selected conflict is moved to the top if the pane, to make it more visible (before this release, it was located at the bottom of the view, and sometimes it was invisible to the user!)

When resolving all the directory conflicts, the merge view jumps to pending "file conflicts" tab (just if there are pending file conflicts to resolve).

"File conflicts" tab:

There is a red counter telling the user the number of pending file conflicts to resolve vs total file conflicts.

The counter turns green when no pending file conflicts left.

"Automatic merges" tab:

"Discarded conflicts" tab:

All platforms - Plastic: we renamed the "Apply local changes" context menu option in the Pending Changes view to "Checkout". This way it is easier both for newcomers and experts to understand what that menu option really does!

Long story: We refused to write "checkout" because for us it means "hey, tell plastic I'm going to work on a file and optionally lock it if the file is lockable", but for Git users it just means "update/download". But, yes, we were wrong. "Apply local changes" means nothing to most of you.

Windows - Plastic: After a UX review, we improved some texts and explanations in the merge view.

The "recalculate merge" button is now a standard "refresh" button. We moved it to the left-upper corner.

We use red/green colors depending on how many conflicts remain to be resolved.

We improved some help texts.

The automatic merges in file conflicts tree (deletes to apply, moves to apply, etc.) are collapsed when the number of children is greater than 10.

And the comparison before and after:

All platforms - GUI: You can specify a default list of values for attributes now! You just need to include a line like the following in the attribute comment:

The GUIs will scan the attribute comment to find that line and then they'll parse that list of comma-separated values to populate the drop-down list of suggested values whenever you want to apply the attribute to an object.

This is particularly useful when you use our Mergebots, to let all users know which are the expected values they're monitoring.

Bear in mind that if you define a list of default values, you won't see other non-default values that the attribute might have in other objects being suggested in the GUIs.

macOS, Linux - Plastic: you can now specify a comment when creating a new Attribute, just like your Windows-using colleagues.

Here is how it looks on macOS:

Windows - Plastic: now a new help text explains how to enter default values in attributes

All platforms - CLI: We added a new 'cm attribute edit' command that enables you to change the comment of attributes. You can use it as follows:

This is especially useful to edit the list of default values available for an attribute!

All platforms - Server (Jet backend): We made the 'delete changeset' operation more fault-tolerant. You'll be able to keep working with the same branch even if it fails! Before these changes the branch was left unusable, pointing to the deleted changeset - which no longer existed.

Windows - Plastic: we added some help that explains how to do a great review in order to help users to discover how the new Code Review system works. Now you'll see how to add comments, add questions, request changes, apply or close a change request...

The help button is placed in the right top corner of the code review window.

Remember, right now, you need to launch the application with "plastic --codereview" to enjoy the new feature.

All platforms - Plastic, Gluon: We added a new column called "Location" in all Workspace Views. It will display the currently loaded branch, changeset or label in each workspace. This is useful if you have many workspaces or if you have multiple workspace for the same repository: this new feature will allow you to know at a glance what you will find if you open a given workspace.

This is how it looks like in Windows:

Windows - Plastic: Recently, we added a feature in the new Code Review system that allowed a developer to mark the changes requested by the reviewer, as resolved, from the pending changes view.

The current mechanism did not allow to resolve several changes in one checkin, because when a change was selected, the text in the comment's TextBox was replaced. We fixed it by inserting the text in the comment's TextBox at the current caret position.

All platforms - Plastic: the Pending changes view will let you know if new changes have appeared in your branch since you last updated. There used to be an option to disable this alert, but we think it's a useful feature for everyone, so we removed the option and made the feature always enabled.

Windows - Installer: From now on, unattended installations of Plastic will update the system environment PATH variable with the client and server installation path.

Example of command to run the Plastic installer on unattended mode:

Windows - Installer: From now on, unattended installations of Plastic will configure the Plastic Server with default values and start it up. This is done just when no previous Plastic Server installation was detected in the system.

All platforms - GUI and CLI: We improved the message you get when your credentials are set to a user that doesn't exist. It was simply "User unknown", so now we ask you to check your credentials information. We also point out that the username check is case-sensitive.

Windows - Plastic: We changed the "Rename" context menu option in the attributes view to "Edit"! It will now allow you to change the name and the comment of the attribute. This will make your life easier if you want to change the list of default values for the attribute.

macOS - Plastic: When you configure Plastic SCM Team Edition for the first time, a dialog shows up asking you your Plastic SCM server's address, and your credentials (if necessary). In that dialog, the Cancel and OK buttons were slightly cut out on the top. You didn't notice? Good! You did notice? That's now fixed!

Windows - Plastic: New Code Review system: applied some usability improvements code review window layout:

The comments and summary panels are now collapsible in order to allow the user to increase the available size of the diff viewer.

The summary panel is displayed as collapsed when there are no changes or questions to show.

When the changes and questions lists are empty, we display an empty state message, instead of the empty list.

The comment list will only appear when there are comments (old legacy review comments) to show. Note that the new Code Review system is designed to encourage users to use only 'Changes or Questions'.

Remember, right now, you need to launch the application with "plastic --codereview" to enjoy the new Code Review feature.

All platforms - Plastic, Command line client: we made adding files to source control even faster by making the file type determination more efficient. In our testing, adding 300,000 files is now twice as fast.

All platforms - Plastic, Command line client: we were generating excessive quantities of log information when adding files to source control. We pruned this a bit, and have achieved some significant improvements in the performance of "cm add" in the CLI and "Add directory tree to source control" in the GUI when logging is enabled. In our testing, adding 300,000 files is around 5 times faster.

Linux - Plastic: We've made it easier to filter the Branch Explorer to show only those changesets you want. Now you can easily show changesets from the last week, 15 days, month, 3 months, or since any specific date.

All platforms - Plastic: The Branch Explorer got enhanced! We extended the conditional format capabilities -which were previously available only for branches- to changesets and labels. You'll find new menu options in the "Custom format" button menu to add rules for labels or changesets using find-like queries. Give some color to your Branch Explorer!

Here is how it looks in Windows...

Server: some users had issue where their internal database files has invalid versions. We added some code to detect and correct this issue.

All platforms - CLI: You can now edit Xlinks in partial workspaces using the command line.

You can always edit a read-only Xlink to change the content that you are loading using it.

But you cannot do the same with a writable Xlink. You can only edit it to change the target branch and only until someone creates a change under the writable Xlink.

This happens because partial workspaces always point to the branch head, including writable Xlinks. As a result, writable Xlinks only care about branches instead of changeset IDs… even if you still have to specify changesets to create them.

Windows - Plastic: New Code Review system: If users apply the requested changes in a code review while having the code review window opened, the window will be updated correctly showing the requested changes as "Done", and the new changesets created as well.

Windows - Plastic: You can have multiple Branch Explorer windows open at the same time, showing different repositories. This means, if you're not paying full attention, you can switch to a branch or changeset that you didn't mean to and have to wait patiently while your workspace is overwritten by data from the wrong repository. You can switch back of course, but it can waste a lot of time.

We've added extra warning text to the confirmation dialog when we see that you are about to switch to a different repository, to reduce the chance of this mistake occurring.

Windows - Plastic: We've added dynamic date filtering to the Branch Explorer. You can easily set the Branch Explorer to show changesets from the past week, month or year. Most importantly, the filter updates dynamically so that it always only shows changesets within the specified time frame. Check it out in the gif below!

Windows - Plastic: The Workspace Explorer did not display errors properly. Now it's fixed.

macOS - Plastic: We've added dynamic date filtering to the Branch Explorer. You can easily set the Branch Explorer to show changesets from the past week, month or year. Most importantly, the filter updates dynamically so that it always only shows changesets within the specified time frame. Check it out in the gif below!

All platforms - Command line client: Now the "cm licenseinfo" command prints the information it was missing before for servers with Unlimited Users licenses. The information we omitted (because we considered it was somehow useless, sorry about that!) was the number of active users (the number of available users is useless if you have an unlimited number!) and the list of active and inactive users. Now, Unlimited Users licenses will see something like this:

Remember that you have some useful flags to further filter the users list - for example:

Windows - Plastic: Maybe you already know Plastic installation contains semantic merge tool feature out-of-the-box. However, in order to enable java files to be semantically merged, it is required a valid Java Virtual Machine (version >= 8). But, if no valid Java Virtual Machine is found, the merge operation for a java file will automatically fallback to regular, embedded text-based mergetool (a.k.a. XMerge tool).

Windows - Plastic: Added a dropdown button to the pending changes view to resolve pending Code Review change requests.

The new Code Review system allows the reviewer to request changes by the developer. Then, the developer can set those changes as resolved using pre-defined text in the checkin comment.

We added a dropdown button next to the checkin comment textbox:

When the developer selects a change, the checkin comment text is automatically filled and, after checking-in your changes, the change will be marked as applied in the changeset.

Command line client: Now, the "cm lock unlock" command help shows an example about undoing an item lock on a cloud server.

Windows - Plastic: Code reviews: Changed the default title. Now, it always use the reviewed object in the title.

Also, improved the alignment of titles and edit boxes in the header of the review, that were wrong before.

Windows - Gluon: Pending changes data was not visible in the checkin changes view when the column names were modified in the localization files. Now it's fixed.

GitSync: A "key duplicated" exception was thrown if two Git tags were escaped to the same name and they were not listed in a consecutive order. Fixed.

When pulling tags from Git to Plastic, the following characters in the tag are escaped: '~','^',' ', '' and '..'. It can happen that two tags are escaped to the same name (such as 'tag^3' or 'tag\3', both would be escaped to 'tag-3'). Now, the second one is skipped.

Windows - Plastic: fixed an issue related with the navigation keyboard shortcuts of the Differences window that prevented navigating in second and later windows.

The issue is quite easy to reproduce:

Open a first "sticky diff" from wherever - for example, the Branch Explorer, pressing the Shift key at the same time you double-click the object you want to diff.

Open a second "sticky diff", doing the same.

Try to navigate the files and differences on the second sticky diff using the sortcuts - before this fix you can't! You are navigating differences in the first diff window, regardless of it not having the focus!

Windows - Gluon: The maximized state of the window was not correctly remembered when closing and reopening Gluon. Now it's fixed.

All platforms - Plastic: We have removed an unnecessary warning message that was confusing a lot of users. It appeared if you clicked "Update Workspace" when you were already on the head changeset, and you had local changes.

In this situation we used to show a message telling you that you have local changes that you might want to undo, and it looked like we were reporting an error, when of course there was no problem. We will introduce a better way to let you know that you're already on the head changeset in a future release.

Windows - Plastic: New Code Review system: Display a visual guide when creating a new comment.

Now, when you're creating a new comment, we highlight the line under the mouse when you're moving it. This guide helps to figure out the line number you're adding the new comment:

Windows - Plastic: to help users discovering how the new Code Review system works, we added some help to the review comments panel that explains what happens and how to proceed.

If the code review is empty, it will indicate to the user how to create a new comment.

If the selected file has comments but no comment is selected, it will indicate how to view those comments.

Remember that for now you need to launch the application with "plastic --codereview" from a terminal in order to access the new feature.

macOS, Linux - Command line client: As you might know if you are a power user, you can use redirections with the "cm" command line client in order to get things done. For example, if we want to add all of the *.txt files in a given directory, we can do so as follows:

However, this was not working good with the Checkin command because of the dynamic checkin progress. Now that's fixed! The following command should work as expected under macOS and Linux:

All platforms - Plastic, Gluon: back in release 8.0.16.3400 we made the differences launched from the Item's History panel editable if the right revision was the one loaded in the workspace.

But this had an undesired side effect! If the revision loaded in your workspace had local changes, you would see these local changes in the differences... which is weird, because if you are looking into the history, you probably expect the content at the selected changeset, not the one in your workspace. So we reverted that change.

Launching a diff from the Item History panel will always show you the content at the given changeset - never from the workspace. And the diff won't be editable, even if you are diffing the revision currently loaded and unchanged in your workspace.

Remember that if you want to diff your current workspace content, you can do so from the workspace explorer - right click on an item, then "Diff with previous revision". Pending Changes also works, of course :)

DevOps: Jenkins CI Plug: We detected that in some Jenkins servers the anti-forgery crumb expires fast, preventing Jenkins plug to queue builds in Jenkins server. Fixed. Now the crumb is updated before performing any HTTP request to Jenkins server, if required.

All platforms - Plastic, Gluon, Command line client: When undoing changes with dependencies, if an error occurred whilst working through the chain of undo dependencies, we would sometimes leave some files in a temporary state. We now attempt to clean things up and put you back into a consistent state as you were before the undo operation.

Specifically, when undoing a file that was moved from "oldName" to "newName" and that undo depends on another undo which fails, we used to leave the file "newName" in a temporary location. We now move it back to where it belongs.

All platforms - Gluon: We have implemented a new mechanism to avoid corner cases where some new items were not downloaded after the user had configured the whole repository because he wanted to download always everything.

Now, after a full configuration of the workspace happens, the workspace enters in a "full update" mode where every new item will be downloaded without relying in the granular directory configuration.

If the file '$workspace/.plastic/plastic.fullupdate' exists, then the full update is enabled for the specified workspace.

Windows - Plastic: The new Code Review system now warns you when you try to change the status to 'reviewed' with required changes to apply or questions to answer.

Remember, right now, you need to launch the application with "plastic --codereview" to enjoy the new Code Review feature.

All platforms - Gluon: The helpful download info message that lets you know in advance how much data your new workspace configuration will download now also updates in real-time when you select items from the search results.

Here's how it looks in Windows:

Windows, Linux - DevOps: Greatly improved the mergebots and plugs configuration forms in WebAdmin.

We added collapsing to the different configuration sections, which radically simplifies use.

This is how it looks like now, with sections collapsed so you can understand the whole thing at a glance.

And then start expanding the section you need:

Finally, this is how it looked like before these changes. Hopefully, we greatly improved usability this time.

All platforms - CLI: When you run the 'cm undo' and 'cm unco' commands in a workspace and the loaded changeset doesn't exist anymore in the server (it was deleted elsewhere), you're prompted to confirm that you'd like all your current changes rolled back and your workspace switched to the last changeset in the current branch.

The problem is that this interactive behavior produced an infinite loop when the standard input was redirected (e.g. 'cm shell' in plugins, CmdRunner, custom scripts...). We changed that so whenever the stdin is redirected, the client aborts the operation and returns an error to prevent unexpected loss of changes.

To make this compatible with unattended/batch setups (e.g. plugins) we changed the behavior of the commands so that if you include both '--all' and '--silent' as CLI arguments, the client will automatically update the workspace to the last available changeset in the branch without any user interaction or output messages.

Windows - Plastic: We noticed that Spanish users couldn't type the ']' character if they had a Diff Window opened. This happened because that character is triggered by the combination of the special key 'AltGr' of the Spanish keyboard and the '+' key. The 'AltGr' key is translated to Control + Alt, and the Diff Window has Control + '+' as the shortcut for "Next file". Therefore, the ']' character in Spanish keyboards was triggering the shortcut, rather than getting written. Kind of obscure but annoying nonetheless.

All platforms - CLI: We fixed a corner-case scenario that prevented you from removing changesets. This happened if four conditions were met:

1- You ran the command in a workspace

2- You had pending changes in your workspace

3- The head changeset of the branch loaded in the workspace had the same ChangesetID as the changeset you wanted to remove

4- The changeset you wanted to remove belonged to another repository (not the one loaded in your workspace)

In this case, you were prompted with a message notifying you that you can't remove the changeset of the current branch while there are pending changes. That didn't make sense because the changeset you selected wasn't even in the same repository.

All platforms - WebAdmin: The Lock Rules and Merge Rules sections in the WebAdmin Configuration area weren't displaying the appropriate information in multi-instance environments. They read/wrote config files in the server binaries directory instead of the expected shared directory for those special environments. Fixed!

macOS - Plastic, Gluon: The "Browse" button in the first steps dialog (the one we show when you don't have configured the client yet) didn't work if the path to open contained spaces. It's fixed now!

All platforms - CLI: Downloading revision contents failed if a proxy server was configured and unreachable. It will automatically retry the download against the main server now. This wasn't failing in the GUI.

Windows - Plastic: Fixed a minor aesthetic issue in the "Create Label" and "Create Attribute" dialogs. The issue was related to positioning the comment TextBox in HDPI monitors. It didn't look its best, but it does now! Just so you can appreciate the aesthetic nuisance I'm talking about, check in the picture below the before and the after - notice how the Comments TextBox is a little bigger than it should?

Windows - Plastic: Fixed a nullref error that could happen on the following scenario:

Fresh start of Plastic GUI.

Run a merge from another branch. On this merge, semantic merge resolves automatically a file conflict. But there is a text file conflict on another file that requires user intervention.

Finish the merge and open the pending changes view.

Show differences for the text file that required manual intervention causing a nullref error.

Now this error is fixed. It was just an aesthetic issue (the file contents in the merge are the correct contents).

All platforms - Command line client: we changed date format in XML output. It was inconsistent across different commands, so we unified it and made it compliant with ISO 8601 (without decimal places).

These are the affected commands:

If you use or develop any script or integration that rely on these commands, please make sure it still works before updating your production environment.

You can still manually override the date format though. The 'cm find' command accepts a '--dateformat' flag. For other commands that do not accept the '--dateformat' flag, you can add the OutputDateFormat to your client.conf file. For example:

All platforms - Plastic, Gluon: We got some important feedback about how many of our users add their files to source control.

Emulating the usual initial steps in other popular VCSs, one of the first steps a Plastic SCM user does after creating a new repository is adding a ignore.conf file prepared for the project they are going to work with.

Then, they start adding files to source control, but because private files are unchecked by default in the pending changes, this workflow is error prone.

We have addressed that way of adding files adding a new preference - in the Pending Changes (Plastic) and Checkin (Gluon) views, under the Options dialog > What to show, now you can set private files (private and private-added, but not private-ignored) to be selected for checkin by default.

Hope you don't have to write any more "Files I forgot in the previous changeset" checkin comments!

Windows - Plastic: A few usability improvements applied to the new Code Review system, designed to encourage users to use the new 'Changes and Questions' system instead of the old regular review comments.

'Request a change' is set as default option when adding a new comment.

Allow users to choose the comment type in the replies too.

The review comment summary at the bottom of the window shows only first level regular comments, not the replies. Except for 'Changes and Questions' that will continue appearing on their lists even if they are replies.

The comment navigation now marks as selected the comment and scrolls to it in the comment panel in order to make it more visible.

Remember, right now, you need to launch the application with "plastic --codereview" to enjoy the new feature.

All platforms - Gluon: No more surprise massive downloads when you configure your workspace. We've added a handy text box to the configuration window which tells you exactly how many files, and how many bytes, your configuration change will download.

Here are some screenshots for Windows:

All platforms - Command line client: the subtractive and cherrypick merges can now use the --keepsource and --keepdestination flags to automatically choose a contributor! Before, the subtractive was ignoring these flags.

Imagine that you want to undo a change in a file that was introduced in a changeset along with other changes. These flags are useful to pinpoint only the changes you want to undo.

For example, imagine both file_A.txt and file_B.txt were changed in cs:4, and have more changes afterwards. We only want to undo changes introduced in cs:4 for file_A.txt, while preserving file_B.txt. How can we achieve that?

DevOps: Trunk-bot with Jenkins-plug: Since public release 8.0.16.3442, the cm undo command became user-interactive when the workspace is loading a deleted shelveset. This scenario could happen if you have a repo configured with DevOps feature (trunk-bot and jenkins-plug), causing unexpected "build failed" in some builds launched in Jenkins. Now it's fixed.

Windows - Mergetool: The mergetool contributor shortcuts (Ctrl+1, Ctrl+2, Ctrl+3) didn't work as expected if you opened a diff window (e.g. double-clicking a branch in the Branch Explorer) and then you performed a merge. They were toggling the contributor change twice. It's fixed now.

Windows - Mergetool: Saving changed files when the diff is editable (i.e. the destination revision is the one loaded in the workspace) displayed a null reference exception message if there wasn't any selected items in the changed files tree. It's fixed now.

All platforms - All clients: We have enhanced how exceptions are communicated from the server to the client.

Now, if you are running against an updated server that has exception messages your client doesn't know about, your client will still be able to show you a helpful error message. The message will be localized to the server locale, rather than the client locale, but this is better than the previous behavior, which was to show an unhelpful generic message in this case.

All platforms - Plastic: The new Code Review system (available on Windows only at this point, when you launch the Plastic GUI with --codereview) allows you to request "changes".

It is just a special comment where you request the author to make a change, and the system tracks if the change was really applied or not.

Changes are identified with a GUID, to let you refer to them later when doing checkins.

To mark a change as "done" you simply add a special comment to your checkin. Suppose you want to checkin code to fix the change request GUID c0d1ce00-b457-4424-99ff-a3f1c0fa2582.

All you must do is to enter a comment like this:

Or even in a shorter form:

As you see, there is a long format and a short format. The long format requires specifying the whole GUID, whilst the short format only requires the first 8 bytes.

If you specify a change request comment that doesn't exist, the checkin will fail.

If you delete a changeset referenced by a change request through this method, the changeset id related to said change request will be reset.

All platforms - Plastic: Corrected the English text shown in the code review module when a file has no associated review comments.

Windows - Plastic: The new Code Review system now allows you to navigate to the applied change when you double-click the change in the list.

Remember, right now, you need to launch the application with "plastic --codereview" to enjoy the new feature.

macOS, Linux - Plastic, Gluon: We changed the Items view delete confirmation dialog to be more consistent with the Windows version

All platforms - Installers. A new installer named "DVCS Edition" is born! This is the way to go if you are targeting the following layout for your Plastic servers:

Have a central, on-premise Plastic server in your company.

Developers have their own, local Plastic server to work with, pushing/pulling from/to central, on-premise server.

Some developers work directly with the central server.

The advantages of this installer is that you don't have to setup any local Plastic license on every developer machine for its local server.

Also, you can use this installer for your local projects out of the box, with almost zero-conf required.

And still you will be able to push/pull from/to central server.

(Working with a central server is just a matter of entering the server host:port and user credentials. Period).

REMARK: You can access to your local server using the "local" alias as server name, instead of "localhost:8087". Example of local repository spec: my_personal_toolbox@local

Windows - Plastic: The new Code Review system now allows you to review a branch, changeset by changeset.

When a developer checks-in often, keeping reviewers in mind, it's helpful to review the branch walking through each changeset. You can read more about this here: https://www.plasticscm.com/book/#_checkin_often_and_keep_reviewers_in_mind

So, we added a new tab that allows you to review a branch, stepping through changeset by changeset:

Note: While reviewing a branch, you can switch between the modes 'Review changeset by changeset' and 'Review entire branch' at any time, adding comments in either of them. Each comment will be displayed in the mode it was added.

Remember, right now, you need to launch the application with "plastic --codereview" to enjoy the new feature.

All platforms - Server: Now the server logs the inner exception of the failed calls, so in case of error there is more info available.

All platforms - all clients: If you deleted a changeset in the plastic-global-config, every operation that needed a file from said global configuration could end up in a stack overflow. This is caused by the following sequence of events:

Every time the client needs to read a file from the global configuration a hidden, special-purpose workspace is updated to ensure that we have the latest config available.

Said update operation is typically a fast-update, unless the changeset previously loaded in that workspace is missing from the server.

If that happens, Plastic must run a full update.

That full update requires Plastic to check the status of the workspace first.

And to do so, it needs to read some configuration files from -you guessed it- the plastic-global-config.

As you might have noticed, this would end up in an infinite loop only stopped by an application crash due to a stack overflow.

Windows - Plastic: The Update Workspace operation wasn't working fine if there was already another update operation running. It notified you about that and told you to wait until the current operation was finished, but then it continued anyway and the new update operation took over control of the progress panel. The side effect was that the original update operation could be running after the second one finished and you had no way to find out when it was completed. If you closed the GUI at that point you could abort the operation midway -without any warning messages- and the workspace could be left in an inconsistent state. It's fixed now!

Windows - Plastic: The dialog to resolve file conflicts (non-automatic, with conflicts) sometimes failed with the following exception: "The calling thread must be STA". This only happened if you ran the "Update Workspace" operation in the Workspace Explorer and there were local changes that conflicted with the latest contents of the branch. Now it's fixed.

Note: Users can proceed in three ways when they find themselves in this situation:

Solve the merge directly when they try to checkin their local changes.

Solve the merge by clicking the 'View new changes' button in the Pending changes view.

Solve the merge after clicking the 'Update workspace' button in the Workspace Explorer view.

The merge tool was launched correctly in the first two scenarios to solve the file conflict. It only failed in the last one - which is the least used, by the way!

All platforms - WebAdmin: We updated the Merge Rules section to enable the new Merge Rule types! You can now select the one that fits your needs best.

All platforms - Plastic, Gluon: External diff is now incredibly faster!

This is because our diff tool is now launched within the same process instead of spawning a new one, which makes it start up super-fast.

The diff window appears in 0 secs!

Here goes the "before and after":

Windows - Branch Explorer: The Branch Explorer didn't update the repository objects info on refresh. So, if a colleague renamed a branch while you were running the Windows GUI, you'd never get those changes no matter how many times you hit the Refresh button. That's fixed now.

On top of that, if you tried to merge from the renamed branch, you'd get a "No objects selected" message. Funny, right? We changed that to let you know that the object you selected no longer exists in the server and suggesting you refresh the view and repeat the operation.

All platforms - Gluon: You got an unspecified error when you tried to show differences of a checked-out item in the "Checkin" view if the changeset of the loaded revision had been deleted somewhere else. We fixed it to show you an informative message letting you know what's going on.

Windows - Plastic: if any of your server's after-checkin triggers failed, the Windows client did not log the checkin result to the configured issue tracker. This is because the client was re-throwing the exception originated in the server, rather than just displaying it, which was wrong - if your after-checkin trigger fails, is because the checkin already finished, and thus the client has valid checkin data to log into the issue tracker. That's fixed now. You'll still see the after-checkin trigger exception from the server, but that will not abort the next steps in the checkin workflow.

The command line client did not have this issue.

Windows - Plastic: in the Pending Changes views the buttons were not disabled when an operation started, resulting in you being able to double click the button and maybe leave the GUI in an inconsistent state. We know you usually don't hit the Checkin button several times in a row (after all, it won't result in the checkin finishing faster!), but faulty mice are a thing and it is better to prevent the issue in the first place.

All platforms - Command line client: the 'cm log' command returned a misleading error message if you executed it outside a workspace with a changeset spec that didn't specify the repository. That's now fixed.

All platforms - Jenkins plugin: We fixed an issue that caused builds to fail if the last built changeset had been deleted elsewhere.

Windows - Plastic: Sorting code review comments by line didn't work in the new CodeReview system. Now it's fixed.

All platforms - Command line client: cm status command is showing an "Error: Object reference not set to an instance of an object." message when the workspace is pointing to a shelve. Now it's fixed, and if workspace is pointing to a shelve, the proper object prefix (sh:<shelve_num>) is shown.

All platforms - Command line client: the 'cm applylocal' command was not printing local changes dependencies. Fixed!

All platforms - Command line client, Plastic: until now, if a user had the applyattr permission denied at the repository level, said user could not apply an attribute on an object (branch, changeset or label) inside the repository even if the applyattr permission was overridden-granted for said object (changesets here have the same permissions of the branch they belong to).

Now, the applyattr permission is only checked at the object level, and not at the repository level (which prevented Plastic from checking overridden permissions for this operation!). Remember that permissions are inherited, so if you deny said permission at the repository level, it will be denied for all objects inside it unless explicitly overridden.

macOS - Plastic, Gluon, Mergetool: We improved the dark theme colors used in syntax highlighting. We noticed that some of them (comments, keywords) made text difficult to read if it was inside a changed block, due to the highlighted background. Here's a before/after comparison:

All platforms - Command line client: the automation command "getworkspacefrompath" / "gwp" now admits keywords in its format string argument. For example:

For further information about the available keywords refer to the integrated help:

All platforms - Server: We have new types of merge rules!

Let me walk you through them:

For the repository "codice", merges to branch "/fix3.0" are only allowed from branches named "fix3-*" (remember that you can use wildcards).

In the repositories with name "game*", branches with name "task*" can only receive merges from their parent branch. This way you can prevent merges across different task branches.

However, branches with name "iteration*" can only receive merges from their child branches. So, for example, "/main/iteration-32/task23" can be merged into "/main/iteration-32", but it cannot be merged into "/main/iteration-15", as it is not a child of that branch.

Right now you can edit these new kind of merge rules manually - the WebAdmin doesn't support them yet. The file is stored alongside server binaries, and its name is "mergerules.conf".

This new merge rules are not available for Cloud yet, but will be soon!

Windows - Plastic: The GUI was not able to restart the file system watcher if it stopped due to an internal watcher error. In that eventuality, the pending changes calculation would take a noticeable amount of time more because it would need to check the disk contents instead of using the cached contents. This affects the auto-refresh feature as well, because it would trigger a refresh of the pending changes view whenever the GUI is focused, even when the workspace doesn’t contain any changes. Now, the file system watcher errors are properly handled and the watcher is correctly restarted afterwards. This issue appeared first in version 8.0.16.3281.

Windows - Plastic: Semantic multifile - We addressed several usability issues in the case that we detect that code has moved between files and the displayed file is either added or deleted:

The semantic outline panel didn't keep the selection.

The option 'Go to moved code', that you can find under the 'M' icon, didn't go to the right location for multi-file moves.

Sometimes the moved icon for the multi-file moves was not shown.

All platforms - Server: There was an issue when moving an older repository to be a submodule of a newer one. Imagine the following scenario:

The repository myProject/webpages is older than myProject/doc (as determined by the moduleId, which is 1 for webpages and 2 for doc). Now, we are going to move doc to be a submodule of webpages:

Everything looks sort of right (doc should be listed before webpages, but all of the repos are there). But see what happened when you restarted the server:

What happened to all of the repositories that should be after myProject? Well, we had an issue in the way we load repositories from the backend, which is now fixed:

macOS - Plastic: A few releases ago, we changed the order of the sidebar items. However, if you opened views using the View menu, or using the shortcuts, the views showed up corresponded to the old ordering. Fixed!

All platforms - Plastic: The "create replication package" command failed with the error "Can't create a replication package from a repository with data replicated using the --nodata flag. Please hydrate the source repository first." if there was an empty file revision (i.e. its size is 0 bytes) without a related empty data object. Now it's working, as empty file revisions don't really need data objects.

Jenkins: We fixed an issue in the polling results parser that prevented the SCM Polling from returning the appropriate results.

Linux - Plastic: symlinks pointing to directories or to themselves had a wrong status and icon in the workspace explorer. Fixed.

Windows, Linux - DevOps: Users with spaces in their username were not able to configure a profile for DevOps using the GUIs. They'd receive an error message that said something in the lines of:

All platforms - Server: The fast update was not able to switch to a different branch when the user cannot perform a merge from that branch because they don't have the mergefrom permission or because there is a merge rule that restricts it. Now it's working.

Windows - Plastic: The new Code Review system allowed you to comment xlink changes but, later, it would fail when trying to visualize them.

For now, we have disabled comments on files under xlinks (same as in the old system). We will work to add this functionality and much more soon!

Remember, right now, you need to start with plastic --codereview to enjoy the new feature.

All platforms - Jenkins Plugin: We fixed some serialization issues that prevented the REST API output from working.

Jenkins: Builds failed if your selector targeted a cloud repository. Fixed.

All platforms - Team Edition, Enterprise Edition and Cloud Edition. Now you can manage your merge rules from the WebAdmin!

As our friend Unai Landa from Digital Legends likes to say: "It is not a feature until it has a GUI".

So, the awesome merge rules now can be configured from a GUI:

To configure merge rules for your cloud organization repos, go to your cloud dashboard https://www.plasticscm.com/dashboard/cloud and click on "Edit merge rules" button:

Remember we launched merge rules a few versions ago (8.0.16.3442), and they allow you to restrict merges to certain branches so they only allow merges from branches that have an approved code review (yes, this is part of the new Code Review project).

We plan to add more merge rules options in the near future: restrict based on branch hierarchy (only merge from parent/child... sort of what Perforce streams do).

All platforms - Server - Now the replication is more resilient to errors. If the parent revision cannot be found on the destination, the revision is replicated without parent instead of aborting the full replication operation.

Windows - Installer: The displayed name of Plastic SCM Server service has been updated to "Plastic SCM Server". This is just an aesthetic change, since the internal service name is still "Plastic Server 6", to avoid breaking any scripts you may have to start/stop/status your Plastic server.

macOS - Plastic: Improved the error message shown in the replication progress panel to correctly use the available space. We saw that for long messages the text was cropped.

Here goes the "before and after":

Jenkins plugin: Version 3.0 is out! You can have a look at the improved Wiki page to see the new features: https://wiki.jenkins.io/display/JENKINS/PlasticSCM+plugin Enjoy!

All platforms - Command line client, Plastic, Gluon: We wrongly documented that 'n weeks ago' was a valid WHERE clause for date fields. For example:

Instead of fixing the documentation, we implemented the feature.

Windows - Plastic: An unexpected error was thrown when the mergetool is configured without the progress command line option and semanticmerge is launched to solve the merge. Now it is fixed.

Server merge multifile: Fix the following failing scenario:

You move a method to a different file.

Meanwhile someone else modifies the method in the original location in a different branch and also modifies other method in the other file, where the method was moved.

In this case, the merge was automatic but the change done in the moved method was lost. Now it's fixed.

Remember, this feature is used by the mergebots. They can merge conflicts across files!

Windows - Plastic: We had some GUI components too narrow for the Spanish translation of the Windows GUI. The detected aesthetic issues are now fixed - don't hesitate to contact us if you see something out of place!

All platforms - GUI and command line. Fixed an issue trying to merge moved paths that were already in use in the workspace.

When merge failed to apply a move because the path was in use, it updated the metadata but not the filesystem, creating an inconsistency.

Now the merge doesn't apply the move to the metadata if it can't be done on disk.

Now you can also continue the merge if you release the path that was in use and click on "process all merges" again. You no longer need to undo all the changes and restart the merge after releasing the path.

All platforms - WebUI: We fixed the "File explorer" navigation link in the top bar. It was always redirecting to the tree of br:/main, but users that renamed their main branch to something else were getting Not Found results.

All platforms - Command line client, Plastic: Imagine the following scenario - you are working in a changeset, and somebody else deletes it! Apart from your colleague being a little disrespectful towards you and your work, Plastic warned you in the Pending Changes view that there were new changesets in the repository, which is not true… if any, there are only older changesets for your branch!

Now, Plastic won't show that misleading message. Instead, it will warn you that the changeset you are working on was deleted when you try to checkin your changes.

All platforms - Plastic: The undo operation left checked-out xlinks pending -you needed to undo them again- sometimes when trying to undo all changes. This happened if the checked-out xlink was part of the targeted changes and under it there was a moved item with dependencies (e.g. a moved directory whose source is in use by a copied directory). Now all changes are undone the first time, as expected.

Windows - Plastic: improved the embedded semanticmerge to take into account the preferences related to the merge conflict resolution (manual or automatic when possible).

Windows - Plastic, Gluon: some users reported that, in Gluon, the purpose of the checkin comments textbox wasn't obvious. Our bad! Luckily, that's what hint texts are for - so now both Plastic and Gluon have a hint text so you never leave a checkin comment empty ever again!

All platforms - Fixed the checkin error 'There has been an unexpected error "The item should be found on the server tree. Child [readme.txt]. Parent [doc]". For more information check the server log.' trying to checkin a merge result on a workspace with cloaked items under some special circumstances.

Let's see a simplified case that reproduces the error that now is fixed:

1- Create a new workspace pointing to a new repository.

2- Add and checkin the following content:

3- Cloak /src (the items remains loaded but as cloaked).

4- Create a child branch task from cset:0

5- Merge from main to task

6- Checkin the merge result -> The checkin failed with the following error: 'There has been an unexpected error "The item should be found on the server tree. Child [foo.c]. Parent [src]". For more information check the server log.'. Now it's fixed

All platforms – Plastic, Gluon, command line: Now update always goes to latest.

Suppose you switched your workspace to a particular changeset, then decided to update. You were stuck on that changeset, by design.

We thought (for a few years already) that if you had switched to a given changeset, why would you want to jump to latest during an update?

But then we realized it was a true UX pain. Why wouldn't you want to switch to latest?

So, we just changed the behavior. Now, when you update, you'll always go to latest in the branch, even if you were working on a given changeset or label before.

Windows - Plastic: The new Code Review system now displays questions in the comments list.

Remember, right now, you need to start with plastic --codereview to enjoy the new feature.

All platforms - Plastic: Small refactor and cleanup of the merge code to get ready for the "incoming changes" feature that will hopefully simplify working on single branch and will make all Perforce users rush to Plastic.

macOS - Plastic, Gluon: With the performance improvements we made some releases ago, we introduced a change in how the autoexpanded items in the Pending Changes (Plastic) and Checkin (Gluon) views were handled. When you refreshed the view, the only category that got expanded was the one you had an item selected in. This didn't like some users, so we reverted it - autoexpansion saving will work for less than 5000 items (whilst it won't for 5000 items or more, for performance reasons).

Windows - Plastic: The new CodeReview system supports outlining.

When a comment was placed in a line that was collapsed due to outlining, it was rendered in a wrong line. Now the comment is hidden when the line is collapsed and visible when the line is not collapsed.

We also improved the comments navigation. When navigating to a comment, we always ensure that the line that contains the comment is always expanded. Otherwise, in some scenarios a comment could be not visible.

Remember, right now, you need to start with plastic --codereview to enjoy the new feature.

Windows - SemanticMerge tool: Improved declaration matching mechanism to detect properly the conditional inclusion in the following 'merge' scenario:

Destination contributor:

Windows - Visual Studio package: After installing .net 4.8, the Plastic SCM views were not visible in Visual Studio 2019. Now it's fixed.

.NET Framework 4.8 comes with several enhancements to support Per-Monitor V2 DPI Awareness (PMv2) and Mixed-Mode DPI hosting in both Windows Forms and Windows Presentation Foundation (WPF). Unfortunately, tool windows created in Windows Forms were not render correctly when its Per-Monitor Awareness (PMA) setting is enabled. We made changes in the code to address this issue.

Windows - Plastic: we had a bug in the new code review that resulted in some branch reviews showing an empty GUID for the branch, instead of its actual GUID. Now that's solved!

Linux - Plastic, Gluon (Cloud Edition): The preferences dialog displayed duplicated ok and cancel buttons. Now it's fixed.

Server - macOS, Linux, Windows: We enabled multi-file semantic merge by default in mergebots. Check http://blog.plasticscm.com/2019/07/merge-moved-code-across-files.html for more info.

Windows - Plastic: The new Code Review system now allows to visualize comments that are located in revisions that are not loaded by the diff window. This happens when, for example, you applied revision comments, and created new revisions for a file in the branch. When this happens, we display a panel with three actions:

Diff revision with comments: This action allows to visualize the revision with the comment on the right diff pane, and the base revision on the left diff pane.

Last in branch: This action displays the last revision in branch on the right diff pane, and the base revision on the left diff pane (the same as when you select a file in the top tree).

Diff with head: This action the revision with the comment revision on the left diff pane, and the last revision in branch on the right diff pane.

Remember, right now, you need to start with plastic --codereview to enjoy the new feature.

Windows - Plastic: The new Code Review system now allows to visualize change `sts in the comments list.

Remember, right now, you need to start with plastic --codereview to enjoy the new feature.

Windows - Plastic: The new Code Review system now allows to choose the comment type when adding a new comment. You can 'request a change', 'ask a question' or simple write a regular comment.

Also we added the possibility of discarding requested changes.

Remember, right now, you need to start with plastic --codereview to enjoy the new feature.

Server - DevOps: Our built-in mergebot that implements trunk-based-development cycle (a.k.a. trunk-bot) is now able to use embedded Plastic code reviews to drive the CI/CD lifecycle.

Enable the following "Process reviewed branches only" toggle button in trunk-bot configuration to activate this feature:

The feature works as follows:

When a code review of a tracked branch (those that starts with the configured branch prefix in trunk-bot config) is created, or its status changes, the task branch is queued in trunk-bot.

Then, trunk-bot will eventually dequeue this task branch. But before continue its processing in the CI cycle, trunk-bot will check whether there is at least an "Approved" code review for this branch. Otherwise, the branch processing is skipped but enqueued.

If there are more than a code review linked to this task branch, all of them need to be approved before processing the task branch.

If all the code reviews are approved, the task branch continues its processing by the trunk-bot:

a)If the merge fails (manual conflicts detected), or the branch build in the configured CI system fails, the status of the linked code reviews of the branch will be set to "Pending".

b)If the merge succeeds and the branch build succeeds too, the task branch is merged, and the "status" attribute of the branch is set to "merged" (these fields must be filled in the trunk-bot configuration).

You can use this "Process reviewed branches only" alone to drive the CI/CD cycle, or use the legacy "branch status" based lifecycle to drive the process, or combine them: before trying to merge a task branch into trunk, both the status of the branch must be set to "resolved" value, and all the code reviews must be set to "Approved".

macOS, Linux - Plastic: Merge: corrected the merge behavior for scenarios involving writable xlink conflicts.

The merge is one of the strongest and key features about Plastic SCM so we can't afford failures on it.

Windows - SemanticMerge tool: A 'Value cannot be null. Parameter name: source' exception was thrown when the destination file of the merge was empty. Fixed.

All platforms - Plastic: The Merge-to was wrongly showing the merge finished status if a file was individually solved under a writable xlink conflict but there were more conflicts pending to solve. Now it's fixed.

All platforms - Command line client: we fixed a bug which meant that the help wasn't displayed for some "cm partial" subcommands. For example, "cm partial update --help" now works as expected.

Linux - Plastic, Gluon: Sometimes, when closing the diff window, an unexpected "Index out of range" error appeared. Now it's fixed.

Windows, Gluon: "Checkin Changes" view: Sorting files by "Date modified" was not working as expected. Now it's fixed.

We broke this by mistake when we reorganized the columns a few releases ago.

Windows - SemanticMerge tool: A 'Value cannot be null. Parameter name: source' exception was thrown when the destination file of the merge was empty. Fixed.

Windows - Plastic: The new Code Review system now allows to start conversations, using the "Reply" functionality.

Remember, right now, you need to start with plastic --codereview to enjoy the new feature.

You can check how it looks here, dealing with a conversation with several threads.

macOS - Plastic: Improved the progress text shown in the workspace window toolbar to correctly use the available space and adapt it when the window is resized. We saw that sometimes the progress text was cropped even when there was plenty of space available to display it.

Here goes the "before and after":

All platforms - Server: New Merge Rules system.

We added a Merge Rules system (mergerules.conf). Use it to make branch reviews mandatory prior to merge.

This is a good equivalent to the popular "pull request restrictions" that force to review branches before merge.

The Merge Rules define what branches must be reviewed when merged to certain branches.

If a merge can't happen, you'll receive an error like this:

Here is an example of a very simple mergerules.conf forcing all branches QUAK-* to be reviewed prior to be merged to main.

The new mergerules.conf is a JSON file that must be placed in the server directory (where plasticd.exe is located).

You will find a mergerules.conf file with some examples in your server directory, inside config_samples, and alongside the binaries for clean setups (on Windows using the installer, and GNU/Linux using the official packages) so you can directly modify it. You don't need to restart the server for changes to take effect!

Each rule defines source and destination branch matching as well. Branch matching is done using name patterns (with '*' to represent any substring), attribute matching, and you can specify multiple rules of each kind, too.

Finally, when you're about to merge a branch, the server will check whether there are any rules that apply to that source/destination pair.

We plan to support different kinds of mergerules in the future, but right now there is only one: 'only_allow_merges_if_reviewed'. If both source and destination branches match a rule of this kind, the server will only to merge source branches that have an Approved review.

It is also possible to filter branches by attributes, instead of names. Check the example mergerules.conf to find all the filtering options.

Server, DevOps: Added notifications of "code review changed" events through the web socket channel the DevOps mergebots use. This means the mergebots will now be able to implement filters to avoid merging branches that don't have an approved code review.

We will enable this filter for our built-in "trunk-bot" really soon. Stay tuned!

To enable this notification on custom mergebots you may have written, your mergebot will have to subscribe to these events by sending a message to the Plastic Server websocket endpoint (e.g. ws://<SERVER_IP_HOSTNAME>:7111/plug).

The subscription message looks like the following json:

(The "eventlist" array could also contain "newChangesets" and "branchAttributeChanged" trigger types to subscribe to these events too).

Once the subscription is completed, your mergebot will be able to receive "code review changed" messages when a code review is created, when the code review status is changes, when the code review title is changed, and when a code review is deleted.

The message sent this way through the web socket looks like the following json:

REMARK: The code review notifications are sent only if the code review is bound to a branch.

All platforms - Command line client: we have added an "--ignored" option to the "cm rm private" command.

By default, ignored files are skipped during the delete. The "--ignored" option allows you to include ignored files.

Note: this is a change from the previous default behaviour. Previously, ignored files were included by default.

macOS - Plastic: Sometimes, when switching workspaces, users got the following error:

"cannot access a disposed object".

macOS, Linux - Plastic: Disable the 'Diff changeset' context menu in annotates for lines changed locally.

We were investigating a bug reported by a customer. They occasionally see an evil "cannot process your request" exception. We weren't able to reproduce their case, but the closest was this thing: same error (and similar stack dumped) if you have local changes and "diff changeset" over the changed lines in an annotate.

All platforms - Plastic, Gluon: We improved the behavior when you have local changes and the changeset loaded in your workspace is deleted by a different user.

Before these improvements, this meant that you got stuck: at that point you were unable to checkin, shelve or undo your local changes.

We modified the client behavior to enable you to undo your local changes, letting you out of that loophole. Shelving or checking them in will still be unavailable, as they wouldn't have a parent changeset.

The 'undo' behavior will be slightly different depending on the client you use:

Gluon will always allow you to undo the local changes. If the original contents aren't available anymore, the head contents of the current branch will be used instead.

Plastic, on the other hand, will notify you about the inconsistency and then ask you for confirmation to undo all your local changes and update the current workspace.

Server: The sync view was failing with the error 'Error: There has been an unexpected error "Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host.". For more information check the server log.' on the following case:

We have the servers A and the server B

On both servers we have the repository myrep

On myrep@B, we create the branch main/task and perform 2 checkins on it (changeset 4 & 5).

We create a sync view with source myrep@A and destination myrep@B

We pull all changes -> We pull main/task

On myrep@B, we delete the changeset 5.

We try to sync, and the sync view fails with the error ''Error: There has been an unexpected error "Unable to read data from the transport connection: An existing connection was forcibly closed by the remote host.". For more information check the server log.'

macOS - Plastic: Right-clicking in the Workspace Explorer view before the view is loaded triggered an unexpected error.

Windows - Visual Studio integration package: Include missing JAR files necessary to show the semantic history of java and c++ files.

Server: We added on the Jet backend a mechanism to verify that all files are on the right version. This mechanism will be needed by the future upgrade on the Jet backend.

Windows - Plastic: More improvements in the prototype of the upcoming Code Review system.

Now you can change the assignee directly in the code review window.

As we already announced, it is not yet functional but you can give it a try if you start your Plastic this way:

Let's see it in action:

More improvements really soon :-)

All platforms - Command line client: as requested by users, we now append a newline character to the end of xml output, so the output plays more nicely when fed into xml parsers.

Bonus: we fixed the xml output of the "ls" command. It used to incorrectly append the standard output to the xml.

Windows - Plastic: When you create a branch with a name that already exists, the error message will be shown in the dialog and the dialog won't be closed. Before, the error was displayed in an additional popup window (more clicks for users) and the dialog was closed.

Windows - Plastic: Evolved prototype of the upcoming Code Review system. Now, the prototype manages real data. You can give it a try if you start your Plastic this way:

You can create new reviews, and edit existing ones. Feel free to share your feedback.

Windows - Gluon, Plastic: Under some circumstances, the label that shows the metadata info is cut in the diff and changeset explorer windows.

All platforms - Command line client: suppose you move a file, and then you move another file to where that first file used to be, and then you "cm undo" those two moves. Of course, the first move can only be undone after the second move, and, of course, Plastic takes that kind of dependency resolution in its stride.

However, the cli, being modest, would only tell you that it successfully undid the second move. We've now fixed the output so it tells you about the first move too.

All platforms - Plastic, Command line client: improved handling of occupied paths.

You may have noticed that when Plastic needs to write a controlled file to disk, but the path is occupied by another file, it moves the existing file out of the way (to "file.private.0") so that you don't lose any data. The same for directories.

There were a couple of cases we weren't handling so gracefully, and would produce an error message. We have fixed the handling for these cases. Specifically, you can now undo the move or remove of a file when the path is occupied by a directory, and undo the move or remove of a directory when the path is occupied by a file, and your local data is preserved in all cases.

Windows - Server: Udt wasn't working to do replicas between servers unless you forced Remoting protocol using plasticpipeprotocol.conf. It is now fixed.

All platforms - Plastic, Gluon: Pending Changes will now fly when you have files with timestamp but not content changes.

Many Unreal and Unity users face this issue: their IDEs modify timestamps of files "randomly" but not content. Plastic finds them as changed.

Then they check this preference in Plastic: "Check the content to determine files as changed, not only timestamp" and the fake changes disappear but... at a cost. Pending Changes starts getting slower and slower because it has to calculate the hash of each "fake change".

Now this is fixed because Pending Changes (on GUI, CLI, plugins, everywhere) will update the timestamp of its metadata to avoid having to rehash next time.

From now on, fresh installs of Plastic SCM Team or Enterprise editions will be packed with a 5 days free trial license for 5 users (before this version, the free trial license only allowed 1 user).

Windows, Plastic: More improvements in the prototype of the upcoming Code Review system.

We removed the initial dialog to create the code review. Now it will be created directly and users will be able to edit anything (title for now) in the code review window.

As we already announced, it is not yet functional but you can give it a try if you start your Plastic this way:

And then go to create, edit and delete a Code Review.

More improvements really soon :-)

All platforms: We improved the error message you get when you try to undo some locally moved files but their original directory cannot be found. This usually happens because you aren't allowing plastic to detect locally deleted directories, so the client can't restore them. The error message now suggests you to enable deleted item detection.

For instance, let's say you transform this workspace tree:

/a/b is detected as locally deleted in this scenario.

At that point, if you run 'cm undo --moved -r' the client can't restore the moved files because directory /a/b can't be found (it's detected as locally deleted). You'd need to include the --deleted argument.

In the GUI you'd normally get a dependencies warning before the undo; however, if you don't check the "Show deleted files and directories" option in the "What to show" tab of the Pending Changes view, the operation can't properly calculate the dependencies and it will fail.

All platforms - Plastic, Gluon: When diffing from the history view, when the loaded revision was the right revision, the diff was not editable. Now we detect that case, and make it editable.

All platforms - Command line client: We improved the error message generated when 'cm undo' can't undo a change because there is a dependency. It now advises you to include the depended upon item in the set of paths passed to the command.

All platforms - Plastic, Command line client: merging a change to a binary file (when only the source has changed) used to fail if file in the destination branch was read-only. You used to get an error about "Access to the path" being denied. We fixed this, and the merge now completes successfully.

macOS, Linux - Plastic: The checkin operation did nothing (and displayed no feedback) if you performed a merge that created no changed files. That can happen e.g. if the only merge conflict is a readonly-xlink modified in both contributors (a directory conflict) and you select "Keep destination" to solve it.

Linux, macOS - Plastic: The external tools failed to launch for items that were not in the workspace (for example, opening an external tool on a file when browsing the repository in other cset different than the current one). That's now fixed!

All platforms - Gluon: The update was not able to download new items in a very specific scenario with delete, add and move operation related among them. The error shown in the report was the following "The new item cannot be loaded in the workspace. Probably, the path is already used. Please unload the item (from the configuration view) and retry the operation." The specific scenario was the following:

Having this repository structure:

One user loads in the workspace (wk1) the following content (the whole repo except for /bar.c).

Another user that loads the whole repo, make the following changes and checkin them:

When the user (wk1) run an update, he got the "The new item cannot be loaded..." error. Now, the /src/code/qux.c is correctly download.

Windows, Plastic: Here goes a prototype of the upcoming Code Review system.

It is not yet functional but you can give it a try if you start your Plastic this way:

And then go to edit an existing Code Review.

Remember, this is just a prototype, so the comments won't be stored. The goal is just to try how good the new comment system works and get feedback.

It is now finally possible to reply in comments.

And also create threaded conversations, something we always missed (and didn't find on competitors either).

Hope you enjoy it. This is just a first step to implement our Code Review vision :-)

All platforms - Client-side triggers: From now on, missing client-side triggers won't make trigger execution fail: the next trigger in the list will be executed instead. Bear in mind that by "missing client side trigger" we mean "when the executable of the trigger is not accessible by Plastic process" (CLI or GUI). If the trigger executes, but fails, will make trigger chain execution fail as before.

This is useful when you store triggers in a repository: on first update, the trigger is not present, and thus it is skipped, instead of making update operation fail (forcing you to remove the trigger, run the update, restore the trigger…)

macOS - Plastic: We changed the cherry-pick link color when the Dark Theme is enabled. They were extremely difficult to notice until now, so we're dragging them out of the shadows! Take a look at how it looks:

Xlinks: Fixed a couple of scenarios where the user couldn't perform changes inside an xlink due to the "Can't perform a checkout in an edited xlink" error.

The first one was related to checking-in partial changes inside an xlink.

Having the following structure in the workspace, where /xlink is an xlink :)

If we add a couple of files:

But we only checkin one of them:

All platforms - Plastic, Command line client: When undoing complex locally moved changes, you could get the error "The item XYZ already exists!". That's been fixed. If you want a deeper explanation of the problem, continue reading!

Imagine this scenario - you have a deep tree structure and you do the following operations outside of Plastic SCM:

Rename a file inside said directory (from name A to B).

Move up a file deeper in the tree structure to be alongside the recently renamed file.

Rename the file you just moved to have the same previous name as the other file you renamed (from name C to A).

With a little diagram, we have transformed this (simplified):

…where numbers (1), (2) and (3) indicate the item correspondence (directory or file), and (LM) indicate the new status from said item.

Now, before doing further operations (undo, checkin, and so on), Plastic SCM needs to convert local changes to controlled ones. The problem was that, because of how Plastic SCM calculates precedence between local changes, it was trying to apply first the LM on item (3) instead of on item (2). An item with the same name and path already existed in the metadata (because changes on (2) were still to be applied), and the command execution failed. Now, Plastic SCM correctly calculates locally moved changes precedence in order to apply them in the right order.

This is a good moment to remember you that, for doing complex restructurings, you can use the GUIs or the command line client. Plastic SCM will update the metadata with each move, delete, and rename operations, which makes the process much less error-prone.

Server: We improved the error message generated when a changeset is unexpectedly not found in the database. Rather than a generic message, we now return a message specific to the scenario, with appropriate advice for the user where applicable.

All platforms - Plastic: We all know you can easily merge a branch or changeset into your workspace from the branch and changeset context menu. Did you know you can also merge a branch or changeset into another branch, essentially performing a "workspace-less merge"?

That feature has been available for a while, but users couldn't find it because we hid it in an "Advanced" submenu. We've moved the "Merge from this changeset/branch to..." menu option up to the primary menu so make it easier to find.

All platforms - Plastic: the "Replication" submenu item in the branch context menu has been renamed to "Push/Pull" so it's a bit easier to find when you're looking for the various Push and Pull options.

All platforms - Gluon: Until now, cancelling an update worked as follows: if Plastic was downloading a block of files (the server sends small files together in a block to improve performance), the GUI would finish downloading said block, and then cancel the update. However, if instead of a block of small files Plastic was downloading a huge file, the operation would not cancel until said file finished downloading. For files in the megabytes range this is not that much of an issue, but for files of several gigabytes having to wait didn't make much sense. That's why we changed how cancelling an update works: the update will stop right away, and the big file in progress will be left incomplete - it will show up as changed in the pending changes / checkin views.

All platforms - Plastic: we have improved the error message you get if you try to delete a changeset that can't be deleted. There are a number of reasons why a changeset could not be deleted. Ideally we would tell you the specific reason in your case. At some point we will, but until then, we have updated the error message to tell you the possible causes.

For reference, a changeset cannot be deleted if:

It is the parent of another changeset

It is the source of a merge link

There exists a shelveset created from the changeset

There is a label on the changeset

All platforms - Plastic and Gluon: We improved the confirmation dialog you get when you Lock and Checkout an item and there aren't any existing lock rules that match its path. It allows you to choose between these kinds of rules:

Extension rule ('*.db')

Name rule ('Database.db')

Directory path ('/Library/Assets')

Full exact path ('/Library/Assets/Database.db')

Windows - Gluon: Great news! The Workspace explorer now includes auto-refresh!

Now, every time Gluon becomes the key window you'll notice that the Workspace Explorer view is automatically refreshed if there are new changes in the workspace since the last time it was refreshed.

Additionally, we improved the Status column to display whether a file or directory is ignored, not on disk or added.

All platforms - Mergetool: Sometimes automatic merges produced joint lines at the end of files. This happened if the base file didn't end with a newline character, comparison method was set to "Ignore EOL" and automatic merge was enabled (manual merges were OK).

For example, having this base file base.txt (no EOL at the end):

This source file src.txt (ends with EOL):

and this destination file dst.txt (ends with EOL):

If you ran 'mergetool.exe -s=src.txt -d=dst.txt -b=base.txt -r=result.txt -i=eol -a', you got this in the result file result.txt (ends with EOL):

Windows - Plastic: there were a couple of issues in the 2D revision tree (when you browse the history of an item as a 2D tree). The first one was considering changesets that were the source of shelves with merge traceability (used in DevOps operations by the mergebots) as relevant. The second one was not discovering the destination of a merge involving an item if no new revisions of the item were originated in the destination branch of the merge. Both of them are fixed, so you shouldn't see "Unchanged" changesets without mergelinks.

Jenkins plugin: Windows agents couldn't update their workspaces if the master ran in Linux and the agent root directory was defined with forward slashes instead of windows-like backwards slashes. Fixed!

Windows installer: Installing Plastic using the client-only installer, and then upgrading to a cloud edition was causing the local server component not to be installed. Now it's fixed.

All platforms - Plastic, Gluon: The ability to force Lock and Checkout in the Workspace Explorer context menu is now available!

It can be even invoked from the search menu in Gluon:

If you select a single controlled item, the context menu that appears on right click will include a new "Lock and Checkout" option. It will ensure that an appropriate lock rule the selected item exists in the server, and if it doesn't you'll be prompted to confirm that you want to add a new one.

Important: We added a new permission 'configlocks' that controls access to this feature. Please make sure you are granted that permissions in the current repository (or repository server) and also that your server is updated to a compatible version.

macOS - Gluon: We have tweaked the column width and order in several tables across the application.

Now, the relevant information should be more accessible.

This change affects only to Gluon newcomers - if you already use Gluon for macOS, the order and width of the columns in the applications are stored in a preference. If you want to reset this preference, you can execute the following command:

All platforms - Gluon: When diffing a file from the "Workspace Explorer" or the "Checkin changes" views, the diffs was not editable. Now it's fixed.

All platforms - Mergetool: the mergetool used to show the full path and branch or changeset specification for each of the 3 contributors to the merge (or 2 contributors for a diff).

Of course, if the path is the same for all the contributors there is no point showing multiple times. In this case, we now display the file path in the title bar, and only show the unique specification of each contributor above each file pane. This makes it much easier to see all the relevant information, especially for long paths.

macOS, Linux - Plastic, Gluon: We replaced text entries for editable comboboxes in many of the places we ask you to type in a server. Those comboboxes are filled with the servers you use frequently - this way, there is no need to remember a server address. What's even better, if you are a Cloud Edition user, the comboboxes actually have ALL of the organizations you are part of! Check out how it looks in macOS:

Linux and MacOs: Gluon and Plastic. Added the edit comment operation to the diff window.

Let's see it in action!

macOS, Linux - Plastic: Implemented two new options in the history view:

Diff changeset -> Launches the diff window for the changeset the revision belongs to.

Revert to this revision -> Checkouts the file on disk and replaces the file content with the content of the selected revision.

macOS - Plastic, Gluon: there was a bug that could crash the application if it tried to display a dialog when hidden. Now it's fixed - the dialog will appear as soon as the application is in the foreground again.

CodeBeamer Issue Tracker extension: A deserialization error could be shown when creating a new branch in Plastic SCM with this extension enabled. This could happen if the CodeBeamer server API response contained "assignedTo" field values different than an array (e.g. a single object). Fixed: now the CodeBeamer extension supports "assignedTo" responses as arrays and as single objects.

Linux - Gluon: The 'Search files' dialog in the 'Explore workspace' view could return wrong results when typing while a previous search was running. Fixed.

All platforms - Command line client: running "cm status" with both the "--head" and "--cset" options set resulted in a null reference exception being thrown. We fixed this and these two options can now be used together.

"--head" prints the details of the head changeset on the branch

"--cset" gives you the output in the legacy format

macOS, Linux: Plastic, Gluon: Added actions to semantic diffs buttons. Now changed (C) and moved (M) buttons allow to diff changed code and go to moved code.

This is how it looks like in macOS:

Jenkins plugin: We added support for job parameters in Pipeline checkout selectors.

Jenkins plugin: The cm path setting in the global plugin settings has now a validation action.

DevOps: JiraPlug: The JiraPlug will now be able to connect to Jira Cloud servers using Basic Authentication with an API token instead of user's password.

The related configuration field in JiraPlug will now be more descriptive about this fact:

To create an API token for the user configured with your JiraPlug instance, go to Jira API Tokens page and paste the token in the Password / API Token field of JiraPlug configuration.

DevOps: JiraPlug: Improved check connection on plug startup. If the entered credentials are not valid, a proper error message will be logged inside devops/logs folder of your plastic server instance, and the JiraPlug execution will be gracefully stopped. Maybe you are using a Jira Cloud Server and you need to configure an API token for the user configured with JiraPlug to perform queries and status updates.

Jenkins plugin: Changes in release 2.21 altered how workspace names are set. This was disruptive for some setups that rely on workspace names to build. It's fixed now.

Jenkins plugin: Pipeline checkouts always checked the "use multiple workspaces" option. Fixed!

Windows - Gluon: Sometimes the switcher window appeared behind the Gluon window where you clicked "Switch workspace". We modified how we display the switcher window to ensure it is displayed in the right place, i.e. over the Gluon workspace window.

macOS, Linux - Plastic, Gluon: the application could come into an unresponsive state for a few minutes when trying to download the Plastic global configuration from an inaccessible server. This was because of a thread interlocking issue. One easy way to reproduce this problem was as follows: open Plastic SCM in a workspace whose repository server is not available (maybe because it is in another network), and try to change to another workspace. The second Plastic SCM window won't be able to load the Workspace Explorer view until the first one finishes trying to download the inaccessible global configuration. This is now fixed!

Windows - Plastic: SemanticMerge is now part of Plastic SCM!

Yes, you read it right: now you get the full power of SemanticMerge bundled with Plastic, no extra purchase, everything included.

It means if you are merging C#, Java, C, C++, VB.net or any other language supported by Semantic... you get the extra power of code-aware merges.

Now all the SemanticMerge power is inside PlasticSCM. Enjoy!

Windows - Plastic: Conflict resolution is now incredibly faster!

This is because our merge tool is now launched within the same process instead of spawning a new one, which makes it start up super fast.

For automatic file conflicts, the resolution is immediate. Before this improvement, the conflict resolution speed is normal but now it flies!

For file conflicts that require human intervention, the merge window appears also in 0 secs.

Windows: Gluon and Plastic. Added the edit comment operation to the diff and changeset explorer windows.

Let's see it in action!

Pending changes: We improved how ignore.conf rules are processed to improve the performance of the Pending Changes view refresh operation in the GUIs and the 'cm status' command.

Now, ignored directories will be entirely skipped if there aren't any ignore exclusion rules (you know, those that start with the '!' character) that might apply to a child item.

These are the rules that, if present, automatically mean that any ignored directory could have any of its child items excluded from being ignored:

Extension rules: '!.exe', '!.pdb'

"Ends with" rules: '!.exe.config', '!/log/results.txt'

"Contains" rules: '!bin'

Name rules: '!Debug', '!parameters', '!package.json'

Besides that, path rules such as '!/src/lib' or '!/path/to/a/very/particular/directory' will only force an ignored directory to be fully processed if that ignored directory is a parent of the excluded path.

In a nutshell, this means that no matter what your ignore rules are, if you stick to path rules (e.g !/src/lib, !/doc/api/summary) for your ignore exceptions you'll notice that calculating changes with private items runs a lot faster now.

Let's see that using an example. If you have two directories, /Library and /cfg whose contents you'd like to ignore but you want to exclude /cfg/keys_default.cfg, you'd normally write these rules:

The mere existence of the last rule (!/cfg/keys_default.cfg) caused the complete tree under /Library to be processed, even if none of its children could be excluded! Fortunately, we changed that now. The last rule, the exclusion one, will only affect items directly under /cfg. If you had some directory like /cfg/db, it won't be processed either: there aren't any rules that might exclude one of its children from being ignored.

Windows - Plastic: The diff viewer did not draw the current difference border for moved regions, when the changed lines in the moved regions were the first or the last. Now it's fixed:

GitSync / fast-export: The sync command failed with the message "The user xxxx appears as an inactive user because his/her license has been deactivated. Please activate it and then try again." when the user who launched the operation didn't exist in the repository used by the command. The same happened with the fast-export command.

macOS - Plastic SCM: We have tweaked the column width and order in several tables across the application.

Now, the relevant information should be more accessible. This change affects only Plastic SCM newcomers - if you already use Plastic SCM for macOS, the order and width of the columns in the applications are stored in a preference. If you want to reset this preference, you can execute the following command:

Here is how it looks:

Windows - Gluon: we've added a Repository column to the "Checkin changes" view, and we've changed the default column order of the Changesets view to make it consistent across all 3 platforms.

Jira Extension: We enhanced our Jira issue tracker extension to disable it when it detects that the entered credentials are invalid. This prevents the extension from performing many unauthorized requests. That would lock users out of their accounts, needing to reset them using CAPTCHAS in some organizations.

macOS, Linux - Plastic, Gluon: The differences viewer did not show a mark for added/deleted differences. This is how it looks like in macOS:

Linux - Plastic SCM: We have tweaked the column width and order in several tables across the application.

This change will only affect new users of the tool. Existing users of the tool have their view configuration stored in a preferences file. To reset your views to the new default values, close the application and delete the preferences file as follows:

Windows - Plastic, Gluon: On the repositories lists (Repositories view, Cloud view, and repository list dialog), the Refresh button has been moved to the right of the server entry field, to make it clearer that we are refreshing the view based on the content of that field. Same goes for Gluon's "Available Plastic SCM repositories" dialog.

Linux - Plastic, Gluon: On the Repository switcher dialog, and the Cloud view in Plastic, the Refresh button has been moved to the right of the server entry field, to make it clearer that we are refreshing the view based on the content of that field.

What? A screenshot? Oh, go on then!

All platforms - Plastic, Command line client: Suppose you've switched your workspace to a past changeset. You edit a file. Then you switch to the head. You wouldn't want your edit to be overwritten would you? And if you tried to checkin that file, you definitely wouldn't want that, because you'd be losing all the changes between that past changeset and the head.

Good news - Plastic (and the CLI) handle all this perfectly. However, the error message we displayed if you tried to checkin in this situation wasn't very clear. More good news - we changed the text to make it clearer what the issue is, and more importantly, how you can resolve the issue.

Incidentally, the solution in this case is to temporarily back out your local changes, update the file to the head version, and reapply your changes.

macOS, Linux - Plastic, Gluon: Added the "similarity" column to the Pending Changes view as in the Windows counterparts. For locally moved files, you can see the similarity percentage that determined that the file was indeed moved. Remember that you can change this threshold from the Pending Changes options.

Note: by default the Similarity column is between "Date modified" and "repository", to keep consistency with the Windows GUI. Remember that in macOS and Linux you can reorder columns. Pending Changes' column width and positions are reset after adding the Similarity column to ensure it is displayed OK. If you had customized width and positions in this table, you will need to do so again.

Windows - Plastic: We changed the default order of the columns in the Shelvesets view to make the most relevant data more prominent.

New users will see this change when the run Plastic for the first time. Existing users can reset all their view settings to the new default values by deleting the preferences file, located here:

Here's what the new layout looks like:

Plastic, Gluon - macOS: We improved diff rendering. Now the colors are stronger and easier to spot the differences.

Check how it looks like in the clear theme, before and after:

And now the dark theme:

All platforms - The checkin operation sometimes failed due to a duplicate key error while checking in the results of a merge. This happened if path permissions were applied, the merge included at least one moved+changed change and the user chose to keep the sources in a "loaded twice" conflict. Now it's fixed.

Jenkins plugin: Changes in release 2.21 altered how workspace names are set. This was disruptive for some setups that rely on workspace names to build. It's fixed now.

macOS, Linux - Plastic: The directory conflict resolution was not working on the merge-to operation. After resolved the conflict, the process all failed with this error: "There are X directory conflict(s) that must be resolved before processing the merge.". Now it's fixed

Linux - Plastic, Gluon: In some setups, depending on the GTK icon theme enabled in the computer, Plastic GUIs could flood the user with the error message "Icon 'unknown' not present in theme". Apparently, this error is more common after an Operating System upgrade (for example, from one version of Ubuntu to the next one). The error is now protected - if an icon is not present in your GTK theme, Plastic and Gluon will display an empty one instead.

Tip: you can force a GTK icon theme creating a file with name ".gtkrc-2.0" in your $HOME with the following content:

Replace "Humanity" for one of the icon names you have installed at /usr/share/icons. For changes to take effect you must restart Plastic and Gluon after changing .gtkrc-2.0.

macOS, Linux - Plastic, Gluon: The update operation was failing when the "Update and checkin operations set files as readonly" & "Update operation sets repository timestamp on files" options are both enabled. Now it's fixed.

macOS - Plastic: To make the mac GUI Branch Explorer more usable we have added a date filter and an "Only relevant" toggle button. Now you can more easily configure your Branch Explorer view to show only the information you want.

The date filter works as follows: only changesets created after the date chosen will be displayed on the canvas. This can reduce clutter in the view, and aid performance.

The "Only relevant " toggle button also reduces clutter in the view, by only showing initial and final changesets on branches.

Here is a look at the new Branch Explorer:

Create workspace: If you have a Plastic SCM workspace in your filesystem but it got removed from the list for some reason (the list is stored in the file plastic.workspaces, in your config directory) you can now safely add it back using the CLI or any Create Workspace GUI dialog. We changed the behavior to avoid overwriting the workspace name and repository.

Plastic, Gluon - macOS: We finally have auto-refresh in Plastic Pending Changes and Gluon Checkin views.

Now, when the Plastic/Gluon window becomes the key window, the Pending Changes view is auto-refreshed if there are new changes in the workspace since the last time it was refreshed.

This was one of the top usability missing features in macOS! :-)

macOS - Plastic: Conflict resolution is now incredibly faster!

This is because our merge tool is now launched within the same process instead of spawning a new one, which makes it start up super fast.

For automatic file conflicts, the resolution is practically immediate. Before it used to be as slow as 4 seconds per file.

For file conflicts that require human intervention, the merge window appears also in 0 secs.

Windows - Plastic: We have updated the column ordering for the Workspace Explorer, Pending changes, Changesets and Labels views to make the more logical, and present the more useful information first. They are also consistent across all 3 platforms now.

We also updated the default column widths, so, out of the box, users should no longer need to resize columns to see the full content.

Visual Studio Integration - Windows: The Visual Studio integration was only compatible with some Visual Studio 2019 versions (v16.0 - Preview). Now, we extended the compatibility to support all Visual Studio 2019 versions.

As a side effect, the code base is not compatible with Visual Studio 2010 anymore. If you need support for Visual Studio 2010, please contact support@codicesoftware.com and we'll help you get it going.

Linux - Plastic: Conflict resolution is now incredibly faster!

This is because our merge tool is now launched within the same process instead of spawning a new one, which makes it start up super fast.

For automatic file conflicts, the resolution is immediate. Before this improvement, the conflict resolution speed is normal but now it flies!

For file conflicts that require human intervention, the merge window appears also in 0 secs.

macOS - Plastic: We added a small panel under the Workspace Window toolbar to show you the branch/changeset /label (and its repository) of the current workspace, the current workspace name and path and the current user's name. This info previously appeared next to the "Switch workspace" button and was hard to see sometimes. Enjoy!

Plastic, Gluon - macOS: Added a new option in the pending changes/checkin view, to enable or disable the auto-refresh feature.

Windows - Plastic: concerned about wasting mouse clicks? We've got your back. Now, when you push a branch to a remote repository, and everything goes fine, we don't pop up an additional dialog to tell you this. Of course, we still let you know if anything goes wrong during the replication.

Linux - Gluon: We have improved the default column widths for the "Explore workspace" view, and made the "Details" pane of the "Checkin" view a bit smaller, so it doesn't hide so much of the changelists table.

Existing users can reset their view configuration, and enjoy all our recent changes to column order and widths, by deleting the following configuration file:

Here's how the GUI looks now:

Linux, macOS - Plastic: there was an unexpected exception when committing the results of a merge-to operation if the source changes already existed in the destination and there was nothing to do. This case is now handled nicely.

DevOps: Jenkins mergebot plugin (the plugin installed on jenkins server side): The jenkins job using mergebot could fail with "Workspace already exist" error when the Jenkins server is a Linux machine but the job runs in a Windows agent. This could happen if the configured Windows agent "Root directory" has a different drive letter case than the registered existing plastic workspace paths. Now it's fixed.

Jenkins Plugin: There were issues with shared libraries when two or more projects were consuming a single shared library. They were related to the workspace names assigned to the shared library workspace for each project, which turned out to be always the same. We fixed that to make every shared library workspace have its own self-generated workspace name.

When a check-in operation fails against the cloud due to a client network issue, if the same client is used to perform a new check-in under some corner circumstances a file content could be wrongly updated to the cloud. Although the issue is pretty rare and hard to reproduce, we strongly recommend updating your clients to this version.

macOS - Plastic: An exception was thrown when you try to open a file or directory with whitespaces in the path using the 'Open > Reveal in Finder' context menu option. Now it is fixed.

macOS, Linux: The "merge selected files" action in the Merge view failed with an error ("The path {file_path} was not found in merge conflicts") if the path of the file conflict to resolve wasn't the same in the merge source and the destination. This can happen if the file or one of its parents was moved in any of the contributors.

macOs - Mergetool: Fixed window rendering error. The various selection colours and strikeouts would disappear and reappear when scrolling the merge window, so it looked like the merge was wrong, but in reality it was just the UI rendering that was wrong.

Text differences in all GUIs: We have tweaked a little bit difference navigation. Previously, if you restored or deleted the current selected difference, the new current one was the next difference, but the diff didn't jump to it. This way, if you clicked on "next", the diff jumped to the next difference of the new one, making you feel you skipped one. Is a little bit complicated to explain, but we hope that differences navigation feels more natural now that these skips are prevented.

All platforms - Gluon: The refresh of the 'Explore workspace' view is now instant even with big repositories.

Using a repository of almost 700.000 items the refresh time is:

What we do is just to skip some checks for the 'owl help' when there are big repositories involved.

Windows installers: We modified the installer to be downloaded when clicking in the "Download" button when "A new version available" message is notified:

Before this version, the "Client only" installer was downloaded.

From now on, the "Client + Server" installer will be downloaded, and the components you selected to be installed before upgrading to the new version will be enabled by default when running the "Client + Server" installer.

Windows installers: If you initially installed Plastic using the "Client + Server" installer, and then you upgrade to a new version using the "Client only" installer, a warning message will be shown telling that the server component will be removed (although databases, logs and config will be kept). Before this version, the installer didn't want about this fact.

macOS - Plastic, Gluon: Calculating the pending changes in the GUI is remarkably faster now!

The Pending Changes view is now capable of detecting changes by monitoring the filesystem using the OS events API (FSEvents) instead of simply walking the workspace directory structure.

This way the client only walks down the workspace directory tree the first time (on GUI this means the first time the user refreshes the Pending Changes view). After that, only directories with changes under them will be checked.

Just to share some numbers: calculating the pending changes in a workspace with 600k files went down from 180s to 5.75s.

This is a first step to implement the auto-refresh you all need in macOS. :-)

All platforms - Plastic: Until now, you could try to annotate binary files - it wasn't working well, was it? The annotate is meant for text files! Now, we detect if the file can be annotated, and if not, we display an alert. Worry not! In the (unlikely) scenario of we detecting as a binary what is really a text file, we tell you in that very same alert how to force the type on an item.

macOS - Plastic, Gluon: Fixed several issues related to the pending changes view/checkin view:

The UI hung when displaying some files, especially those that had very long lines or were big. Now it's fixed.

The syntax highlight was slow with long lines. Now we skip coloring long lines.

The UI thread was locked displaying big files (>~2MB). Improved the performance by a 50%.

When displaying added or private files, the width of the line numbers view was not correctly calculated. Now it's fixed.

The progress spinner and text saying "Calculating diffs..." was overlapped. Now it's fixed.

Windows - Gluon Performance: Improved checkin changes view performance when there are a large number of items.

For a workspace with 220k items, the gui got stuck around 20s after refreshing the view before showing the list of changes. Now it's much better, the time has reduced to 4s. More than 5 times faster!!

Plastic GUI (all platforms): As part of an ongoing series of gradual usability improvements in the Plastic GUI we made a small change to the order of the items in the sidebar. "Branch Explorer" now appears before "Changesets" and "Branches" as it is generally the more commonly used item.

Command line client and Plastic GUI: improved the progress for the partial checkin operation adding the operation status (starting, uploading, confirming, restoring file access, finished).

You can see it in the following image:

Plastic GUI and Gluon: The performance of the Pending Changes view is now 5 times faster when searching for tons of private items in the workspace.

Let us give you a real example: we used the 3 copies of the 'gcc', 'mono', 'linux' and 'node' repos (that can be found in GitHub) - 632,555 files and 42,096 Folders, 4.76 GB.

And then opened the Pending Changes view in Plastic GUI or Gluon.

The main problem was in the log (which is enabled by default). With the log disabled, the improvement is smaller but very important anyway.

Windows - Gluon Performance: Improved checkin changes view key handling in the tree when there are a large number of items. Before you couldn't navigate with keys because it was terribly slow. Now it's much better!

Windows - Plastic SCM: sometimes we say hello, and sometimes we say goodbye. The "Change statistics" view is gone, and with it, the "Review & Stats" section. You can find now the Code Review below Sync Repositories (for regular users), or below Shelves (for Cloud Edition users).

Mac Plastic: We made the Pending Changes view a bit prettier by moving the "Checkin comments" drop-down list to the same line as the other buttons.

Plastic GUI for Linux: a null exception was thrown when you type a filter during the load of the browse repository view. Now it is fixed.

Plastic GUI: Corrected the window title when performing an image diff from the History view using the built-in image diff tool. It used to show a temporary file path, now it shows the path of the item in the workspace.

Command line client: we fixed an issue where "cm find" wouldn't work if you had extended characters in your object names. We were using the wrong encoder in the query parser.

Reminder: if you're using the cm shell, then you can pass in the correct code page for the character set you are using like this:

Command line client: The progress bar for the "switch", "update" and "setselector" commands was accidentally disabled in build 8.0.16.3140. We have reinstated it to its former glory.

Plastic GUI: a null exception was thrown when you click to the cancel button for the checkin operation. Now it is fixed.

Plastic - all platforms: When creating a new branch, the "Switch workspace to this branch" checkbox is now checked by default.

Plastic GUI: We greatly improved the checkin progress:

Now the GUIs only show the details bar with slow operations. There was a small bug that made them appear when they shouldn't.

Also, now the GUI shows the correct size unit when the upload operation for a 4MB block finishes.

The GUI displays the checkin status when there is no info about the current file in the header.

These changes should make the checkin experience much smoother.

You can see the details in the following image:

Plastic GUI: We improved the update progress:

Now the GUIs only show the details message when the total files to update is calculated. There was a small bug that made them appear when they shouldn't.

Also, the details message is not shown when there are no files to update.

macOS - plastic: fixed an "unexpected error" that occurred if you double clicked on a group header in the changeset diff view.

Cloud Edition: The progress shown when pushing a branch to an empty cloud repository was incorrect on some stages of the push operation. Maybe you were seeing progress values > 100%, or abrupt progress decreasing inside the same stage. Now it's fixed.

Remark: This bug also affects on-premise plastic servers configured with a database backend different than Plastic Jet backend.

Linux - Gluon: while configuring Gluon, the workspace path could not be changed exploring the filesystem through the "Choose…" button. Now that's fixed.

Cloud Edition: Performance improvement: Pulling a branch from Cloud Server to a local on-premise server were taking more than 2 minutes on fetching items to be pulled. The operation progress seemed to be hung on this stage (altought it wasn't).

This could happen when the branch to be pulled contains several thousands of items on its tree. Now it's fixed, and these extra 2 minutes were removed.

Remark: This improvement also affects on-premise plastic servers configured with a database backend different than Plastic Jet backend.

DevOps: MergeBot engine: Now the merge the mergebot API uses won't ignore whitespaces when resolving conflicts automatically.

More info about DevOps Mergebots can be found here

Command line client: you can now use all the wonderful functionality of the new "undo" command on your Gluon workspaces, by calling "cm partial undo".

Plastic GUI: improved the checkin progress to show the correct size units when the uploading operation is finished.

macOS - Plastic Performance: Improved the "add directory tree to source control" operation from the workspace explorer view. When adding a directory with a large number of items, the gui got stuck for several seconds before showing any progress. For a workspace with 220k items, nearly 40s without a response :( Now it's much better!

Cloud Edition: The data transfer is now 3 times faster when uploading or downloading tons of small files to Plastic Cloud.

Let us give you a real example: we used the 'gcc' repo (https://github.com/gcc-mirror/gcc): 96423 files - 517 MB.

And then we ran a checkin to Cloud from Windows using a standard connection (100Mbps download - 60Mbps upload):

Before: Upload time - 478 s (total checkin time - 564 s)

Now: Upload time - 143 s (total checkin time - 223 s)

We modified how the number of upload/download threads are configured. Now we select a number dynamically depending on the number of files to upload/download.

macOS - Plastic Performance: Improved pending changes view performance when there are a large number of items. Loading, sorting and filtering times have been improved significantly.

For a workspace with 220k items, the pending changes refresh time has improved from 58447 ms to 3469 ms. Nearly 17 times faster!!

macOS - Plastic, Gluon: Items search box: The search box lost the focus when the user stopped writing (e.g. to let the results list be updated). Now it's fixed.

We also improved the key navigation in the file search of the Workspace Explorer view. Now you can navigate the search results using the following keys: Up, Down, Home, End, PgUp, PgDn).

Plastic SCM Server, Linux/macOS: The Plastic SCM Cloud Edition local server threw an exception in the shutdown process on Linux or macOS. This prevented some of the shutdown routines from running, and that in turn could prevent some resources from being freed. It's now fixed.

Windows - Plastic: When the diff window had unsaved changes and it was closed, it failed with a "File not found" exception. Now it's fixed.

Windows - Plastic: The diff window did not update the diffs when editing the right content. Now it's fixed.

Windows GUI: the progress bar for the checkin operation was not completely filled. Fixed.

GTK Plastic: the help panel in the Merge View prompted an error message when you clicked the "OK" button to close it, making it impossible to dismiss. Fixed.

Linux - Plastic, Gluon: When focusing main window, the pending changes view was auto-refreshed while a checkin operation was performed. Now, it's fixed.

Windows - Gluon: When pressing 'End' key in the pending changes view, the files tree scrolled more than allowed, leaving half of the control blank. Now it's fixed.

macOS - Plastic: after some time stalking the NSInternalInconsistencyException that our customers kept getting in the mac client when trying to open a diff window, we finally caught it and fixed it. Sorry for the inconvenience.

Command line client: the 'cm undo' command has arrived! It unifies the three (now deprecated) commands we had for undoing changes in a workspace: 'undocheckout', 'undochange' and 'uncounchanged'.

One Command to rule them all, One Command to find them,

One Command to bring them all and in the darkness undo them

The best thing is, the new undo it is smart enough to undo a change whether it be a local change (changed, locally moved, locally deleted) or a controlled change (added, checkout, moved, deleted). For more in-depth help and examples refer to the documentation ('cm help undo'), but let me quickly highlight how it replaces the old commands:

The cm undo command also has flags to take into account only checked-out items (--checkout), or certain kinds of changes (--changed, --moved, --deleted and --added). It is automation-friendly too: with the --machinereadable flag and the format options, the output is easy to parse.

Limitations: the cm undo can undo deletions, but they are not detected automatically. If you want to undo a deletion, you have to either undo all of the changes in its directory recursively, or specify the full path of the deleted item.

Command line client: "cm remove" has a brand new subcommand, "private", for deleting private files in your workspace.

Note: files are permanently deleted and are not recoverable. Use with caution! It is recommended that you perform a dry run of any delete operation (using the "--dry-run" option) before permanently deleting files.

The command has a "--verbose" option if you want to see all the paths of deleted items.

You can recursively delete private files and directories within controlled directories by using the "-r" option.

Here are some examples of how to use the command:

WebAdmin: We changed the position of the link "... branches processed today" in the DevOps dashboard. It's now aligned right and underlined to make it easier to notice!

IntelliJ IDEA plugin: We updated the README description to let you know from which URL you can download the old version, compatible with IntelliJ IDEA 15.x or older.

Windows - Visual Studio Package - Cloud Edition: The credentials dialog appeared every time you switch from using any Plastic GUI to Visual Studio plugin in Cloud Edition installations. Now it's fixed.

Using Cloud Edition? Upgrade!

You need to upgrade to this release to unlock the new "Activity reports".

You will receive an email like this every week:

With a link to browse the full report online:

And the report will also be accessible from your Cloud dashboard:

https://www.plasticscm.com/dashboard/cloud

Command line interface: we improved the error message you get when you pass a shelveset specification to command, like setowner or showacl, that doesn't accept shelveset specs.

Command line client: the error message when trying to run acl operations on workspaces wasn't very nice. We made it more user friendly.

Command line client: we corrected some faulty indentation in the help text of the "showfindobjects" command.

WebAdmin: We improved the form layout of the "New/Edit mergebot" page to make a better use of space.

Command line client: we improved the phrasing of the help for commands that take piped input.

Windows - Mergetool: After changing the color configuration in mergetool, selecting/unselecting a manual conflict contributor caused the application to crash. Now it's fixed.

JIRA extension: when using JIRA Cloud, now you can't login with a password, as that authentication method is deprecated. You need to use your email address and a personal token generated here . This caused the assignee field of the tasks query to be your email instead of your name, returning zero tasks. That is fixed now. If you have to login using the email, the extension will solve your name before querying for tasks.

Command line interface: we improved the error message you get when you pass a shelveset specification to command, like setowner or showacl, that doesn't accept shelveset specs.

Command line client: the error message when trying to run acl operations on workspaces wasn't very nice. We made it more user friendly.

Command line client: we corrected some faulty indentation in the help text of the "showfindobjects" command.

WebAdmin: We improved the form layout of the "New/Edit mergebot" page to make a better use of space.

Command line client: we improved the phrasing of the help for commands that take piped input.

Windows - Mergetool: After changing the color configuration in mergetool, selecting/unselecting a manual conflict contributor caused the application to crash. Now it's fixed.

JIRA extension: when using JIRA Cloud, now you can't login with a password, as that authentication method is deprecated. You need to use your email address and a personal token generated here . This caused the assignee field of the tasks query to be your email instead of your name, returning zero tasks. That is fixed now. If you have to login using the email, the extension will solve your name before querying for tasks.

Command line interface: we made a few minor improvements to the inline help for the "branch" command. Remember, you can get help for any command by running "cm help" followed by the command name.

Gluon: out-of-date items are now easier to identify! They now have a warning overlay icon to prevent you from modifying them before an update. Check it out (pun intended)!

Plastic - Windows: In the Windows branch explorer, the "Show excluded replication sources" checkbox was not persisted when you close and re-open the GUI. Now it's persisted.

Command line interface: we made some minor improvements to the help for the diff command. Hopefully, it should be a bit clearer what the 'revid', 'baserevid' and 'parentrevid' fields are when you get the results of a diff.

IDEA Plugin: We've updated our plugin and it supports IntelliJ IDEA 2019.x now! On the other hand, we dropped support for IntelliJ IDEA 15 and older. Please have that in mind when upgrading the Plastic SCM plugin.

IDEA Plugin: Great news, people! Our IntelliJ IDEA plugin can be installed as well in any other JetBrains IDE! Rejoice!

Command line client: we updated the help for commands which take an "object_spec" argument to explicitly say which objects are valid for the command. Affected commands are "cm attribute", "cm acl", "cm showacl", "cm setowner" and "cm showowner".

Command line client: did you know you can pipe directory listings to the "add" command like this:

Cool, huh? This also works for checkin, checkout, getstatus, remove, undocheckout, uncounchanged and undochange. We updated the help with some more details about this.

Windows - Visual Studio Package: When diffing a branch, changeset or label, the diff window did not answered properly to some command keys (backspace, control, arrow keys, etc ...). The problem was that we were displaying the diff window as a non-modal window. The window was not getting messages, events, accelerators, etc... We fixed it displaying the diff window as a modal window.

Command line client: back by popular demand, "cm status" has regained the "--all" option. "--all" is a handy shorthand for "--controlledchanged --changed --localdeleted --localmoved --private" when using the "status" command.

We removed "--all" in build 8.0.16.2999, but, to be honest, we probably shouldn't have, as it is actually pretty useful. Sorry about that.

Server: Logging subsystem: The loader.log.conf file appenders will now accept the following property in the "file" configuration: %property{NodeName}

This could be useful in multi-instance scenarios where several server nodes are configured to work in parallel.

Find below an example of a file appender configuration using the new property:

REMARK: To use this property in the file name value, the file type has to be set to log4net.Util.PatternString

Command line client: we've made it easy to run queries against all your repositories. Just use '*' as the repository name parameter:

In fact. you can use any wildcard expression:

Plastic, Gluon - all platforms: When you use the items search to find a private item that is on disk, but is not present in the items view, because the items view is not refreshed, the item was not focused properly in the items view. Now it's fixed.

GitSync. Applies both to the command line (all platforms) and Windows GUI.

Suppose you have a repo "quake" synced to https://github.com/psantosl/quakefromplastic.git

And now you try to sync with a different GitHub repo: https://github.com/psantosl/newquaketest.git

Plastic will complain saying there are mappings for the old repo. We added info of where the mappings are stored, so that advanced users can go and delete the mappings or move them to be used later.

cm sync quake@localhost:6060 git https://github.com/psantosl/newquaketest.git --user=psantosl --pwd=my-personal-token

Error: The settings you've introduced don't match with the stored ones for branch/repo quake. Stored are: https://github.com/psantosl/quakefromplastic.git. Mappings are stored here: C:\Users\pablo\AppData\Local\plastic4\sync\git\fbcb3273-0371-4821-92ac-01e380200c5a.

We expect to remove this restriction in the future, so you can gitsync a repo to as many destinations as you want, but right now this is the behavior we support.

Command line client: we have improved the formatting of the ls command output so that the columns are nicely aligned even when you have a mixture of long and short branch names.

Plastic SCM GUI and Command Line Client: improved progress messages for one of the stages of the merge. When performing a merge with many added files on source, processing the copied files and directories can take a while (depending on the number of files and the performance of your computer), giving the impression that the tool hanged. Now, Plastic gives more granular progress messages, so you know what's going on under the hood.

Refactor part of the "find changes" code. Yes, no new features, just code clean up. But, since if you are reading this you are probably a developer, we're sure you appreciate we spend time in refactors too ;-)

Mantis integration: we had a couple of bugs in the plastic.php file we distribute alongside the Plastic SCM client to integrate it with the Mantis issue tracker. Now it is fixed.

If your Mantis integration works OK, you don't need to do anything unless you update your server's PHP version to 7 or greater. In that case, you will have to replace the plastic.php file in your Mantis install directory with the new one.

For further info regarding Plastic SCM and Mantis extension configuration, please visit the following documentation page

Windows - Visual Studio Package: Visual Studio 2019 crashed when displaying some Plastic SCM views. Now it's fixed.

Linux and macOS: Uploading data to the cloud (through a checkin or push operation) with network issues make the operation fail due to the "Cannot access a disposed object" error. Now, the error is handled and the upload retried like it is done with the rest of network issues.

Command line client: we have renamed the "remove" subcommand of "cm changeset" to "delete" to make the naming consistent with the other commands.

Windows GUI and Gluon: Avoid weird "Invalid value for registry" errors when opening an URL from plastic or gluon. Some of them were causing the tool to crash. In this case, Plastic or Gluon will just log the error with the requested URL.

REMARK: The "Invalid value for registry" error is not caused in any case by Plastic or Gluon. Contact Microsoft support if you are experiencing such errors when opening URLs from outside your web browser. It will fail not only from Plastic or Gluon, but also from other tools, or even shortcuts to web pages.

Command line client: some fields of the 'cm status' XML output were obfuscated. Instead of their actual name ("MovedPath", "Size", "LastModified" and so on) all you could see was "a", "b", "c"… Now it is fixed.

Additionally, there are "printable" fields now. They contain redundant information, but in a human-readable format.

"Type" contains a couple of characters to indicate the type of the change, but "TypeVerbose" uses the full word.

"PrintableMovedPath" shows both "Path" and "OldPath" for moved files and directories, separated by an arrow.

"Size" is the size of the file in bytes, but "PrintableSize" represents the size in the best suitable unit measure.

"LastModified" field is a parseable DateTime, but "PrintableLastModified" is a human-friendly string of the type "9 hours ago".

Server: multi-instance and heavy load. There was a bug that was reporting that all threads were busy (more than 10 seconds attending a request) when in reality only a few threads were.

GUIs and Web: Great improvements in the Cloud Edition onboarding process.

We changed the first steps in Cloud Edition, so joining to an organization and creating a new one is now much easier.

Here is a summary of the improvements:

All GUIs: New signup/login dialogs to help new users getting aboard.

All GUIs: Links with relevant information during evaluation.

The old cloud.plasticscm.com has been replaced by https://www.plasticscm.com/dashboard/cloud. The new dashboard has been redesigned too.

Plastic Cloud Edition subscription information has been improved.

Let's now detail each of the improvements.

Now new users can signup to plasticscm.com directly from the GUIs, which makes the process much faster and reduces friction.

And it is also possible to create the new organization and subscribe to Plastic Cloud without leaving the GUI:

As a bonus, the GUI now selects your nearest datacenter by default.

Once you start the GUIs, there are new links to help you find your way during the evaluation:

If you look at the bar in the bottom of the window, you'll find the following information:

A message saying how many days are left to evaluate Cloud Edition.

If you are the owner of the subscription, then a button will open the web-dashboard directly. This is the option to check your usage, invite new team mates, etc.

Finally, a button helps you contact support in case you have any questions or found a problem.

We used to have cloud.plasticscm.com and plasticscm.com. They were part of the same domain, but implemented as separate applications. Now we unified the experience.

We also used the opportunity to redesign the interface and make it much more intuitive.

Now you'll be able to access more information about your actual Plastic Cloud usage.

Now it clearly shows the total storage use and also charts to quickly review the daily active users and the key operations performed in Plastic Cloud.

Command line client: the 'cm clone' command can now clone a repository to a replication package. This is useful for moving data across servers when there is no direct connection between them.

To clone a repository to a replication package, do the following:

You can then import that package using the pull command:

Command line client: PowerShell receives autocompletion support! It only completes command names for now, but expect future improvements.

To install it, just run (from your Windows PowerShell):

Remember that command autocompletion also works in Bash. Do you use another shell and you want to have cm autocompletion support? Let us know!

GitSync won't fail anymore if for whatever reason it can't access the contents of a given revision. It will add an empty revision in the Git package instead.

This way we allow syncing with Git even if an old revision is not present due to an old issue.

Windows, linux - Plastic, Gluon: Windows will be maximized first time you open them. After that, their size, status and position will be restored when you close and reopen them. Please note that this doesn't apply to macOS since it's not usual to work with maximized windows in that OS.

Windows - Gluon: We added a new context menu action in the diff window called "External diff". It's available when you right click a file in the diff window, i.e. the one that appears when you run a diff action. This is really useful when you have a specific diff tool that is best suited to diff a particular kind of files.

Windows - Plastic: When using parameters in view filters,

the parameter was not working ok for the first column. Now

it's fixed. You can use "columnName:value".

Linux/macOS GUI: A "The item {id-value} cannot be found on tree" exception was thrown when the user tried to solve more than one delete-change conflicts for the same delete item keeping the delete as resolution. Now it's fixed.

CLI: The '--keepsource' option in the 'cm merge' command didn’t work for files that were modified on source and locally changed in the workspace at the same time, if they had to be checked out exclusively (locked). Now it's fixed.

Windows - Gluon: The window title in the Windows task bar was not visible. Now it's fixed.

Linux/macOS, all GUIs and CLI: If the Plastic client didn't have access to a given directory (e.g. the current user doesn't have read/execute permissions), no error appeared in the pending changes view. It's now displayed including the failing path.

Gluon: The update of an out-of-date file failed and displayed the error message "Could not find a part of the path '{filepath}'" when its parent was locally deleted. It also failed systematically if you tried to force update it in the update results dialog. Now it’s fixed.

Linux - Plastic: The second column title in the repository list was wrong. It's not "Repository"; it's "Server". Now it's fixed.

Cloud edition: Windows GUI: Fixed a bug that caused Plastic GUI to be immediately closed after login with your cloud edition account and creating a workspace on a new install. This issue just happened in release 8.0.16.3165, which was published just for a few hours and then unpublished due to the described failure.

Command line client: When updating a single item, the cm update command now forces the --cloaked flag by default.

If you specify the item you want to update, then you know for sure what you are doing, so having to add the --cloaked flag is just a hassle.

This means that, for the following directory structure:

Command line. The progress of the cm push/pull/clone commands has been improved so that it shows the number of objects being fetched, like the GUI does, which gives a much better idea of what is going on.

In the example below, you see the tree count together with "fetching trees".

Plastic GUI Windows: We have fixed an error in the display of progress messages during replication. A bug was introduced in release 8.0.16.3114 which caused the tool to display some internal strings rather than the nice display strings you are used to.

Server: Performance: We implemented a new log4net appender in the server that performs a 38% better (overall server response time) when the server is stressed with requests.

New installations of Plastic will already take advantage of these improvements.

Regarding existent installations, it's a matter of changing each log4net appender in loader.log.conf file as follows:

Having the following appender:

1- change the appender name as follows, from:

2- Create a new appender on top of previous one as follows:

3- Do the same with other appenders.

Full example can be found on the following snippet

Windows Cloud Edition installer: We moved the selection of the client application to start to the last page of the installation wizard. Now, the last wizard page of the cloud edition installer looks like the following screenshot:

Plastic GUI: The Diff control showed the message 'Value cannot be null. Parameter name: key' when it loaded text files > 2MB. Fixed!

GitSync: The rejected references (if they existed) were not always properly printed after a sync operation This could happen pushing big packages (>500 MB) with hundreds of references. Instead of printing the failed references, the sync command just failed with the error 'Stream terminated early'.

Remarks: Pushing a Plastic repo to GitHub through the 'cm sync' command will fail if the repo contains some file bigger than 100 MB. The error returned by GitHub is 'pre-receive hook declined'. This happens due to the GitHub disk quota policies: https://help.github.com/en/articles/what-is-my-disk-quota

Server: Permissions were not properly updated when the group members of the authentication provider were changed. The server should automatically update this information every 5 minutes, but it was only done after a server restart. Fixed.

Command line client: we noticed that commands that update the workspace would tell you "Searching for changed items in the workspace..." lots of times when there were changes in the workspace. We fixed that so it only prints once.

Command line client: We modified the "cm objectspec" command so that it prints out lots of useful help on defining object specifications, without you having to specify the "help" option.

Command line client: the obsolete findchanged, findcheckouts and findprivate commands have been hidden, although they still work if invoked.

Then why bother you with this? Just to tell you that if you use them in any automation script, you should migrate to cm status:

The reason to hide these commands is because they offer a redundant functionality. Moreover, the status command is way more powerful than findchanged, findcheckouts, and findprivate. Just check its documentation to find out the possibilities.

In any case we will warn you when these commands cease to exist.

Command line client: The 'cm partial checkin' command now shows dynamic progress, just like its regular 'checkin' sibling! Check it out (pun intended) the next time you checkin something in a Gluon workspace from the CLI!

Command line client: it is with great joy that we announce the arrival of the latest addition to our command family. We are sure "shelveset" will bring as much happiness to your daily coding life as it does to ours.

To create a shelveset:

To apply a shelveset:

To delete a shelveset:

Note: the old "shelve" command is still available in the tool but is considered deprecated.

Command line client: the cm label command now comes with added subcommand goodness.

Check out these examples:

Sets the label BL001 on the latest changeset in the current workspace.

'create' is the default subcommand for 'label', so this works too!

Some other ways to set labels.

Note: 'makelabel', 'removelabel' and 'renamelabel' are now deprecated, but remain available in the tool.

Command Line Client: the new 'clone' command joins the family! You probably already imagine what it does: the clone command clones a source repository (all of its branches, changesets, labels, code reviews, and so on) into a destination repository. If the destination repository does not exist, it is created automatically. If it does, it must be empty, or the clone is cancelled.

These are a few examples of how to use the clone command:

Like its push and pull siblings, the clone command also supports authentication and owner translation options:

You can also use the clone command to clone repositories from your Plastic Cloud organization:

For further information, you can execute:

Hope you find it useful!

(This closes the UserVoice request Simple repository clone operation).

DevOps: The trunk-bot CI Integration plug selection is now optional. This is done this way to ease the evaluation of the DevOps mergebot cycle for a repository without actually having to configure a CI system and its related plug. Therefore, no builds in any CI system will be triggered when merging a task branch.

Server: DevOps: trunk-bot configuration for fixed recipients in the "notifications" section now allows entering a comma-separated list of values, where these values could be either a raw value (such as an email address) or a plastic user. In case of the latter, the actual value will be resolved with the defined user profile field, if possible.

Consider the following example, where a trunk-bot is configured with an email notifier:

The "Always notify to" contains :

An actual email address: developers@plasticscm.com

Three plastic users: jemago, will and andrea -> their actual email addresses will be calculated getting their configured "email" profile value:

(Before this release, the "Always notify to" field in trunk-bot configuration didn't allow specifying plastic users, just email addresses).

Command line client: No need to checkout a changed file before checkin. Before, to checkin a locally changed file, you had to do one of the following actions:

Now the flag is not necessary if you specify the files you want to checkin:

We think that if you explicitly specify the file then you know what you're doing, and forcing you to checkout the file first is just a hassle.

However, this does NOT work with directories nor wildcards, as it might be dangerous (we humans tend to overlook things!):

All of these changes also apply to the 'cm partial ci' command, the checkin command for partial (Gluon) workspaces.

Linux/macOS GUI: After trying to process a merge conflict involving a readonly xlink, the operation never finishes and the user is stuck (the merge cannot be processed). Now it's fixed.

GitServer: The issue "The revision for the git reference 0000000000000000000000000000000000000000 cannot be found" during the git push operation was fixed. It could happen when the same (or similar) directory structure was added to the local repo, committed and pushed to the central server multiple times.

All platforms - Plastic, Gluon: Improved the window default size (make it bigger). Also, adjust the window size to the screen size if it doesn't fit.

All platforms - Gluon: Added the "undo changes" option in the context menu. Now you can select several files in the checkin view, right click and select "undo changes" for the selected (highlighted) items, regardless of the files are checked or not.

Command Line Client: the '--parents' option of the 'cm add' command has been deprecated. Now, it is the default behavior.

For example, let's say that you have the following (private) directory structure, and you want to add 'file.txt' to source control:

Now, you can do so by executing:

…which we hope feels more natural :-)

Command line client: We have introduced a new "workspace" command (short form, "wk"), for all workspace related activity.

Here are some usage examples (using the short form):

Rename the current workspace

Move the current workspace

As always, you can check out the inline help (cm workspace --help) for full details and more examples.

Note: the existing workspace commands ("mkwk", "lwk", "rmwk" and "renameworkspace") are deprecated but will still work.

Command line client: We have introduced a new trigger command for managing triggers. It has the following subcommands: create, delete, edit, list and showtypes.

Note: the old trigger commands are deprecated but are still available in the tool for backwards compatibility.

Windows installer: A wizard step allows selecting which application should be started after the installation finishes. This application could be either Plastic SCM (classic GUI for developers) or Gluon (for documentation and game-dev artists). We improved the description of these apps to help choosing the desired app wisely. Note that both applications will be installed and available for you, regardless of this initial selection!

CLI: The 'unco --all' was failing with the error "Selector can't locate a revision for the item " under certain circumstances when there was a locally moved directory with local changes inside include other moved from the directory to outside or from outside into the directory. In order to fix it, we have improved the directory moved detection. See an example:

Starting with the following controlled, and up-to-date, content:

We perform the following local changes:

Create directory /Assets/Editor/MainMenu/Testing

Move /Assets/Scripts/MainMenu/Testing/Editor to /Assets/Editor/MainMenu/Testing/Editor

Move /Assets/Scripts to /Assets/Runtime

Now the detected local changes are:

But before they were:

Command line client: the following cm commands related to repository handling are now deprecated:

lrep, replaced by 'repository' (without any arguments) or 'repository list'.

mkrep, replaced by 'repository [repname]' or 'repository create'.

rmrep, replaced by 'repository delete'.

rnrep, replaced by 'repository rename'.

addrep, replaced by 'repository add'

These commands are now equivalent:

The arguments and flags supported by the old commands are supported by the new ones as well, in the same order (if applies) and of the same type as before.

The deprecated commands are still available if you call them, but we recommend you to migrate any automation or script that relies on them to the repository command.

In any circumstance, we will warn you through the release notes when the deprecated commands cease to exist.

Command line client: There is now a single command for all your attribute management needs. We've called it ... attribute.

Here is some example usage:

Note: the beautifully named commands mkattr, rnatt, rmatt, statt and rmattr are deprecated, but still available in the tool for the more masochistic amongst us.

Command line client: There is now a new command for managing locks. You guessed it! We called it "lock".

Here are some examples:

Note: the old lock commands can still be used, though they are now considered deprecated.

Command line client: the following cm commands related to branch handling are now deprecated:

mkbr, replaced by 'branch' or 'branch create'.

rmbr, replaced by 'branch delete'.

rnbr, replaced by 'branch rename'.

branchhistory, replaced by 'branch history'

getmainbranch, replaced by 'branch showmain'

getmergeneededbranches, replaced by 'branch showmerges'

These commands are now equivalent:

The arguments and flags supported by the old commands are supported by the new ones as well, in the same order (if applies) and of the same type as before.

The deprecated commands are still available if you call them, but we recommend you to migrate any automation or script that relies on them to the branch command.

In any circumstance, we will warn you through the release notes when the deprecated commands cease to exist.

Command line client: the cm replicate command is now deprecated. It is replaced by push and pull, in an effort to make it easier to use, and improve the semantics of the command line.

These commands are now equivalent:

The authentication options (--authmode, --authdata, --authfile, --user, and --password), and the translation options (--trmode and --trtable) work exactly the same as before, both for pull and push.

The deprecated replicate command is still available if you call it, but we recommend you to migrate any automation or script that relies on it to the new push and pull.

In any circumstance, we will warn you through the release notes when the replicate command ceases to exist.

Plastic GUI: The replication source aliases in the Branch Explorer view were lost when the GUI closed. We fixed that to make them persistent.

WebAdmin: The DevOps dashboard didn't work if the Plastic SCM Server owner was a group. Now it's fixed.

CLI: The 'cm listlocks --onlycurrentworkspace' command used the workspace name instead of the workspace ID to filter the locked files. This caused issues if two developers had workspaces with the same name. We fixed the code to use the workspace ID in the lock filter and prevent collisions.

However, this change will only affect locks created with this version or higher, so don't be alarmed if you don't see any changes in the 'cm listlocks --onlycurrentworkspace' output immediately. As a side effect, old clients will see the workspace ID in the command output as part of the workspace name for locks created with a newer client version, example:

History commands (CLI history command and History View in GUIs) didn't check permissions. As a result, all revisions were displayed regardless of what permissions the current user was granted. We fixed this issue so that users will only see revisions from branches available to them, according to their permissions.

Eclipse plugin: The plugin now handles a few merge conflict warnings that we previously missed. It will now display discarded change, discarded filesystem protection change and path in conflict warnings.

Here is a screenshot of the updated Eclipse plugin in action:

Windows - Plastic: Added more log to the differences window. Sometimes an unexpected error occurs and it's not written to the log.

Command line client: Calling 'cm status' for a path not in the current directory used to result in a pesky "Error: Object reference not set to an instance of an object." message. This bug was introduced when we recently added the head changeset info to the status output by default. We have now fixed this, and cm status works as expected.

CLI shell: The Shell processed quotes as if they were boundaries of arguments, which caused quotes in the middle of an argument to split it in two. For instance, "serverpath:/doc/Table of contents.md"#br:/main@project was considered as two separate arguments: 'serverpath:/doc/Table of contents.md' and '#br:/main@project'. It's fixed now.

GUIs: Improved password management for encrypted servers. Now, if the user enters an incorrect password the 'encryption configuration' dialog appears in order to allow the user to enter the correct one, instead of having to edit the 'cryptedservers.conf' file manually.

Gluon for windows: The workspace name appeared in two locations when the user entered or exited the configuration mode in the Workspace Tree view. Now it's fixed.

Windows GUI: we fixed the performance of the add operation. Once again, adding in the GUI is just as fast as with the command line (cm).

We didn't notice the slowdown in the GUI sooner because all our performance tests are done with the command line. But, of course, the performance in the GUIs has to be just as good as with the cm.

Linux and macOS GUIs were not affected.

For more info and performance results see https://www.plasticscm.com/games/performance/performance-results-of-plastic-scm

The update operation didn't report the proper error when downloading a file bigger than 4MB and it wasn't completely downloaded. Fixed.

SemanticSCM: Under some circumstances, the semantic differences were not calculated fine when the source files were very large and several differences were being calculated concurrently (e.g. analyze refactors and file diffs). This is now fixed.

Windows GUI: after an update operation, the gui would freeze for a while if the update had to report a lot of errors. This is now fixed.

macOS installers: Now all the pkg installers are signed.

We improved the data update phase in the check-in operation to improve how we handle network issues and try to reconnect if the network is gone for a few seconds. This was already implemented for check-in against our cloud, now it's available for any Plastic SCM server. Enjoy!

Remark: You'll need to upgrade your Plastic SCM client and server to take advantage of this feature.

Issue tracker extensions: The configuration files will encode/decode parameter values using URI-encoded strings. This means that you'll be able to use special characters, such as '#' (which is regularly used to start comments).

Plastic and Mergetool for linux and macOS: The diff editor automatically added the UTF-8 BOM (byte order mask) when the file was saved to disk. Now it's fixed.

Plastic GUI: Changing quickly the selected file in the diff window could sometimes display empty contents in the diff panel. This was incorrect and it happened particularly when the diff was calculated in a distant server (high latency). Now it’s fixed

Jira extension: protected queries to handle issue types project keys and "resolve status" names with special characters.

Command line client: We have given "cm switch" and "cm setselector" a nice new animated progress bar, so now you have something interesting to watch during a long update. Note: you can get the old multi-line output by redirecting the console output.

Windows GUI: The "version tree" diagram now survives application restarts. When you close and reopen the Plastic SCM GUI for Windows, the 2D History diagram tab will be reloaded, and the custom display options, including date filters, will be restored as well, without affecting the settings of the regular Branch Explorer.

Plastic and Gluon (all platforms): Now Plastic and Gluon notify when a new version is available.

When you close the notification using the "OK" button, this will be ignored in the future, until a new version is displayed.

When you close the notification, checking the "Got it, don't show me again" checkbox, you won't be notified again, until after 10 releases. Then you'll be notified again.

Command line client: The cm status command output now includes the head changeset by default.

Plastic for Windows: Improved the look and feel of the splitters, in the Pending Changes View and the Diff Window.

Command line client: Previously, when working with a Gluon workspace, you had to cd into the workspace to check items in. Now, you can checkin from outside the workspace - just like for a regular workspace.

Command line client: We have given "cm replicate" an animated progress that better matches the GUI. You can still get the old output by redirecting the command output.

Here's a sneak preview of what you can expect (on a very small repository):

We found out that file content downloads that failed due to network issues were incorrectly interpreted as items replicated without their data. The client displayed a message like "Cannot download revision 1432842 from server: Can't download '/wk/src/foo.c' (revid:1432842). It was probably replicated with --nodata, but it is not available in the repository test@localhost:8084.", but that was misleading. We fixed it so that the client displays the original error, rather than the 'nodata' message.

GitServer: Concurrent git clone operations could fail with the error "pack has bad object at offset XXX" since they wrongly share a buffer to build all the packages. Fixed.

Plastic Windows GUI: We fixed the text color of the annotate view bottom panel when using the Montana-Dark theme. It blended with the background before, rendering it unreadable.

Creating a workspace sometimes failed with the error "The workspace cannot be initialized with the given selector. Probably you don't have enough permission to load the initial changeset of the repository of the selector". This happened when the user that performed the 'create workspace' operation only had permissions to see a subtree (e.g. '/game/art'). Now it's fixed.

Plastic GUI: Transformable workspace rules used to fail for paths containing spaces, but now you can enclose the path in double quotes, and the transformer rule will work as expected.

For example, the "plastic.transformerrules" file could contain:

rm "/Path with/spaces in/"

mv /No/Spaces "/Dir with spaces"

Command line client: We have given the "cm update" command a nice new animated progress bar. Spoiler alert: it looks like this:

Note: if the command output is redirected, you will get the original output.

Command Line Interface: the 'cm' CLI utility has gained Bash superpowers! Now, the 'cm' command can provide command line autocompletion for Bash (more shells coming soon!).

To install it do the following:

After that, your .bashrc file is modified with a script to hook 'cm' autocompletion to the 'cm autocomplete' command, so you need to restart your session for changes to take effect.

For now, 'cm' can only autocomplete command names (makeworkspace, showacl, renamerep and the like), but expect more improvements soon.

Eclipse: The Diffs view crashed when it was displayed from the Window -> Show view -> Other -> PlasticSCM -> Diffs menu. Now it's displayed with a "No content to compare message". We also detected and fixed a layout issue in the view that now it's fixed.

Command line client: We have introduced a new, clearer format for the console output of the status command. This change brings the CLI inline with the Pending Changes view of the GUI.

However, don't worry - you can still get the output in the legacy format, if that's your thing.

First of all, here is an example of the new output.

Beautiful, right? As you can see, we have a new format for the workspace status, we have made the pending merge list more prominent, and the changes lists have been updated with file sizes and last modified dates and are now organized similarity to the Pending Changes view.

We have added some new options to the command, including:

Please check-out the inline help "cm status --usage" or the online CLI Guide (https://www.plasticscm.com/documentation/cli/plastic-scm-version-control-cli-guide) for more information.

By default, all changes, controlled and local, are displayed. Since this is the default, we removed the "--all" option, but you can still use "--controlledchanged" to show only controlled changes.

The option "--nochanges" has been renamed to "--header", and outputs just the workspace status.

The option "--nostatus" has been renamed to "--noheader", and outputs just the changelists.

New option, "--head", displays the head changeset status.

The "--selector" and "--wkconfig" options have been deprecated.

In case you still need the old format, for automation purposes:

The following options can be used to generate output in the legacy format:

"--cset" outputs the workspace status.

"--compact" outputs the workspace status and changelists.

"--noheaders" can be used with "--compact" and removes the changelist group headers from the output.

Windows GUI: Improved readability in Branch Explorer label captions. When a label was too long, the caption was cut and added ellipsis, so the caption couldn't be read. Now, when a label that doesn't fit it's caption area is hovered with the mouse, we draw the complete caption, so it can be easily read:

Gluon for Windows: We added an option menu button in the top right corner that allows you to display the preferences and the about dialogs.

Gluon for Linux: We added a button in the left sidebar that displays the about dialog.

Plastic (all platforms): Some users reported that they got stuck when a merge was started and it was not finished. We added a help case to detect this situation and help the user to continue the merge, or undo (and cancel the merge in progress).

Windows installer: The server-only installer was failing trying to extract 'vswhere.exe' file, a file needed to detect Visual Studio installations. Now it's fixed.

Eclipse plugin: The Eclipse views (branches, labels, changesets, pending changes ...) failed to open due to a layout issue. Now it's fixed.

Linux: Added an "Applications" shortcut to launch the Plastic SCM server administration page. This shortcut will open a browser on http://127.0.0.1:7178, which is the default admin page location of plastic server.

See screenshot below (Ubuntu):

REMARK: the shortcut internally uses xdg-open to launch a browser, which is likely to be installed on supported linux desktop environments. Otherwise, you will have to install it using the package manager of your distro.

Plastic (windows, gtk, osx): When a user switches to a changeset, the last changes on the branch won't be downloaded when the workspace is updated. When a user clicks the "update workspace" button in the items view and we detect that they had previously switched their workspace to a changeset, Plastic displays a help message to warn about this situation.

Plastic all platforms: Improved the performance calculating the cloud organization for a user in the welcome dialog.

Plastic for Windows: When you show the changesets for a branch (branches view -> right click -> view -> view changesets in this branch), the following options were disabled:

Merge from this changeset

Cherry pick from this changeset

Plastic GUI, Gluon and CLI (Windows, Linux and macOS): Now all Plastic clients use the environment variable PLASTIC_HOME to load and save the settings.

If defined, Plastic will use the folder defined in the PLASTIC_HOME environment variable to save setting files. Otherwise, the default config folder will be used.

NOTE: The PLASTIC_HOME environment variable will is ignored by the java cm client (our java-based CLI).

Gluon for windows: If you set a filter in the Checkin View, after refreshing it, the filter was not re-applied. Now it's fixed.

Plastic for windows: The option "Filter only parents" in the Version tree 2D was not correctly saved/restored. Now it's fixed.

The update operation didn't report the proper error when downloading a file locked by another process and bigger than 4MB. Fixed.

Plastic, Gluon and CLI (all platforms): Fixed a performance issue. The client configuration file (client.conf) was parsed thousands of times due a bug in the code. Now it's fixed.

Plastic SCM turns 8.0!

New year, new number. For all of you using subscriptions it will be transparent.

If you have an "unlimited license", remember to request a new license where "major version supported" is updated to 8.

As you know, we no longer release major super new versions anymore. We don't wait and package tons of new features together for a big launch. It seems the world has moved past that, and for us it is much better since it better fits the way we work.

We release a few times a week, so being subscribed to Plastic, or purchasing support+updates if you are on perpetual, means receiving a constant flow of updates.

The initial 8.0 won't be different from the latest 7.0, but in a few months 8.0 will be incredibly much evolved, week after week.

These are some of the things we are cooking:

A brand new Unity plugin: While the current one, officially deployed by Unity, will still be there, we are working on a totally new one. Expect a more "plastic-style" UI with all the things you are used to in "Pending Changes".

Multi-process Enterprise server: We are working at full speed right now in a greatly improved server that spawns multiple processes to increase reliability even on a single machine. This probably doesn't sound super exciting, but it will be the basis for the new upcoming Plastic Cloud infrastructure we are working on.

After these two big ones, we have plans for: Code Review (finally!), improved single-branch workflows, built-in cross-file semantic merge, and heavily focusing on usability.

Windows GUI: SemanticMerge understands your PHP code now ;)

This feature closes one of the most requested UserVoice features: PHP Please!.

The PHP parser is released as a beta, so we'd love to have your feedback about things that don't work for you or any other suggestion.

All platforms: Filter rules confirmation dialog: we unified how the "apply for all workspaces" checkbox is displayed. Each platform (windows, gtk, osx) displayed this button in different ways, depending on whether the operation could be applied or not: Some platforms didn't show the checkbox, others displayed the checkbox in a disabled state, etc.

We unified the behavior this way (example with ignored files, but applies the same for cloaked items and hidden changes):

Plastic (all platforms): Now it is possible ignore files for all workspaces, always displays the checkbox.

Gluon (all platforms) Ignore files for all workspaces is not possible, the checkbox is not shown.

DevOps: "trunk-bot" and "conflictsbot" are now able to track all configured repository's branches. To do that, just leave the "Branch prefix" field empty while configuring any of these mergebots. Nevertheless, the field description has been improved in order to explain how to configure this use case.

Command line tool. We have added a cool new ability to the diff command. Previously, the process for viewing the diff of a file changed within a changeset was a little convoluted, because you had to call diff once to get the revisions and call diff again to see the differences. Now you can view the differences with a single call by specifying the filename as the last parameter.

For example "cm diff br:/main@myrepo src\common\myfile.cs" will show any differences in the file "myfile.cs".

In actual fact, you only need to specify enough of the path to uniquely identify the file. See the following output for an example of this intelligent path matching in action:

Find queries that used the "like '%'" condition (i.e. a catch-all clause) returned a server error if it was configured to use Jet as backend. Fixed.

Server: Using special characters, such as (# / ? :, etc. in bot/plug/bottype/plugtype names, caused the DevOps system to fail. Now, the following characters are forbidden: / : * ? " < > | #

Also in some circumstances, using blank spaces or other reserved characters caused the bots to fail when trying to communicate with the plugs. Now it's fixed.

Windows GUI: The "explain merge" diagram was unable to draw the contributor labels properly when a changeset was the base and destination of the merge at the same time. A red label with "UNKNOWN" text was displayed instead. Now it's fixed.

Filter matching: We fixed a bug that caused name-only rules to be applied to the complete directory hierarchy of every workspace item. This means that writing e.g. 'wkspaces' as a rule in your /ignore.conf file would cause every private file in all workspaces inside /home/myuser/wkspaces to be ignored.

Windows GUI: Fixed two bugs in the code review window.

When a recently added file was commented in a revision that was not the last in the branch, the file content was displayed as empty. Now it's fixed.

When a changed file was commented in a revision that was not the last in the branch, the action "show this revision in the left pane did nothing. Now it's fixed.

**Examples:**

Example 1 (unknown):
```unknown
> cm ls / --tree=264526ea-eae6-407d-ba24-e3fcb646d7ee@codice@ourinternalserver.com:9090 -R
```

Example 2 (unknown):
```unknown
> cm ls / --tree=264526ea-eae6-407d-ba24-e3fcb646d7ee@codice@ourinternalserver.com:9090 -R
```

Example 3 (unknown):
```unknown
Specified argument was out of the range of valid values. Parameter name: lineIndex
```

Example 4 (unknown):
```unknown
Specified argument was out of the range of valid values. Parameter name: lineIndex
```

---

## Cloud Save Player Data

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/concepts/player-data

**Contents:**
- Cloud Save Player Data#
- Access Classes#
- Limits#
- Additional resources#

Cloud Save Player Data is key/value storage intended for data associated with a player. You can read and write Player Data from a game client and from Cloud Code.

You can configure Player Data so that the data is queryable and supports different Access Classes. Queryable data means you can have data that only a player can read and write, data that is public for other players to see, and data that a player can't directly modify.

You can use the Unity Dashboard to view and edit Player Data.

Cloud Save supports 3 different Access Classes for Player Data.

Note: If you need data that is readable by players and only writable by a server, you can use Default Game Data.

You can read and write to any Player Data from a server authortative context, such as Cloud Code, a game server, the Unity CLI or the Unity Dashboard.

To further restrict client access, you can use Access Control for Unity Gaming Services. For example, you can disable all write access from clients and allow write access only from Cloud Code or from a game server.

These limits are per player, there isn't a limit on the number of players you can have.

For example, a player can have 2000 keys of 2.5 KB each, or 1 key that is 5 MiB.

---

## View changesets

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/unityeditor-plugin/view-changesets

**Contents:**
- View changesets#

Note: To view changeset diffs, you need to install the VCS desktop app.

You can compare previous content with files for specific changesets:

---

## Create a repository

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/create-repository

**Contents:**
- Create a repository#
- Create a repository in the Unity Dashboard#
- Create a repository in the GUI#
- Create a repository in the CLI#

To work in Unity Version Control (UVCS), you need a repository.

You can create a repository through the Unity Dashboard:

Note: Since a workspace is a local copy, you need to Set up a workspace through the desktop application or the command line.

To create a repository, you can use the cm repository command:

For more information and options, refer to the cm repository CLI reference documentation.

**Examples:**

Example 1 (unknown):
```unknown
cm repository
```

Example 2 (unknown):
```unknown
cm repository create rep_name
```

Example 3 (unknown):
```unknown
cm repository create rep_name
```

Example 4 (unknown):
```unknown
cm repository
```

---

## SDKs for Matchmaker

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/matchmaker-unity-sdk-landing

**Contents:**
- SDKs for Matchmaker#

Find the right Matchmaker SDK for your version of Unity.

Note: For most users, the unified Multiplayer Services package replaces the Matchmaker standalone package, which is deprecated in Unity 6. Consider migrating to the unified package to facilitate a smooth transition. Visit the migration guide for a step-by-step transition process.

The following SDKs have all the functionality necessary to use Matchmaker services in your game.

---

## Extensions

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/extensions

**Contents:**
- Extensions#
- Which Extensions are supported#
- Account requirements#
- Configuration and setup#
- Considerations and restrictions#

Use Multiplay Hosting to deploy and run your game servers at scale. When your fleet grows in size, you will need more information on those fleets. Use Extensions to leverage 3rd party services with your game servers to enhance observability and gather valuable insights.

With Extensions, you can ask your Technical Account Manager (TAM) to enable and monitor 3rd party services. These services aim to answer questions around observability, for example: you can bring your logs or your server metrics to your monitoring solution.

Currently, we support the following Extensions:

Each of these Extensions provides insights into your server's behavior.

You need a separate account with each 3rd party provider before you get started with Extensions. For example, if you plan to utilize Datadog, ensure you have an active contract with them. Additionally, you need to define what specific metrics you want to measure and how you do this. Extensions enable your Technical Account Manager (TAM) to take your configuration and seamlessly integrate it into your Multiplay Hosting deployment.

Enabling an Extension involves collaboration with your TAM. Refer to the following steps:

It's important to note that certain network configurations, such as using "host" as network_mode, are restricted for security reasons. Your TAM will be able to guide you on any related questions.

---

## Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDAuthentication

**Contents:**
- Authentication#
- Service account#
- API Key#

To authenticate with the service, you need to use a service account. Ensure that your service account has the appropriate roles assigned for the required access levels:

For instructions on how to create and use service accounts, refer to the Service Account Authentication documentation.

The API Key is officially deprecated and will no longer receive updates. We recommend all users to transition to service accounts

An alternative way to authenticate with the Content Delivery Management API is to use an API Key linked to your Unity developer account. To retrieve your API Key from the Unity Dashboard, select the API Key tab and select the Copy API Key to Clipboard icon. When you make a request with the API Key, you need to do the following:

For example, with the API key d6d2c026bac44b1ea7ac0332694a830e, you include the following Authorization header:

**Examples:**

Example 1 (unknown):
```unknown
d6d2c026bac44b1ea7ac0332694a830e
```

Example 2 (unknown):
```unknown
Authorization: Basic OmQ2ZDJjMDI2YmFjNDRiMWVhN2FjMDMzMjY5NGE4MzBl
```

Example 3 (unknown):
```unknown
Authorization: Basic OmQ2ZDJjMDI2YmFjNDRiMWVhN2FjMDMzMjY5NGE4MzBl
```

---

## Create a Discord web trigger

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/tutorials/discord-webtrigger

**Contents:**
- Create a Discord web trigger#
- Create a Discord Webhook#
- Create the UVCS Webtrigger#
  - Example Discord web triggers#

You can create a web trigger to connect Unity Version Control with Discord to receive notifications. The notification includes the information available to the specific trigger that you use.

First, you need to choose which channel you want to receive notifications:

You can then use the Discord Webhook URL to set up a webtrigger. For a complete list of the types of triggers you can use, refer to this list of triggers.

You need to use the webtrigger-discord string (instead of webtrigger) before the script path, followed by the Discord webhook: webtrigger-discord https://discordapp.com/api/webhooks/${channelId}/${token}

This example uses an after-ci so that you get a notification when someone runs a check in operation:

The following example uses an after-mkbranch trigger so that you get a notification when anyone creates a new branch:

**Examples:**

Example 1 (unknown):
```unknown
webtrigger-discord
```

Example 2 (unknown):
```unknown
webtrigger-discord https://discordapp.com/api/webhooks/${channelId}/${token}
```

Example 3 (unknown):
```unknown
> cm trigger make after-ci NotifyTeam-Ci "webtrigger-discord https://discord.com/api/webhooks/<channelId>/<token>" --server=localhost:8787
```

Example 4 (unknown):
```unknown
> cm trigger make after-ci NotifyTeam-Ci "webtrigger-discord https://discord.com/api/webhooks/<channelId>/<token>" --server=localhost:8787
```

---

## Configure syntax language

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/languages-conf

**Contents:**
- Configure syntax language#
- Create a languages.conf file#
  - Example languages.conf file#
  - Supported languages#

Configure the language that Unity Version Control (UVCS) uses to syntax highlight the contents of files or revisions in the side by side diff tool.

The following options are available for syntax highlighting:

To customize the syntax highlight language, create a languages.conf configuration file in the syntaxhighlight directory under the plastic4 directory.

Write each configuration on a new line in the format .<fileextension>:<language>.

The following are supported languages that UVCS can syntax highlight:

**Examples:**

Example 1 (unknown):
```unknown
languages.conf
```

Example 2 (unknown):
```unknown
languages.conf
```

Example 3 (unknown):
```unknown
languages.conf
```

Example 4 (unknown):
```unknown
syntaxhighlight
```

---

## Cloud Save Files

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/concepts/files

**Contents:**
- Cloud Save Files#
- Limits#
  - Limits on accessing files#
- Additional resources#

Cloud Save Files provide a way to store large save files (up to 1 GiB) in any format in the cloud. You can use Cloud Save Files to access players' save files across multiple devices and platforms.

You can use the Unity Dashboard to view, download, and delete player files.

Note: These are the data limits per player, there's no limit on the number of players you have.

Files are intended for you to use for Binary Large Object (BLOB) save game files that are saved and loaded directly by a game client, with the file backed up in the cloud and avalible to the player on any platform.

A player can save and load any of their uploaded files in Cloud Save but these files can't be accessed directly by other players. Cloud Save Files cannot be used with Cloud Save Queries.

---

## Frequently asked questions

**URL:** https://docs.unity.com/ugs/en-us/manual/game-overrides/manual/frequently-asked-questions

**Contents:**
- Frequently asked questions#

How much does Experimentation cost? How is it priced?

Experimentation is included as part of Unity Analytics. You can learn more about Unity Analytics pricing here.

Is there a limit to how many experiments I can run at once?

There is no limit to the number of experiments you can run in total, or concurrently. We would recommend not running overlapping experiments for the same players to reduce the chances of experiments interfering with one another.

What do I need to implement in my game to use Experimentation?

Experimentation requires Unity Analytics to enable reporting. Game Overrides can be configured as split-variant tests without Unity Analytics but no reporting data will be available for them.

Why can’t I see the results of my experiment before it’s ready?

To prevent “peeking” the results of an experiment are only shown once the required sample size has been reached for all variants. Experiments also need to run for at least 7 days to account for weekly seasonality in the results.

Where can I learn more about Experimentation?

Refer to experimentation best practices and regularly used terms. You can also contact the support team.

---

## Unity Version Control (previously Plastic SCM)

**URL:** https://docs.unity.com/devops/en/manual/unity-version-control

**Contents:**
- Unity Version Control (previously Plastic SCM)#
- Example workflow#
  - Task#
  - Task branch development#
  - Code review#
  - Automated testing and merge#
  - Deployment#
- Use Unity Version Control#
  - Use Unity Version Control via the Desktop Client#
  - Use Unity Version Control via the Hub#

Unity Version Control (UVCS), previously named Plastic SCM, is a version control and source code management tool you can use for game and real-time 3D development to improve team collaboration and scalability with any engine.

UVCS offers you workflows optimized for artists and programmers, and efficiency when you work with large files and binaries.

The UVCS web experience in the Unity Dashboard has new and deeply integrated role-based workflows, code reviews, and user and user group management. These capabilities not only connect teams, they help increase productivity for real-time content creators.

For more information on the tools available with UVCS, refer to the Concepts section.

You can customize your workflow to best support your needs.

A version control workflow starts with a task. This task can be in your issue tracker or project, so that each change in code has an associated task.

Next, you create a branch for the task. You can work on the task branch and make check-in changes with comments as you go to record your work.

Once you mark your task as completed, you can request a code review from one of your coworkers. They can then add comments, ask questions and request changes until they are happy and approve your changes. You can also get a coworker to manually test your code for validation if necessary.

Once the task is reviewed or validated, you can merge the changes. Before you check in the merge, the task changes are tested to check for merge conflicts to avoid breaking the build. To test for merge conflicts before the merge, or to automatically merge changes after a review, you can use a mergebot.

You can deploy changes in the way that best suits your projects. If you use a mergebot, you can enable automatic CI integration.

You can enable Unity Version Control through your Unity Dashboard.

You can use UVCS with multiple applications and repositories through the UVCS desktop client. For more information, refer to the documentation on how to Get started via the desktop client.

You can also add UVCS to your projects through the Unity Hub. For more information, refer to the documentation on how to Get started via the Hub.

---

## Moderation actions

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/actions

**Contents:**
- Moderation actions#
- Game bans#
- Communication sanctions#

Actions are how moderators can respond to player reports. Moderators can take actions on players to block them from selected features after reviewing a report. Moderators can take action from individual report pages found in the Moderation queue on the Unity Dashboard.

There are two types of actions available:

Safety Moderators can create their own custom actions as well as edit the existing actions. By default, actions can be active for 1, 3, or 7 days, or permanently. These time settings can be edited on the Moderation actions page, allowing moderators to customize the length of time actions are in place for.

You can also set up events for actions that will trigger when used, letting you leverage Cloud Code scripts to customize actions to your game's needs.

Important: For action events and custom actions you must be using Unity Cloud Code.

Game bans are applied at the authentication level. When a game ban is applied, the player is blocked from UAS authentication and will no longer be able to access the game due to not being able to be authenticated.

You need to use the Unity Authentication Service (UAS) to identify players to use game bans in your game. For information on getting started with Unity Authentication Service, refer to the UAS documentation.

When restricting user communication, Moderators can choose:

When a user is muted with either Voice Mute or Mute All they are still able to listen and read conversations but can’t participate themselves.

Communication sanctions take effect immediately.

Note: You must use Vivox Voice and Text Chat version 16 or higher and UAS to use communication sanctions in your game.

For information on getting started with Vivox Voice and Text Chat, refer to the Vivox documentation.

---

## Set up merge rules

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/merge-rules/set-merge-rules

**Contents:**
- Set up merge rules#

Edit the mergerules.conf file in your server directory to configure your merge rules.

Note: You can also set up merge rules in your webadmin server administration console.

The mergerules.conf file is a JSON file that contains your merge rules. To add a merge rule, you need to place the rule inside an array:

You can use the following parameters to define your merge rules:

You can filter the branches that you apply the merge rule to. Use the following parameters under either to or from:

**Examples:**

Example 1 (unknown):
```unknown
mergerules.conf
```

Example 2 (unknown):
```unknown
[{
    "enabled": true,
    "repositories": "code*",

    "rule": "only_allow_merges_if_reviewed",
    "to":
    {
        "branchNames": ["main"],
        "branchesWithAttribute": [
            {
                "attribute": "merge_only_reviewed",
                "value": "enabled"
            }
        ]
    },
    "from":
    {
        "branchNames": ["scm*"],
        "branchesWithAttribute": [
            {
                "attribute": "task",
            }
        ]
    }
}]
```

Example 3 (unknown):
```unknown
[{
    "enabled": true,
    "repositories": "code*",

    "rule": "only_allow_merges_if_reviewed",
    "to":
    {
        "branchNames": ["main"],
        "branchesWithAttribute": [
            {
                "attribute": "merge_only_reviewed",
                "value": "enabled"
            }
        ]
    },
    "from":
    {
        "branchNames": ["scm*"],
        "branchesWithAttribute": [
            {
                "attribute": "task",
            }
        ]
    }
}]
```

Example 4 (unknown):
```unknown
repositories
```

---

## File explorer

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/file-explorer

**Contents:**
- File explorer#
- View 3D files#
- ReadMe#

In a repository's File explorer tab, you can do the following tasks:

From the file explorer tab, you can preview 3d binary files.

You can also diff a 3d file by displaying its state over time, in a side-by-side view by comparing 2 changesets and selecting the 3d file that you want to review.

On the Repository file explorer page, you can also add a ReadMe file directly. The ReadMe file is populated at the start of a repository creation. You can also add screenshots and attachment links.

---

## Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/matchmaker-authentication

**Contents:**
- Authentication#
- Player authentication#
- Service Account authentication#

There are two ways to authenticate to Matchmaker:

Player authentication uses Unity Authentication to enable player-driven matchmaking so that a game client can contact the Matchmaker service to create a ticket.

Make sure to initialize the Authentication service and sign in before making any calls using the Matchmaker SDK.

There are multiple ways to sign in, the simplest method is using anonymous sign-in.

Service Account authentication is used when a backend service creates a matchmaking ticket on behalf of a game client. This is useful when it is required to add server authoritative data to a matchmaking ticket like a skill value for example.

To create a Service Account follow these instructions.

To use the Service Account in Matchmaker, follow those steps.

Here is an example of a typical service-to-service authentication flow:

The client performs an anonymous authentication as described above in Player authentication.

The client calls a custom backend server with the PlayerId as the parameter.

The custom backend calls the ticket creation route with the impersonate-user-id header set to the PlayerId value:

The custom backend sends the ticket ID back to the client.

The client polls the ticket status using the client SDK.

**Examples:**

Example 1 (unknown):
```unknown
impersonate-user-id
```

Example 2 (unknown):
```unknown
curl --location --request POST 'https://matchmaker.services.api.unity.com/v2/tickets' --header 'Content-Type: application/json' --header 'Authorization: {{SERVICE-ACCOUNT-TOKEN}}'
 --header 'impersonated-user-id: {{PLAYER-ID}}' --data-raw '{ "players": [ { "id": "{{PLAYER-ID}}", "customData": { "Skill": {{ENRICHED-DATA}} } } ] }'
```

Example 3 (unknown):
```unknown
curl --location --request POST 'https://matchmaker.services.api.unity.com/v2/tickets' --header 'Content-Type: application/json' --header 'Authorization: {{SERVICE-ACCOUNT-TOKEN}}'
 --header 'impersonated-user-id: {{PLAYER-ID}}' --data-raw '{ "players": [ { "id": "{{PLAYER-ID}}", "customData": { "Skill": {{ENRICHED-DATA}} } } ] }'
```

---

## Vivox Unity release notes

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/release-notes

**Contents:**
- Vivox Unity release notes#
- Version 16.7.0#
  - Release overview#
  - Key features and bugs addressed#
  - API changes#
  - Known issues#
- Version 16.6.3#
  - Release overview#
  - Key features and bugs addressed#
  - API changes#

Find release notes for all UGS products on the UGS release notes page.

This release introduces new metadata capabilities for messages, improves SDK initialization workflows, and addresses an important memory management issue. The release also includes updates to the minimum supported Unity Editor version and removes deprecated Mint service functionality.

Version 16.6.3 officially provides support for Nintendo Switch™ 2.

This release adds support for 16 KB page sizes on Android and decreases the size of the AAR library.

Version 16.6.0 introduces comprehensive audio processing improvements with enhanced noise suppression, expanded platform support for audio processing features, and significant performance optimizations.

This release focuses on improving voice quality while optimizing resource usage across all supported platforms.

For further technical details on all the changes included in this release, refer to the CHANGELOG.md file within the SDK.

Audio Processing Improvements:

Performance Optimizations:

Platform-Specific Changes:

Implementation Considerations:

Noise suppression controls:

Echo cancellation settings:

Audio processing features:

This release updates the licenses and third party notices for the package and contains multiple fixes for the Unity SDK.

This release includes a slew of bug fixes, particularly around token behavior and audio taps along with the inclusion of a couple of new API's to be used in conjunction with the new Vivox Safe Voice service.

WebGL now has limited support for voice and text chat in a single channel.

Moved the IVivoxTokenProvider validation step from Vivox SDK initialization to the Login operation.

Made the error reported by the VivoxParticipantTap a bit clearer when the 'Channel Name' or the 'Participant Name' parameter are unknown or not set.

Resolved an issue where attempting to rejoin a channel was not possible after a JoinChannelAsync operation experienced a TimeoutException.

Resolved an issue where CancellationTokenSource instances used internally were not being disposed of when no longer needed, occasionally resulting in unexpected behavior.

Fixed a bug where allocated memory that was supposed to be aligned was not actually aligned.

Fixed a bug where the "Channel Name" field for Audio Taps would reset to empty when an unexpected value was entered.

Improved the overall experience of interacting with the Audio Tap inspector by registering the tap only after all fields are fully edited, instead of on every character entry.

Fixed a bug that would prevent the VivoxParticipant.ParticipantMuteStateChanged event from firing.

This release adds a new sample focused on text-based features such as editing and deleting DMs and channel messages.

A new sample, Text Chat Sample, has been added to the package. This text-focused sample showcases a robust chat experience that demonstrates sending, editing, and deleting DM or channel messages, as well as retrieving past conversations and their message history.

Fixed a bug that would cause the SDK to throw an exception when trying to perform cleanup operations, such as leaving channels, during OnApplicationQuit in the Unity editor.

**Examples:**

Example 1 (unknown):
```unknown
VivoxParticipant
```

Example 2 (unknown):
```unknown
VivoxMessage.Metadata
```

Example 3 (unknown):
```unknown
MessageOptions.Metadata
```

Example 4 (unknown):
```unknown
IUnityServices.GetVivoxService()
```

---

## Code-Link

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-code-link

**Contents:**
- Code-Link#
- Set up Code-Link#
- Sign in using Code-Link#

Minimum SDK version: 3.0.0

See the following scenarios in setting up authentication for players in your game with Code-Link:

Sign in as a player using these Code-Link functions:

Note: Step 4 can be skipped if device B polls the service until the Code is either confirmed or expired.

To sign in using Code-Link, follow these steps:

Use the GenerateSignInCodeAsync method (passing an identifier is optional but recommended to identify the device that generated the sign in code) from the unauthenticated device that wants to authenticate to generate a Sign In Code.

Show the generated SignInCode and expiration to the player.

Note: The identifier has a maximum length of 128 characters.

Give player access to input the SignInCode, in a second already authenticated device.

(Optional) Use the player-provided SignInCode to fetch the SignInCode information, using GetSignInCodeInfoAsync, and display it to the player to confirm they're authorizing the correct device by comparing the identifier on both devices.

Authorize the Code-Link sign in using ConfirmCodeAsync.

Note: The ConfirmCodeAsync method also supports optional parameters in idProvider and externalToken. These parameters should only be used on consoles. Using them on other platforms will return an error.

Call SignInWithCodeAsync to sign in the player on the same device that generated the SignInCode. (The credentials to validate the Code-Link sign in are stored in memory so make sure to call GenerateSignInCodeAsync before calling SignInWithCodeAsync or it will throw an exception). If the code has yet to be authorized, this method is successful, but the player won't be signed in; look for the SignedIn event to see if the sign in was successful.

Note: The SignInWithCodeAsync method also allows for automatic polling (every five seconds), so the device automatically signs the player in after the code has been authorized, or throws an exception if the code has expired. This method also accepts a CancellationToken to cancel the polling.

**Examples:**

Example 1 (unknown):
```unknown
GenerateSignInCodeAsync
```

Example 2 (unknown):
```unknown
async Task GenerateCodeAsync(string identifier)
{
    try
    {
        var codeInfo = await AuthenticationService.Instance.GenerateSignInCodeAsync(identifier);
        // Display code, and expiration and identifier to the player
    }
    catch (Exception e)
    {
        // Notify the client something went wrong generating the code
    }
}
```

Example 3 (unknown):
```unknown
async Task GenerateCodeAsync(string identifier)
{
    try
    {
        var codeInfo = await AuthenticationService.Instance.GenerateSignInCodeAsync(identifier);
        // Display code, and expiration and identifier to the player
    }
    catch (Exception e)
    {
        // Notify the client something went wrong generating the code
    }
}
```

Example 4 (unknown):
```unknown
GetSignInCodeInfoAsync
```

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/privacy

**Contents:**
- Privacy and consent#
- Privacy overview#
- Apple privacy survey#
- Google Play data safety#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs such as Unity Leaderboards.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Unity Leaderboards.

---

## Unity Version Control 9.x Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/9

**Contents:**
- Unity Version Control 9.x Release Notes#
- 9.0.16.5315#
  - New#
    - SSO included in the Enterprise Edition#
    - Protected the push operation (submitting changes…#
    - Improved the progress of the Perforce multibranch…#
    - The pull operation could skip changes if the tmp…#
    - Branch name displayed when trying to switch branch#
    - Added the recent checkin comments button#
    - Disable all tips#

This document contains all release notes for Unity Version Control major version 9.x, organized from newest to oldest.

All platforms - Plastic, Gluon: SSO included in the Enterprise Edition

So far, we only allowed to sign in with SSO in the cloud editions of Plastic and Gluon, and the Enterprise Edition of Plastic on Windows.

Now we extended this feature, and you can sign in using SSO on every platform, either from cloud or enterprise edition. This is how it looks:

All platforms - P4Sync: Protected the push operation (submitting changes to Perforce) when it cannot continue due to some specific changes.

Now, if the Perforce submit operation fails, it tries to skip the changes that make it fail and continue with the rest of them.

All platforms - P4Sync: Improved the progress of the Perforce multibranch pull.

We don't know the total number of changesets to pull in advance, so we just use the last changelist number in the depot to estimate the number of changesets to pull.

Now, we update this estimation after discovering gaps in the changelist numbers. So, don't worry if you see that the number of changesets to pull goes down in the progress, that's what is really happening!

All platforms - P4Sync: The pull operation could skip changes if the tmp path contained blank spaces.

This was a problem if the path was looked like 'C:/Users/ruben de alba/AppData/Local/Temp'. It could be easily workarounded by setting the TMP environment variable to a path without blank spaces.

All platforms - Plastic: Branch name displayed when trying to switch branch

Now when trying to switch to a different branch from the GUI, the confirmation dialog's message shows the target branch name:

All platforms - Gluon: Added the recent checkin comments button

In the Pending Changes view in Plastic there is a "Checkin comments" button, that allows you to quickly fill the checkin comments text box with the previous changesets' comments. Now we added this button to the Gluon checkin view in all platforms! This is how it looks:

All platforms - Plastic, Gluon: Disable all tips

If you don't want to see more tips in Plastic or Gluon, now you can mark the "Disable all tips" checkbox inside any help panel to disable all of them at once. If you want, you can still show them manually from the information button

All platforms - P4Sync: The Perforce sync now supports multiple branches!

Some weeks ago, we released (9.0.16.4995) the support for importing from P4 branches/streams to Plastic SCM branches.

Now, you can also export the changes from your Plastic branches to P4. This is needed to keep you changes in sync between Plastic & P4 when you are concurrently working with both systems.

How to do it? You just need to use the 'p4multibranch' source in the 'cm sync' command:

The command needs to explicitly know what p4 folder matches with the main branch and what p4 folder includes the rest of your branches folders.

Example. With the following depot structure:

where //depot/project/dev is the main branch folder and //depot/project/release-01 & //depot/project/release-02 are also branch folders. The command should receive the following parameters (notice that these depot paths don't end with /...):

We also added new options to skip paths or branches during the sync process:

The sync ignores the changelists that contain changes of different branches (or what we consider different branch folders) in the same changelist.

The branch starting point is wrongly calculated when the changelist used to create the branch (populate/integrate commands) only contains delete operations. In this scenario, we use as starting point the closest parent changelist with any change different than a delete.

The progress of the changelists to pull can be improved. If the last changelist in the depot is 500, we say that we are pulling 500 changelists although there are big gaps in the ids and, finally, we only import 100. This works this way to avoid requesting all the changelists at once at the beginning (it can be slow and error prone).

The sync operation can say that there are new changelists to pull, although it later pulls nothing. This happens if these changeslist were pushed from Plastic before or if there are new changelists in the depot that apply to paths not related to what's being synchronized.

The sync operation can leave some empty directories in Plastic. Since p4, doesn't handle directories, when all files are removed the directory doesn't exist anymore.

The sync report might show some changes skipped due to the following reason: 'The path couldn't be deleted'. This report is harmless, and it will just keep a file loaded in p4 that shouldn't be there (in the worst scenario).

Perforce doesn't support to reuse a path in the same changelist so, we cannot export these changes from Plastic to Perforce. In these cases, we do our best to keep the same structure in the Perforce side. Check 'Paths reused in the same changelist' appendix.

The push ignores changes on empty directories since p4 doesn't handle directories at all.

The '--user' parameter is mandatory when pushing changes to a depot of type 'stream'. In this case, all the streams created to push the Plastic branches are created of type mainline.

The branches are always created in Plastic using the full content of the starting point. It means, if only a subdirectory of //depot/project/main/...@24 is branched in P4, we will see the whole content under //depot/project/main/... in Plastic.

The branches created from custom configurations doesn't keep this custom configuration in Plastic. A branch always starts from an existing and defined configuration (changeset) in Plastic. So, the importer will choose only one specified path@changelist configuration as base. Check 'Branch from different configurations' appendix.

net.parallel.max P4 setting must be set (to a value higher than 1) to enable parallel download of contents while syncing. However, in those scenarios where the user is not a super user, parallel processing won't be enabled by default as it requires to check a p4 variable and it will fail in this case. The workaround is asking a super user (usually a company admin) to set both variables: net.parallel.max and net.parallel.threads and these values will be used during the sync. You can also force the number of threads to download data from p4 by using the parameter --p4threads=X.

Pending to implement:

All platforms - Plastic, Gluon: handle LDAP credentials using Single Sign On

Now, the LDAP credentials are handled correctly when your client points to the local cloud server and is configured to use the SSO working mode.

All platforms - Plastic, Gluon: automatically change display language on East Asian systems

You might have seen in an earlier release that to take advantage of newly supported languages Chinese Simplified, Chinese Traditional, Japanese, and Korean, you can set the language in your client.conf.

Furthermore, so that users unaware of this can also enjoy the new languages, we will now automatically set the display language to match the system language if the system language is one of the above and the language in the client.conf is "en" or "zh" or not set.

NOTE: if your system is set to an East Asian language, but you want to force Plastic to appear in English, simply set "force_en" as the language in client.conf, like this:

All platforms - Gluon: Solved credentials issue when using SSO

When opening Gluon for the first time and signing in using SSO, there was an error that prevented the user from creating a workspace, asking for a password. We solved this issue, and now you can create the workspace without being asked for credentials again.

Windows - Installer: The server is now started on unattended installs

Unattended installations of Plastic SCM (CLOUD and DVCS editions) will configure the Plastic Server with default values and start it up. This is done just if no previous Plastic Server installation was detected in the system.

Note that the Enterprise edition installers already behaved in this way.

You can launch the installers in unattended modes using the following command:

You can find additional details for the other arguments by typing --help with the client installer.

All platforms - Plastic: Check if the selected server is cloud when creating a distributed workspace in cloud edition

When creating a new distributed workspace, you must specify the remote cloud repository. If you wrongly selected a non-cloud repository, Plastic showed an ugly DNS error after trying to connect to the non-existing server. We improved this behavior, and now we check if the selected repository is on a cloud server, so you can see the error before trying to connect to the server

All platforms - Plastic: Connect to cloud servers from enterprise edition

When we launched SSO we created an issue that prevented the enterprise edition client to correctly connect to a cloud server. We fixed this issue

macOS, Linux - Plastic: Fixed exception when listing objects in a different repository

The GUI sometimes displayed an error in query views (branches, labels, changesets, ...) and got closed if the user clicked one of the listed items. This happened when the user modified the query to retrieve objects from a repository different from the one loaded in the current workspace.

This happened for labels, shelves, changesets, branches and attributes. We fixed all of them in macOS and Linux. This issue didn't happen in Windows.

Windows - Plastic, Gluon: Users can now display differences between images of different sizes.

Now when comparing two images, the smaller image is scaled to match the size of the larger image while maintaining its aspect ratio:

You can try out different combinations of images, see what results you get!

All platforms - Plastic, Gluon, CLI: Introducing Plastic in Chinese, Japanese and Korean!

We are pleased to share with you our progress to date in expanding the set of languages supported by the Plastic toolset.

We have added support for Simplified Chinese, Traditional Chinese, Japanese and Korean to Plastic and Gluon, inlcuding the Diff and Merge tools, and to the command line interface for Windows, MacOS and Linux.

"Wow! How can I see Plastic in my favourite East Asian language?" I hear you ask. Don't worry, it's simple.

First, close any open Plastic or Gluon applications. Then,

Open up your "client.conf" setting file.

Find the "language" setting. It probably looks like this: en

Change "en" to one of the following:

"zh-Hans" for Simplified Chinese

"zh-Hant" for Traditional Chinese

You should see something like this:

Traditional Chinese Plastic on Windows:

Japanese Gluon on Linux:

Korean Plastic on MacOS:

All platforms - IntelliJPlugin: we fixed UI lags on high latency networks

IntelliJ requires PlasticPlugin to check if a file can show its history every time the file is scrolled. Plastic was retrieving that information from the server which caused lags when the network latency was noticeable. Now this is fixed

All platforms - All clients: We improved the log for the status operation!

Do you know how many different operations involve calculating the pending changes in a workspace? Well, let me tell you - a lot. But we can classify them in three different categories: time spent traversing the disk, time spent doing network operations, and overhead time (the time spent in running the nice algorithms that so precisely identify moved files and directories, for example).

Now, when you calculate the status of a workspace, the log breaks down these times. If something starts working slow, we can diagnose it with ease!

All platforms - Plastic: Updated New Label dialog

When a user now adds a new label to a changeset, and they wish to add the label to all

XLinked repositories, the label now specifies that it explicitly applies to all the

All platforms - Plastic: Updated code review comment time stamps

When a user posts a new comment or a question in a code review, the and the time stamp is less than 10

seconds old, the text displayed will be "Just now", instead of "1 seconds ago", or sometimes that same amount was 0, or a negative value.

Plastic - All platforms: Improve merge-to dialog message

We received a request to improve and clarify the message received when a user has to re-start a merge-to process, if another user has submitted a new changeset(s) to the same branch, in the middle of that initial merge-to process.

This is the message that we were using:

We've now clarified this, using the following format:

Windows, macOS - Plastic: Unity Smart Merge path configuration is fixed

The configuration of the Unity Smart Merge tool was not checking the latest version installed and the path by default wasn't correct. We fixed that problem and we just configure it with the latest version installed on your machine.

Windows - Plastic: Protect users to wrongly rerun a server-side merge in progress

When performing a server-side merge, and clicking on the "Apply" button, it was still enabled while performing the operation. For big merges that took some time to process, the user had the possibility to run the same operation again, creating an inconsistent destination branch with multiple heads.

We solved this issue by disabling the "Apply" button when the operation is running.

All platforms - All clients: We fixed a wrong error message when the server closed the connection.

Before the fix, if the server closed the connection, the client would throw an "End of file" error. This was because we were not correctly identifying the situation. Now, the client shows up the correct error message for this situation: "The remote host closed the socket".

macOS - Server: Enabled support for Apple M1 chipset.

Recently we updated the Plastic Server we bundle in the macOS installers: now it is a netcore-based application as you may know.

But the server was unable to start in Apple M1 chipset computers. We had to enable our build to start the server on those archs in emulated mode. And that's what we did.

We will support Plastic Server natively for Apple M1 chipsets soon, once net core 6 it's officially released in LTS mode.

macOS - Plastic: Preference Diff and Merge tools were not localized.

Now those strings are localized and waiting for their translations to be included!

macOS - Plastic, Gluon: Solved exception when creating a workspace from the cloud tab

When creating a workspace for a repository from the "Cloud" tab, by selecting the "Create workspace for this repository..." option, an exception was thrown. We fixed this issue, and also modified the behavior to match Windows: now, after the workspace is created, the current workspace is automatically changed to the new one, and Plastic shows the items view of that workspace.

All platforms - Command Line: Command cm help autocomplete didn't show any help.

The cm help autocomplete command was showing the following message:

Now it is fixed, and shows the expected command help.

All platforms: Unity ID is now fully supported!

Welcome to full OAuth support for Unity ID, including 2 factor authentication. No more passwords!

We added support to ALL GUIs, so now you will be able to enjoy the full integrated experience:

This is a great step ahead in terms of security, ease of use and integration with the Unity ecosystem.

All platforms - Plastic - Gluon: Missing translations at help panels

Some words were not translated on the workspace's help panel and the pending changes' help panel:

All platforms - All GUIs: localization strings default to English

Whenever we add a new feature there will be a period of time between releasing the new feature and translating all the text values shown in the new feature into all the languages we support.

During that period, the text for the new feature will be shown in English.

Windows - Plastic: Improved help dialog for built-in mergetools

When a user decides to specify an external diff or merge tool, they'll have an improved

resizable help dialog box. This new box contains usage examples for how to set up an external

tool, and links to the kdiff3 and araxis diff/merge tools, that are commonly used.

Help dialog box for an external diff tool

Help dialog box for an external merge tool

In addition to this, we've updated the help dialog boxes for our own merge tool options.

Help dialog box for our merge tool:

Help dialog box for our binmerge tool:

DevOps - Triggers: Added Plastic Link to Discord integration message.

More info about Plastic triggers https://www.plasticscm.com/documentation/triggers/plastic-scm-version-control-triggers-guide

DevOps - Triggers: Webtriggers now support sending Discord and Slack notifications.

More info about Plastic triggers https://www.plasticscm.com/documentation/triggers/plastic-scm-version-control-triggers-guide

All platforms - All GUIs: only one credentials dialog will show up simultaneously.

We solved a well-known issue that has been hitting us since the beginning of times: multiple credentials dialogs were displayed simultaneously, which looked awful and was also a pain to use.

It happened because multiple threads required credentials at the same time, then even if all of then required to access the same server, you had to type creds again and again and again.

Now only one dialog will be displayed at the same time and if the creds are ok, they will be reused by the other threads, so you won't have to type them multiple times.

All platforms - Plastic, Gluon: applications brought to front after Single Sign On

During Single Sign On, a browser is launched to complete the sign in process. When this completes, we now bring Plastic to the foreground automatically, so you can continue the sign in process.

Windows - Installer: Improved performance installing the Visual Studio Package

We detected in some configuration that PlasticSCM installation was taking much longer time when Visual Studio was previously installed and had to reinstall it, taking up to 25 minutes to get it done. Now it's fixed so it takes the expected extra time to install a VSIX package on Visual Studio

DevOps - Slack: The Slack plug was not adapted to work with Slack API recent changes

Slack has removed support to some endpoints, one of them used to get a user private channel Id. Fixed to use the new way to send private messages using Slack API.

More info about Slack deprecation endpoints here

All platforms - Server: The pull operation is protected against concurrent delete changeset operations.

The pull could leave a changeset without data on the following scenario:

Mary pull branch /main/task0103 from the central server

Mary's pull ends with all the metadata from /main/task0103 and starts pulling the data.

John deletes the last changeset of the branch /main/task0103, the changeset 2021.

Mary's pull doesn’t find the data of the changeset 2021.

Before this task, the pull operation left the changeset 2021 replicated without data.

Now, the pull operation is canceled when it detects that the changeset 2021 was deleted. It warns about the situation and asks for retrying the operation, so next pull doesn't include the changeset 2021.

Windows - Plastic: Wrong font size at onboarding Login Panel textboxes

When the SSO mode was enable login panel textboxes's font was bigger than the font used in other texts. Now font size is the same whether the SSO is enabled or not for all panel texts:

All platforms - Plastic, Gluon: East Asian language strings updated

All platforms - Server: The new .net core builds now support Tube.

You probably never heard of Plastic Tube, but it is a cool P2P tech we can enable to access servers behind firewalls. It has been around for years but we never made it official. https://www.plasticscm.com/features/tube.

We just made it work in .net core servers, because it only worked for .net framework and mono, and we're deprecating those.

Not sure what the future of the feature will be, but we continue testing it in stealth mode.

All platforms - Plastic: fix issue where code review comments were not displayed

We corrected an issue where code review comments were not being shown for deleted files.

DevOps - Triggers: Before add item trigger fails during merges with only merge link in changes.

More info about Plastic triggers here

All Platforms - Plastic: Removed incoming changes notification when the workspace is on a label

When the workspace is pointing to a label, your configuration is static, so you shouldn't be able to update the workspace to a more recent changeset. We removed the incoming changes notification that appears at the top of the window and in the pending changes view when the workspace is configured against a label.

All platforms - Server: fixed messages in command line server configuration tool

We broke the messages in the server configuration tool (that you can launch by running "plasticd configure"). It displayed the message keys instead of the messages themselves. Fixed!

All platforms - P4Sync: The Perforce changes with blank spaces were skipped. Fixed.

The changes with blank spaces in their paths were not properly processed while importing changes from Perforce to Plastic, so they didn't appear in the equivalent Plastic changeset.

This only affected to the standard Perforce importer (p4), not to the new Perforce multibranch importer.

Example of paths that were skipped:

All platforms - JetBrains Plastic plugin: The plugin no longer affects IDE's performance.

Some users experienced lags in the interface using our JetBrains plugin for Rider. We detected that, in specific situations, the IDE was requesting long lasting operations to Plastic from different threads, and sometimes the UI thread had to wait for them to finish. That's fixed now!

All platforms - Plastic: cm status help indentation error on Japanese

All Platforms - Plastic: Pending changes Help missing translation corrected.

We fixed the problem with the translation for Sync Repositories. Now is translated to all languages which includes Korean, Japanese and Chinese. See the fix:

Windows - Plastic: fixed word wrapping rules for East Asian languages

We applied the word wrapping rules specified here Line breaking rules in East Asian languages to improve the layout in some dialogs.

For example, here is the Sign Up dialog in Korean:

Linux - Plastic: Workspace Explorer Path Permissions dialog: truncated strings are now fixed.

The 'Allowed' and 'Denied' labels were truncated when showing the Path Permissions dialog from the Workspace Explorer view.

We fixed this problem and now these labels can be showed entirely, and they are aligned with their columns to show whether the permission is checked as allowed or denied.

See how it looks now:

macOS - Server: The new .Net Core build is now the default!

All the macOS installers will now bundle a netcore-compiled plastic server, as we recently did with Linux packages too.

Prior to this release, the default server for macOS was a mono-based server.

This mono-based server had several stability glitches, it lacked of some features (latest SSL protocols)... but now we use the super-stable netcore server compiled to target macOS specifically as the default server.

== How this will impact you? ==

Just upgrade your setup to this new version by using the .pkg installer that best fits for you. No special actions required, and you'll get the new binaries.

Also, the .Net Core experimental packages will be no more, since now they will be the official ones, so this means less options in the docu.

All platforms - Plastic server: webtriggers now send to you readable messages to Discord!

We just made a fix and now webtriggers https://www.plasticscm.com/documentation/triggers/plastic-scm-version-control-triggers-guide#Chapter5:Detailedtriggerreference can send messages to Discord.

Find an example here:

=== Create a Discord channel with a Webhook ===

First step is create your own channel on Discord server

Edit your channel and go to Integrations section

Add a new Webhook, set a name (like "PlasticHook") and copy Webhook URL

=== Add your Webtrigger to Plastic ===

Next step is create a webtrigger in your Plastic. You need to indicate which action you wan to trigger. Take a look to all options

Let's go to create a webtrigger for after any check in

Here we will use our Plastic host and port and copied Discord Webhook URL

=== Let's try the trigger ===

Do any check in action on your Plastic and take a look to your Discord Channel

Linux - Plastic: Branches view buttons resized

We adjust the size of the button Clear history on the Branches options view at Advanced button to fits the text properly, especially in Chinese, Korean and Japanese.

Also we made the Loading branches... show progress label bigger to fits the text.

Linux - Plastic: fixed layout issues in xlink creation dialog

We made the rule creation dialog wider so that the Japanese text fits properly.

Check out this before / after shot:

Linux - Plastic: fixed layout issues on Pending changes view

We made the "Checkin comments" drop down taller so that the text fits properly. Here's how it looks in Korean:

We also made the Pending changes options panel bigger, so that text fits in Japanese.

Linux - Plastic: Branch explorer option panel buttons resized

We made the buttons on the Branch explorer options panel bigger so that the text fits properly, especially in Chinese, Korean and Japanese.

We also made the Edit comment button taller in the changeset diff view.

Windows - Plastic: On demand connection type help text was wrong

Wrong text has been fixed and the connection type's explanation text is now less close to the panel's bottom.

All platforms - Gluon: Deadlock solved

Gluon would hang if it had to display the credentials dialog on start-up. Now it's fixed.

Linux - Plastic: Custom query rule title label is not truncated anymore.

Label with New conditional ... title was truncated when adding a Custom query rule for Japanese language at Branch explorer view at Filters & format tab. We fixed that problem and now the label can be seen perfectly.

DevOps - TeamCity: The TeamCity plug was not adapted to work with versions above 2020.1

The TeamCity plug didn't have support for CSFR protection that TeamCity 2020.1 and above enforces. This caused the mergebots using TeamCity as CI not to queue any job. Fixed.

More info about CSFR and TeamCity here

Windows: Plastic: onboarding panels dpi's bigger than 100% were broken:

Check out how onboarding panels looked and how they are now:

Linux - Plastic, Gluon: Fixed localization truncation issues in the preferences panel in Japanese and Chinese [simplified]

Linux - Gluon: wrong layout and cut text

We had cut text in the create new repository dialog and missing text in the repository path permission dialog.

As you can notice on those images we removed the unnecessary scroll for the permissions' box. Similar modifications were done to the permissions dialog:

All platforms - IntelliJ plugin: Plastic plugin status bar is no longer showing a selected state when mouse passes over it.

Status bar has been reworked to change its appearance when mouse is hovered. It will also display a tooltip with the current branch and label (if available).

Linux - Server: New super stable, super fast bits are now the default!

The new .Net Core build is now the default!

Our server ran on Mono on Linux for more than 15 years, but last year we decided we should port it to the more stable and future looking .Net Core. And so we did.

.Net Core builds have been available since January 2020 and all our cloud infrastructure runs on them, and also all our major customers were upgraded to this new tech. So, we thought it was a good moment to just make it official for everyone.

So, dear Mono on Linux, you served us well, but it is now time for an official goodbye.

If you stay tuned, you'll see the macOS server will be the next one to be officially moved to .Net Core and, you guessed it, Windows will be next.

Once we complete this we'll be also able to simplify our code base a little because, while not dramatic, we'll stop building servers in .NET Framework and Mono.

And most likely command line and GUIs will be next.

== How this will impact you? ==

Just upgrade your current server package, no special actions required, and you'll get the new binaries.

Also, the .Net Core experimental packages will be no more, since now they will be the official ones, so this means less options in the docu.

All platforms - All GUIs: new languages available!

We are happy to announce alpha-version support for Korean, Japanese, Simplified Chinese and Traditional Chinese in Plastic and Gluon.

The language shown will be chosen based on the culture set for your machine.

Please note that support for these languages is still in ongoing development. It is likely you will see layout and translation issues in this initial release. We will be resolving this issues during the next few releases.

If you need to force Plastic back to English, you can do so by setting the following line in your client.conf file:

Windows - Plastic Image Preview: ImageMagick preview adapted to version 7.x.

ImageMagick deprecated the tools convert.exe and identify.exe. Our default configuration was based on those executables. We updated the configuration template configuration to use the new magick command available in ImageMagick 7.x.

Server: Improve threadpool boosting system to avoid running out of threads.

Now the server creates a new bunch of threads to process the pending requests when there are too many long-running requests (over 90% of the running requests are running for more than 5s).

Windows - Plastic: ImageDiff toolbar buttons are now "push" buttons.

We changed the Image Differences toolbar buttons that allow changing the image diff mode for the sake of usability. This way, the buttons will now help to reflect which mode is selected.

All platforms - WebUI: fixed display of the file history diff view

All platforms - Jira Extension: Owner is now correctly shown on Cloud instances

Due to differences between on-premise and cloud editions, the Jira extension didn't correctly show the owner of a task. Now it's fixed.

Windows - Plastic: ImageDiff changed symbolic info

Removed the symbolic name link from the panels below the toolbar, which is the same behavior as the macOS and Linux implementations. This information is now shown on the togglable properties section.

All platforms - Plastic, Gluon: Javascript-related files now detected as text

We added four javascript-related extensions to the list of known files, so they are detected as text files by default, instead of binaries. These are the new extensions:

All platforms - Server: It failed to create new threads after out of mem.

The server failed to start a previously created thread due to a lack of resources. It happened even when the missing resources became available again. Now it's fixed.

macOS - Server: The netcore-based installer wasn't deploying any configuration file for the server logs. Fixed.

New installs of plasticscm server in mac using the netcore-based installer wasn't deploying the required loader.log.conf file so the server is able to write log entries. Now this issue is fixed.

Windows - Plastic: toolbar's filter label cut

Top toolbar's filter label's text now shows correctly

macOS -Plastic: preferences wrong layout

Diff and Merge, Diff tools and other Options tabs contents showed some wrong layout. Now all are fixed!

macOS - Plastic: fixed layout of Create/Edit xLink dialog

The xLink name field label was misaligned for non-European languages. Fixed!

Mac - Plastic: No highlight applied on Path permission/Permissions table

We were not applying any highlight method to the Permissions table's rows and titles were disappearing when a row was selected and users goes out the Plastic's environment.

Mac - Plastic: Pending changes binary file message text was cut

Text was cut when message takes two lines. E.g. Japanese localization. From now on, text allows displaying two lines of content:

Linux - Plastic: Resized Refresh button for Japanese

The refresh button was too small in Japanese, so we made it bigger.

Linux - Plastic: widened sync view buttons to fit Japanese text

Also widened the Refresh buttons for the same reason.

Windows - Plastic: wrong Japanese translation display

Some texts were cut on the Sign Up panel and the Pending Changes view. Also the help panel were showing wrong format text in it's help panel at the bottom.

Both bugs are now fixed!

Windows - Plastic, Gluon: corrected unicode character encoding in help panels

We fixed encoding issues in the help panels when displaying unicode characters. Japanese, Korean and Chinese should now display correctly in the help panels.

Windows - Plastic: Japanese localization: text cut fixed

There was a text cut on the "new attribute" dialog. Now it is fixed.

We also fixed some DPI inconsistencies when the screen scale was not 100%, both on new attributes and Preferences/Diff tool dialogs.

Windows - Plastic: Branch explorer layout issue corrected for Korean language

We moved the date picker and nearby controls so that the controls were not overlapping when using the Korean language.

Windows - Plastic, Gluon: fixed help panel display for Chinese

Help panels should now display correctly when using Traditional Chinese.

Windows - Gluon: minor gui fixes for Japanese localization

We made the checkin options panel and diff tool panel wider so that Japanese text fields would fit correctly.

Windows - Plastic: Fixed layout issue on Permissions dialog

Checking path permissions from the Workspace Explorer context menu the button "Change..." was overlapped by the label next to it. We fixed this problem and now the button and the label are shown correctly.

This is how it looks:

Windows - Gluon: PlasticLink feature now allows whitespace in the path!

We now support whitespaces in the name or in the path when using the PlasticLinks feature to share files. Spaces are now encoded as +.

All platforms - P4Sync: The Perforce importer now supports multiple branches!

You can finally import your depot with branches/streams from P4 to Plastic SCM.

How to do it? You just need to use the 'p4multibranch' source in the 'cm sync' command:

The command needs to explicitly know what p4 folder matches with the main branch and what p4 folder includes the rest of your branches folders.

Example. With the following depot structure:

where //depot/project/dev is the main branch folder and //depot/project/release-01 & //depot/project/release-02 are also branch folders. The command should receive the following parameters (notice that these depot paths don't end with /...):

Only the pull/import operation is implemented so far. It means you can import changes from P4 to Plastic, but not export changes from Plastic to P4. But... don't worry, we are working on it!

The sync ignores the changelists that contain changes of different branches (or what we consider different branch folders) in the same changelist. Check 'Changelist with changes in multiple branches' appendix.

The branch starting point is wrongly calculated when the changelist used to create the branch (populate/integrate commands) only contains delete operations. In this scenario, we use as starting point the closest parent changelist with any change different than a delete.

The progress of the changelists to pull can be improved. If the last changelist in the depot is 500, we say that we are pulling 500 changelists although there are big gaps in the ids and, finally, we only import 100. This works this way to avoid requesting all the changelists at once at the beginning (it can be slow and error prone).

The sync operation can say that there are new changelists to pull, although it later pulls nothing if there are new changelists in the depot that apply to paths not related to what's being synchronized.

The sync operation can leave some empty directories in Plastic. Since p4, doesn't handle directories, when all files are removed the directory doesn't exist anymore.

The branches are always created in Plastic using the full content of the starting point. It means, if only a subdirectory of //depot/project/main/...@24 is branched in P4, we will see the whole content under //depot/project/main/... in Plastic.

The branches created from custom configurations doesn't keep this custom configuration in Plastic. A branch always starts from an existing and defined configuration (changeset) in Plastic. So, the importer will choose only one specified path@changelist configuration as base. Check 'Branch from different configurations' appendix.

net.parallel.max P4 setting must be set (to a value higher than 1) to enable parallel download of contents while syncing. However, in those scenarios where the user is not a super user, parallel processing won't be enabled by default as it requires to check a p4 variable and it will fail in this case. The workaround is asking a super user (usually a company admin) to set both variables: net.parallel.max and net.parallel.threads and these values will be used during the sync. You can also force the number of threads to download data from p4 by using the parameter --p4threads=X.

Pending to implement:

The sync operation only pulls changes from Perforce. It doesn't push changes from Plastic to Perforce.

Labels are currently ignored, not pushed or pulled.

Windows - Gluon: File Plastic Links won't fail when are created with ssl or other supported protocol

When the server is configured with a ssl or other protocol connection the file plastic link included it at the uri but Gluon wasn't able to open it. Now these generated links can be openend correctly.

Also fixed links with child repositories. See the examples of these corrections:

plastic://ssl://192.168.100.25:8085/repos/repo_zero/test/changesets/1/path/icongluonlink.png?ui=gluon

plastic://ssl://192.168.100.25:8085/repos/repo_zero/changesets/1/path/icongluonlink.png?ui=gluon

Windows - Plastic, Gluon: plasticlinks are turned ON!

We implemented a new way to share files: plasticlinks!

Plasticlinks let you share links to files within Plastic repositories, as well as links to branch, changeset, label, and shelveset diffs.

To use it, you just have to click on the plasticlink button to copy the link to your clipboard and share the link with your mate. To open a link you just need to click it or open it in your favorite browser, and the file or diff will be displayed in Plastic.

From Plastic you can share diffs with your colleagues.

We added a button to the top-right corner of the diff window. For shelves, it has been added on the Shelves view

Here are some plasticlinks examples:

plastic://test.cloud/repos/NikkiTest1/branches/main/Mi+rama/MiSuperRama%24%24/diff

1.2 Changesets (single or two elements comparison)

plastic://test.cloud/repos/NikkiTest1/changesets/50/diff

plastic://test.cloud/repos/NikkiTest1/changesets/34..47/diff

1.3 Labels (single or two elements comparison)

plastic://test.cloud/repos/NikkiTest1/labels/My+nre+super+label+%25%25/diff

plastic://test.cloud/repos/NikkiTest1/labels/Reviewed+Dpi+Training+Doc..My+nre+super+label+%25%25/diff

plastic://test.cloud/repos/NikkiTest1/shelvesets/2/diff

From Gluon you can share direct links to files within the repository.

We added a new panel between the details section and the history of the file. This is how it looks!

To share your file just click on the copy button to obtain the link!

If you received a file plastic link, you just need to click on it. Gluon will show you the file and the changeset on the screen. Don't worry if you don't have the file in your workspace, it will be downloaded automatically.

All platforms: fixed duplicated deleted after incoming changes operation.

The incoming changes could leave a duplicated deleted directory. It happened if there were 2 moved files plus a delete of their source parent directory as pending changes. Let's see an example:

Windows - Plastic: fixed exceptions in Code Review when opening certain comments

An exception was thrown when opening a Code Review comment, if that comment required showing a diff, and no diff had been shown yet. We fixed that by correctly initialising the diff view.

An exception was also thrown when opening a Code Review comment for an added or deleted item, if further changes were made on the branch after the creation of the comment. We also fixed that scenario.

All platforms - WebUI: Diff xlink without changes failed.

Diffing a branch or cset with an xlink pointing to the same target changeset in source and destination failed. We fixed it.

Linux - Client and Server: netcore-based server in Ubuntu 20 rejected SSL connections from any plastic client. Fixed.

The netcore-based server installed in Ubuntu 20 just accepts Tls1.2 for SSL connections. To match this requirement, the client now is able to negotiate Tls1.2 protocol when connecting to the server using SSL.

REMARK: If you are using a Plastic SCM client in Linux to connect to a Plastic SCM server (netcore-based) in Ubuntu 20, it is likely you will have to install a recent version of mono and configure the Plastic SCM client to use this recent version instead of the default one. Contact our support team for this matter (support@codicesoftware.com), as there might be combinations that may not work even with newer mono versions, such as ubuntu 18 with mono 6.12.

macOS, Linux - Gluon: Fixed error when canceling the switch branch operation

When selecting "Switch branch" in Gluon on macOS and Linux, and canceling the dialog, an unexpected error occurred. We solved this issue and made some improvements to prevent this from happening again

All platforms - WebAdmin: The configurator didn't eat 'any' string as bind address. Fixed.

If you type "any" in the "WebAdmin" > "Network" > "Bind To" property for a server port, the server won't listen on that port. Fixed.

Windows - Plastic: Fixed performance degradation when using Spell Checker.

Typing text or pasting text into the Pending Changes textbox caused micro-freezes to the Plastic GUI when the Spell Checker option was enabled, due to a WPF issue: https://github.com/dotnet/wpf/issues/3350. We applied a workaround and now it's fixed.

Windows - Plastic: fixed exceptions in Code Review when opening certain comments

An exception was thrown when opening a Code Review comment, if that comment required showing a diff, and no diff had been shown yet. We fixed that by correctly initializing the diff view.

An exception was also thrown when opening a Code Review comment for an added or deleted item if further changes were made on the branch after the creation of the comment. We also fixed that scenario.

All platforms - WebUI: Diff xlink without changes failed.

Diffing a branch or changeset with an xlink pointing to the same target changeset in source and destination failed. We fixed it.

Windows - Gluon: Plastic Links won't fail when the URL points to a plastic server that require ssl.

When the server is configured with ssl, the plastic link for a file contains the "ssl" protocol for accessing the plastic server. But Gluon wasn't able to open it.

From now on, links generated with servers configured with ssl can be opened correctly.

Also fixed links containing submodules repositories. See examples of these corrections:

All platforms: fixed duplicated deleted after incoming changes operation.

The incoming changes could leave a duplicated deleted directory. It happened when you have before running the incoming 2 moved and their source deleted. Let's see an example:

Linux - P4Sync: We released HUGE improvements in Perforce Sync on Linux!

First of all, we ditched the API in favor of a Command Line wrapper. This means Perforce Sync now works on Linux, which was a must for many users out there looking forward to making the switch!

We also took advantage of new Perforce versions to make a multithreaded push and pull. This way, bidirectional file transfer is much faster than before.

If you are a Perforce-using team looking to migrate to Plastic SCM, don't hesitate to contact us. We can help you in every step of the way!

All platforms - WebUI: We added a Comments List section when viewing a Code Review.

By clicking on a comment in the list, it will scroll it into view.

Windows - Plastic: Plastic Links won't fail when are created with ssl or other protocol

When the server is configured with a ssl or other protocol connection the plastic link included it at the uri but wasn't able to open it. Now these generated links can be opened correctly.

Also fixed plastic links with child repositories. See the examples of these corrections:

plastic://ssl://192.168.100.25:8085/repos/repo_zero/test/changesets/1/diff

plastic://ssl://192.168.100.25:8085/repos/repo_zero/changesets/1/diff

macOS - Plastic: fixed unexpected error when selecting a code review comment

We fixed an issue where selecting a code review comment would very occasionally result in an unexpected exception. It happened if the first file selected to display when opening the Code Review did not contain changes, and then you clicked on a comment made on a file with differences.

macOS - Plastic, Gluon, command line: Added network retries for very slow networks.

We found that our operation retry system didn't work on macOS (probably Linux too) with very slow networks using SSL (typically Cloud) because the actual error code being raised didn't match the expected ones. We fixed it.

All platforms - WebUI: We fixed a bug that was causing infinite loading if the session was expired.

All platforms - Update: The multi-thread update uses 6 threads by default now.

Plastic can be super-fast, but historically we were too shy enabling the full power by default. But, smart defaults are key for usability, because nobody wants to dig into config files. So, that's what we are doing now.

Update uses 2 threads to download and write. The setting is controlled by DownloadPoolSize in client.conf and was set to 2 by default. The default will be now 6.

We tested the performance of the update downloading 63,715 files and 7.14 GB and it improves by 37%, from 290s (2 threads) to 183s (6 threads) :)

All - P4Sync: P4 Sync using CLI has improved Submit to P4 speed

We improved the Perforce sync operation when transferring files from Plastic to P4 as it will take advantage of CPU multi threads.

All - P4Sync: P4 Sync using CLI has improved the "Submit to P4" speed

We improved the Perforce sync operation when transferring files from Plastic to P4 making all the Add and Delete operations in bulk.

All platforms - Plastic, Gluon: fixed overflow when calculating remaining update and checkin time

We fixed a numerical overflow in the calculation of the remaining update and checkin time. The worst bit is that this error caused the update operation to terminate. We fixed the overflow, and also improved the robustness of the update and checkin operations to this kind of error.

All platforms - Installer: Trial license is now an Enterprise Edition trial license.

Before this version, new installations of Plastic SCM deployed a Team edition trial license. So, some features were not available, but not anymore.

Windows - Gluon: File plastic links are ready to use!

This is a new feature flag. We implemented a new way to share files. We added a new panel between the details section and the history of the file. This is how it looks!

To share your file just click on the copy button to obtain the link!

If you received a file plastic link, you just need to click on it. Gluon will show you the file and the changeset on the screen. Don't worry if you don't have the file, we will download it for you.

But first, to activate this new feature flag you need to add to your gameui.conf file this entry:

Windows - Gluon: Check existence of a file or directory when creating a new one.

Corrected the behavior when a new file or new directory is created and the item already exists on disk. If exists, a descriptive error text will be shown in the dialog. See below.

Plastic: Windows - Plasticlink for shelvesets is not working

We found labels were not working either and fixed both cases.

Now plasticlinks are correctly working for shelvesets and labels cases.

Windows - Plastic: plasticlink to compare two objects wasn't working correctly.

Plasticlinks were not generated correctly when a "Compare with" diff is launched, both on labels and changesets cases. We also found that labels' name encoding and decoding were wrong too.

Now this is all fixed and "Compare with.." diff are working as expected:

Before: plastic://test.cloud/repos/NikkiTest1/labels/FirstCset..My nre super label %%/diff

Now: plastic://test.cloud/repos/NikkiTest1/labels/FirstCset..My+nre+super+label+%25%25/diff

Windows - Plastic: two changeset plasticlink sorting was wrong.

The src and dst are the wrong way round in the generated changeset links.

E.g., diff changesets 1 and 6, link is

The same error happened when generating label diff. Furthermore, we found wrong sorted information at the label diff window. Source and destination labels are reversed.

This was the result when comparing "new Label" label with "Cset=23" label:

Fixed two label diff window:

All platforms - Server: corrected value of PLASTIC_CHANGESET trigger variable.

In a specific scenario the PLASTIC_CHANGESET variable of the after-checkin trigger could contain the incorrect value.

Specifically, this happened when checking in the results of a "merge to..." operation after creating a shelveset. The PLASTIC_CHANGESET variable would contain the shelveset spec instead of the changeset spec.

This is now corrected.

Linux - Plastic: Added workspace info bar

We added the workspace info bar, already present in macOS, to Linux Plastic.

It is a small panel at the top of the window to show you the branch/changeset/label (and its repository) of the current workspace, the current workspace name and path, and the current user's name.

This is how it looks:

P4 sync - Linux: P4 Sync available in Linux using P4 CLI

The P4 sync operation didn't work in Linux, even if you enabled the P4. We fixed a few minor issues and it's now supported!

All platforms - WebUI: We upgraded JavaScript third party libraries in order to solve security vulnerabilities.

Windows - Plastic: plasticlinks branch name error

Plasticlinks failed to open when users shared links related to branches that included special characters in their names.

This encoding error is solved now.

All platforms - Command line client: fixed exception calling "cm update --forcedetailedprogress" from node.js

The aforementioned command (and any other using the --forcedetailedprogress" flag) now runs successfully when invoked from node.js.

Windows - Plastic: Plastic links are here!

We implemented a way to share diffs by using a link. You just need to click on the new "share link" button, and it will get copied to your clipboard. The links look like this:

You can find this new button at the top right corner of the Diff View. This is how it looks!

The final goal is to be able to share with your teammates not only diffs, but links to any part of the repository.

For now, Plastic links are Windows only, and in preview. To activate them you need to add this entry to your plasticgui.conf file:

You can find the plasticgui.conf configuration file under %LOCALAPPDATA%\plastic4.

Enjoy it and let us know your feedback!

All platforms - P4 sync: More improvements in P4 Sync!

We improved the Perforce sync operation. Now, it's able to:

Set file type of a file using the P4 CLI client.

Submit changelists in a depot using the P4 CLI client.

Windows - Plastic: We edited the message when removing a custom "Open with..." tool

Before, we were showing the same message as when removing a "Preview" tool.

Now, the message shown when you remove an "Open with..." tool is correct:

All platforms - Command line client: We changed 'cm changelist' flags.changelist - (--)

'persistent' / 'notpersistent' flags now contain a '--' prefix.

We fixed an incorrect behaviour. When entering cm clist myclist --persistent it showed a success message but did nothing. Now we are able to edit the --persistent / --notpersistent flag without having to rename or edit the changelist description.

We updated the CLI help texts and included missing information in the Spanish version.

Windows - Wwise plugin: We updated the plugin for the latest SDK!

From version 2019.1.x.y to version 2019.2.x.y of Wwise there was a breaking change in the SDK we use to build our plugin. We updated the plugin to be compatible with the latest version of Wwise.

If you are using version 2019.2.x.y of Wwise, simply replace your current PlasticSCMWwisePlugin.dll with the new one.

Note, if you already configured an older version of the plugin you will need to reconfigure it after you update. This is because of a change in the way the configuration is stored.

We had to add a new field to the configuration dialog where you must enter the Wwise project root path. Note, the Wwise project must be inside a Plastic workspace. Having a separate project path and workspace path allows us to operate more efficiently when your workflow involves having multiple Wwise projects within a single Plastic workspace. (The preferred usage is one project per workspace however).

When configuring the plugin, enter the cm.exe path as before, and now set the project path before clicking "Test connection" to test the connection.

Here is what the updated dialog looks like:

Windows - Plastic: Open Workspace dialog now has its window state saved and restored.

From now size settings from Open Workspace window are saved and restored everytime the window is opened or closed.

All platforms - WebUI: We fixed a bug that prevented the diff view content from scrolling to the first change.

Linux - Plastic: We fixed an issue during server side merges.

Performing a server side merge (or merge to) operation in Plastic Linux resulted in an exception being thrown where certain conflicts were detected. We fixed the issue and now the merge works on every scenario.

All platforms - client REST API: We fixed switch/update operations in cloud workspaces.

We detected that the client REST API couldn't switch or update workspaces that pointed to cloud repos. An error in repository server resolution led to internal server errors. It's all fixed now!

Linux - Plastic: more permission dialogs arrive to Linux!

We have added a permissions dialog to the Linux GUI so that you can edit your object permissions from the GUI, rather than the command line.

Check out the Security Guide to see how you can you permissions to better secure your data.

You can control permissions for repositories, branches, labels and attributes. You can open the permissions dialog from the context menu in the Branch Explorer, Branches, Labels and Attributes view. Enjoy!

Here are some screenshots:

Opening the permissions dialog:

The permissions dialog:

But wait, there's more!

We also added the ability to edit the path permissions for repositories! This way you can see all the existing path permissions for a repository from one place!

This is how it looks:

This is part of our ongoing effort to reach feature parity across all platforms.

All platforms - P4 sync: P4 Sync using CLI can retrieve changeset metadata now!

We improved the Perforce sync operation. Now, it's able to retrieve metadata of a changeset using the P4 CLI client.

Command-line client: The 'fast-import' and 'fast-export' commands now include new options!

The --nodata option lets you execute the commands without importing or exporting the data to verify that they will run correctly later with the data.

The --from option exports from a particular changeset.

Run the following to get more information:

macOS - Plastic: We fixed a bug in which moving files appeared as locally deleted on the pending changes view.

On macOS Catalina, when you moved a file using Plastic, the Pending Changes view wrongly showed it as locally deleted. This happened when you opened the pending changes view before moving the file. Let's see a case:

1º Open pending changes view

2º Open workspace explorer

3º Cut file /dirA/file1

4º Past file at [/code]/dirB[/code]

5º Open pending changes view

Before this fix, the pending changes wrongly showed /dirB/file1 as locally deleted. Now, the pending changes correctly view shows the moved file from /dirA/file1 to /dirB/file1.

This error only affected the macOS Catalina since Plastic version 9.0.16.4488.

All platforms - Command line client: Deleting a branch from outside a workspace now works OK.

To do so, you must use the full branch specification:

Windows - Plastic: Fix conditional changeset format panel's description text.

This text was cut out when it's container's was not wide enough:

Now the description wraps and it is fully visible:

Linux - Plastic: You can now edit path permissions from Linux GUI!

We added the ability to configure path permissions in Linux Plastic, the same way you can already do it on macOS and Windows.

Check the documentation fr more info on using path permissions to secure user access to your codebase!

The path permissions dialog is launched by selecting "Path permissions" on a file or directory in the Workspace Explorer view.

You can then set access permissions on this path for users or groups.

You can set permissions for all branches, individual branches, or groups of branches.

All platforms - Command-line client: We improved 'cm acl' documentation!

Now you can read all about the options you can use with secured paths.

All platforms - Server: We added new setting for LDAP connections - override for groups filter

We have added a new setting to server.conf that allows you to override the filter used when querying the LDAP server for the list of groups. This will enable server administrators to modify the filter to be more efficient for their specific LDAP configurations.

WARNING! This setting should be considered "expert only", and should only be modified by server administrators familiar with the details of their LDAP server configuration. Incorrectly configuring this setting will lead to unexpected behaviour.

The new setting is "GroupFilterOverride" and must be specified in the "LdapSettings" section of the server.conf.

Optionally, you can include the string "{filter}" in the filter. This will be replaced by the value of the filter option of the "cm listusers" command, if specified.

For example, for the command 'cm listusers --onlygroups --filter=admin', the filter override will be modified as follows:

If no filter is specified, "*" is used:

Windows - Plastic, Gluon: We improved the message we show you when removing a Diff tool or a Merge tool configuration from the Preferences window.

Before it was "Deleting the tool specification. Continue?". And now is "Do you want to delete this diff tool configuration?".

All platforms - P4 sync: P4 Sync using CLI can retrieve file metadata now!

We improved the Perforce sync operation. Now, it's able to retrieve metadata of for a file using the P4 CLI client.

All platforms - Gluon: Newly added items now have the correct size.

When adding a new item to the source control, the size shown in the workspace view was always 0 bytes, as shown in the picture:

We solved the issue, and now you can see the real size of the file or directory before it is checkedin:

All platforms - WebUI: The diff view content/diff editors weren't fully displayed. Their bottom ends were abruptly cut. We noticed this because the horizontal scrollbars never appear and when moving down using the keyboard arrows there was an offset between the cursor disappearing below and the editor starting to scroll.

Now it's fixed, and the horizontal scrollbars are visible:

Windows - Plastic: We fixed a bug that prevented Plastic from starting with custom scaling.

When setting up a custom scaling in Windows, the Plastic GUI failed to start. Now it's fixed.

All platforms - Plastic, Gluon: Christmas GUI-help owls!

From December 1st to January 6th our owls will celebrate Christmas too.

See how they dressed up:

All platforms - Plastic, Gluon (only Windows): We improved the Incoming Changes sub-branches warning message!

Incoming Changes does not currently support sub-branches and cannot handle the merge. We improved the error message you get in this scenario to specify the changeset you need to manually merge from to resolve the situation.

Windows - GUI: now code review comment's text box has spell checking!

We included also spell check errors' suggestions to the spell check context menu.

Linux - Plastic, Gluon: Now you can edit repository server permissions from the GUI!

We are working on making permissions editable from the GUI for our GNU/Linux users. This is part of our goal to have feature parity across all platforms.

The first set of permissions made available from the GUI are the repository server permissions!

You can access the new dialog from the repositories view:

Add Users or Groups for which you want to edit the permissions:

Set permissions for each User or Group:

Check out the Security Guide for more info on using permissions:

macOS, Linux - Plastic, Gluon: We removed the "apply" button from permissions dialog.

Dialogs on macOS and Linux don't usually have an Apply button like on Windows. We removed the button from the macOS and Linux versions of the tools, to be consistent with other dialogs on those platforms.

Here are some screenshots. Where's the Apply button? Gone!

All platforms - Command Line Client: We deprecated the 'cm shelve' command.

Now, if you get help for cm shelve, you will see a notethat indicates that the command is deprecated. Please use cm shelveset instead.

p4 sync - Windows: We enhanced Perforce sync (p4 sync) to take advance of the Command Line:

The sync process can now use command line capabilities to:

Get the content of a file.

Get information about streams.

Check user privileges.

Get the history of a file.

All platforms - Server (.NET Core flavor): We upgraded the LDAP library we use for the .NET Core version of the server.

By upgrading the library, we fixed a specific issue we saw in the setting of timeouts for LDAP queries. Previously, LDAP requests would fail when setting a non-zero timeout value of less than 10 seconds in the WebAdmin. The new library fixes this issue!

All platforms - Plastic: Now the "Cancel" button is enabled for big checkin operations.

When performing a checkin of a big amount of files, the "Cancel" button at the bottom of the panel sometimes appeared disabled, making it impossible to cancel the check-in operation once started. We fixed this, and now you can cancel the operation at any time during the upload process.

All platforms - Plastic, Gluon: Enterprise Edition configuration was unable to connect to Cloud.

This is a little bit of a corner case but here it goes:

You install an Enterprise Edition client.

Run it for the first time on a clean system.

And try to connect to Cloud.

It failed and now it works. It was a small thing in Cloud region resolution.

All platforms - Plastic, Gluon: Now .json files are correctly detected as text type files!

Windows - Plastic: We fixed colors here and there for the Old School theme!

For instance, check out how in the Update Workspace dialog the text "don't ask me again" is now white!

Windows - Plastic: We fixed an unexpected error when the changeset is missing at diff window!

Before this fix, you would get an uncontrolled error message if somebody deleted a changeset whilst you were browsing its differences. Now you get a nice explanation about what happened!

All platforms - Server: LDAP user filter override is now applied correctly for LDAP type servers!

To accommodate varying LDAP configurations we have the ability to specify an override for the user filter Plastic uses in LDAP searches. We were not applying this override for a particular query when the Server type is set to "LDAP" (as opposed to "Active Directory"). We fixed this so that the filter is applied to all relevant queries!

To set the override, add or modify the element <MemberNameFilterOverride> within the <LdapSettings> tag in server.conf.

Now {user} will be replaced by the username when a query is made.

Chek the documentation for further information.

All platforms - Plastic, Gluon: download speed and estimated remaining time

Rumor has it that Plastic downloads your data faster than any other SCM tool. Is that true? We think so. And now you can see for yourself how blazingly fast your data is being downloaded.

We've enhanced the progress status shown during workspace updates with the current download speed, and the estimated time until update completes. Is there time to grab a biscuit from the kitchen while you switch branches? Well, now you'll know!

Take a look at these screenshots:

All Platforms - Plastic, Gluon: speed and remaining time estimates for checkins!

We added the upload speed and estimated remaining time to the checkin progress bar. No more guessing when your checkin will complete. Let us guess instead :)

Here's what it looks like:

Windows - Shell Extension: Main menu will now show the Plastic SCM icon

Windows - Shell Extension: "Add directory tree to source control" context menu option will be always enabled when a folder is selected. This behavior will now match what Plastic application does.

macOS - Gluon: notification for incorrect workspace mode!

Gluon uses workspaces in "partial" mode, whereas Plastic uses workspaces in "full" mode. You can easily switch the workspace to the mode you want by updating the workspace in the application you want to use.

However, it wasn't always obvious if your workspace was in the correct mode, which could be confusing if you switch between Plastic and Gluon a lot in the same workspace.

To help, we have added a notification that pops up if the workspace is in the wrong mode. From the notification you can update the workspace and continue working.

Here is how it looks:

Linux - Plastic, Gluon: workspace mode alerts!

We added a notification to Plastic and Gluon on linux that let's you know when your workspace is in the wrong mode, and let's you easily fix the issue and continue working.

What are workspace modes? Plastic workspaces are "full" workspaces. Gluon workspaces are "partial" workspaces. If you want to work on a "full" workspace in Gluon, or a "partial" workspace in Plastic, you need to Update your workspace in the tool of choice to change the workspace mode.

To make this clearer, we added the notification with a handle link to let you update and continue working.

Here are some screenshots:

Command-line client: We added a note in the cm checkin command to clarify that you can checkin private items.

We included double dash support for the following commands' options:

*'''cm acl''' now supports:

*'''cm setowner''' now supports:

*'''cm changerevisiontype''' now supports:

Windows - Visual Studio Package: Removed obsolete option from the Plastic SCM menu.

The Visual Studio package still displayed an obsolete "Change workspace selector" option. Now it has been removed.

macOS - Plastic: partial workspace notification bar!

Plastic and Gluon use different kinds of workspace: a full workspace and a partial workspace, respectively.

For Windows, we've recently introduced a new feature that allows you to easily switch between them when you open a partial workspace from Plastic. A warning notification appears at the top of the window letting you change your workspace to the correct mode.

Now, this feature is also available for Plastic on macOS! Here is how it looks:

Windows - Gluon: full workspace warning!

Plastic and Gluon use a different kind of workspace. They are incompatible, but you can easily switch from one to the other by updating in the relevant tool.

Now we made this even more transparent. If you open a Plastic workspace in Gluon, you now get a warning with the option to update the workspace and continue working.

All platforms - Plastic, Gluon: improved update progress!

We improved the progress for the update operation to show correctly the current file when some files are downloaded in parallel.

Command-line client: We fixed some misspelled words. Now, you won't find (we hope so!) anything like "directoy".

All platforms - Command line client: We fixed a bug in the cm help command.

Before, cm help with a non-existent command failed with an uncontrolled error message. Now it is fixed.

macOS - Plastic: path permissions now editable in the GUI!

Continuing our work to bring feature parity across all platforms, we have added the ability to configure path permissions in macOS Plastic.

See here for more info on using path permissions to secure user access to your codebase: https://www.plasticscm.com/documentation/security/plastic-scm-version-control-security-guide#Preventusersfrommodifyingspecificitems

The path permissions dialog is launched by selecting "Path permissions" on a file or directory in the Workspace Explorer view.

You can then set access permissions on this path for users or groups.

Permissions can be set for all branches, individual branches, or groups of branches.

macOS - Plastic: Manage path permissions for a repository from the GUI

We added a new menu option to the repositories view that lets you manage all the path permissions for a repository directly from one place.

You can add, edit, and remove secured paths, as well as specific branches for each one.

All platforms - Server: Added support for allow list to restrict connections to certain IPs.

This new feature works both for on-premises servers (only .net core build) and Plastic Cloud.

In Plastic Cloud a web interface will soon be available to configure the allow list.

Create a networkallowlist.conf file as follows:

Then as user1, from localhost, run the following:

You'll see the following log in the server

Which means the networkallowlist was loaded and the command succeeds.

Now modify the networkallowlist.conf to contain the following lines:

Wait at least 60 seconds for the server to notice the configuration change (at this point we only check for changes every minute), and rerun the cm repo list command.

You'll find this in the server log:

Which means the file was reloaded. And then:

And your command will fail as follows:

For security reasons, no extra info is sent to the client, the connection is simply closed at the server side.

== What rules networkallowlist.conf currently supports? ==

The following is a valid config file.

It can't restrict groups, just users.

It can't use patterns to specify users.

IPs are specified as strings, no CIDR patterns supported yet.

Negation rules are supported yet.

Command-line help: We are making a complete review of the command-line help.

This review consists of fixing formats and editing texts and descriptions. For example, before this task, the usage of the 'cm lock list' was:

Windows - Plastic: partial workspace notification bar!

Plastic and Gluon use different kinds of workspace: a full workspace and a partial workspace, respectively.

It can be a bit confusing for users if they use Plastic and Gluon on the same workspace, because you have to remember to update the workspace in each tool to switch between workspace types.

We've made that a whole lot easier now. If you open a partial workspace in Plastic you now get a notification message, from which you can easily update the workspace and continue working.

Jenkins plugin: We added multiple cleanup options for build checkout

Thanks to the contributions of Krzysztof Knapik from Housemarque, we just released a new version of our Jenkins plugin that enables you to select the cleanup action to perform before your build checkout. There are four options to choose from: minimal (just undo), standard (undo and remove privates), full (undo, remove privates and remove ignored) and delete (removes the whole workspace directory).

Windows - Plastic: Code review list items colored by review status!

We fixed the colors used in the code review tab's list. Now there are three colors accordingly to the three different code review statuses.

See renewed rows in action!

macOS - Plastic: Repository server permissions now configurable in the GUI!

We are working on implementing all object permission configuration dialogs on mac. Currently mac users have to resort to the cli to configure permissions. Not anymore! It will all be available in a nice graphical interface.

In this release we have added support for the Repository server permissions.

Here is an example screenshot:

See here for a guide to configuring permissions in Plastic: https://www.plasticscm.com/documentation/security/plastic-scm-version-control-security-guide

During the course of the next few release we expect to add support for configuring permissions an all object types in the system.

macOS - Plastic: more permissions dialogs on mac!

We recently added a dialog for editing repository server permissions in the application. As promised in that release note, we've been busy adding the remaining permission control dialogs to Plastic on the mac. Mac users can now edit permissions for all object types in the GUI, rather than use the cli.

Check out the Security Guide to see how you can you permissions to better secure your data https://www.plasticscm.com/documentation/security/plastic-scm-version-control-security-guide

You can control permissions for repositories, branches, labels and attributes. You can open the permissions dialog from the context menu in the Branch Explorer, Branches, Labels and Attributes view. Enjoy!

Spoiler alert! Here are some screenshots:

Opening the permissions dialog:

The permissions dialog:

All platforms - Plastic: notification when working changeset is deleted

If someone else deletes the changeset you are currently working on, you will get a notification with a button allowing you to update your workspace to the new head.

It looks something like this:

Windows, macOS - FMOD plugin: Our FMOD plugin got outdated and didn't work with recent versions of FMOD. It's fixed now! You can drop the plugin scripts in the FMOD scripts directory and control your project sources with Plastic SCM from inside FMOD. Contact us if you want to try the plugin out!

macOS - Plastic: Select user and groups now available!

We included group management in the dialog to select a user or group.

For now, you can use this dialog to change the reviewer of a code review. But soon, it will be also used from the permissions dialogs. We are working on it!

All platforms - Plastic, Gluon: We added early detection of the system language!

Now we detect your system's language the first time you run Plastic, and use it to show the onboarding panels.

Before this release, the language check was made after the configuration, and you had to restart the application to see the changes. Now you can configure Plastic SCM and start using it in the same language as your machine.

For now, Plastic SCM supports Spanish and English, but we are working on adding four new languages. Stay tuned for more!

Linux - Plastic: Added permission check before attempting a merge!

Before attempting a merge we check that you have permission to modify the file. This means we can provide an error message before running the merge process, rather than allowing you to resolve conflicts only to find you can't save the result.

Linux - Plastic: We modified the Incoming Changes notification bar colors!

The now match the colours in Windows, as you can see in the following screenshots:

Windows - Plastic: We fixed GUI performance issues because of the auto-refresh feature.

When the Pending Changes view was auto-refreshed, sometimes it performed some heavy calculations in the UI thread. it caused the app to be unresponsive for a few seconds. Now it's fixed!

Linux, Mac - Plastic: Avoid repeated error message when calculating merge.

If a problem is discovered while calculating the merge for incoming changes we display the issue. Unfortunately, dismissing the error message would refresh the view, cause the merge to be recalculated, and the error to displayed again. An endless loop. We fixed that.

Windows - Shell Extension: We fixed context menu item separator height!

The context menu items from our PlasticSCM Shell Extension displayed the separators using a wrong height value, making it uncomfortable to use.

We fixed it so those context menus now use a correct size for separators.

Linux - Plastic: We added the Incoming Changes Plastic SCM for Linux!

We are happy to announce that we added Incoming Changes functionality to Plastic SCM GUI on Linux.

What is the Incoming Changes?

A typical workflow can involve multiple developers checking in changes on the same branch. When someone else checks in a change on the branch you are working on, it means your local workspace is out of date. To get your workspace up to date, you need to download the lastet changesets from the server. We call these new changesets "Incoming Changes".

Incoming Changes in Plastic SCM makes the process of updating your workspace with other people's changes as easy and painless as possible.

The first addition is a notification bar which alerts you when there are new changesets on the server. This appears at the top of the screen and lets you know how many new changesets there are, and also if they conflict with your local changes.

Here is what the notification bar looks like:

Or, if there are conflicts:

Of course, you can ignore the notification until you are ready to update your workspace. At that point you can click on the button in the notification and launch the Incoming Changes view.

The Incoming Changes view shows all the pending changes on the server and lets you resolve any conflicts between the incoming changes and your local changes.

If there are no conflicts, simple updating the workspace will get you up to date. Otherwise the Incoming Changes view allows you to resolve the conflicts and get your workspace up to date. You are then free to check in your changes.

Here is an an example of what the Incoming Changes view looks like:

The client also launches the Incoming Changes view if you try to check in when there are other changes on the server. This is so you can resolve any conflicts before the checkin.

Linux - Plastic: We greatly improved the UX of the Merge View!

We made some visual changes in the four merge view tabs, to match the design of Windows and macOS applications. All texts, icons, and behaviors are now the same in the three platforms.

This is a detailed description of changes done on different merge view tabs:

== "Directory conflicts" tab ==

Now the first directory conflict is automatically selected.

The "unsolved" icon has been removed.

There is a red counter telling the user the number of pending directory conflicts to resolve vs total directory conflicts.

The "Resolve directory conflict" button for the selected conflict is moved to the top of the pane, to make it more visible

When resolving all the directory conflicts, the merge view jumps to the "file conflicts" tab (just if there are pending file conflicts to resolve).

The counter turns green when no pending directory conflicts left.

== "File conflicts" tab ==

There is a red counter telling the user the number of pending file conflicts to resolve vs total file conflicts.

The counter turns green when no pending file conflicts left.

The "unsolved" icon has been removed.

== "Automatic merges" tab ==

Apart from text changes and icon removal, the categories in this tab (Deletes to apply, Moves to apply, etc) will be collapsed if the number of items is >= 10.

== Discarded conflicts" tab ==

Just text changes and icon removal.

All platforms - Command line client: We updated the help of the 'merge' command!

It now includes documentation of the following options:

--resolveconflict - Used to solve a particular directory conflict. This option must be used in conjunction with some other parameters to indicate the index of the conflict to solve (--conflict), the type of conflict resolution (--resolutionoption) and the files (--mergeresultfile and --solvedconflictsfile) to output the information of the merge result and the conflicts solved;

--nointeractiveresolution - To avoid prompting the user for manual conflict;

--machinereadable - Used in conjunction with some other parameters, outputs the result in an easy-to-parse format.

These options are mainly used by plugins or integrations. We think they can be useful also for those users that want to extend the Plastic functionality.

All platforms - Plastic, Gluon: More intuitive incoming changes notification

We modified the text for the "incoming changes" notification button. Now, instead of "Update" or "Resolve", the button says "View", making clear that pressing it will not change anything in your workspace.

This button appears at the top right corner of Plastic and Gluon when the current workspace can be updated with new changes.

When you click the notification button, Plastic shows a window from which you can update your workspace or resolve any possible conflicts.

Windows - P4Sync: We applied sharding to distribution of pulled files!

As storing a huge amount of files in the same folder affects FileSystem Performance, we have applied folder sharding so the client now distributes the downloaded files in subfolders, boosting the FileSystem performance.

Windows - P4Sync: The client now removes any generated temp file after P4 sync!

The client did not delete Temp files after pulling files from P4. We've changed it so now the client removes any temp files used during the synchronization.

All platforms - Gluon: Gluon now automatically fills your server name and credentials!

If you have a local server running, Plastic SCM can automatically detect it during the setup process, and fill the server name and credentials for you. Now we added the same functionality to Gluon.

macOS - Plastic: Now you can navigate changes from Semantic diff overview!

On the left hand side of the semantic diff there is an overview panel, showing all the differences. You can now navigate the code by clicking items in the overview.

Windows - Plastic: We eliminated GUI freeze during branch query!

We fixed an issue where the GUI would freeze for a few seconds while running certain branch queries. The problem was that we were generating huge quantities of superfluous log entries. It could happen when the server in the query was not the server of the current workspace. We removed the excess logging and these queries now run without freezing the GUI.

Windows - Gluon: We enabled long path support for Gluon!

Now you can create and use Gluon workspaces in paths that exceed the traditional limit of 260 characters. Remember that this is only available for Windows 10 users starting on Anniversary Update (version 1607, a.k.a. Redstone 1), and that you must have long path support enabled at the OS level.

You can check your Windows 10 version by running winver on a terminal, and you can enable long path support by following these instructions.

All platforms - GitSync: We added retries when the GitHub LFS http requests fail due to transient errors.

Windows, macOS - Cloud Edition: Now we include clconfigureclient command-line utility in Cloud Edition!

Maybe you are a command-line hacker, maybe you are writing your own tooling. clconfigureclient is the command-line utility that lets you configure your Plastic SCM client. We hope you find this useful!

All platforms - Plastic: We fixed the number of merges in the Cloud Activity report.

The number of merges in activity reports was incorrect. You could find this number in the Cloud Edition Activity page or in the weekly activity report we email you if you've got an active Cloud Edition subscription.

We included all incoming changes calculations in those reports. However, those are automatic checks that the GUI performs in the background. It didn't make sense to count them as part of the merge operations you perform.

You should notice a decrease in the amount of reported merges you get once you install this version!

macOS, Linux - Plastic: We added custom applications to the file "Open" context menu!

Now you can customise the "Open" context menu for files in the Workspace Explorer view and the Pending changes view.

In the future we will add a preference dialog to configure the menu. If you can't wait, you can use this feature right now by adding a new file "openwith.conf" to your config directory.

Each line of the config file specifies:

The text to appear in the menu

An optional keyboard shortcut

The path to the executable to launch

Arguments to pass to the executable

The format is slightly different on each platform. Here are some examples of a typical line. For macOS you simply specify the key, "t" in this case", to get the Command+T shortcut:

For linux you specify the control key and the letter key:

Here you can see the menu in action!

All platforms - Jenkins plugin: We fixed some XML serialization issues.

The plugin sometimes failed to execute commands that output large amounts of XML information. Those commands are 'cm log' (used to build the changes list for a build) and 'cm find' (used to poll the VCS).

If you have a large amount of changes in a build, the XML output can cause issues in the Java process buffers. We changed the code to make the Plastic SCM commands output their XML directly to a file instead of to stdout. That way, the buffers don't get overloaded and the parser works seamlessly.

All platforms - Command line client: We fixed unsetting of attribute values from paths outside the workspace.

You can set an attribute value like this...:

...even if your current directory is outside the workspace. The fully specified attribute gives us all the info we need.

Sadly, the equivalent cm attribute unset was broken. We have fixed it!

Windows - Plastic: We added missing info in the Path Permissions dialog.

The Path Permissions dialog for a given path only displayed the permissions for all branches. It didn't show the permissions defined for other groups of branches.

Users could still check all secured paths from the path permissions dialog by launching it from the repositories view.

Now both dialogs show the correct info!

All platforms - Jenkins Plugin: We removed unexpected updates when your plan workspace is switched to a changeset.

Following changes in the behavior of CLI command 'update', it unexpectedly changed the current changeset of workspaces switched to a changeset. The 'update' command now switches to the latest changeset in the branch of the current changeset. The Jenkins plugin will avoid this update if the workspace is switched to a changeset or a label.

Windows - Plastic: We fixed item focus when adding new files in the Workspace Explorer.

We now expand the selected directory and set focus on the new file when it is added in the Workspace Explorer.

Windows - Plastic: Now you can use custom applications to open files in Differences and Code review!

In Plastic Preferences you configure custom "Open with..." options which then appear in the context menu for items in the Workspace explorer. We have now added the same options to the context menu in the diff and the Code review windows.

All platforms - Plastic: We improved the usability of the onboarding panel!

This affects the onboarding panel in Cloud Edition. When creating a workspace to work distributed, you had to either type the remote repository manually or browse it in a separate window. Now you can also choose from a list! The client fills this list with the available repositories from you organization(s).

Take a look at the before and the after!

Windows - Plastic, Gluon: The 'update' triggers now run when updating the workspace from the Incoming changes view!

Now, when you click "Update workspace" in the Incoming changes view, any before-update and after-update triggers will be run, just as if you did "Update workspace" from the Workspace explorer view.

All platforms - Command line client: There's a new flag to force detailed progress when redirecting output!

When you run cm update, switch or setselector, you get an animated progress bar in the console while the client updates your workspace.

Normally, if you redirected command output, we don't show the progress bar. But now you can force output of the progress bar by specifying --forcedetailedoutput.

All platforms - GitSync: We fixed a 'git reference 0000..00' error

GitSync could fail with this error: 'The revision for the git reference 0000000000000000000000000000000000000000 cannot be found'. It could happen when:

The repository contains 2 folders, dirA and dirB, which have the same contents.

dirA is added/copied during a merge operation.

This error depends on how Git handles the references to send the commit, during the fetch operation. So, even in the described case, the error does not always happen.

macOS - Plastic, Gluon: We improved the About Dialog aesthetic.

It now has a new look and matches the one in GTK and Windows! Don't forget to check the release songs :)

Windows - Plastic: We made a minor aesthetic change.

We changed the background color of the information notification strip that appears (when needed) above the views tabs.

All platforms - Plastic: We fixed the sync view to take into account the view permission for the branches.

A customer reported that the sync view shows all branches with pending changes to sync although the user didn't have permission to see those branches.

We fixed the sync view to show only the correct branches taking into account their permissions.

Windows - Plastic Drive: We fixed an issue with the setup that affected Plastic Drive!

We were missing a library in the install! This caused that, when clicking "Mount this changeset in Plastic Drive", nothing happened.

Remember that you will need Dokan 1.4 for Plastic Drive to work!

Windows - Gluon: We improved the integration with the Windows Desktop UI.

Snapping Gluon to the monitor edges now activates the Windows Aero Snapping feature. Pressing Windows + Arrow keys enables the Aero Snapping feature / move the window to another monitor.

Linux - Plastic: 'Sync with Git' available!

We added the 'Sync with Git' option under the Push/Pull context menu in the branch explorer and branches views.

From now on, you won't have to use the command line to sync your git repositories in Linux.

Linux - Plastic, Gluon: We improved the about dialog in Linux!

The GTK "About" dialog on Plastic SCM and Gluon has a new look. Now it matches Windows style!

Windows - Visual Studio Integration: Sometimes Visual Studio was unable to load merge tools from PATH.

In some scenarios, the Visual Studio package was unable to resolve merge conflicts, because it was unable to find a suitable merge tool in the PATH environment variable. Now we include the merge tool executables in the package binaries.

Linux - Plastic: We fixed a display issue in the Sync repositories view!

When you include a branch (that you previously excluded) the view updates correctly. Previously the branch would not be shown in the view.

All platforms - Plastic: We fixed the "WebAdmin and configure locks" link in help system!

Corrected the "WebAdmin and configure locks" link in the help system for Cloud Edition.

All platforms - Plastic: Some Code Review comments were not visible.

We recently updated the Code Review system. In some Plastic SCM configurations, the Code Review comments created with the old system were not visible with the new one. Now it's fixed.

All platforms - Plastic, Gluon: We improved ignore.conf for Unity workspaces!

We fine-tuned the way we detect when client should create the ignore.conf in workspaces that contains Unity projects.

Now, the Plastic SCM client automatically generates the ignore.conf file after updating an empty workspace if it contains a Unity project in order to correctly set up the files the should be ignored.

macOS - Plastic: 'Sync with Git' is now available!

We added the 'Sync with Git' option under the Push/Pull context menu in the branch explorer and branches views.

From now on, you won't have to use the command line to sync your git repositories in macOS.

macOS - Installers: We fixed an issue with package notarization!

A few versions ago, we bumped the version of Xamarin.Mac. This included a new native assembly that was not notarized. The unnotarized assembly caused the whole package to fail the notarization process, thus showing a security warning for those of you who use macOS. This is now fixed!

All platforms - Issue tracker extensions: We fixed the version compatibility issues to develop custom issue tracker extensions.

Some customers reported that the version of our 'issuetrackerinterface' library changes every new release. This means that users of custom issue tracker extensions for Plastic SCM need to re-compile said extensions every time they upgrade their Plastic SCM clients.

We fixed our build process so it always sets version 5.4.16.0 to the issuetrackerinterface.dll assembly.

All platforms - Server: added setting to allow disabling StartTls for LDAP connections

When connecting to an LDAP server, Plastic automatically attempts to secure the connection using StartTls.

However, this attempt can run for a long time, and block other requests to the same server. So, if your LDAP server does not support StartTls, or you experience blocked LDAP connections, you can now disable StartTls.

You can do this by using setting UseStartTLS in the server.conf file, like this:

<ServerConfigData ...>

All platforms - Plastic, Gluon: Launch GUI diffs using program arguments.

Plastic SCM for windows already was able to launch the diffs for a branch/changeset/a pair of changesets using the command line arguments. Now we extended this functionality for all the GUIs (Plastic and Gluon) in all platforms (win/gtk/macOS). Examples (windows platform).

Show changeset diffs:

Show diffs between two changesets:

All platforms - Plastic: Plastic SCM now switches to the parent branch when you delete the working branch.

Consider the following scenario. You create a new branch and switch your workspace to it. However, you decide it wasn't what you wanted and decide to delete the branch.

When you proceed, the Plastic SCM selector (the internal workspace configuration) points to a branch that no longer exists. This caused problems refreshing some views. But it's fixed now! Plastic will automatically switch your workspace to the parent changeset of the deleted branch.

Now, when Plastic SCM detects that the user deleted the working branch, it automatically switches to the branch's base changeset.

Windows, macOS - git sync: Plastic SCM now supports sync with GitHub LFS! You can run the sync operation and it'll automatically pull/push your large files from/to the storage if your git repository is configured to use LFS.

If you'd like to skip LFS revision contents, just add the new --skiplfs parameter. That will synchronize your git repo with Plastic leaving out any revision data stored in LFS.

This feature isn't currently available on Linux. The mono version we ship (4.6.2) doesn't support TLSv1.2 and the LFS endpoints are TLSv1.2-only. We're working in a solution for this.

All platforms - Plastic, Gluon: More descriptive text when creating a new repository

When creating a new repository in Plastic SCM and Gluon, now there is a hint showing the possible formats.

Windows - Plastic: Usability improved in the diff tool creation dialog

When adding a new diff tool or merge tool, if the option to match files with a specified pattern is not selected, the text box is disabled.

All platforms - Plastic Cloud Edition: Improve user experience during the onboarding!

In the centralized mode, if the user didn't select any repository, the workspace was created against the default@local server, what it wasn't correct. Now, this field cannot be empty. The user has to select or create a repository.

All platforms - Gluon, Plastic, Unity Plugin: Changed the way we add rules to the ignore.conf file.

Recently, in version 9.0.16.4473 we released a feature that added common ignore patterns to the ignore.conf file, when we detect a Unity project in the workspace.

Some users reported feedback about this. When the ignore rules don't fit the project features, this automatic behavior can be harmful.

So we changed the behavior just to create the ignore rules ONLY when there is no ignore configuration for that workspace.

In other words, we don't change the ignore configuration if:

We find a ignore.conf file in the workspace.

That workspace has ignored rules in the plastic-global-config.

Windows - Plastic: The Branch Explorer view was not displayed when Plastic loaded without internet connection.

We fixed the following scenario:

Open Plastic SCM and show the Branch Explorer.

Disconnect from the internet.

Open Plastic SCM again.

The Branch Explorer view was not displayed. Even connecting again to the internet, and trying to show the view again, it failed.

Windows - Plastic Cloud Edition: Users couldn't create a workspace in the centralized mode.

We broke the workspace creation during the onboarding in the centralized mode in the last release.

Although there was a repository selected in the dialog, an error message appeared preventing the user to continue 'Repository name must not be empty'.

macOS - Plastic Cloud Edition: Use your Unity ID to sign up!

From now on, you can sign up using your Unity ID and password.

Linux - Plastic Cloud Edition: Use your Unity ID to sign up!

From now on, you can sign up using your Unity ID and password.

All platforms - Plastic Cloud Edition: Improve user experience during the onboarding!

In the centralized mode, when the user just created the organization, there was an error message in the panel that said "No repositories found. Check that your Plastic SCM server is running and that there are repositories on it". We removed this message because it can confuse users. The user just has to create a repo to start working, everything is well configured!

Windows - Plastic: Just an aesthetic GUI improvement.

Remove legacy icons from some user dialogs to match the new look of Plastic.

All platforms - Plastic Cloud Edition: Protect corner scenario during the onboarding!

The logging process failed if the user didn't belong to any organization or didn't have the rights to create a new one.

This is not a normal scenario but it could happen if you belong to an organization that was deleted.

Windows - Gluon: The server entry in the repository browser now includes a list!

We took the previous text-only control we had in the repository browser and replaced it with a drop down list that allows you to enter text as well. This will help Cloud Edition users discover their cloud repositories. It's also useful when you have multiple profiles configured and you don't remember the exact server address.

The Plastic SCM Team: We joined the Unity family!

What does this mean for you? Just what you could expect - you will be using the best VCS there is, and it will keep getting better. Just at a faster pace! So let's get back to our usual business... and keep reading to see what's new on this release!

Windows - Plastic Cloud Edition: Now you can use your Unity ID to sign up!

From now on, you can sign up using your Unity ID and password.

All platforms - Plastic, Gluon: The GUIs now auto-generate a ignore.conf file prepared for Unity projects!

Both Plastic SCM and Gluon can auto-detect Unity projects inside your workspace, and auto-generate a ignore.conf accordingly.

All platforms - Server: You will no longer be able of deleting or moving changesets in repositories in sync with Git.

We do not recommend you to rewrite the repository history when you synchronize your Plastic SCM repositories with Git. This could lead to unexpected results! To prevent that, the server now forbids you from deleting or moving changesets in a repository once you sync it with Git.

All platforms - Proxy server: The Proxy server now works with Cloud Edition!

The proxy server now is able of downloading data from the new cloud2. Good news for teams working behind a slow connection!

All platforms - Plastic (Cloud Edition): We improved the Welcome wizard!

We simplified our Plastic SCM Cloud Edition Welcome wizard since we saw that our users got confused with the existent options.

Now there are only two paths to start working with Plastic Cloud: centralized or distributed, easier to understand!

Windows - Gluon: We fixed the checkbox drawings.

The application draw the checkbox glyphs misalinged in some DPI resolutions. But now it is fixed!

Issue tracker extensions - Polarion: We fixed a Null Reference Exception when showing tasks.

Sometimes the data returned from a Polarion query contains invalid data. This would cause us to throw a null reference exception when sorting the task list. We made our code more robust to handle this.

Note: one scenario in which the invalid data scenario occurs is when a user has a task assigned to them but later has all of their Project Roles for the project removed.

All platforms - Command line client: We fixed a duplicated key error on Plastic after fast-import.

After running a fast-import from Git, Plastic could run into an "An item with the same key has already been added" error. This happened when editing on Git (doing a rebase) a changeset alrady exported from Plastic to Git, and thenn importing it again to Plastic.

All platforms - GitSync: We fixed another error while importing Git commits.

The error message was exactly the same as the previous one ("An item with the same key has already been imported"). The scenario where it failed was so complex (it included an evil combination of changes with moves, merges & reused revisions) that you don't want such a long description :)

All platforms - Plastic, Command line client: Revert now supports deleted source changesets.

The revert operation copied the source changeset revisions. The problem is that if the source changeset was deleted, Plastic couldn't load the resulting changeset of the revert anymore.

Now the revert operation creates new revisions, so the source changeset can be deleted without any problem.

Windows - Plastic: We fixed the size of the search bar in the Workspace Explorer view.

Now the search bar takes into account the display resolution. Under some high resolutions (4K) the text box was cut off and the close button did not appear (although you could close the search using the ESC key).

All platforms - Plastic, Gluon: We fixed an unexpected error while detecting refreshing views in Cloud Editon.

Some customers reported an "unexpected error" when refreshing certain views. We were able to reproduce it in one computer refreshing the Branch Explorer.

It was a concurrency problem in setting a local member in a class. That code is now protected, an the problem gone!

macOS - Installers: Our installers are now notarized!

Nothing else changed, but now you won't get a security warning on macOS Catalina and higher. Nice.

Windows - Plastic: We updated example screenshots in the theme selector dialog!

Check out the Preferences > Theme dialog to see how the new Plastic themes look now.

All platforms - Plastic, Gluon: Now, a change on an ignored path doesn't force an auto-refresh.

Now the auto-refresh option doesn't refresh the Pending Changes when the change in the workspace was on an ignored path. You can modify, delete, or add, an ignored item and Plastic will not refresh the pending changes view.

All platforms - WebAdmin: we updated the references to 'admin password' configuration tool!

The old way of setting the web admin password was to run the adminconsolepwd utility. This tool was deprecated a few releases back, and you should now use plasticd adminpwd.

We updated some help text in Web Admin to reference the correct tool.

All platforms - GitSync: The 'cm sync' failed if the user who launched the operation hadn't been used before.

The 'cm sync' command failed with the following error:

This happened because the current Plastic SCM user was wrongly added as inactive, so the next call to the server was rejected since it detected the user as inactive.

This only happened if the Plastic SCM user hadn't been used before in the destination server of the sync operation.

Windows - Plastic, Gluon: The diff tool configuration for Excel files now works.

Diffing an Excel file launches the SpreadsheetCompare tool by default, if it is present on the client machine.

If you configure another tool just for Excel files then Plastic SCM should launch the specified tool instead of SpreadsheetCompare. However, this did not happen if you specified multiple extensions in your tool configuration.

I.e. if you configured a tool for ".xlsx;.xls" it would launch SpreadsheetCompare instead of your tool.

We fixed this, so now it will launch your configured tool whether configured for a single file type (".xlsx" or ".xls") or multiple types (".xlsx;.xls").

All platforms - Command line client: We fixed some typos in output messages!

A tool with less typos is a better tool, at least for your eyes!

All platforms - All clients (Cloud Edition): We are getting ready to login with external services!

We implemented some small changes to get ready to login to Cloud Edition using external login services.

All platforms - DevOps (.NET Core Server flavor): We replaced the WebSockets library we used for SignalR.

This translates into a more stable .NET Core server. The .NET Framework version of the server is not affected by these changes.

If you are using the DevOps features (the WebSocket connection) from outside the Plastic SCM Server (a bot or a plug not managed by the server itself), please pay attention to the changes:

Now the port you should connect your WebSocket to is defined in either WebAdminToolPort or WebAdminToolSslPort. It depends on whether you want or not SSL - as you can imagine by the name. But it has further implications:

The WebAdminToolPort does NOT listen through SSL. You can only connect a WebSocket to it using the "ws://" schema. It also rejects all connections from outside localhost.

The WebAdminToolSslPort ONLY listens through SSL. You can only connect a WebSocket to it using the "wss://" schema. It accepts all connections regardless of their origin. You also need to use TLS v1.2 to connect to the WebSocket.

Regarding the WebSocketServerPort setting:

It is now deprecated. Soon it will no longer work.

For new setups, it now has the same default value as WebAdminToolPort.

It now behaves the same as WebAdminToolPort, including its limitations (no SSL, no connections from outside).

Regarding the WebSocketServerCertificatePath and WebSocketServerCertificatePassword settings:

The certificate to connect to the secure WebSocket (through the WebAdminToolSslPort) is the same the WebAdmin uses. And that certificate is also the same your Plastic SCM uses for secure client connections.

Remember that the WebAdmin does NOT start listening through SSL if you don't have an SSL port defined in your network.conf configuration file. This is because the WebAdmin uses the same certificate as regular Plastic SCM client to server connections and if there is no certificate… there is no SSL!

So this is what you need to do:

If you don't use custom plugs or mergebots: you don't need to do anything.

If you use custom plugs or mergebots, but you use them through the Plastic SCM server (the server manages their lifecycle), you don't need to do anything. The server passes down the WebSocket URI to the integration, so the change will happen automatically for you.

If you use custom plugs or mergebots BUT you don't use them through the Plastic SCM server's DevOps features, you might need to do one or more things:

If the plug or mergebot run in the same machine the Plastic SCM server does, you could not do anything. However, we advise you to start using the WebAdminToolPort instead of the WebSocketServerPort, because the later setting is deprecated.

If the plug or mergebot runs in a different machine the Plastic SCM server does, you need to change some things. Your integration needs to use the WebAdminToolSslPort, it needs to use the "wss://" schema to connect to the WebSocket, and it needs to use TLS v1.2 connections.

If you find any issue, we will be more than glad to help you. Remember you can ping us on Twitter at @plasticscm and one of our minions will jump right in. Or you can write at support [at] codicesoftware [dot] com and we will guide you through whatever problem you might encounter.

All platforms - Command line client: Now you can set encryption parameters on the command line!

Use the following arguments to set the parameters required to work against an encrypted server:

--encryptmethod: This must be AES128, AES192 or AES256. Note: it is recommended that you use AES128, as the other options may require further configuration.

--encryptpassword: Your encryption key - usually stored in the .key files in your config directory.

--encryptserver: The server for which the previous values apply.

When using these arguments, the values will not be stored to disk on the client machine, and it is not necessary to have a cryptedservers.conf file or any .key files on the client machine.

Note: these settings will be saved on the server if they are used to perform a replication.

DevOps - Slack Notifier: We updated the Slack Notifier Plug to adapt to Slack API channel changes!

Slack made some modifications to their API around channels and supported security protocols. This caused our Slack Plug to stop functioning correctly.

We updated our code, and the Slack Plug is back in action!

Windows - Gluon: Gluon now supports high DPI screens!

Gluon didn't support scaling and looked blurry in high DPI screens. Now it is a DPI aware application, and looks much much better when you configure the screen to be scaled more than 100%.

Windows - Plastic: We fixed a null reference exception in the 2D revision tree.

Viewing a file's history as a 2D revision tree is cool. Getting an "unexpected error" when you do so is not cool! It sometimes happened when you tried to launch the view from a changeset diff view.

We took care of a null reference exception, and now all is good.

All platforms - Server: We fixed issue with port 8086 when connecting to Cloud.

There was a problem in local servers and GUIs when their organizations were migrated from cloud1 to cloud2. Some users saw an error saying that it was impossible to connect to a given address with port 8086. Users had to restart their local server to fix it.

Now the problem is solved.

It happened because the local server cached the old url in cloud1, and kept the old port, instead of replacing it by the new one.

Windows - Plastic: The tabs and the sidebar now have a new look and feel!

We rewrote the style from scratch! Take a look at how beautiful (and modern) it looks now:

Issue tracker extensions - JIRA: The extension now supports next-gen projects!

Next-gen projects do not support the type of custom field we use for the JIRA integration.

To resolve this, we added the option to add the checkin info to the JIRA issue as a comment.

Leave the "Custom field ID" blank in your Plastic Issue Tracker configuration to have checkin info added as a comment.

Windows - Gluon: The window is now resizable from all edges!

The Gluon window was only resizable from its bottom left corner.

Now you can resize it from all of its edges! Take a look:

All platforms - Server: We updated "clconfigureserver" references to "plasticd configure".

We deprecated clconfigureserver. The correct way to configure a server using the command line is by calling "plasticd configure":

We also updated the error message you get if you try to start an un-configured server to reflect this change:

All platforms - All products: The token expiration still hits Cloud Edition users.

We just made another fix that caused Cloud Edition users to suffer from token expired when connecting to Cloud directly without a profile (the default).

All platforms - Server: The server now writes logs to the correct directory when it is running as service.

The server would write the logs to your SYSTEM home path under these circumstances: your loader.log.conf has relative paths, and the server runs as a Windows service. Now the paths in the log config are relative to the server's executable location.

Windows - Plastic: We fixed a bug rearranging the tabs.

Sometimes a tab rearranged to its previous position when clicking it near its left border. Now it's fixed!

Windows - Plastic: We fixed an issue reverting to revisions in the diff window.

You can revert files to an early revision on a branch or changeset differences window. You can do so by selecting "Revert to this revision" option in the left panel's context menu.

However, this would silently fail if you saved changes to the file in the right panel of the diff before trying to revert.

We fixed this! Now the revert functionality is consistent whether you have local changes, have unsaved edits in the diff window or have saved edits in the diff window.

All platforms - Command line client: We fixed the fast-import stats flag.

The fast-import command would fail on any non-trivial repository if you set the --stats flag. It is now fixed!

All platforms - WebAdmin: The WebAdmin/WebUI server will now restart (or stop) whenever you change any settings that might affect it!

This includes changing the SSL certificate in your network configuration, editing the WebAdmin ports or disabling it altogether.

Windows - Plastic, Command line client: Network share root (and drive root) can now be a workspace!

Previously, creating a workspace in the root of a network share would appear to work, but "cm status" and the Pending changes view would show the workspace as locally deleted. The same happened if you create a workspace in the drive root.

We fixed that now, so workspaces in the drive and network share roots work as expected.

Windows, Linux - Gluon: We fixed item focus after deleting private items on Checkin view.

After deleting a non-empty directory in the Checkin view, the wrong item would be highlighted. This is now fixed!

All platforms - Issue tracker extensions: We fixed an issue listing Polarion user's work items!

There was a problem with the way we handled unexpected results when searching for Polarion tasks assigned to a specific user. If ANY of the assigned tasks contained invalid data we would discard ALL of the results. We fixed this so that it now ignored the invalid results and still shows the valid results.

Note: the invalid data scenario occurs if a user has a task assigned to them (they have the "project_assignable" Project Role for the project containing the task) but later all of this user's Project Roles for the project are removed.

All platforms - Server: The WebAdmin/WebUI supports HTTPS now!

The web server will automatically use the first certificate you configured in your network settings. This means that the web interface will use the same certificate you use for your Plastic SCM SSL connections automatically, without any further configuration. If you don't have any SSL ports defined in your server network configuration, only the HTTP endpoint will start.

The WebAdmin/WebUI HTTP endpoint will still listen on port 7178 by default, but from now on it will be bound to localhost only! So you won't be able to access WebAdmin/WebUI from other machines. If that's what you want, you'll either need to setup HTTPS or use a reverse proxy.

The WebAdmin/WebUI HTTPS endpoint will listen on port 7179 by default. You can configure that port using the 'WebAdminToolSslPort' setting in server.conf. This endpoint will listen on any network interface.

If you change the certificate you use for the SSL port at some point, make sure you restart the server to refresh the certificate information in the WebAdmin/WebUI.

All platforms - Server: We changed the default value of AbortRequestIfSocketCloses in server.conf.

AbortRequestIfSocketCloses should be true on Windows systems running .NET Framework builds of the server. All other configurations should have the value set to false.

We changed the default value to reflect this.

All platforms - Command line client: We fixed an issue with repeated error messages during the update.

The command line client could print errors and warnings multiple times if the message was longer than the console window width. We fixed it to only output the message once.

All platforms - JetBrains IDE Plugin: We detected that our plugin for IntelliJ IDEA, Rider, etc. always started in offline mode when you started the IDE. There were also class loading exception traces showing up. We fixed those issues, so now you should have your Plastic SCM view fully functional every time you start the IDE in a properly configured project.

All platforms - Server: LDAP connections now support StartTLS!

We improved the security of connections to the LDAP database by enabling StartTLS.

There should be no configuration change required. If your LDAP server supports StartTLS, any new connections will automatically be made secure.

Note: you should connect to port 389.

macOS, Linux - Gluon: We noticed that the "set files as read-only" setting didn't work as it should in partial (i.e. Gluon) workspaces. Let's say you run these steps:

You check the "Update and Checkin operations set files as read-only" option in Gluon preferences

You add a file that has its permissions set to 644

You checkin that file

You verify that the file permissions are now 444 (i.e. read-only)

You run a workspace update

Suddenly, the file permissions are 644!

We fixed that behavior so that running a workspace update from the Gluon GUI or a 'cm partial update .' command from the CLI leave the appropriate filesystem permissions.

All platforms - Plastic: We added extra info about Privacy Statement in the Sign-Up screens.

All platforms - Cloud2: Soon you will be able to recover deleted repositories!

Right now, if you delete a repository by mistake, you need to contact support to bring it back. Soon, you will have up to two weeks (14 natural days!) to resurrect (or "undelete", as we called it on the GUI) a deleted repository. Once these 14 days pass, the repository data and metadata will get removed forever.

All platforms - Server: We implemented a token renewal system!

There's still work to do, but we are getting closer to renewing the full token system.

We actually implemented this because the new tokens in cloud2 expired during long replicas, which was not good.

All platforms - Plastic: the "Pending changes" view now does fewer calls to the server!

The refresh of the "Pending changes" view now performs half of the original number of calls to the server.

This decrease in calls improves the refresh performance over a slow network. Besides that, it reduces the server load. As a result, the server is able to handle more user requests with the same resources.

All platforms - Client and Server: We added experimental support for UDT and Secured UDT for Plastic Protocol!

UDT was historically supported only on Windows servers. We changed that a few releases ago, but still it only worked with the about-to-be-deprecated Remoting protocol, which means it was not possible to use it with .NET Core builds. Also, it was not secured.

Now this changes and you can both configure a regular server and a .net core one to support UDT. Our preference is to run it on .net core buids.

== How to configure remoting.conf ==

Required only for .net servers: add a new channel to the xml in remoting.conf

== How to configure for .net core servers ==

Modify your network.conf to add this:

Where security can also be "none"

== How to use it from the client ==

Remark: this is still pretty much experimental!

Windows - Plastic: We disabled the controls on the Pending Changes view when refreshing its contents!

Clicking on "Checkin", "Undo changes" or the refresh button while the Pending changes view is being refreshed does nothing. We now disable those controls during the refresh, to avoid confusion.

All platforms - Client: The "Token expired" showed up again in LDAP servers and Cloud.

We fixed an issue that we think only happened on sync views between local/on-premises server and Cloud:

You tried to recalculate a sync view

But the token to cloud expired

But you ran a command recently from outside the GUI with another GUI or command line

The initial GUI throws token expired and it takes its time to recover

We hopefully fixed it.

The issue was because the profiles were not reloading tokens, while the underlying conn mechanism reloaded tokens.conf since a different app had changed it. Little bit weird but we saw it a few times.

macOS - DevOps: We enabled the DevOps feature in our .NET Core falvor of the server for macOS!

Remember the built-in DevOps feature we bundle in our Plastic SCM Servers out-of-the-box? Well, we lacked of this feature in macOS platform. Wait no more! Now it's available for Mac OS "Server .NET Core installer" & "Server .NET Core bundle".

Windows - Plastic, Gluon: Spreadsheet Compare is now the default tool for Excel file diffs!

When you diff Excel files (.xls or .xlsx) in Plastic and Gluon, we now launch Microsoft's Spreadsheet Compare tool by default.

Of course, if you have configured another tool for Excel files, that configuration will be honoured.

Here is a sneak preview:

Launching the tool depends on Plastic being able to find an installed SpreadsheetCompare.exe. We search in:

...and also on the PATH environment variable.

So, if you have it installed somewhere other than the above, please add it to your PATH.

Windows - Plastic: We fixed the "Maximum number of recent comments" preference.

The "Maximum number of recent comments" preference, which sets how many previous comments are seen in the "Checkin comments" drop down of the Pending changes view, is no longer ignored.

All platforms - Server (Jet backend): The server now releases the locks of an abandoned replication operation.

Now the server can detect which replication operations were abandoned and release their locks after 2 hours.

We consider a replication operation is abandoned when the Plastic client doesn't cancel or finish it. This generally happens because it is killed (e.g. Ctrl+C on a CLI cm push command). It also happens when the operation fails due to the error "The LDAP token expired".

All platforms - Server (.NET Core flavor): The server can now handle the db.conf configuration file again.

A code obfuscation oversight rendered the Plastic server unable of reading the db.conf file on startup, giving a null reference error. That's now fixed!

All platforms - Logging: New option for daily rolling logger

We have added option MaxDays for the daily rolling file appender. It controls that log files of more than "MaxDays" days old will be deleted.

NOTE: this replaces the option MaxFileCount.

This improves the control over log file directory sizes for multi-instance servers. For multi-instance, several log files can be created each day. So, limiting the age of log files is more useful than limiting the number of log files.

Here is an example daily rolling file appender configuration:

All platforms - Server: We keep improving Cloud 2!

We dramatically reduced the memory and time needed to upload and download blobs in our Cloud storage backend, which should result in a leaner server. Less RAM used in mundane tasks is more RAM the server can use to give you a better service!

All Platforms - Proxy (.NET Core flavor): We fixed some issues cleaning caches.

The .NET Core flavor of the proxy was always detecting 1GB of free space on disk. As a result, the cache was wrongly cleaned to free space. Now the proxy detects the correct free disk space.

Also, the Proxy was not loading the cached content on application startup. As a result, it did not clean some disk content until the cache was rebuilt hours later from the disk content. Now the cache gets loaded when it should!

Windows - Plastic: A minor fix to line highlighting in Code Review diff.

In the Code Review diff we were not clearing the line highlight when the mouse left the right text box. This was confusing because it would remain floating above the text even after you scrolled the view. We now clear the highlight correctly.

Windows - Gluon: We fixed a bug in Incoming Changes autorefresh.

If auth failed, or the server was unreachable, the Incoming Changes looped over and over because the autorefresh was trying to recalculate all the time. Fixed!

Windows - Gluon: We improved autorefresh for Incoming Changes!

Now the Incoming Changes view doesn't refresh the view if it's not needed. The view is only autorefreshed when:

Something has changed on disk in the workspace.

There are new incoming changes in the working branch.

macOS - Plastic: We also improved autorefresh for Incoming Changes for Plastic in macOS!

The new stuff is basically the same as before. Only refreshing when something changed on disk, or there are new incoming changes in the working branch.

All platforms - Jira issue tracker extension: We fixed the connection failure for hosted Jira servers.

A fix we made in 9.0.16.4182 to handle email addresses in the "User name" field for Jira Cloud unfortunately broke hosted Jira servers (for which you specify the username, not the email address). We fixed that, and both types of Jira server will now work.

All platforms - Command line client: We fixed the clconfigureclient output for Cloud servers.

For Cloud servers, there is no need to specify a port when configuring the client. In this case we were accidentally appending ':' to the server name. Now we don't.

All platforms - Server: We fixed the issue that prevents the differences calculation process to end on really big repositories.

We used an 'int' (i.e. 32-bit) number to walk the merge changes (revisions that were modified during the merge operations). However, there are extremely big repositories (e.g. more than 117 million merge changes) that use numbers so big that they don't fit in an 'int' type. The fix was pretty simple: we ensured that we never use an 'int' to walk data.

We only used this type for data we didn't expect to grow too much. But our expectations were too naïve in this case!

Now we use a 'long' (i.e. 64-bit) number to walk all data types, not just the main ones.

All platforms - Client: We improved the performance of deserialization code.

Metadata deserialization is now about 30% faster than before this task. This makes deserializing big trees, branch explorers, etc, faster than before.

All platforms - Server, all clients: We enabled code optimization flags that will make serialization and deserialization faster.

We enabled optimization on some components that do CPU intensive operations. Optimizations were disabled because they caused issues with localization. We're trying to fix those issues to benefit from better serialization/deserialization speed. These improvements are clearly noticeable when sending big trees, big merges, etc.

Linux - Server: We improved udt data transfer speeds for Linux.

We tweaked some parameters in our .NET Core UDT implementation, and got a 300% performance increase when running on high latency connections. In our tests we downloaded 250 MiB of data from a server in Singapore to a client in Paris.

We also found you can considerably boost UDT download rates by increasing your UDP receive buffer size. You can do so as follows:

This helps to eliminate packet loss, which can slow down the transfer.

With that setting, we achieved transfer rates of 600 mbps using udt, compared with 70 mbps using tcp over the same connection.

All platforms - Bamboo plugin: We added support to perform customized runs.

This kind of runs let you specify the changeset to build. Before these changes, Bamboo considered those runs as simply building the latest contents.

All platforms - Server, all clients: New expiration token system for LDAP.

When you enable LdapTokenPrivateKey in your server that is connected to LDAP, a new token expiration system will greatly reduce calls to LDAP.

This will greatly increase performance for command line applications, and overall server response.

The reason why we implemented this is to support external login systems in cloud2, but it will help in LDAP servers too.

All platforms - Server (.NET Core flavor): We moved the location of loader.log.conf in the .NET Core bundle.

You see, the ideal way of upgrading your Plastic SCM Server in custom setups (this is, when you DON'T use the installer) is just replacing the binaries. That's also pretty much what our Watchdog does when upgrading (although with some fancy steps such as preparing a sparse node to prevent downtimes and the like).

The issue is that if you just replace your binaries' directory contents with the content of the .zip or .tar.gz, you will override your loader.log.conf file! No more - we just moved it to the config_samples directory.

All platforms – GUIs and CLI: Fixed a problem during checkin that prevented encryption.

This only happened to a few customers who started using Cloud 2, not the ones migrated from version 1.

The problem was that if you had an encrypted organization and you were doing push/pull, it worked fine, encrypting data at rest as expected, but if you were doing checkins, data was not encrypted at the client side.

We're contacting all customers affected by this.

Anyway, do NOT panic, because this doesn't mean data is insecure. Many customers decide not to encrypt the data, and data is still safe, it is always transferred through SSL/TSL and so on. The good thing about encryption is that data leaves your machine encrypted and only you have the keys (you and your team) to decrypt, not even us can access it. So even if Google/Amazon/Azure were hacked, nobody could decrypt your data.

Server - Triggers: editreview triggers output new code review status strings

We have updated the before-editreview and after-editreview triggers output the new code review status strings "Under Review", "Reviewed" and "Rework Required" to the PLASTIC_REVIEW_STATUS variable. Previously the values were "pending", "approved" and "discarded".

All platforms - Command line client: The codereview command now uses the new code review status strings.

When using cm codereview to set the status of a new or existing code review, use one of the new status strings: Under Review, Reviewed or Rework Required, not the old ones.

All platforms - Mergebots: We updated trunkbot to use new Code Review statuses.

As part of work to update Code Review status strings we updated trunkbot to use the new strings when determining a code review's status.

Server: LDAP token expiration time configurable

Now you can configure the LDAP token expiration time using:

You can set any expiration time using the format [d.]hh:mm:ss.

By default the expiration time is 1 hour.

Windows - Plastic: Added scrollbars to the comment dialog after merging to a different branch.

The dialog that asks you for a comment when committing the result of a merge-to operation didn't include scroll bars. This could be annoying if you typed in a multi-line comment. We added a vertical scroll bar to help you with that.

All platforms - Issue tracker extensions: We added some missing parameters in the issue tracking configuration example files.

All platforms - Server, clients: Improvements in LZ4 compression when used with SSL.

LZ4 compression for metadata is still experimental, and we just fixed an issue in combination with SSL that made it use more bytes than without LZ4.

Windows - Plastic: We fixed a race condition in the Code Review Window.

If you open a branch code review that contains a really large number of changes and/or changesets and quickly selected "Review branch", you could see sometimes that the branch diffs vanished and were replaced by the first changeset diffs. It's now solved!

All platforms - Gluon, Plastic: We fixed credentials being asked twice on first installation of Cloud Edition.

There was a bug introduced in the previous releases that forced to enter creds twice during Cloud Edition installation. Now it is fixed.

This is part of the transition to cloud2, and we had a loose end here :) Sorry.

Windows - Plastic: We fixed the occasional "File not found" error in the diff view.

We fixed an issue in diff window that occasionally caused a "File not found" error to appear when Plastic regained focus. The error could happen if you switched to another application while you had unsaved changes in the diff window.

All platforms - DevOps: The log files were not generated in the expected directory.

The built-in mergebots were not writing the logs in the expected directory ($server/devops/logs). This happened when the path where the server is contains spaces.

All platforms - Server (.NET Core flavor): Fixed an obfuscation issue in the PlasticMethods enum.

This obfuscation issue made the ChannelCall log useless in the .NET Core flavor of our server, as it was impossible to identify the methods without the obfuscation mappings.

All platforms - .NET Core server: We fixed the mergerules!

We noticed that the WebAdmin didn't properly write the merge rules to file when you saved them in your browser. It's fixed now!

All platforms - Server: fixed trigger script hangs

If your trigger script produced so much output that it would fill the StandardOutput buffer, the script process would hang.

Btw, the output buffer is only 4096 bytes.

macOS, Linux - GitServer (.NET Core flavor): The calculation of the Git mappings leaked threads from the process ThreadPool.

This could lead to strange and temporary behaviors such as requests that took several seconds to start being processed after the connection was established. This happened because the server ThreadPool was exhausted and it hadn't available threads to read the request.

During this wait, the network connection could be aborted by the server making things worse (since this connections were detected as idle).

This behavior was only a problem in Linux & macOS because they don't have dedicated IO threads as Windows has.

All platforms - Client: Token expired error.

We introduced a new system for LDAP token expiration and Cloud token expiration. But there was a bug that happened only when you used a profile to connect to the LDAP server or the cloud, so you had to restart your GUI every hour.

By default, every user connects to cloud using the cloud server as their default server (it means, the default server in client.conf). When that was the case, no error happened.

But, if you had a profile to connect to cloud, because your default server is a different one, then when the token expired after 1 hour, the profile code wasn't really doing login again, but just returning the token already cached, and this caused the problem. The renew never happened.

All platforms - Server, clients: Improvements in LZ4 compression when used with SSL.

LZ4 compression for metadata is still experimental, and we just fixed an issue in combination with SSL that made it use more bytes than without LZ4.

All platforms - Server: We added HTTPS support to the WebAdmin/WebUI!

The web server will automatically use the first certificate you configured in your network settings. This means that the web interface will use the same certificate you use for your Plastic SCM SSL connections automatically, without any further configuration. Just keep in mind that you'll need to access the server using https:// instead of http:// now!

If you change the certificate you use for the SSL port at some point, make sure you restart the server to refresh the certificate information in the WebAdmin/WebUI.

All platforms - Issue tracker extensions: We added some missing parameters in the issue tracking configuration example files.

All platforms - Bamboo plugin: We added support to perform customized runs.

This kind of runs let you specify the changeset to build. Before these changes, Bamboo considered those runs as simply building the latest contents.

All platforms - Server, Client: New expiration token system for LDAP.

When you enable LdapTokenPrivateKey in your server that is connected to LDAP, a new token expiration system will greatly reduce calls to LDAP.

This will greatly increase performance for command line applications, and overall server response.

The reason why we implemented this is to support external login systems in cloud2, but it will help in LDAP servers too.

All platforms - Server (.NET Core flavor): We moved the location of loader.log.conf in the .NET Core bundle.

You see, the ideal way of upgrading your Plastic SCM Server in custom setups (this is, when you DON'T use the installer) is just replacing the binaries. That's also pretty much what our Watchdog does when upgrading (although with some fancy steps such as preparing a sparse node to prevent downtimes and the like).

The issue is that if you just replace your binaries' directory contents with the content of the .zip or .tar.gz, you will override your loader.log.conf file! No more - we just moved it to the config_samples directory.

Windows - Plastic: Add scrollbars to the comment dialog you get after merging a branch or changeset to a different branch (merge-to operation).

The lack of scrollbars could be annoying if you typed a multi-line comment. We added a vertical scroll bar to help you with that.

All platforms - Server, clients: We enabled code optimization flags that will make serialization and deserialization faster.

We enabled optimization on some components that do CPU intensive operations. Optimizations were disabled because they caused issues with localization. We're trying to fix those issues to benefit from better serialization/deserialization speed. Clearly noticeable when sending big trees, big merges, etc.

Linux - Server: improved UDT data transfer speeds for Linux.

We tweaked some parameters in our .Net Core Udt implementation, and got a 300% performance increase when running on high latency connections. In our tests we downloaded 250 mb of data from a server in Singapore to a client in Paris.

We also found you can considerably boost udt download rates by increasing your udp receive buffer size, using the following command:

This helps to eliminate packet loss, which can slow down the transfer.

With that setting, we achieved transfer rates of 600 mbps using udt, compared with 70 mbps using tcp over the same connection.

Windows - Plastic: We fixed a race condition in the Code Review Window.

If you open a branch code review that contains a really large number of changes and/or changesets and quickly selected "Review branch", you could see sometimes that the branch diffs vanished and were replaced by the first changeset diffs. It's now solved!

All platforms - Gluon, Plastic: Credentials asked twice on first installation of Cloud Edition.

There was a bug introduced in the previous releases that forced to enter creds twice during Cloud Edition installation. Now it is fixed.

This is part of the transition to cloud2, and we had a loose end here :) Sorry.

Windows - Plastic: fixed occasional "File not found" error in the diff view

Following a contrived sequence of steps including editing a file in the Pending changes diff window, saving the edit but then making another edit, cancelling the dialog asking if you want to Save changes, switching to another application and back to Plastic with the edit still not saved, with "auto refresh" enabled on the Pending changes view, resulted in a mysterious "File not found" error dialog because a temp file got deleted when it was still required. Now it does not.

All platforms - Devops: The log files were not generated in the expected folder.

The server wasn't writting the log files of built-in mergebots and plugs to the "$server/devops/logs" folder. This could happen when the server is installed in a path that contains whitespaces. Fixed.

All platforms - Server (.NET Core flavor): Fixed an obfuscation issue in the PlasticMethods enum.

This obfuscation issue made the ChannelCall log useless in the .NET Core flavor of our server, as it was impossible to identify the methods without the obfuscation mappings.

All platforms - Server (.NET Core flavor): We fixed an obfuscation issue that affected merge rules.

The WebAdmin didn't properly write the merge rules to file when you saved them in your browser. It's fixed now!

All platforms - Server: fixed trigger script hangs.

If your trigger script produced so much output that it would fill the StandardOutput buffer, the script process would hang.

Btw, the output buffer is only 4096 bytes.

All platforms - Server (.NET Core flavor): the mergerules don't work in this version.

If you use the .NET Core flavor of the Plastic SCM server, please be aware that currently the mergerules do NOT work. It will get fixed ASAP, so if you depend on them, please abstain from upgrading your .NET Core server.

The regular server is not affected by this issue. Sorry for the inconvenience!

All platforms - Server: The "before-mkbranch" trigger correctly handles branch filters.

We corrected a branch filter matching issue for the "before-mkbranch" trigger. It was an issue for child branches.

For example, if you created this trigger

Then, creating branch "/main/task" would not trigger the associated script. But now it does!

"after-mkbranch" did not have the same issue.

Windows - Plastic: We fixed a typo in the credentials dialog.

We were asking for "pasword" instead of "password" in the Cloud credentials dialog!

All platforms - Plastic: We fixed an issue when linking issue tracker items using the checkin comment.

If you have an issue tracking system setup, it is possible to link a checkin to task by setting the task id into the checkin comment, prefixed with a #. For example "#TASK-7: my comment".

This feature was temporarily broken, but we fixed it.

All platforms - Server: New htop command for plasticd shell.

Just run plasticd shell in your server, then htop and a beautiful console based UI as follows will show up:

It is also possible to analyze specific requests and filter:

All platforms - Command line client: "checkout" command can recurse into piped directory arguments.

Previously "checkout" would ignore the recursive flag when arguments were piped in from standard input, but now we do the recursion.

Linux - Server: Now multiple servers can run in the same port.

network.conf learns to do ReuseAddress. This is only valid for multi-instance setups on Linux at this point, something we're using for our cloud2 efforts.

All platforms - Server: override for LDAP user filter.

To support LDAP setups that are not compatible with our default LDAP user search filters, we have added a limited ability to override the filter with a user specified filter.

Warning: this should be considered an expert level feature, and only used if you really know what you are doing, and ideally after consultation with our Support team.

The filter override is specified in the server.conf file by adding the following xml fragment inside the ServerConfigData element:

For example, LDAP setups without the "uid" attribute can use the following filter:

Cloud 2: Now Cloud 2 supports webtriggers!

Cloud 2 is the new Cloud that you'll be using soon (did the "2" in the name gave it away?)

Some of you are already using it, and it now supports webtriggers.

..creates a web trigger. If the webtrigger fails, the operation won't finish. In this case, the repository won't be created.

If you write an error message in the response, the error message will pass down to the user.

You can learn more about webtriggers in the documentation.

All platforms - Server, Command line client, GUI: Refactored the way to parse servers.

Each "server:port" is parsed by a class called PlasticServer. We refactored and cleaned up the code and removed a bunch of singletons.

All platforms - Command line client, Plastic: Fixed an error undoing changes in a merge result.

Performing the Undo Changes operation on some merge result changes sometimes failed, displaying an error message like: "Unable to move file '/wk/art/global/water.tif' back to '/wk/art/level1/water.tif': Could not find a part of the path.".

This happened only if some of your workspace items were cloaked, the merge moved a file from under a cloaked directory, and said merge also deleted the cloaked directory. Now it's fixed!

All platforms - Gluon: Fixed an issue in checkin that could cause data loss.

We were chasing an elusive bug in Gluon that happened very, very rarely during checkin. It happened both in on-premises servers and Cloud.

On-premises: The following error could happen "The checkin operation could not be completed because an internal error occurred transferring the data. Please retry the checkin operation" and the checkin would be aborted.

Cloud: No error message but the recently checked in file would disappear. It only happened during concurrent checkins (many checking in to the same branch to cloud and only during certain moments of the checkin).

Both issues now fixed!

All platforms - clconfigureclient: fixed clconfigureclient --clientconf option when the default client.conf is missing.

clconfigureclient would fail when you used the --clientconf option to create a new config file if the default client.conf file was missing.

It now handles this case.

All platforms - Server: secure LDAP connections now supported on port 636.

We added support to the Plastic server for SSL connections to your LDAP server. Configure your server (using the "plasticd configure" command, or the web based administration tool) to switch the LDAP port from 389 to 636 to take advantage of a secure connection to LDAP, assuming your LDAP server is configured to support this.

All platforms - Command line client: partial update and partial switch errors now output to standard error.

We used to write the errors for these commands to standard output but, after several C-level internal meetings and public consultations, decided to write the errors to standard error, like we do for other commands.

All platforms - clconfigureclient: optionally specify (alternative) configuration file path.

We have added an optional argument to "clconfigureclient" which lets you specify an alternative configuration file location.

The argument can be a full path, a filename or a directory.

All platforms - Server: new adminpwd subcommand added to plasticd!

To set the Plastic server administrator password you can now run the following command:

This replaces the previous method:

All platforms – All clients and servers: Implemented Cloud organization region server resolution.

We're getting ready for the new cloud2, a greatly improved version of Plastic Cloud!

The new version will feature an entire constellation of servers around the world, not just storage places like in the current cloud.

This means when you try to connect your_org@cloud it won't automatically resolve to server cloud.plasticscm.com but it will retrieve the right server for your region.

We implemented that resolution to get ready for the new Cloud.

All platforms - Server: Now the Jet backend allows configuring the max amount of memory used by caches.

When the process reaches the memory limit, it starts to clean the caches of the least recently used repositories. The server will clean the configured percentage of the total number of caches.

By default, there is no memory size limit. You need to configure it to enable this functionality. In that case, the default percentage to free will be 25% (not used unless a size limit is set). You can configure both values can be in jet.conf, using the following settings:

Bear in mind that the memory will not be released until the GC runs the next full collection.

All platforms - Server (.NET Core flavor): Fixed an obfuscation issue that affected the log.

Our custom appender was obfuscated in the .NET Core flavor of the server. This prevented log4net from being able to find it. Now that's fixed!

All platforms - Plastic, Gluon, Command line: Fixed a broken checkin to encrypted repos if a fragment was bigger than 4MB.

It only happened on encrypted repos (typically Plastic Cloud) and only when a big file compressed in chunks of 4MB had one of the compressed fragments growing beyond 4MB due to the encryption. We never seen that before and it happened to us internally doing a simple checkin of an Excel.

We fixed the issue and should work fine now.

All platforms - .NET Core Server: We reduced the memory used in caches by up to 50% for big repositories.

In servers like ours -with several repositories hoarding more than 1 million revisions each- you can save more than 1GB of memory.

All platforms - Server: Now you can limit the number of repositories that have the Jet caches enabled.

By default, when using the Jet backend, the server keeps caches for 500 repositories. The server selects 10% of the least recently used repositories and cleans their caches when it reaches the 500 repos limit.

MNow you can change both values in the jet.conf configuration file using the following settings:

All platforms - Issue tracker extensions (codeBeamer): The 'CodeBeamer' extension now is 'codeBeamer', which is the correct name.

All platforms - Issue tracker extensions (codeBeamer): We now include a default config file for codeBeamer.

This default codebeamer.conf file will help you to configure the codeBeamer extension.

You will find it alongside your client binaries, under extensions/config_samples/.

By default, client binaries are in:

All Platforms - UDT protocol: Now the UDT protocol is available for everyone, regardless of your OS!

Users behind high latency networks will find this especially useful. Keep reading!

We have had the option to go with UDT for our Windows users for a long time.

Now, all users will be able to use it as we replaced the existing UDT implementation with our own fully .NET compatible version.

There is a caveat: right now UDT is only available when using 'remoting' as the network protocol. This means that the new .NET Core based server, which only uses PlasticProtocol, can't take advantage of this yet.

UDT also doesn't allow secure connections (SSL), but we have plans to add it for PlasticProtocol too, making it much more usable.

By the way, we decided to share our work with the Open Source community. UdtSharp, as we named it, is available under the MIT licence.

Unity plugin: Now, the plugin considers local project packages for versioning.

This means their folders and contents will appear in the 'Pending changes' view of 'Version Control' window in Unity when they contain any change.

This feature is available for Unity 2019.3 or later.

All platforms - Plastic, Gluon: We fixed a small issue that could wrongly show help panels in the first hours of the day.

Dates of help panels "last seen" info are stored locally to avoid bugging you if you already saw the help. Dates are stored in UTC, but the code was not using UTC, which means during the first hours of the day they could be wrongly displayed.

Here's some trivia for your: we found this issue because of an automated test always failing just after midnight!

Server - Linux: We improved UDT speed on Linux.

We found and corrected an issue in our home grown implementation of UDT which made it run really, really slow on Linux.

All platforms - Server: Backup prototype.

We're working on a new version of Plastic Cloud, code named cloud2, and we've created a way to backup repositories to cloud, that will be soon available in any on-premises server too, as long as you configure a certain cloud bucket to contain the backup. It supports Amazon, Azure, and soon Google Cloud Storage.

It will work this way. I hope you find it interesting!

All platforms - Server: We implemented a smart scheduling algorithm for backups.

Now that on-premise servers will be able to do cloud-based backups, it would be nice that backups executed automatically, wouldn't it? The issue is that you can't back up a file somebody is writing to at the same time. So backups block repository write operations.

But what happens if you are using your repository, and the Plastic SCM server blocks write access to it? I'll bet you would be sad. Even angry!

We implemented an somehow intelligent system to decide the best time to execute a backup. It is based on the write activity for the last seven days. If you and your team are regular human beings, the backups will probably be scheduled at night time, but if you are night owls, backups will be scheduled to execute at day time. Good enough to get out of your way!

All platforms - Server: connection strings and keys now obfuscated in logs.

We now obfuscate your Amazon S3 connection keys and Azure connection strings before we write the database configuration settings to the log file. This means you can safely share your logs with our Support Team without divulging this private data!

All platforms - clconfigureclient: no need to set port when configuring cloud servers.

When validating the command line arguments for clconfigureclient, we would return failure if the port was not specified, even for cloud servers. The port is not required for cloud servers, so now we don't require the port argument in this case.

All platforms - Server: for LDAP users, Plastic now functions correctly when the LogonWorkstations parameter has been set on the AD server.

Unity plugin: Now, the local project packages are considered for versioning. This feature is available for Unity 2019.3 or later.

This means their folders and contents will appear in the 'Pending changes' view of 'Version Control' window in Unity when they contain any change.

All platforms - Plastic: JIRA extension didn't list issues.

JIRA platform was unable to list issues when creating a new Plastic branch. Now it's fixed.

All platforms - CLI: We improved how the 'getworkspacefrompath' command works!

Now, the getworkspacefrompath automation command returns a failure result if the specified path is not in a workspace. It used to always return success, which made catching problems when scripting more difficult than it should have been. Sorry about that!

All platforms - Logging: We changed the default filename format of the daily rolling file appender.

It was "yyyy-MM-dd-{filename}" but now it's "{filename}.yyyyMMdd". This way we think it is easier to navigate these files using a shell with autocompletion.

We also added the option to preserve the file extension. You'll probably want to use this on Windows so that, for example, if your base filename is "logfile.txt", the generated log files will be like "logfile.yyyyMMdd.txt" instead of "logfile.txt.yyyyMMdd".

To configure this log appender, add something like the following to your "log.conf" file.

This will generate files like: cm.debug.log.20200227.txt, cm.debug.log.20200228.txt and so on.

The maxFileCount property is the maximum number of files to keep on disk. The system removes the oldest files once the number of log files exceeds maxFileCount.

The preserveLogFileNameExtension property should be true if you want to preserve the extension, as discussed before.

All platforms - Command line client, Plastic: We fixed two errors in the 'undo' operation.

The first one is that undoing changes could fail with a null error. This happened very rarely and only when the pending changes contained a duplicated change.

The second one is that undoing changes could also fail with the error message "An error occurred processing the request. No more information is available...". This happened when a merge operation deleted a cloaked directory.

All platforms - Command line client, Plastic: We fixed an error in the move operation.

Moving items around in a controlled manner could fail with the error "Can't add an entry with the same name. Duplicated child...". This happened when you moved a Copied or Added item to a directory that contained another workspace change with the same name. Now it's fixed!

Linux - Watchdog: We fixed a bug after upgrading servers using a ZIP.

The watchdog removed write permissions to the plasticd binary after an upgrade. This caused consequent upgrades to fail, as the watchdog could not override the plasticd file. Fixed!

For now we don't distribute the Plastic SCM Watchdog, but if you think you could benefit from it, don't hesitate to contact us at support at codicesoftware dot com.

Windows - Plastic: We fixed an unexpected error in the Code Review window.

When you resolve a change request, the Code Review window displays a clickable link in the change requests list panel. It allows the reviewer (or anyone, actually) to navigate to the changeset in which the change request was applied.

However, these links should only work for code reviews of branches. If you created a code review for a single changeset, you got the aforementioned error when you clicked the change request resolution link.

We changed the UI so those links don't appear if the displayed code review was created for a changeset.

Windows - Plastic: The Code Review failed to show diffs when selecting a comment.

Sometimes, when navigating to a change, question or comment, due to concurrency issues, the diff viewer did not display the diff content. Now it's fixed.

All platforms - Command line client: The fast-import command will now use the correct server.

Before, the command always used the server configured in the client instead of the server specified in the command.

This was because it ignored the server specified in the repository spec that the command received . So, when running the command...

...it tried to do the import in the server configured in the client (i.e: localhost:8087) instead of doing the import in the test@cloud organization.

macOS - Plastic: We fixed an issue when redimensioning the "Mergelink description" panel in the Pending Changes view after a merge.

Do you remember the "Check/clear all" button in the Pending Changes view? It didn't have a fixed height. This caused an issue redimensioning the "Mergelink description" panel - the Pending Changes' file tree went down with the splitter, and you couldn't see the list of files.

Under some circumstances (hundreds of files pending to checkin) this issue could also even lead to the application crashing. But that's now fixed!

All platforms - Gluon: Improved the way 'cm partial update' works for items under a Xlink.

If all the specified paths in the 'cm partial update' are inside the same Xlink and you use the --changeset flag, then Plastic searches the changes to update in the specified changeset of the xlinked repository instead of using the top-level one.

This is how it worked before for files. But now it also supports directories!

Linux - Proxy: New .NET Core-based Proxy.

Good news! We bundled a new Linux package to distribute our Proxy server, this time using the .NET Core runtime. You can install it by targeting the package plasticscm-proxy-server-netcore. It's incompatible with the .NET Framework version plasticscm-proxy-server but you can install it alongside a Plastic SCM server. Enjoy!

Windows, macOS - Plastic: Detailed the reason why a file cannot be commented in the Code Review.

The Code Review system does not support adding comments in some scenarios:

When the selected file belongs to a different repository.

When it's an unsupported file type (image diff, directory diff, ...).

In all scenarios we were always displaying the same informative message: "Review comments are not yet supported for this file type", which was confusing. Now we display a suitable message for each scenario.

All platforms - Command line client: We fixed credential input for commands with animated progress.

Previously, sometimes the cursor would stick to the start of the line when entering credentials for those commands. It affected the following commands: switch, update, setselector, checkin and replication (push & pull).

All platforms - Plastic, Command line client: Fixed a bug with when merging.

The merge operation sometimes failed with the error message "The merge operation was failing '{path}'". This happened when the merge workspace contained a cloaked, out-of-date empty file. It's fixed now!

macOS - Server: new PKG installer for our .NET Core server.

A new pkg installer is now available! It contains our brand new Plastic SCM .NET Core server for macOS.

We strongly recommend to upgrade to this new product if you are running servers on macOS. We will deprecate the old server soon.

Bear in mind, the current installer just supports Team and Enterprise editions. It doesn't support Cloud Edition yet - which is bundled with the client anyway.

Upgrading to this new version preserves the already existing server configuration and license files.

All platforms - Server: New "webadmin" subcommand for plasticd.

We added a new subcommand: plasticd webadmin. It opens the webadmin homepage in your browser! For it to work your server needs to be already running - as it servers the webpage!

Windows - Plastic, Gluon: We fixed a visual bug in the Pending Changes list.

You could encounter the bug by deleting some files from disk, and then, checking-in the deletions from the Pending Changes view. When the checkin operation finished... the deleted items were still present in the changes list!

It was just a visual issue - the checkin worked fine and the deletions were already checked in. However, seeing the files still there could cause dismay. Worry not! The issue is now fixed.

Windows - Plastic: We fixed possible duplicated entries in recentservers.conf config file.

If you sometimes used uppercase chars and sometimes used lowercase chars on your Plastic server in the repositories view, you could end up having duplicate entries in the recentservers.conf file. Now it's fixed!

Linux - Plastic, Gluon, Server: some of our application icons didn't look OK in some GNU/Linux distros. We fixed them!

Windows - Gluon: We improved the look & feel of the 'Check all' checkbox.

Some time ago we added a 'Check all/clear all' checkbox in the checkin view. We added a border around the checkbox to improve the group feeling.

Windows - Plastic: We improved the checkin progress.

When performing a checkin in a fast network, or uploading a bunch of small (or empty) files to a fast server, the checkin progress sometimes displayed the message "0 blocks in parallel was displayed". Now it's fixed.

Windows - Plastic: We fixed some errors in the Incoming Changes view, that could happen after experiencing an error.

A dialog with the message "an error occurred processing your request" appeared when refreshing some views.

When closing the GUI, it failed to save the guivisualstate.xml configuration file.

Windows - Gluon: We fixed an error calculating the status.

Under some circumstances, Gluon was unable to correctly display the status if working with corrupt workspace metadata. But now Gluon is stronger and it is able to handle this situation!

Windows - Plastic: The Workspace Explorer could sometimes freeze after a search.

You could reproduce this freeze as follows: type a search term in the Workspace Explorer, and quicly press the 'Enter' key to go to the first result. But now it's fixed!

Window - Plastic: We made the new daily rolling log file appender work in Plastic (adding to cm and the server).

Reminder: the daily rolling file appender writes one day's logs per file, and lets you set a maximum number of files to keep on disk. Configure it by adding something like this to your plastic.log.conf:

Windows - Plastic: We fixed an issue when selecting text in the Code Review window.

You could reproduce the issue by moving your cursor out of the bounds of the textbox when selecting text from the diff's right revision. But now it's fixed!

Windows - Plastic: The JIRA extension didn't filter assigned tasks correctly.

Using the JIRA extension, the "Create branch" dialog allows you to create a branch from a given JIRA task. There is a checkbox in that dialog called "Display pending tasks from all users". It's unchecked by default, so you should only see tasks assigned to you. Unfortunately, a bug caused the dialog to display tasks from all users instead. Now it's fixed!

Windows - Gluon: We fixed a "Cannot access a disposed object" error.

Sometimes you could encounter this error after switching the workspace, when the help panel appears. But now it's fixed!

macOS, Linux - Gluon: We implemented checkins with symlinks.

The cm partial ci command allows the [/code]--symlink[/code] option like the cm ci does.

With this --symlink option, Plastic SCM checkins the symlink instead of the target. Please note this only works in UNIX-like OSs such as GNU/Linux based distros and macOS.

All platforms - Server: We protected the connection collector thread.

First, some background: a lost connection is a connection that stays too long doing nothing, normally because of a network issue.

So, the connection collector thread is a thread that collects these lost connections to purge them. See the importance of keeping the collector thread alive?

The issue was that, when debugging our server, we caused an exception that killed said thread. The only way to recover from this was restarting the server. We now protected this scenario - which was already very very unlikely to happen to you!

All platforms - Server: We protected socket "begin receive async" code.

Connections could stay alive forever if the client closed it when the server was invoking said receive. Now it is fixed!

All platforms - Server: We fixed a memory leak during LZ4 negotiation.

Don't worry - LZ4 is not mainstream yet. It is almost impossible you were hit by this one! But we had a memory leak during the LZ4 negotiation. We detected it in our internal production server, 2MB buffers grew too much.

We fixed the leak and also improved how we log buffer's sizes. Now there is no change of an overflow if the buffer size gets too big!

All platforms - Plastic: We fixed some duplicated entries in repository comboboxes.

This issue could appear when creating a workspace from the Welcome dialog (this is, the first steps with the application).

The combo to select a Plastic SCM repository could have duplicated entries if your organization's name has any uppercase character. Now it's fixed!

All platforms - Proxy: We improved the log details. Now all requests will include these in each line:

*A request Id to identify all the messages that are part of a given call

*The name of the user who performs the call

*The client address of the caller

You need to update your plasticcached.log.conf file with the default one provided with the installer.

Windows - Plastic: We don't distribute the Leap Motion libraries for licensing issues. If someone wants to use it, please get the Leap Motion SDK, and copy the following files to the Plastic SCM client installation:

All platforms - Server: Jet can store blobs to different paths.

We added a new setting to jet.conf to allow storing blobs and metadata in different paths.

This way it is now possible to put metadata in faster storage, and blobs in slightly slower one.

All platforms - Proxy: The proxy incorrectly cleaned recently used data to free space. It always targeted data downloaded from the Plastic Cloud server as the best option to purge. It's fixed now.

All platforms - Server: We have re-enabled logging for the proxy, using plasticcached.log.conf, after accidentally disabling it back in release 8.0.16.4035. Sorry about that!

Plastic SCM becomes 9.0!

As every year, we jump to a new number, 9.0 this time. For all of you using subscriptions it will be transparent.

If your team uses an "unlimited license", remember to request a new license where "major version supported" is updated to 9.

We no longer release major huge new versions anymore. We don't wait to package tons of new features. We simply keep releasing at least once a week, and making new features available version after version. That's how we ended up in version 9.0.16.4057, the one we converted to 9 today.

If you subscribe to Plastic, or you purchase support+updates, it means you will receive a constant flow of updates.

This initial 9.0 won't be a lot different to the latest 8.0, but in a few months 9.0 will be very different, week after week.

These are some of the things we are cooking:

.NET Core based server – we already previewed it, but it will turn official in the months to come. It means faster operation and a more stable core specially on Linux and macOS.

We'll keep improving the Code Review system.

We are working on a new Plastic Cloud that will run circles around the current one.

We'll update the current GUI look and feel as we teased here.

And many, many more to come.

**Examples:**

Example 1 (unknown):
```unknown
cm sync <repspec> p4multibranch <p4server> --mainbranch=<main_branch_folder> --branchesfolder=<branches_folder> --user=<usr_name> --pwd=<password> [--skipplasticbranches=path_to_file] [--skipp4branches=path_to_file] [--skipp4paths=path_to_file]
```

Example 2 (unknown):
```unknown
cm sync <repspec> p4multibranch <p4server> --mainbranch=<main_branch_folder> --branchesfolder=<branches_folder> --user=<usr_name> --pwd=<password> [--skipplasticbranches=path_to_file] [--skipp4branches=path_to_file] [--skipp4paths=path_to_file]
```

Example 3 (unknown):
```unknown
cm sync plastic-repo p4multibranch p4server:1666 --mainbranch=//depot/main --branchesfolder=//depot --user=user --pwd=mypwd
```

Example 4 (unknown):
```unknown
cm sync plastic-repo p4multibranch p4server:1666 --mainbranch=//depot/main --branchesfolder=//depot --user=user --pwd=mypwd
```

---

## Google Play data safety section for Cloud Content Delivery

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/GoogleDataSafety

**Contents:**
- Google Play data safety section for Cloud Content Delivery#
- Data collection survey#
  - Data types#

Starting April 2022, Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Cloud Content Delivery. For your convenience, Cloud Content Delivery provides information on its data collection practices below.

Important: The data disclosures below are for the Cloud Content Delivery SDK only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

*Data is collected via HTTPS for analytics purposes.**via HTTPS.

---

## Configure external tools

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/externaltools-conf

**Contents:**
- Configure external tools#
- Create the externaltools.conf file#
  - Syntax#
  - Parameters#
- externaltools.conf file example#

Use the externaltools.conf file to run actions from external tools on selected objects.

If you configure actions, these actions appear in the submenu when you right-click and select Open in the following locations:

The actions also appear as a new context menu item, External tools, in the following locations:

Create the externaltools.conf file in one of the following locations:

Note: The following locations are listed in order of precedence. For example, a configuration file in plastic-global-config overrides a configuration file in the plastic4 directory.

Use the following syntax for the externaltools.conf file:

Refer to the following example of a valid externaltools.conf file:

**Examples:**

Example 1 (unknown):
```unknown
externaltools.conf
```

Example 2 (unknown):
```unknown
externaltools.conf
```

Example 3 (unknown):
```unknown
externaltools.conf
```

Example 4 (unknown):
```unknown
plastic-global-config
```

---

## Get a range of scores centered around a player from a leaderboard version

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/get-range-score-player-centered-version

**Contents:**
- Get a range of scores centered around a player from a leaderboard version#

To get a range of scores centered around a player from an archived leaderboard, use the GetVersionPlayerRangeAsync method:

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetVersionPlayerRangeOptions configuration object:

For details on how to get available leaderboard version IDs, visit Get available leaderboard version.

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
GetVersionPlayerRangeAsync
```

Example 2 (unknown):
```unknown
public async void GetVersionPlayerRange(string leaderboardId, string versionId)
{
    // Returns a total of 11 entries (the given player plus 5 on either side)
    var rangeLimit = 5;
    var scoresResponse = await LeaderboardsService.Instance.GetVersionPlayerRangeAsync(
        leaderboardId,
        versionId,
        new GetVersionPlayerRangeOptions{ RangeLimit = rangeLimit }
    );
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 3 (unknown):
```unknown
public async void GetVersionPlayerRange(string leaderboardId, string versionId)
{
    // Returns a total of 11 entries (the given player plus 5 on either side)
    var rangeLimit = 5;
    var scoresResponse = await LeaderboardsService.Instance.GetVersionPlayerRangeAsync(
        leaderboardId,
        versionId,
        new GetVersionPlayerRangeOptions{ RangeLimit = rangeLimit }
    );
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 4 (unknown):
```unknown
IncludeMetadata
```

---

## Authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/authentication

**Contents:**
- Authentication#

To use the Lobby service, authenticate yourself using Unity Authentication. Make sure to initialize the authentication service and sign in before making any calls using the Lobby SDK. While there are many sign in methods, the easiest way to get started is with Anonymous sign in. See the Unity Authentication anonymous sign in guide to get started.

---

## Get a range of scores centered around a player from a leaderboard version

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-range-score-player-centered-version

**Contents:**
- Get a range of scores centered around a player from a leaderboard version#

To get a range of scores centered around a player from an archived leaderboard, use the GetVersionPlayerRangeAsync method:

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetVersionPlayerRangeOptions configuration object:

For details on how to get available leaderboard version IDs, visit Get available leaderboard version.

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
GetVersionPlayerRangeAsync
```

Example 2 (unknown):
```unknown
public async void GetVersionPlayerRange(string leaderboardId, string versionId)
{
    // Returns a total of 11 entries (the given player plus 5 on either side)
    var rangeLimit = 5;
    var scoresResponse = await LeaderboardsService.Instance.GetVersionPlayerRangeAsync(
        leaderboardId,
        versionId,
        new GetVersionPlayerRangeOptions{ RangeLimit = rangeLimit }
    );
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 3 (unknown):
```unknown
public async void GetVersionPlayerRange(string leaderboardId, string versionId)
{
    // Returns a total of 11 entries (the given player plus 5 on either side)
    var rangeLimit = 5;
    var scoresResponse = await LeaderboardsService.Instance.GetVersionPlayerRangeAsync(
        leaderboardId,
        versionId,
        new GetVersionPlayerRangeOptions{ RangeLimit = rangeLimit }
    );
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 4 (unknown):
```unknown
IncludeMetadata
```

---

## Get started

**URL:** https://docs.unity.com/ugs/manual/authentication/manual/unreal-engine-sdk/get-started

**Contents:**
- Get started#
  - Understand the requirements#
- Download the Authentication SDK#
  - From the Unreal Engine Marketplace website#
  - From the Epic Games Launcher#
  - Configure the Authentication SDK#
  - Sign up for UGS#
  - Link your project#
- What's next?#

The Authentication SDK for Unreal Engine is a part of the Unity Gaming Services SDK plugin for Unreal Engine. To use Unity Authentication inside the Unreal Engine, you’ll first need to install the Unity Gaming Services SDK.

The Authentication SDK plug-in for Unreal Engine supports the Unreal Engine versions 4.27 to 5.3.

Sign in to the Unreal Engine Marketplace.

Access the Unity Gaming Services SDK for Unreal Engine Marketplace page.

Select Open in Launcher.

Skip to Step 4 in From the Epic Games Launcher.

>Note: If you use a version of the engine built from sources then you can access your Marketplace folder by doing the following:

Before you begin using the Authentication SDK, you need to sign up for Unity Gaming Services and register a project.

>Note: If you already signed up for Unity Gaming Services and have a registered project, skip this step.

If you don't have a Unity account, create one and create a new project to sign up for Unity Gaming Services:

>Note: We’re copying the name of the environment, not the Environment ID. In the example above, the name is “testenv”. Using any other value causes Authentication requests to fail.

After you copy both fields, the project settings in the Unreal Editor should look like the following:

The Default Player Profile Name field grants a different name to be given to the default Authentication player profile. This can be left alone, or customized according to your needs.

>Note: A valid player profile name is between 1-30 characters, and consists of characters a-z, A-Z, 0-9, -, and _, with no spaces.

See Player Profiles to read more about Player Profiles inside the Authentication SDK.

Proceed with either integrations:

**Examples:**

Example 1 (unknown):
```unknown
C:\Program Files\Epic Games\UE_5.3\Engine\Plugins\Marketplace
```

Example 2 (unknown):
```unknown
UnityGamingServicesSDK
```

---

## Find shelves

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-shelves

**Contents:**
- Find shelves#
- Filtering options#
- Output options#
- cm find shelve example#

Find and filter shelves.

The following list displays the different filtering options (where) that are available to use with the cm find shelve command:

The following list displays the different output options (--format) available to use with the cm find shelve command:

Find shelves created by your team members in the past year:

**Examples:**

Example 1 (unknown):
```unknown
cm find shelve
```

Example 2 (unknown):
```unknown
cm find shelve
```

Example 3 (unknown):
```unknown
cm find shelve
```

Example 4 (unknown):
```unknown
cm find shelve "where owner != 'me' and date >= '1 years ago'"
3848     2        04/10/2018 5:58:22 PM pablo    doom3code Shelve - temporary compilation.txt file
3860     3        06/23/2018 11:08:06 PM pablo    doom3code Shelve - test with a new configuration
```

---

## Use case sample: Initialize newly signed-up players with default configuration values

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/use-cases/initialize-new-players

**Contents:**
- Use case sample: Initialize newly signed-up players with default configuration values#
- Prerequisites#
  - Authenticate using a Service Account#
  - Configure the UGS CLI#
- Examine the signed-up event#
- Set up Cloud Code#
  - Cloud Code C# module#
  - Cloud Code JavaScript script#
- Configure a trigger#
- Validate the result#

The use case sample demonstrates how to use Triggers to initialize new players with a default health and stamina values in Cloud Save when they first sign up. It uses the signedUp event emitted by the Authentication service, and records the value in Cloud Save.

You must first create a service account with required access roles and configure the UGS CLI.

Before you can call the Triggers service, you must authenticate using a Service Account.

Add Product roles and create a key:

For more information, refer to Authentication.

Follow the steps below to get stated with the UGS CLI:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Authenticate using the Service account you created earlier. Refer to Get Authenticated.

The Authentication service emits a signed-up event when a new player is created. The event payload looks like this:

The event payload is passed on to Cloud Code as parameters.

Refer to Authentication: Signed up for more information.

Define a module endpoint or a script that calls Cloud Save to initialize a newly authenticated player with default health and stamina values.

Create a InitializeNewPlayer module function with required string argument playerId with contents as below:

Refer to Deploying Hello World to learn how to deploy a module.

Note: If you are deploying the module using the UGS CLI, don't forget to add additional Service Account role of Cloud Code Editor.

Create a InitializeNewPlayer script with a required string parameter playerId using the contents as below:

Note: If you are using Unity Editor to manage your scripts, you can uncomment the code at the bottom of the script to declare the required playerId parameters in-script. To learn more about how to manage in-script parameters, refer to Modify script parameters within the Unity Editor. Publish the script.

Refer to Deploying Hello World to learn how to deploy a script.

Note: If you are deploying the script using the UGS CLI, don't forget to add additional Service Account roles: Cloud Code Script Publisher and Cloud Code Editor.

To connect your Cloud Code resource to the Authentication signed-up event, create a trigger. The trigger executes the Cloud Code script or module when the event is fired, for example, every time a new player signs up.

Run the new-file command to create a trigger configuration locally:

If you created a Cloud Code script, update the triggers-config.tr file with the following configuration:

If you created a Cloud Code module, update the triggers-config.tr file with the following configuration:

Deploy the configuration using the UGS CLI tool:

You should get a response similar to the following:

Now you have a trigger that executes your Cloud Code script or module when a player signs up.

Note: You can define multiple triggers to execute different Cloud Code scripts or modules for the same event. You can expand this use case to add more triggers to initialize other player data.

To validate the result, sign up a new player using the Authentication service. This can be done by calling out to any Unity Gaming Service that's authenticated as a player.

For example, to trigger the player authentication flow, you can select the Generate icon to generate a new player ID through the Cloud Code script page in the Unity Dashboard.

Given the trigger is configured to fire on the signed-up event, every new player that signs up, their values are initialized in Cloud Save.

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
{
  "playerId": "string",
  "providerId": "string",
  "createdAt": "string"
}
```

Example 4 (unknown):
```unknown
{
  "playerId": "string",
  "providerId": "string",
  "createdAt": "string"
}
```

---

## Lobby data and player data

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/lobby-data-and-player-data

**Contents:**
- Lobby data and player data#
- Limits#
- Data access and visibility#
  - Public data#
  - Member data#
  - Private data#
  - Data access table#

Lobbies support two types of custom data:

There are three levels of access to data:

Depending on a player's role in the lobby (host, member, or non-member), they have different access restrictions to data:

Note: Only the host can modify lobby data. In addition, a player’s data can only be modified by the player themselves.

---

## CHANGESET

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/changeset

**Contents:**
- CHANGESET#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Executes advanced operations on changesets.

cm changeset <command> [options]

cm changeset <command> --usage

cm changeset <command> --help

cm changeset move cs:15@myrepo br:/main/scm005@myrepo

cm changeset delete cs:2b55f8aa-0b29-410f-b99c-60e573a309ca@devData

cm changeset editcomment cs:15@myrepo "I forgot to add the checkin details"

**Examples:**

Example 1 (unknown):
```unknown
cm changeset <command> [options]
```

Example 2 (unknown):
```unknown
cm changeset <command> --usage
```

Example 3 (unknown):
```unknown
cm changeset <command> --help
```

Example 4 (unknown):
```unknown
cm changeset move cs:15@myrepo br:/main/scm005@myrepo
```

---

## Configure stateful Audiences

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/ConfigureStatefulAudiences

**Contents:**
- Configure stateful Audiences#

To create custom stateful Audiences, go to Analytics > Audiences, and select Create Audience.

Give your Audience a name and description. Use rules paired with operators to define your Audience.

To use your Audience in a Game Override:

---

## Multiplay Hosting

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/welcome

**Contents:**
- Multiplay Hosting#
- Get started#
- Interfaces#

Welcome to Multiplay Hosting, Unity's scalable server hosting platform.

Note: Multiplay Hosting is Unity's self-serve experience for hosting and scaling your game. If you’re using the legacy version of game server hosting, refer to the Clanforge documentation.

Typically, a game developer or studio has expertise in areas directly related to game creation, such as gameplay, animation, and level design. However, successfully managing the hosting and scaling of multiplayer games can be challenging, and time pressures to ship your game. These obstacles can make multiplayer games challenging to implement, especially if you don't have enough servers to meet the player demands. Refer to the Ecosystem overview and Integrations to learn more.

Multiplay Hosting removes the complexity of running and operating infrastructure at scale, so your development team can focus on creating engaging player experiences. It also provides ways for you to:

Use the Get started guide to learn how to start leveraging Multiplay Hosting in your project.

Also check out the following samples to help you get started:

There are multiple ways to integrate and manage your application with Multiplay Hosting:

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/modules/getting-started

**Contents:**
- Get started#
- Video walkthrough#
- Set up the Unity Editor#
  - Link project#
  - Install required packages#
  - Install and set up .NET#
  - Set up the Deployment window#
- Create a C# Module Reference file#
- Generate a new module#
- Generate bindings#

This page describes the steps you need to create a C# module in the Unity Editor and deploy it to the Cloud Code service.

Note: Only Unity 2021.3 and above support Unity Editor integration for modules.

The examples in the workflow create a simple Hello World C# module. To get started with Cloud Code modules, follow these steps:

Note: For alternative authoring methods to create and deploy modules, refer to Write modules.

Watch the video below for a walkthrough of the steps to create a C# module in the Unity Editor and deploy it to the Cloud Code service.

To create Cloud Code modules within the Editor, you need to install the required packages and link your Unity Gaming Services project with the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

If you create a new Unity project, you can link your Unity Gaming Services project with the Unity Editor during the project creation process.

If you are working with an existing Unity project, you can link your Unity Gaming Services project with the Unity Editor from the Services window.

In Unity Editor, select Edit > Project Settings > Services.

Link your project.If your project doesn't have a Unity project ID:

If you have an existing Unity project ID:

Your Unity Project ID appears, and the project is now linked to Unity services.

To create Cloud Code modules within the Editor, you need to install the following packages:

Note: Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

You can install and add these packages to your list of available packages from the Package Manager window in the Unity Editor:

To deploy Cloud Code modules in the editor you need to install .NET.

To set your default .NET path in editor, use the following steps:

The Deployment window allows you to deploy Cloud Code modules to your remote environment.

If you installed the Deployment package, you can access it from the Unity Editor.

Before you can use the Deployment window, you need to select the environment you want to deploy to:

To create a Cloud Code module within the Unity Editor, you need to create a Cloud Code C# module reference file. This file is a reference to a solution containing the C# module project you want to deploy.

The new module reference is now visible in the Project window and in the Deployment window.

A Cloud Code module is a simple .NET project which exposes endpoints that a game client can call. In the Unity Editor, generating a module creates a solution with a module template that you can modify. To learn more about how a Cloud Code module is structured, refer to module structure.

With a module reference file, you can generate a new module from the Deployment window. The generated module contains the required basic setup for you to start to develop your module.

You can also generate a new module directly from the Deployment window.

You can find the generated module in the root directory of your Unity project, in the HelloWorld folder. The module is a .NET project that you can modify and extend.

Note: Cloud Code modules are .NET projects, so they use the NuGet Package Manager to manage dependencies. Cloud Code modules require the Cloud Code Authoring package to enable you to create endpoints you can call out to. This is a NuGet package that you can install into your project, and it's already included in the generated module.

After you generate a new module, you can generate bindings. Bindings are type-safe client code that you can use to call your module endpoints from your game client.

To make your module endpoints accessible to the game client, you need to deploy the module to the Cloud Code service. You can use the Deployment window to deploy modules.

To deploy the module:

For more information, check the Deployment package manual.

A successful deployment shows a green checkmark next to the module reference file in the Project window.

To verify that a deployment is successful, you can call the module endpoints from your game client. The generated module contains a default endpoint called SayHello.

To call a module function from your game, you first need to set up the Cloud Code SDK in your game client.

Note: Players must have a valid player ID and access token to access the Cloud Code services. You need to authenticate players with the Authentication SDK before you use any of the Cloud Code APIs.

The following example shows how to call the module function SayHello from the module HelloWorld within your game client.

Important: If a module hasn't received any traffic in the last 15 mins, you might experience a cold start latency. Any subsequent calls to the module are faster.

Learn about the next steps after deploying your first module.

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.deployment
```

Example 2 (unknown):
```unknown
com.unity.services.cloudcode
```

Example 3 (unknown):
```unknown
using Unity.Services.Authentication;
using Unity.Services.CloudCode;
using Unity.Services.CloudCode.GeneratedBindings;
using Unity.Services.Core;
using UnityEngine;

public class TestModule : MonoBehaviour
{
    private async void Start()
    {
        // Initialize the Unity Services Core SDK
        await UnityServices.InitializeAsync();

        // Authenticate by logging into an anonymous account
        await AuthenticationService.Instance.SignInAnonymouslyAsync();

        try
        {
            // Call the function within the module and provide the parameters we defined in there
            var module = new HelloWorldBindings(CloudCodeService.Instance);
            var result = await module.SayHello("World");

            Debug.Log(result);
        }
        catch (CloudCodeException exception)
        {
            Debug.LogException(exception);
        }
    }
}
```

Example 4 (unknown):
```unknown
using Unity.Services.Authentication;
using Unity.Services.CloudCode;
using Unity.Services.CloudCode.GeneratedBindings;
using Unity.Services.Core;
using UnityEngine;

public class TestModule : MonoBehaviour
{
    private async void Start()
    {
        // Initialize the Unity Services Core SDK
        await UnityServices.InitializeAsync();

        // Authenticate by logging into an anonymous account
        await AuthenticationService.Instance.SignInAnonymouslyAsync();

        try
        {
            // Call the function within the module and provide the parameters we defined in there
            var module = new HelloWorldBindings(CloudCodeService.Instance);
            var result = await module.SayHello("World");

            Debug.Log(result);
        }
        catch (CloudCodeException exception)
        {
            Debug.LogException(exception);
        }
    }
}
```

---

## Debug and monitor events

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/debug-events

**Contents:**
- Debug and monitor events#

You can use the Logging service to debug and monitor events.

You don’t need to do any additional instrumentation for Cloud Code as everything is handled out of the box. Add logging to your Cloud Code modules and scripts to debug and monitor the execution of your triggers.

The Triggers service emits the following logs by default:

Refer to Logging for more information and use case samples.

**Examples:**

Example 1 (unknown):
```unknown
triggering action for event
```

Example 2 (unknown):
```unknown
successful response from trigger action
```

Example 3 (unknown):
```unknown
error response from trigger action
```

Example 4 (unknown):
```unknown
error in event filter
```

---

## Release notes

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/core-release-notes

**Contents:**
- Release notes#
- Version 5.26.3#
  - Release overview#
  - Key features and bugs addressed#
  - API changes#
  - Known issues#
- Version 5.26.0#
- Release overview#
- Key Features and Bugs Addressed#
- Public API Changes#

Find release notes for all UGS products on the UGS release notes page.

Version 5.26.3 officially provides support for Nintendo Switch™ 2.

Version 5.26.0 introduces comprehensive audio processing improvements with enhanced noise suppression, expanded platform support for audio processing features, and significant performance optimizations.

This release focuses on improving voice quality while optimizing resource usage across all supported platforms.

For further technical details on all the changes included in this release, refer to the CHANGELOG.md file within the SDK.

Audio Processing Improvements:

Performance Optimizations:

Existing AEC/AGC platforms:

New AEC/AGC platforms:

Memory allocator improvements reducing heap memory requests.

Platform-Specific Changes:

Implementation Considerations:

**Examples:**

Example 1 (unknown):
```unknown
CHANGELOG.md
```

Example 2 (unknown):
```unknown
vx_get_noise_suppression_enabled
```

Example 3 (unknown):
```unknown
vx_get_noise_suppression_level
```

Example 4 (unknown):
```unknown
vx_set_noise_suppression_enabled
```

---

## Privacy and consent

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/privacy-and-consent

**Contents:**
- Privacy and consent#
- Privacy overview#
- Apple privacy survey#
- Google Play data safety#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## Privacy and consent for Friends

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/privacy-and-consent

**Contents:**
- Privacy and consent for Friends#
- Privacy overview#
- Apple privacy manifest#
- Google Play data safety#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---

## APPLYLOCAL

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/applylocal

**Contents:**
- APPLYLOCAL#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Checks for local changes (locally moved, locally deleted, and locally changed) and applies them, so that UVCS starts tracking those changes.

cm applylocal | al [--dependencies] [<item_path>[ ...]] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

cm applylocal foo.c bar.c

(Applies all local changes in the current directory.)

(Applies all local changes in the workspace.)

cm applylocal --machinereadable

(Applies all local changes in the workspace, and prints the result in a simplified, easier-to-parse format.)

cm applylocal --machinereadable --startlineseparator=">"

--endlineseparator="<" --fieldseparator=","

(Applies all local changes in the workspace, and prints the result in a simplified, easier-to-parse format, starting and ending the lines and separating the fields with the specified strings.)

**Examples:**

Example 1 (unknown):
```unknown
cm applylocal | al [--dependencies] [<item_path>[ ...]] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
cm applylocal foo.c bar.c
```

Example 3 (unknown):
```unknown
cm applylocal .
```

Example 4 (unknown):
```unknown
cm applylocal
```

---

## Fair usage

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/fair-usage

**Contents:**
- Fair usage#

The Relay service is intended for the transmission of multiplayer game state only. Usage of the service outside this category is subject to rate limiting or termination under terms of service.

Unfair use of the Relay service includes, but isn't limited to, the following examples:

---

## Reconnect to lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/reconnect-to-lobby

**Contents:**
- Reconnect to lobby#

When using Relay and Lobby together, the services attempt to synchronize the relay connection state with the lobby membership. If the user unexpectedly disconnects from Relay, it notifies the Lobby service, which marks the user as disconnected in the lobby metadata.

If the user disconnects from the Lobby event system, this user is also marked as disconnected in the lobby metadata.

If the user can't reconnect to the services, they are automatically removed from the lobby after a timeout. If the user can reconnect, they can ask the Lobby service to mark the user as connected by using the ReconnectToLobby API.

This functionality is provided in the SDK through the ReconnectToLobbyAsync function, which is displayed in the following code example.

**Examples:**

Example 1 (unknown):
```unknown
ReconnectToLobby
```

Example 2 (unknown):
```unknown
ReconnectToLobbyAsync
```

Example 3 (unknown):
```unknown
using System;
using UnityEngine;
using Unity.Services.Authentication;
using Unity.Services.Core;
​
async Task Reconnect()
{
    await LobbyService.Instance.ReconnectToLobbyAsync(lobbyId);
}
```

Example 4 (unknown):
```unknown
using System;
using UnityEngine;
using Unity.Services.Authentication;
using Unity.Services.Core;
​
async Task Reconnect()
{
    await LobbyService.Instance.ReconnectToLobbyAsync(lobbyId);
}
```

---

## Configure your workspace

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/configure-workspace

**Contents:**
- Configure your workspace#
- Configure maximum preview file size#
- Exclude private items from directory size#

Select which files and directories you want to work on to download them to your workspace.

A workspace is your working directory that contains the project files you create, modify, and delete. You can configure your workspace:

Note: Use Ctrl+A/Cmd+A to select all the nodes in the tree, and then use the space bar to toggle the load/unload status.

Note: To configure your workspace in the command line, use the cm partial configure command.

You can select Configure at any point to load or unload files in your workspace. If you unload a folder that contains private or ignored items, Gluon can't delete them as you can’t remove items outside Gluon's control.

You can configure the maximum file size to generate at the preview of a file when that file isn't loaded in the workspace. To do so, add the following key to your client.conf file:

The default value is 1 MiB (1,048,576 bytes). This means that, if the selected, non-loaded file size is more than 1 MiB, Gluon doesn't download it to generate a preview. Gluon still displays the icon, size, and attributes.

Both the Explore workspace and Configure windows display your directory size. You can choose whether Gluon includes any private items when it calculates the directory size.

To exclude private files, right-click in the Explore workspace tab and select Options > Exclude privates from directory size.

**Examples:**

Example 1 (unknown):
```unknown
cm partial configure
```

Example 2 (unknown):
```unknown
client.conf
```

Example 3 (unknown):
```unknown
<MaxPreviewFileSize>1048576</MaxPreviewFileSize>
```

Example 4 (unknown):
```unknown
<MaxPreviewFileSize>1048576</MaxPreviewFileSize>
```

---

## Find replication logs

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/cm-find/find-replicationlog

**Contents:**
- Find replication logs#
- Filtering options#
- Output options#
- cm find replication log example#
  - PowerShell#
  - Bash#
  - Result#

Find and filter replication operations.

The following list displays the different filtering options (where) that are available to use with the cm find replicationlog command:

The following list displays the different output options (--format) available to use with the cm find replicationlog command:

Find all the replication operations for a specific branch from any time chronologically:

If, for example, you want the last date, filter by date and use PowerShell or bash to select the last row.

**Examples:**

Example 1 (unknown):
```unknown
cm find replicationlog
```

Example 2 (unknown):
```unknown
repositoryname
```

Example 3 (unknown):
```unknown
cm find replicationlog
```

Example 4 (unknown):
```unknown
cm find replication
```

---

## Machine provisioning

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/machine-provisioning

**Contents:**
- Machine provisioning#
- Start on provision#
  - Start on provision enabled#
  - Start on provision disabled#
  - Best practices#

Behind the scenes, game servers run on machines. These machines can be physical machines in a data center or cloud machines from a cloud provider, such as Google Cloud Platform.

Before Multiplay Hosting can use a machine to host your game servers, it must configure the machine to best suit your needs. This configuration process is called machine provisioning.

Multiplay Hosting does the following during the machine provisioning process:

The start on provision setting controls when game servers start. It has important implications for how the game server lifecycle and the allocation lifecycle work in a fleet.

For example, if you use a multi-session allocation lifecycle, enabling the start on provision setting ensures servers are ready to fulfill an allocation as soon as the machine is ready.

Start on provision is disabled by default. You can change this setting by contacting Unity Support.

If the start on provision setting is enabled, Multiplay Hosting starts game servers after provisioning the machine they exist on.

Multiplay Hosting also automatically restarts servers after an intentional exit, giving the servers time to load resources before receiving the next allocation. This functionality shortens the time before the server’s ready to receive the next allocation.

Warning: Multiplay Hosting requires servers to start during the machine provisioning process if the start on provision setting is enabled. This means that if a build executable fails to start due to a bug (or another reason), it will prevent the fleet from scaling.

If the start on provision setting is disabled, Multiplay Hosting doesn’t start game servers after provisioning the machine they exist on. Instead, Multiplay Hosting starts game servers when they’re allocated.

Multiplay Hosting doesn’t restart a build executable process after an intentional exit if the fleet has the start on provision setting disabled.

The recommended best practice for the start on provision setting depends on how you manage your game’s sessions. As a result, there’s no definitive best practice for when to enable (or disable) the start on provision setting. However, in general, starting servers on machine provision works well for multi-session allocations–but that doesn’t mean it can’t work for single-session allocations.

If you use multi-session allocations (long-lived sessions), it might make sense to enable the start on provision setting. This way, game servers start during the machine provisioning process, and they’re ready to accept allocations as soon as Multiplay Hosting provisions the machine. It also ensures servers restart automatically after an intentional exit.

If you use single-session allocations, it might make sense to disable the start on provision setting. This way, game servers don’t start until you allocate them.

Warning: Multiplay Hosting requires servers to start during the machine provisioning process if the start on provision setting is enabled. This means that if a build executable fails to start due to a bug (or another reason), it will prevent the fleet from scaling.

---

## Unity Version Control 11.x Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/11

**Contents:**
- Unity Version Control 11.x Release Notes#
- 11.0.16.9692#
  - New#
    - Asynchronous VFS Processing#
  - Bug#
    - Preserve external file renames/moves during refre…#
    - Download correct installer when updating in ARM#
    - The server could not generate a self-signed certi…#
- 11.0.16.9677#
  - New#

This document contains all release notes for Unity Version Control major version 11.x, organized from newest to oldest.

All platforms - Plugin for JetBrains IDEs: Asynchronous VFS Processing

The processing of file system changes has been improved to run asynchronously, preventing main thread blocking and enhancing overall plugin performance and responsiveness during intensive file operations.

All platforms - Plugin for JetBrains IDEs: Preserve external file renames/moves during refresh instead of converting to delete+add

When a file was moved via the OS file explorer, the desktop app correctly marked it as Moved, but opening the Rider plugin converted it to a Delete + Add pair. This behavior has been corrected, during refresh, external renames/moves are now detected and preserved as a single move/rename operation, preventing spurious add/delete changes and keeping version history intact.

macOS - Desktop GUI: Download correct installer when updating in ARM

When updating to a new version from the application on macOS, we were not taking into account the OS architecture, and always downloaded the installer for Intel-based processors. Now if you are using a Silicon Mac, the ARM version of the application will be installed on the upgrade

macOS Tahoe – Server: The server could not generate a self-signed certificate on macOS Tahoe.

In macOS Tahoe, the server failed to generate a self-signed certificate.

The server automatically generates a self-signed certificate when it is configured to listen on a secured port through network.conf and no other certificate settings are provided for that port. The same applies to the HTTPS port used by the WebAdmin.

Starting with macOS 26 (Tahoe), changes in the Keychain subsystem prevented the plasticd process from creating a valid self-signed certificate, resulting in the following error:

This issue has now been fixed.

All Platforms – All Clients: Improved shelveset creation with Smart Locks

Previously, the "Shelve" operation failed if it encountered files that cannot be checked-out due to exclusive check-out rules.

Now, the operation succeeds by creating the shelveset and including those files without requiring a check-out.

This enhancement applies to both partial and regular workspaces.

Windows - Desktop GUI: Fixed dialog focus on first click

For some modal dialogs in the application, when you first clicked on them they were losing the focus, requiring a second click to focus them again and be able to use them. We fixed this issue, and now on the first click the focus is kept.

Windows - Dynamic workspaces: Add the modification status for checked-out files.

The Pending Changes view now accurately reflects the status of your files. Previously, when using a dynamic workspace (plasticfs), checked-out files were always shown as unchanged, even after being modified. This issue has been fixed, and the view now correctly displays these files as changed when they have been modified.

All platforms - Desktop GUI: Added support for updated Jira REST API search endpoints

Enhanced Jira integration with intelligent endpoint detection that automatically uses the new search/jql API when available and gracefully falls back to the legacy search?jql endpoint when needed, ensuring seamless compatibility across all Jira versions without requiring any configuration changes.

All Platforms - Desktop GUI: Allow selecting the Branch Base when creating new branches

The Create Branch dialog now allows you to choose the base branch when creating a new branch from the quick branch selector (toolbar popup).

If your current branch is not the main branch, you'll see an option to select either the main branch (default) or your current branch as the base. When working from the main branch, this option will be hidden.

All Platforms - Server: Fixed incorrect lock release in undo/check-in operations across workspaces.

Two users, X and Y, and an admin, A.

X locks a file and then goes on holiday.

Y needs the file and asks the admin to unlock it (either with Release or Remove).

Y locks the file and begins working on it.

X returns, notices they have the file checked out (but not locked, as Y now holds the lock), and performs an Undo Checkout.

This mistakenly removes Y's lock, even though it was acquired in a different workspace.

Now, the check-in and undo operations only update or release locks that were acquired in the same workspace where the operation is executed. Locks from other workspaces are ignored.

All platforms - Desktop GUI: Fixed global configuration for unified organizations (@unity)

An issue that was preventing the global configuration from syncing correctly when using unified organizations has been resolved. Global configs, such as issue tracker integrations, now download automatically, and the expected folders under AppData/local/plastic4/globalconfig are created again, including all global configuration files like ignore.conf. With this fix, both legacy and unified organizations now support global configuration successfully.

All platforms - Desktop GUI: Fixed horizontal scrolling issue on tables

There was a problem when scrolling horizontally and then vertically on tables, where some rows were shown with misaligned cells. This issue is now fixed and scrolling works as expected

All platforms - Plugin for JetBrains IDEs: Removed disruptive "Nothing was found to add" dialog

We suppressed a repetitive and hard-to-dismiss notification dialog that gets triggered when no items are detected for certain Add or Checkout operations. While we delivered a set of mitigations in previous releases, some users reported new occurrences of this dialog in certain scenarios where it negatively affects the user experience, offering no extra value.

All platforms - Command-line client: Personal Access Tokens are now available from the command line for Cloud organizations

Personal Access Tokens (PATs) allow you to authenticate non-interactive workflows (CI/CD, scripts, tools) against our Cloud service without sharing your password or compromising any other credentials.

You can use the cm accesstoken command family to manage your tokens. The PATs feature is opt-in, and access is controlled by the organization administrator — more on that later!

The process starts by creating a PAT. When using the command line (the feature is not yet available in the Cloud web portal), you must specify a description and a lifetime for the token. In this example, the token will be valid for 30 days:

Once the PAT is created, you can reveal it. Revealing the PAT displays the actual token you can later use in your workflows:

Users can audit their own tokens: list them, check when they were last used, and delete them. Organization administrators can audit both their own tokens and the tokens of other users in the organization.

Organization administrators can also manage who has access to the PATs feature. As mentioned earlier, this is an opt-in feature rather than opt-out. This ensures that only privileged users and groups can grant access to organization data through a PAT.

To grant access to the feature to all current and future users, add the special user 'all' to the allowlist:

To grant access to all users in a specific group (for example, "QA-hq"), add the group to the allowlist instead. If a user is removed from the group, they lose the privilege. Likewise, users added to the group gain the privilege.

The feature is currently available only through the command line client and will soon be available in the Cloud portal. Personal Access Tokens replace the old plasticscm.com's feature named "API Keys", that could be accessed from the "Edit Account" section on the old dashboard.

It is worth mentioning that PATs are valid only for the account and organization they were created against, whilst the old API Keys were account-wide and granted access to all the organizations the user was a participant of.

All platforms - Plugin for JetBrains IDEs: Fixed " is null" error during startup

Resolved an issue where the plugin for JetBrains IDEs could encounter a " is null" error during the startup process. This error was caused by an unhandled exception in the file checker module, which led to the error message being written to the IDE logs and could potentially interfere with plugin initialization in certain environments. The underlying exception handling has been improved to prevent this issue from occurring, ensuring smoother startup and more reliable plugin behavior across all supported JetBrains IDEs.

All platforms - Plugin for JetBrains IDEs: Fixed unresponsive "Nothing was found to add" dialog

This update completes an earlier fix for the "Nothing was found to add" dialog. In some cases, the dialog could still freeze the plugin and block input. We've now adjusted how dialogs are opened to follow JetBrains' recommendations for threaded processes, ensuring the dialog closes correctly or remains responsive as expected.

All platforms - Desktop GUI: Fixed initialization of the HtmlRenderer component

Fixed an issue that could cause the desktop application to throw an unexpected error during startup on certain system configurations. The initialization logic has been updated to handle these edge cases gracefully, resulting in more robust application startup and improved reliability for users on all supported platforms.

All Platforms - All clients: Fixed issue with revert operation failing due to path reused by different items

Previously, the revert operation for a directory would fail if the target revision attempted to load an item (file or directory) using a path already occupied by another item in the workspace.

All platforms - Plugin for JetBrains IDEs: Fixed unresponsive "Nothing was found to add" dialog

Resolved a condition where the "Nothing was found to add" dialog from the Plastic SCM integration could be displayed in a way that would block the UI thread. The dialog now functions as expected and will no longer cause the application to hang.

All platforms - Desktop GUI: Fixed null exception in labels view

Fixed a null reference exception that occurred when opening the Labels view while a branch filter was applied in the Changesets view. Previously, this issue could cause the Labels view to fail loading (or refreshing) under these conditions. The Labels view now opens and refreshes correctly regardless of branch filters applied in the Changesets view.

All platforms - Server: Fixed array dimensions exceeded supported range error

Windows - All Clients: Improved Path Canonization Performance

We've optimized how clients handle file paths on Windows across all commands.

Path canonization - which resolves symlinks, corrects casing to match the file system, and normalizes paths - now runs 30% faster. While each operation is lightweight, performance gains add up significantly when processing many paths. This improvement boosts overall efficiency in path-heavy workflows.

macOS - Installers: Added support for ARM architecture in UVCS installers

ARM installers are now available for macOS UVCS.

This update allows users on Apple Silicon (M1/M2/M3) devices to install and run UVCS natively without relying on Rosetta emulation. This improves performance and compatibility for the latest macOS hardware.

All Platforms - All Clients: Enhanced shelveset application

Previously, the "Apply Shelve" operation would fail entirely if it encountered files that could not be checked out due to exclusive checkout rules. No changes were applied, and the operation simply stopped.

Now, the operation has been improved to handle such cases more effectively. It can apply changes directly to the disk for files that cannot be exclusively checked out, without requiring a checkout. At the end of the operation, a report is provided, listing any errors for files that could not be checked out.

This enhancement applies to both partial and regular workspaces.

All Platforms - Command Line Client: Added the --dontcheckout option to skip checkouts when applying a shelveset.

The "cm shelveset apply" and "cm partial shelveset apply" commands now include a new --dontcheckout option. This allows users to apply shelvesets (saved sets of pending changes) without checking out conflicting files or modified files, leaving them as local changes instead.

This option is particularly useful for avoiding exclusive checkout restrictions when applying a shelveset.

All Platforms - Plugin for JetBrains IDEs: Supported file operations for ignored files

Command-line client: Faster checkout for thousands of files with cm

We recently improved checkout performance when handling large numbers of files. Files are now grouped by their parent directory and processed in batches, reducing overhead and speeding things up. In our tests, checking out 15,000 files from the same directory in the Desktop GUI dropped from 30 seconds to just 3 seconds - a 10x improvement*. However, cm was significantly slower due to the need to process the input paths right before running the actual checkout operation.

Additional optimizations were applied to this release, especially improving performance on Windows. Thanks to that, the checkout with cm goes from the original 46 seconds to just 10 seconds - almost an 80% reduction.

*Tested on a modern machine with a 10th-gen Intel i9 CPU and SSD running Windows 11.

All platforms - Plugin for JetBrains IDEs: Embed Clone UVCS repository workflow into "Get from Version Control" dialog

To align with recent IntelliJ API changes, we have updated the Clone functionality. Instead of launching a separate dialog wizard, the workflow is now fully embedded within the main "Get from Version Control" dialog. This provides a more seamless and integrated user experience.

All platforms - Desktop GUI and Gluon: Pending Changes View no longer refreshes unexpectedly

We’ve resolved an issue introduced in previous version 11.0.16.9523 that caused the Pending Changes view to auto-refresh unexpectedly, even when the Auto-refresh setting was disabled. This could interrupt workflows—such as reviewing a long list of diffs—by jumping back to the top of the list.

The auto-refresh behavior now correctly respects your configuration. Additionally, we now avoid interrupting your work with save/discard prompts while editing files with unsaved changes.

All platforms - Desktop GUI: Fixed "Switch to" operation didn't refresh current loaded branch/changeset

The "Switch to branch/changeset" operation did not trigger a UI refresh (e.g., topbar, Branch Explorer) upon completion when certain errors were encountered during execution—such as missing Xlink references.

This issue has now been resolved.

All platforms - Desktop GUI: Pending Changes view is now properly refreshed after merges

Resolved a regression introduced in previous version 11.0.16.9523 where the Pending Changes view did not auto-refresh after completing a merge if auto-refresh was disabled in the pending changes options. Now it's fixed.

All platforms - Desktop GUI: Fixed launch SemanticMerge as standalone null exception

An error was raised while running the Semantic Merge tool from the command line with unsupported file formats and using the sorted files arguments format.

plastic semanticmerge v1\README.md v2\README.md

Now, this mode (sortedFiles) is not failing for unsupported file formats.

All platforms - Plugin for JetBrains IDEs: Fixed Create workspace action not available

Now the "Create Plastic SCM workspace..." action under VCS main menu will be only visible for those projects which are not under a UVCS workspace, otherwise it will be hidden.

macOS GUI: Fixed crash that prevented the application from running on macOS 26 Beta

Whilst we don't provide official support for OS beta releases, we are grateful to the intrepid users who upgrade early and report these kind of bugs!

Linux - Installers: Fixed resolution of libicu dependency on Ubuntu 25.04

Some Ubuntu distros were showing an error while installing telling that there is an unmet dependency of libicu that cannot be resolved.

All platforms: Faster checkout for thousands of files

We've significantly improved checkout performance when handling large numbers of files. Files are now grouped by their parent directory and processed in batches, reducing overhead and speeding things up.

In our tests, checking out 15,000 files from the same directory in the Desktop GUI dropped from 30 seconds to just 3 seconds—a 10x improvement. (Tested on a modern Windows machine with a 10th-gen Intel i9 CPU and SSD).

All platforms: Faster status (pending changes)

Good news: Pending changes status updates are now 3-4 times faster! You'll experience the biggest boost in speed after a machine restart, for the very first calculation on any Unity Version Control client, and with every calculation on the command-line interface (CLI).

This enhancement will especially benefit users running Unreal Engine 5 projects with One File Per Actor (OFPA) enabled, along with those who manage large workspaces that can contain hundreds of thousands of directories.

All platforms - Desktop GUI and Gluon: Pending Changes Status in the Top Bar

We’ve introduced a new mechanism that monitors your pending changes and updates the status overlay in the top bar. The working object icon now clearly displays a blue dot overlay when pending changes are detected, making it easier to track work that needs to be committed.

All platforms - Server: LDAP groups are not always identified as groups

When using an LDAP server, some groups were wrongly identified as users instead. This can happen with some LDAP providers like OpenLDAP.

We fixed that, and now they are properly told apart.

All platforms - Desktop GUI: LDAP user names weren't shown in the 'Changeset colors' panel

When using LDAP, user SIDs were shown instead of their names in the 'Changeset colors' panel, located in the Branch Explorer.

We changed this to shown the actual name of the user. If you already have some users added there, you can remove the entries and add them again so the display name gets updated.

All platforms - Desktop GUI: Fixed closing the ephemeral notification banner

The app showed a "A task was cancelled" error after manually closing the notification banner.

All platforms - Desktop GUI: Branch Explorer runs 'before-merge' trigger when there are incoming changes

Windows – Desktop GUI: Drag & drop files from Workspace Explorer to external destinations

You can now drag and drop files from the Workspace Explorer tree view to any location on your file system. This also includes the ability to open files directly in external applications (e.g., Notepad).

All platforms – Desktop GUI: Fixed broken link to Dynamic Workspaces documentation

The URL for the Dynamic Workspaces documentation has been updated. It now correctly points to:

All platforms - Gluon: Support for custom client messages from OnPremise servers

The customizable banner available for OnPremise servers is now supported by the Gluon client.

Command-line client: New "cm getconfig organization" command

This new command will retrieve the information of a Cloud organization stored in the configuration.

You can use --format to change the output:

If no organization is explicitly passed and the cm is within a workspace, it will return the organization information of the workspace. Otherwise, it will show the information of the default organization.

Command-line client: Restore checkout as visible in showcommands

All Platforms - Desktop GUI: Added List/Tree mode switcher to Available branches dialog

It is now possible to visualize the list of available branches as a tree view in the “Available Unity VCS branches” dialog, and switch between 2 modes: list and tree.

All Platforms - Desktop GUI: Persistent the tab selection while changing workspace

If a new workspace is loaded in the application, the Workspace view will be displayed. Otherwise, the last opened view will be displayed. Additionally, the latest loaded view will persist when the application is opened.

Linux - Installers: Debian and Ubuntu won’t fail if ‘xdg-mime’ tool isn’t installed

From now on, if xdg-mime tool (from xdg-utils package) is not installed in the operating system, the installation of plasticscm-client-gui package won’t fail.

Instead, the custom plastic:// links (code review links, changeset links, etc) won’t be recognized and hence won’t be shown in the GUI application when clicking on them.

If this happens, we recommend installing xdg-utils package in the system to ensure the custom plastic:// links are recognized, by running the following command:

All platforms - Server: Support for custom client messages in OnPremise servers

Administrators of OnPremise servers now have the ability to force-display custom messages directly on the client side. Whether you're issuing a critical security alert, rolling out new usage policies, or just want to keep users informed about important updates, this feature puts communication front and center.

== How do I use it? ==

This new functionality is available under the WebAdmin section "Advanced -> Global security settings -> Custom client message", and supports a basic subset of HTML tags.

Once set, clients connecting to any workspace under the server will display a banner with the configured notice.

== Who can remove the banner? ==

Only administrators can remove it by reseting the "Custom client message" field in the WebAdmin.

== A note on visibility ==

This feature is currently supported by the Unity Version Control desktop client, and will be extended to Gluon in a future release.

All Platforms - Desktop GUI: Fixed opening plastic links for migrated @unity organizations

Previously, plastic links for code reviews or diff would fail to open with the Desktop GUI for newly migrated @unity organization having names in CamelCase. With this fix, it is now possible to open these links.

All Platforms - Desktop GUI: Fixed broken onboarding in DVCS edition

The user account sign-in did not work as expected in the Home view for the DVCS edition version. It was because the account was managed as a cloud account instead of an on-premises account.

Now the user can sign in to the local server and obtain the list of repositories for this server.

All Platforms - Server: Merge rules now correctly enforced when using old repository names

All Platforms - Desktop GUI: Issue trackers - Supported MULTIPLE_PROJECTS configuration

Now, Jira issue tracker extension accepts "MULTIPLE_PROJECTS" value for the Project key configuration parameter.

This way, each branch explicitly contains the project key of its related task, instead of defining a global project key for all branches.

All Platforms - Server: Merge rules are now correctly updated when a repository is renamed.

Previously, renaming a repository caused its associated merge rules to retain the old repository name, resulting in the rules being ignored. With this fix, the repository name in affected merge rules is properly updated upon renaming.

Note: This fix does not apply to merge rules that use wildcard patterns.

All Platforms - Server: Trigger filters now correctly handle repository renames.

Previously, when a repository was renamed, the associated trigger filters retained the old repository name, causing the triggers to be ignored. With this fix, the repository filters in affected triggers are properly updated upon renaming.

More info about trigger filters here.

All platforms – DevOps: Mergebots now correctly handle repository renames.

Previously, when a repository was renamed, associated mergebots continued referencing the old repository name. This caused them to stop functioning, even after a restart, unless their configuration was manually updated.

With this fix, mergebot configurations are automatically updated when a repository is renamed, allowing them to continue working seamlessly.

It applies to trunkbot & conflictsbot.

Windows - Installers: Enterprise Edition installer didn't start the GUI client app

All platforms - Plugin for JetBrains IDEs: Fixed diff operation for unity organizations

We fixed an issue provoking the diff panel to fail loading the content of a remote revision under certain conditions.

Server: Restore cm find ability to return parent changesets along with hidden branches

Let's say we have the following changesets:

You could retrieve the parent of the changeset 43 with the following command:

However, if you hid any other branch in the repository at some point, the same command would wrongly return the grandparent changeset:

All Platforms - Desktop GUI: Added copy changeset/shelve link to notifications

When performing a check-in or shelve, users can now easily open and copy diff and shelve links directly from the success notifications displayed at the bottom. Notifications also include links to open the recently created changeset or shelve, improving navigation and sharing changes with other users.

All Platforms - Desktop GUI: Issue trackers - Supported branch names with description

Before this change, issue trackers only supported branch names with format: {branch_prefix}{taskId}.

Now, users can use different formats of branch names {branch_prefix}{taskId}{any_text}, i.e.

Command-line client: Client API now handles modules properly

When using the ‘cm api’ command, endpoints taking a repository in the route were not properly handling submodules, preventing its use.

We fixed it to work as intended. Please remember to escape the repository separator when using submodules on routes!:

DevOps Mergebots: Jira plug now writes the Release Date field on new version creation

From now on, the Jira integration for Mergebots writes the "Release Date" field on "createrelease" action (new Jira version creation).

Before, just the version name and description were set.

All Platforms - Desktop GUI: Improved support for workspace-related actions in Plastic links

When opening a Plastic link, the application now enables workspace-related actions—such as diff, undelete, history, and annotate—in the Diff or Code Review window. It automatically selects the most recent workspace associated with the Plastic link's repository. If no workspace is found, these actions are just disabled (as previously) to ensure a consistent user experience.

All platforms - Desktop GUI and Gluon: Added option to diff the changeset of moved and deleted history items

Before, accessing the changeset diff was only possible for history items that represented new revisions with actual changes.

Now you can quickly open the diff tool in the history view from a moved or deleted item out of convenience.

Command-line client: Fix for incorrect .plastic renaming issue

Previously, it was possible to delete a file and then use the cm move command to rename another file as the workspace configuration directory (.plastic by default):

Example of the sequence that causes the problem:

While the file wasn’t actually renamed on disk and the directory remained intact, this behavior was unintended and could cause confusion.

From now on, renaming any file to .plastic won't be possible (to prevent reaching an inconsistent workspace status) and will show the following controlled error message instead:

Command-line client: Fix 'no such user or group' error when editing the ACLs

When using the cm acl command, users and groups were wrongly solved against your default server (the one set up in your client.conf file). This led to errors or unexpected behavior when targeting a different repository.

Command-line client: Fix 'no such user or group' error when setting the owner of an object

When using the cm setowner command, users and groups were wrongly solved against your default server (the one set up in your client.conf file). This led to errors or unexpected behavior when targeting a different repository.

Command-line client: Improved GitHub LFS Syncing

We have fixed an issue when syncing GitHub repositories containing large files (over 2 GB) using the command-line client.

With this fix, the cm sync command now handles pulling files exceeding 2 GB.

All Platforms - Desktop GUI: Fixed Branch Explorer Label menu

Fixed an issue where label context menu actions in the Branch Explorer (rename, delete, etc.) worked only the first time, then stopped responding on subsequent attempts. All label menu items now function consistently for multiple operations.

All platforms - Desktop GUI: Incorrect Error Message

Fixed an issue where an incorrect error message was shown when attempting to apply changes from a shelf.

The error message now correctly describes the issue, providing accurate information about what went wrong.

All Platforms - Desktop GUI: Double-clicking a file from a Plastic link causes an error

Previously, double-clicking a file in a Plastic link (e.g., in code reviews or branches) caused a NullReferenceException. This issue has been resolved by ensuring the application verifies whether the diff action is available before executing the double-click operation.

All platforms - Plugin for JetBrains IDEs: Branch detection after external switch

All platforms - Server: HTTP request and response buffer sizes are now configurable.

If you use the Unity Version Control WebAdmin tool and/or APIs, you can now configure the HTTP request and response buffer sizes. Bear in mind that this is a server-side configuration, so it can only be customized by on-premise Plastic accounts.

Configuring these buffers' sizes can be useful, for example, to increase throughput in high-latency networks, or, in memory-constrained scenarios, to support more concurrent clients through HTTP.

You can control both settings using the following server.conf configuration keys:

Not specifying the new configuration key, or using a value of -1, indicates that the default buffer size (1MB for requests, and 64KB for responses) should be used.

All platforms - Server: Enhanced control over audit.log file management

Two new configuration keys have been added to the server.conf, allowing you to control audit log file rotation and retention:

Setting AuditLogMaxSizeInMB enables the automatic rotation of audit.log files. When a log file reaches the specified size, it is renamed with a timestamp, following the pattern:

If AuditLogMaxFiles is set, the server will retain the current log file plus the specified number of rotated files.

This update gives you more flexibility in managing log file growth and retention!

All Platforms - Gluon: Security changes now properly update cached changeset trees

Gluon workspaces cache server changeset trees to enhance performance. However, security changes on the server were not properly reflected in the cached trees, potentially leading to outdated visibility information.

All Platforms - Desktop GUI: Support for legacy workspaces in upcoming organization migration (more info here, in our dedicated technical documentation)

This update prepares the Desktop GUI for the upcoming migration from legacy cloud organizations to unified Unity organizations. Changes have been implemented to ensure that workspaces created using the legacy format will remain visible in the repositories list, and they will be properly linked to their repositories after the migration.

Users can expect a smooth transition with backward compatibility for existing workspaces when the migration takes place later this year.

All Platforms - Desktop GUI: Workspace Explorer context menu wrongly updated

The 'New' and 'Change revision type' context menu options were incorrectly computed using the previously right-clicked item instead of the current one.

Right-clicking a directory followed by a file could allow unintended options like "New" to be available. The behavior has been fixed! The context menu now correctly updates based on the currently selected item.

Command-line client: Prevent credentials prompt for @unity organizations when using username/password or token

We've fixed an issue affecting the command line client when determining the datacenter for the new unified organizations (name@unity).

Windows - Installers: Simplified install cycle with less steps

Removed redundant "Start Classic GUI or Gluon" question, since the first startup after a fresh install already asks for this choice.

Removed component selection window, since it allowed the installation of the Eclipse plugin, which is still possible by copying the bundled plugins .jar files located at $INSTALL_DIR/client/plugins/eclipse directory.

A "README.txt" file can be found in that directory with installation instructions.

Besides that, the "More installers and other Operating Systems" section of https://www.plasticscm.com/download enables downloading a "Plugins zip" file containing all java-based plugins, including eclipse plugin.

All platforms - Command-line client: Incoming Changes support for 'cm partial update' command

A new '--incoming' option has been added to the 'cm partial update' command, aligning its behavior with Gluon. This enhancement scans for local workspace changes and applies only those relevant to the operation. Additionally, it will attempt to automatically merge any file conflicts it encounters.

All platforms - Command-line client: Fixed issue when running merge-to outside of a workspace

When trying to run a merge-to operation while the current working directory is not inside a workspace, we were showing an error. Now you can successfully complete the merge-to from any location.

All platforms - Gluon: Check-in failure when reverting a directory with moved items

Fixed an issue where Gluon failed to check in a directory revert operation if any item had been moved between the workspace revision and the reverted revision. The operation would throw the error: "An item with the same key has already been added." This issue has now been resolved.

All platforms - Gluon: Fixed checkin success message

After performing a checkin in Gluon, we show a notification at the bottom telling that the operation was completed successfully. This message was notifying of a successful shelve operation, instead of a checkin. We fixed the text of the notification.

All clients: Incoming Changes may incorrectly flag files as modified despite no actual changes

All Platforms - Desktop GUI: Next/Previous diff shortcuts

We’ve restored the Ctrl+N and Ctrl+M (Cmd+N and Cmd+M in macOS) shortcuts to navigate between differences in the Diff Control.

Now you can move to the next/previous/first/last change without using the mouse.

We also improved focus handling, so these shortcuts work immediately when a diff window or code review is opened.

All Platforms - Desktop GUI: Improve PlasticFS (dynamic workspaces) setup

The command-line option to start the PlasticFS agent has been renamed from --install to --add-to-startup for better clarity.

The EnableCreateDynamicWorkspace GUI configuration key has been removed, as it is no longer needed.

The setup panel text has been rewritten to better explain what PlasticFS is.

All platforms - Desktop GUI & Gluon: "Revert to this revision" for directories

"Revert to this revision" option is now enabled for directories from the history view.

We've also added the history view menu for directories in Desktop GUI bringing it in line with Gluon for a more consistent experience.

All platforms - Plugin for JetBrains IDEs: Renewed icons in the plugin for the JetBrains IDEs

All the icons have been replaced with new designs used from the rest of the UVCS product suite.

Server – All Platforms: Lock rules now update automatically after renaming a repository

Previously, when a repository was renamed, any associated lock rules had to be updated manually; otherwise, they would no longer apply to the renamed repository.

Now, lock rules are automatically updated, ensuring they remain effective without requiring manual intervention.

All Platforms - Desktop GUI: Fixed wrong file for code review comment

Fixed an issue that placed user comments in the previously selected file rather than the intended file when adding comments after switching files from the “Find in files” results.

All Platforms - Desktop GUI: "Find in files" navigation in Diff Window

Navigating between different files in the Diff Window using “Find in files” caused incorrect scrolling and highlighting. Now it’s fixed: Scrolling and highlighting correctly follow the chosen file.

All Platforms - Desktop GUI: Disable “Add to Source Control” for Controlled Items

Selecting a controlled item together with private files in the Workspace Explorer, triggered an error when using “Add to source control.”

Now, the option is only enabled if all selected items are private, preventing unexpected behavior for controlled items.

All Platforms - Desktop GUI: Fixed Code Review Comment navigation

Previously, users needed multiple double-clicks to focus on regular code review comments due to a bug. Now, double-clicking a comment works as expected: it automatically centers and highlights the correct line.

All Platforms - Plugin for JetBrains IDEs: Fixed plugin versioning

The project structure was adapted to properly version the plugin.

All Platforms - Plugin for JetBrains IDEs: Fixed error about deprecated "ActionUpdateThread.OLD_EDT"

Solved an issue present in JetBrains IDEs version 2024 and above, where the system complained about using the deprecated API component "ActionUpdateThread.OLD_EDT".

macOS - Plugin for JetBrains IDEs: Fixed plugin not exported during installation

All platforms - Plugin for JetBrains IDEs: IntelliJ SDK upgraded to 2022.3

We have reformulated the plugin structure to make use of the IntelliJ Platform Gradle Plugin.

This change allowed us to securely upgrade our plugin to offer better support for JetBrains IDEs version 2022.3 and above.

The new version of the plugin is now distributed as a zip file under the plastic installation folder "client/plugins/intellij", and you can reuse this file across all your IDEs. We also include a README file with installation instructions alongside the plugin package.

Windows - PlasticFS: Relocate the storage into a separate disk

By default, PlasticFS backing storage is located at %LocalAppData%\plastic4\plasticfs-storage. Now you can relocate yours into a different directory or disk.

For that, you can just create a plasticfs.conf file next to your client.conf file, also located by default at %LocalAppData%\plastic4.

Then write something like this inside the file:

The plasticfs-storage directory contains the PlasticFS shared cache among other things. The size of this subdirectory will grow as PlasticFS downloads file data on demand. If you want to move the shared cache in isolation, you can also do it, like this:

Now follow these steps:

Stop the PlasticFS tray application.

If you already have a plasticfs-storage directory, move it to its new location. The same goes for plasticfs-shared-cache if you want to move that one.

Restart the PlasticFS tray application, so the configuration file takes effect.

If you want to preserve your existing workspaces, but you didn't follow the second step correctly, a brand new storage directory will be created at the new location and you will be prompted with an error by the tray application. Don't panic! This can be fixed by stopping PlasticFS and replacing that new storage directory with the old one.

All platforms - Plugin for JetBrains IDEs: Fixed error updating files with pending changes

The "Update file/directory" feature has been changed to update the whole workspace instead of single items, and renamed to "Update Workspace", as this is how it should work for standard workspaces.

This way the use cases are,

Update Workspace with no changes should load all the incoming changes.

Update Workspace with changes and no conflicts should load all the incoming changes.

Update Workspace with changes and conflicts should NOT load all the incoming changes and show this error message:

"Error:The update operation detected conflicts. The operation cannot continue since it was run with the --dontmerge option."

All platforms - Plugin for JetBrains IDEs: Annotate not supported from History revisions

The Annotate operation has been allowed for revisions listed in the History view.

All platforms - Plugin for JetBrains IDEs: Fixed java.lang.NoSuchMethodError issue

This error was raised because of the usage of a removed feature from the "com.intellij.util" package (SystemProperties.getLineSeparator()), the usage of this reference has been replaced by System.lineSeparator(), which is still being supported and it's not deprecated.

All platforms - Desktop GUI/Plugin: Ignore.conf is reformatted after adding a new file via the GUI

Fixed an issue where adding new rules caused the ignore.conf, cloaked.conf, or hidden_changes.conf files to be reformatted, which could result in the loss of comments.

Now, comments are retained when updating ignore.conf, cloaked.conf, and hidden_changes.conf.

All platforms - Desktop GUI: Show the list of changesets when diffing a hidden branch

When opening the code review of a hidden branch, the list or changesets appeared empty. The same happened when diffing a hidden branch.

Now, the changesets list of the hidden branch is properly shown.

All platforms - Desktop GUI/Gluon: Improved shortcuts handling

We’ve resolved an issue where using certain keyboard shortcuts without a selection could cause unexpected errors.

For example: In the labels view, pressing Ctrl + D before selecting any label would result in an error.

All Platforms - Desktop GUI: Fixed wrong Switcher Window on startup

We fixed an issue where the switcher window always appeared after installing the Enterprise edition over the Cloud edition.

The problem occurred because of the client.conf file was not updating the LastRunningEdition field when certain configurations were empty.

Now, the last used workspace is correctly remembered, and the switcher window only appears when needed.

All Platforms - Desktop GUI: Properly show private directory contents

Previously, selecting a private directory in the pending changes view, caused two issues:

The directory contents were not displayed in the Content Viewer.

An empty side panel remained visible on the left.

Both issues are now resolved.

All Platforms - Desktop GUI: TextEditor find popup didn't process keyboard shortcuts properly

Shortcuts like Cut, Paste, Select All, and others were intercepted by the diff view instead of the “Find…” popup. Now, the keyboard commands behave correctly when the “Find…” text field is focused. It also fixes tab navigation to move focus as expected.

Windows - PlasticFS: The installer does not honor the PlasticFS configuration on restart

When upgrading to a different version of Unity VCS while using PlasticFS, you are asked to stop the PlasticFS tray application. So far, the installer did restart PlasticFS at the end, but it didn't do it ignoring any special configuration.

All platforms - Server: Prevent moving a repository inside itself

Previously when you moved a repository under itself (MyProject/MyRep -> MyProject/MyRep/tests) fails with the error "Module can't be created because parent repository doesn't exist." and the repository ends up unreachable.

Now when you try to move a repository under itself the operation fails with a meaningful error "The repository 'MyProject/MyRep' cannot be moved inside itself 'MyProject/MyRep/tests'." and the repository remains with its old name.

All platforms - Desktop GUI: Focus set to the Search filter text box

When adding users to code reviews through the "Select user or group" dialog, the focus is now automatically placed in the Search filter text box.

All platforms - Desktop GUI: Ignore.conf is reformatted after adding a new file via the GUI

Fixed an issue where adding new rules caused the ignore.conf, cloaked.conf, or hidden_changes.conf files to be reformatted, which could result in the loss of comments.

Now, comments are retained when updating ignore.conf, cloaked.conf, and hidden_changes.conf.

All Platforms - Desktop GUI: Prevent duplicate key error in Pending Changes

All platforms - Gluon: Folder History Feature Added

We’ve introduced the ability to view the history of folders in Gluon. This enhancement makes it easier to track changes, access previous versions, and stay informed about updates within directories.

Command-line client: New variables in check-in triggers

Added new environment variables to the check-in triggers:

PLASTIC_REPOSITORY_NAME: The repository name where the check-in is run.

PLASTIC_BRANCH_NAME: The name of the check-in target branch.

PLASTIC_FULL_BRANCH_NAME: The full name of the check-in target branch.

These variables have been added to all check-in triggers (client & server and before & after). It means: before-clientcheckin, after-clientcheckin, before-checkin and after-checkin.

These variables can be used to easily get the target branch for the current check-in operation inside the trigger code.

Server - All platforms: Fixed login regression when using Active Directory

We fixed an issue introduced back in release 11.0.16.8845 where user login attempts would fail with an "Invalid Credentials" error in certain configurations.

This happened when the server administrator configured the User Display Name Attribute setting in LDAPWorkingMode when working against an Active Directory server.

All Platforms: Introducing Branch Hiding!

We’re excited to announce a long-awaited feature: the ability to hide branches! This new capability lets you focus on what’s important by removing unwanted branches from your views.

Hiding branches happens at the server level, meaning once a branch is hidden, it disappears from the Branch Explorer, Branches View, and even the Changesets View for all users of the repository. However, the branch and its content still exist in the repository, so you can unhide or use it whenever needed.

== Who can hide or unhide branches? ==

Any user with "change" permission on a specific branch can hide or unhide it. This ensures flexibility while maintaining appropriate access control.

== When to use Branch Hiding? ==

Sometimes, you may ask us to delete branches, but this isn’t always possible—e.g., when a branch has been integrated. In these cases, the Desktop GUI will now offer the option to hide those branches instead, helping you keep your workspace organized without permanently removing data.

== A note on visibility ==

While hiding a branch removes it from immediate views, the branch and its content remain intact in the repository. This ensures that no data is lost, and you can retrieve or unhide the branch at any time.

You can hide or unhide branches using either the command line or the Desktop GUI:

== Command Line: How to use Branch Hiding? ==

Use the following commands to hide or unhide branches. For additional details, include the --help option.

== Desktop GUI: How to use Branch Hiding? ==

A simple and intuitive way to hide/unhide branches is also available directly within the GUI.

From the Branch Explorer or Branches View, there's a new option available to Hide a branch:

Note you can use "Ctrl-H" as shortcut!

To see all the hidden branches, you can go to the Branches View and click on the new 'Show hidden branches' button:

If you use this feature together with display filters, the hidden branches take them into account, making it easier to find the right branch based on your search criteria:

When showing the hidden branches, there's a new option available to Unhide a branch.

We’re confident this feature will make managing your repositories more streamlined and efficient. Try it out and enjoy a clutter-free experience in Plastic SCM!

Windows - Installer Update: Remove discontinued plugins

We’re excited to share an important update! We've optimized the installer by removing discontinued plugins and upgrading older .NET Framework applications to .NET. This change has cut the installer size by more than half, making installation faster and more efficient.

== What’s Changing? ==

We’re discontinuing support for the following legacy Unity Version Control (UVCS) plugins:

Visual Studio Integration

Microsoft Office Integration

== Why are we making this change? ==

These plugins no longer align with our vision for delivering a streamlined, modern product. By focusing on core improvements, we’ll deliver updates faster and enhance the overall user experience.

== What should you do? ==

We strongly recommend upgrading to the latest version of UVCS to enjoy the latest improvements, performance boosts, and bug fixes.

If you rely on the discontinued plugins, you can keep using them by staying on your current UVCS version. However, please note:

These plugins will no longer be maintained or supported.

Compatibility or functionality issues may arise in the future.

Thank you for your understanding and for being part of our journey to improve Unity Version Control. If you have any questions or concerns, feel free to reach out to our support team—we’re here to help!

All platforms: GitSync handles the .lfsconfig URL setting

GitSync now takes into account the .lfsconfig configuration file. It looks for the URL setting in order to use the specified URL for the LFS blobs download/upload (instead of always using the default one).

This allows you to import repositories from Git (to UVCS) that used a custom URL for the LFS blobs though the .lfsconfig file.

It only accepts HTTP/HTTPS URLs at the moment:

All clients: Fixed "Unable to cast object" error checking in a file under an Xlink

This error only happened under very specific circumstances:

You have a file checked-out under an Xlink with a fs protection set from Linux/macOS.

There are new changes only in the root repo, so you need to run an Incoming Changes operation before running the check-in.

After that, the check-in operation throws the error: Unable to cast object of type 'Codice.CM.Common.Tree.CheckinItemData' to type 'Codice.Client.Commands.CheckIn.ClientCheckinItemData'.

All platforms - Gluon: File conflicts not properly detected applying a shelveset

The Gluon shelveset application didn't promote the changes to file conflicts when the file was not modified in the workspace and the workspace revision didn't match with the base revision of the change. This way, it applied directly the shelveset change content to the workspace, losing all the changes introduced later in the file.

All platforms - Command line client: Fix checkconnection failing for @unity orgs

Fix cm checkconnection when used with a @unity organization.

All platforms - Gluon: Failed to checkin an applied shelve

The check-in operation failed when it was run after applying a shelve that contained a changed file in a Gluon workspace. This happened when the check-in was tried from the GUI or when specifying the paths to checkin from the command line. Now it's fixed.

All platforms - Desktop GUI/Gluon: Incoming changes notification panel wrongly updated

Switching between workspaces could lead to have the incoming changes notification of a workspace displayed into another workspace. Also, that we were checking for incoming changes for more than a workspace at the same time, wasting resources unnecessarily.

All platforms - Desktop GUI: Improve progress for directory conflicts resolution.

The Merge & Incoming Changes views need to handle directory conflicts in some scenarios. The progress of the directory conflicts resolution was not properly updated with multiple selection plus the "Apply this action for next X conflicts" option enabled.

Moreover, the "Resolve directory conflict" button was not disabled during the directly conflicts resolution. So, if the button was clicked, it launched more concurrent conflicts resolutions for nothing.

Now, the button is disabled and the progress properly updated during the directory conflicts resolution.

All platforms - Command line client: checkconnection can now check a specific server.

cm checkconnection learned a new optional argument that is used to check the connection against a specified server instead of using the default one configured in the client.conf file.

All platforms - Desktop GUI: Fixed background color for dark theme in code review view

In last release we introduced a bug where the code review view in dark theme showed the comment text boxes in a light background color. We fixed this issue, and now the background color matches the selected theme.

All Platforms - Desktop GUI: Code Review Email notifications

Implemented several functionalities to enhance email notifications in the Desktop GUI.

Users can now subscribe or unsubscribe using a dedicated button, with a status text indicating their subscription state.

Additionally, email address autocompletion with profile pictures has been added for user convenience when typing '@'.

All platforms - Desktop GUI/Gluon: Update Avalonia version to 11.1.5

All Platforms - Desktop GUI: Added version in the title bar

We have included the Plastic version in the title bar for both UVCS and Gluon windows. This enhancement simplifies version identification for users and especially for the support teams when they receive screenshots from customers.

All platforms - Command line client: Now you can see the internal seid from 'cm li'!

The "cm li" command is able to print the raw user seid with the "--printseid" option. It can also sort the list of users by seid specifying the "--sort=seid" option.

All Platforms - Desktop GUI: Update branch icon orientation

The branch icon has been updated from a vertical to a horizontal orientation. This change is intended to improve visual clarity and align with user expectations through all our applications.

All Platforms - Desktop GUI: Pending Changes not displaying changes

The Pending Changes view did not update correctly after checking in or undoing all filtered changes, and clearing the filter required a manual refresh to display the remaining changes. This issue has now been resolved, ensuring that all changes are displayed automatically after the filter is cleared.

All Platforms - Desktop GUI: Fixed a memory leak in the Branch Explorer view

Fixed high memory usage when switching workspaces and loading large branch explorers with date filters set far back. Ensured memory is properly freed after switching workspaces.

All platforms - In order to see the applied attributes of a specific branch or changeset, you now only require the 'read' permission

Previously, a user needed the whole 'applyattr' permission, in order to see the applied attribute of an object (branch, change...).

Now, when users only need to view the object, they only need the 'read' permission granted on the attribute.

You can set the 'read' permission either using the GUI or the 'cm acl' command.

Windows - Installer: Cannot run installer on some windows machines.

When running the installer (no matter which flavor) on some Windows 10 & 11 machines, weird errors appeared, with messages such as "Unkown tag", "Could not create namespace 'substitution'", and many more.

We fixed this problem by building the installers in Windows-x64 mode only, and upgrading to the latest version of our install builder provider.

Polarion: Server-side Polarion integration not loaded

The server-side Polarion integration was throwing an error while trying to configure a Plastic SCM repository.

Now it is fixed, and you can configure it as documented here

Remember the server-side polarion integration relies on the cm.exe command line client: Make sure the command client is configured to work with a valid server and credentials,

and the service account the Polarion server uses to run the service is able to access to the client.conf configuration file.

All Platforms - Desktop GUI: Support for opening file links

Desktop GUI now supports opening file links directly. There are three types of links:

File link: Focuses the specified file in the GUI, creating the workspace if it doesn't exist.

File link on branch: Switches to the specified branch, and focuses the specified file in the GUI, creating the workspace if it doesn't exist.

File link on changeset: Switches to the specified changeset, and focuses the specified file in the GUI, creating the workspace if it doesn't exist.

Users can now copy this kind of links from the Items view in the Desktop GUI from the context menu "Copy > Copy link", "Copy > Copy link (current branch)", or "Copy > Copy link (current changeset)."

All Platforms - Desktop GUI: Fixed error when opening some Code Reviews

Fixed an issue that caused an error when opening code review comments in the desktop client. This error occurred because some comments had incorrect location information. Now, the system will skip problematic comments and handle empty or incorrect location details better, preventing the error from happening.

All platforms - GUI: Fixed an error when contacting a Cloud org. from On-Prem for the first time

When logging in for the first time against a Cloud organization (for example, when adding a destination on a sync view), the GUI could throw a "Failed to resolve the cloud server for organization" error. This is now fixed.

All platforms - Desktop GUI: Merge not working using a renamed repository

Using a workspace pointing to a renamed repository, the merge failed with the error 'new_repository_name@cloud is not in a workspace'. Now it's fixed

All Platforms - Desktop GUI: Fixed view switching shortcuts

Attempting to press Ctrl/Cmd+ from the home view or login screen caused an unexpected error due to the Workspace view not being created yet. This issue has now been resolved.

Additionally, new shortcuts for displaying the Workspaces and Repositories views have been added:

Shift+Ctrl+1 for Repositories view (Windows and Linux)

Shift+Ctrl+2 for Workspaces view (Windows and Linux)

Shift+Cmd+1 for Repositories view (macOS)

Shift+Cmd+2 for Workspaces view (macOS)

All Platforms - Desktop GUI: Deeplink of UVCS repositories

A new plastic link format has been introduced to open repositories hosted in Unity Version Control (Plastic).

Links like the following ones can now open the specified repository in the full client of Unity Version Control (Plastic) or its artist-friendly Gluon applications:

If a workspace pointing to that repository is missing, a "create workspace" dialog will appears with pre-filled fields, allowing users to quickly set up and download the workspace.

Note that you can choose the tool (full Unity Version Control client (Plastic) or Gluon) by adding ?ui=gluon to the link. Existing diff and file links continue to function as before.

All platforms - Desktop GUI: Null exception when showing annotate from code review window

There was an exception when trying to show the annotate for a file from a code review window, when the code review was opened from a plastic link. In this scenario, there is no current workspace, and trying to access it was causing an error. We fixed it, and now you can see the annotate normally

All platforms: GitSync doesn't push the .git folder anymore

GitSync doesn't push the .git folder (if it exists in the Unity VCS repo) to Git since some Git servers/providers could reject the push operation due to it.

All platforms: Creating an attribute via API no longer fails if triggers are set

We detected that creating attributes using the REST API endpoint failed if the before-mkatt or after-mkatt triggers were set. We fixed that issue, so it shouldn't happen anymore.

All platforms - CLI: Purge author could not unregister it

All Platforms - Desktop GUI: Improve Filtering in Code Reviews

Based on user feedback, we’ve enhanced the Code Review feature with better filtering and usability. A new "Reviewer's status" filter lets you filter reviews by the reviewer's status. When combined with the Reviewers filter, this allows for more accurate identification of reviews needing your attention.

We’ve also improved the tooltips to clearly display each reviewer's status.

Additionally, the comments tooltip now shows the count of comments and unresolved issues for added clarity.

All Platforms - Desktop GUI: Make the default changelist always visible

Ensure that the default changelist remains visible even when empty in the GUI clients. This option helps users locate the default changelist for easier drag-and-drop operations between default and custom changelists.

All Platforms - Desktop GUI: Diff View intraline diff misalignment

The diff view in the Desktop GUI showed the highlighted code on the left side (for deleted content) skewed to the left. This misalignment was due to improper handling of tabs as indentation. Now it's fixed.

All Platforms - Desktop GUI: Cmd+A/Ctrl+A not always selecting all pending changes

Cmd+A/Ctrl+A failed to select all pending changes if an item started with "A". This has been fixed by handling the KeyDown event to properly process the SelectAllRows command, ensuring that all changes are highlighted as expected.

All Platforms - Desktop GUI: Drag and Drop error between changelists

Fixed an issue that caused an error when dragging files to custom changelists while the "Group changes by categories" option was disabled.

All Platforms - Support for renamed repositories on existing workspaces

Previously, when a repository was renamed, the workspaces pointing to the repository prior to the renaming stopped working. This happens because they kept using the old name, and the server can no longer find a repository named like that.

Now, workspaces can continue using the old repository name, even after the repository is renamed. The server will keep track of the old name for you after renaming a repository, so you don't need to change anything. Note however that this won't remain valid if the old name is claimed by another repository (i.e., if you rename an existing repository or if you create a new one named like that). In that case, the workspace would automatically connect to a different repository, forcing you to switch.

Remark 1: The Desktop GUI home view will not list workspaces linked to an old repository name. However, you can still find these workspaces in the dedicated workspace view.

Remark 2: There is a limitation that prevents doing client-side merges using the GUI on these workspaces. For now, you can use the command-line client (cm) or use the server-side (aka "merge to") option within the GUI. We will remove this limitation in the next release.

All Platforms - Desktop GUI: Wrong changeset selection in the diff window

When quickly moving through code-review changesets, users might review changes from the wrong changeset due to a concurrency issue. The earlier diff process wasn't properly stopped, causing old changes to display instead of the selected changeset. This issue is now resolved by ignoring outdated diffs when calculating differences for a newly selected changeset.

All Platforms - Desktop GUI: Use the right dir separator char when copy path

Fixed an issue in Windows where the relative path copied to the clipboard was incorrect. The path now uses the appropriate directory separator character for Windows, and the leading slash is removed.

This fix ensures the workspace relative path preserves the right directory structure across all views, including DiffTreeView, Items view, and Merge view in Plastic, as well as CheckinView, Incoming Changes view, and Workspace explorer in Gluon.

All Platforms - Desktop GUI: Drag & Drop error in Tree Mode

Fixed an issue with the new Drag & Drop feature between changelists. When using the Pending Changes view in tree mode, selecting a combination of files and directories caused an error message: "An error occurred processing your request."

This has been fixed by skipping structure nodes during the drag-drop operation.

All platforms - Desktop GUI: Disabled "Create" button when creating a new repository

We fixed an issue that was introduced in the previous release, where the "Create" button in the "Create a new repository" dialog was permanently disabled when opened in the "All workspaces" panel.

All Platforms - Desktop GUI: Add History and Annotate options

We have added "History" and "Annotate" options to the context menus of the Diff/Code Review and Merge views. These new features will allow users to view file history without leaving the current window.

All Platforms - Desktop GUI: Add Copy File Path options

We have added "Copy file path" and "Copy relative file path" options to various context menus in both the Plastic and Gluon GUIs, including Items/Workspace Explorer, Pending Changes/Checkin Changes, Merge View/Incoming Changes and Diff/Code Review views. These new options will allow users to easily copy the path or the relative path of files, which could be needed in some scenarios.

"Copy path" copies the full file or folder path to the clipboard.

"Copy relative path" copies the file or folder path relative to the workspace to the clipboard.

All Platforms - Desktop GUI: Drag & Drop files between changelists

Implemented Drag & Drop support for files within the 'Pending Changes' view when the option "Group changes in change lists" is enabled. Users can now easily move files between changelists, enhancing the workflow and improving ease of use.

All Platforms - Gluon: Improved Switch Experience

On September 5th, in version 11.0.16.8845, we introduced the new Shelve & Switch feature in the UVCS GUI, which allowed users to easily switch with pending changes.

This feature is now also available for Gluon, so you can switch between branches and changesets in partial workspaces without effort!

All platforms - Client and plugins: We fixed a problem where the client couldn’t automatically renew user credentials when using Unity ID with a Cloud organization.

In some situations, client applications can use a token from one Cloud organization (A) with another Cloud organization (B). This let you access all your Cloud organizations with just one login, without needing to log into each one separately.

However, sometimes the client didn’t update all the tokens correctly when renewing credentials. For example, it might update the token for organization B but not for organization A, which could lead to errors like: "Can't obtain a new token (Message: Invalid Refresh Token., Code: 132.104)."

This issue has now been resolved.

Two minor issues have been identified in this version. They will be addressed in the next release.

All Platforms - Desktop GUI/Gluon: Improve keyboard usage

Shortcuts have been added for each view (Ctrl+1/Cmd+1 for Workspace Explorer, Ctrl+2/Cmd+2 for Pending Changes, etc ...). Tooltips have also been implemented to help discover shortcuts.

When a view is selected, now the focus will now shift to the right pane for smoother keyboard navigation.

Additionally, we fixed a bug when pressing Ctrl+F (Cmd+F on macOS) focused on the search textbox but wrongly displayed an "f" character. Now it's fixed.

All platforms - Desktop GUI/Gluon: The Branch Explorer date filter does not load in some corner cases

All platforms - Command-line client, Desktop GUI: Improved Switch Experience with Pending Changes

Now you can seamlessly bring your pending changes with you when switching workspace configurations, both in the command line and in the Desktop GUI.

When using the Desktop GUI, a prompt will help you to enable this feature. You can also enable it within the Desktop GUI preferences dialog:

And also, by setting the following key and value in your client.conf configuration file:

Bringing your changes works as follows: when switching your workspace configuration by either using the Desktop GUI or the cm switch and cm partial switch commands, your client will look for pending changes in your workspace. If it finds any, it will ask you what you want to do, and it will present you three options:

To shelve your pending changes and leave them on the source for future use.

To bring the changes with you, moving them seamlessly to the destination branch.

To cancel the operation.

If you choose to shelve your pending changes and leave them on the source, the client will create a shelveset with the changes, then switch your workspace configuration. You can apply the shelveset later on, whenever you want to. If you are using the Desktop GUI, the notifications it provides will indicate you that there are shelved changes and guide you through each step to apply them back, making the process smoother and more intuitive.

If you choose to bring your pending changes, the client will create a shelveset with the changes, then switch your workspace configuration, and finally will try to automatically apply the shelveset, effectively bringing your pending changes with you. If merge conflicts arise, you can choose whether to resolve them or to cancel the operation. Don't worry! If you cannot apply the shelveset, it won't be deleted either, so you can still apply it later on.

Because of output compatibility, this new behavior gets disabled in the command line when using flags such as --machinereadable and --xml. If any of those flags are present, and PendingChangesOnSwitchAction is set to Shelve, the client will temporarily change the configuration value from Shelve to Fail, and you won't be able to change your workspace configuration with pending changes on your workspace. Bear in mind this if you have automated anything on top of the cm command-line client!

All Platforms - Desktop GUI: Rename sync view's 'delete src/dst repo' buttons

Some users reported that the 'delete src/dst repo' buttons in the Sync Repositories view were confusing, as they thought it would delete the entire repository instead of just removing it from the sync view. To address this, the button was renamed to 'remove src/dst repo', and additional tooltips were added to clarify the action performed by the buttons.

Command-line client: Unhandled exception when creating an Xlink outside a workspace directory

Creating an Xlink outside a workspace directory triggered an unhandled exception, printing an unhelpful error message.

Now, the error is handled, and a more apt error message is shown instead:

All platforms - Command line client: Authentication parameters work again wihout a valid client.conf file in place

Back in version 11.0.16.8782, we broke the possibility of authenticating against a given server using command-line authentication parameters without a valid client.conf file in place. This is now fixed: parameters such as --username and --password work again when the client is not correctly configured:

All Platforms - Desktop GUI: Expanded/collapsed branches info was lost

When the Branches view was in Tree View mode, performing certain operations caused all child branches to auto-expand, ignoring the user's setup. Now it's fixed.

All Platforms - Desktop GUI: UI hangs with big minified files

The application previously froze in the pending changes/Diff view when handling minified files (JSON/JavaScript). Now it's fixed. Users can now display and edit these files without causing the UI to hang.

All platforms - Gluon: Fixed external tool option

When having a custom external tool defined in externaltools.conf, you may define @object as an argument to pass to the tool, and it will be replaced with the path of the selected object.

On Gluon, this path was relative to the workspace, so the custom tool couldn't process the file.

All platforms - Gluon: configuration now handles the "full update" mode

After the workspace undergoes a full configuration, it enters a "full update" mode. In this mode, every new item will be downloaded without relying on the granular directory configuration.

Previously, the configuration did not handle the "full update" mode correctly. It failed to properly display the new items as items to load and did not download them. This issue has been fixed.

All Platforms - Desktop GUI: Outdated branches displayed when no connection

When switching to a workspace with no connection, the branches popup displayed outdated branches from the previous workspace. Now it's fixed, and a proper panel displaying the error is shown instead.

All Platforms - Desktop GUI: Syntax Highlight highlighted non-code files

All platforms - Installer: Fresh OnPrem install now enables ssl channel by default

Now the ssl channel is enabled on Plastic SCM server on OnPrem new/fresh installations.

This way, users are able to use this secure channel, or configure their mergebot profiles out-of-the-box without requiring extra admin intervention.

All Platforms - Desktop GUI: Incorrect Encoding in diff view for big files

All platforms - Desktop GUI: Added comments and questions columns to code reviews view

We added two new columns to the code reviews view: the comments column, that shows the number of comments and replies, and the questions column, that shows the number of unanswered questions and unresolved change requests.

All platforms - Desktop GUI: Code review comments navigation fixes

We found and fixed two different issues that happened when opening a code review and navigate to a comment for the first time.

Both issues have been fixed.

Command-line client: The cm fast-import command failed when importing files bigger than 2GB

The cm fast-import command failed if the export file contained a blob bigger than 2GB. This happened because the blobs size was handled as an int32 value. Fixed.

Windows - Installer: Fixed error installing on-prem edition over an existing cloud edition

An error window at the end of the install process was shown when installing on-prem edition over an existing cloud edition.

All platforms - Desktop GUI: Allow to remove branches with changesets

Before, if you wanted to delete a branch containing changesets, you had to delete the changesets first. Now all the data is deleted at once from the delete branch option.

Bear in mind that the operation is atomic. Either all of the changesets or none of them will be removed.

Plastic SCM will prevent removing the changesets in a branch under the following circumstances:

The changeset zero is included in the operation (that is, you are trying to delete the main branch).

One or more of the changesets have children outside of the branch (that is, the branch has child branches).

One or more of the changesets in the branch are the source of a merge, and the destination changeset of the merge falls outside of the branch.

One or more of the changesets in the branch are pointed to by a label.

There are one or more shelvesets created from a changeset in the branch.

All platforms - Desktop GUI: Added advanced filters to the shelves view

The advanced filters that we are adding to several places in the GUI are now available in the shelves view. You can filter the shelves list by branch or user, using the same saved filters that you have for the rest of the views.

All platforms - Semanticmerge: Updated semanticmerge to support C# 12

We updated the parser in semanticmerge to support the new features in C# 11 and C# 12. The syntax highlighting now also supports these new versions.

Also, when semanticmerge detects parsing errors, they are now shown automatically in a modal dialog, warning about possible file corruption if the user continues.

All Platforms - Server: Changeset deletion can fail in partially replicated repositories

The changeset deletion of a replicated changeset failed if its parent was not replicated too. The error thrown was "Cannot show differences between changeset X and changeset Y. The source changeset X has not been replicated to this repository. Make sure that you replicated the branch containing this changeset".

Now, the changeset deletion succeeds regardless of whether the parent changeset was replicated or not.

All platforms - Desktop GUI, Gluon: Allow to specify multiple repositories in the advanced queries

For some of the query views, like the Branches or Code Reviews, if you used an advanced query that contained multiple repositories, an error was raised to the user. We fixed this error, and now you can specify multiple repositories in the query, and use it together with the new filters.

macOS - Desktop GUI: Crash when canceling undo changes dialog

The application crashed when the "Undo confirmation" dialog was closed by pressing the "Esc" key in the pending changes view.

Additionally, a fix was applied to prevent the TreeDataGrid component from incorrectly moving the selected item when Esc was pressed.

macOS - Desktop GUI: Fixed writing issue in merge-to dialog

All Platforms - Gluon/Desktop GUI: New Workspaces View added to the home view

A workspace view option has been added to the home screen, providing an easier way to manage multiple workspaces. This is useful when a user belongs to several organizations or uses different servers. This new view includes the ability to:

Filter existing workspaces.

Interact with them (rename, delete, open, open in a new window, etc )

Create new workspaces.

"Reconnect" workspaces on disk that UVCS is not aware of. A new option has been created for this: "Add an existing workspace".

All Platforms - Gluon/Desktop GUI: Improved Workspace Deletion Process

The process for deleting workspaces has been enhanced. Now, users can delete active workspaces (or repositories with active workspaces). Previously, workspaces that were opened (in the current window or a different window) couldn't be deleted. This change significantly reduces restrictions and improves overall usability.

macOS and Windows - Gluon/Desktop GUI: Drag and Drop functionality for workspaces

A new drag-and-drop feature has been implemented in the workspace management system. This enables users to open or create workspaces (and reconnect existing workspaces), just by dragging a folder to the UVCS window, providing a faster and more intuitive user experience. The drag-and-drop feature is only available in macOS and Windows (the Linux platform is coming soon).

All platforms - Desktop GUI: Fixed error loading branch explorer for old servers

When using a modern client connected to an on-premises server with an old version (+2 years ago) there was an error shown when trying to load the branch explorer.

All platforms - Desktop GUI, Gluon: New options button in the content viewer

We added a new options button when showing the content of added/deleted files. Similar to the one we already had for the diffs, you can change the syntax highlight, encoding or editor options from this new button.

Also now, the code editor settings already configured, are applied in this editor (view whitespaces,...). You already had the code editor settings available from the Preferences window.

Linux - Command-line client: command line package size shrunk by 40%

The plasticscm-client-core linux package has been reduced from 127MB to 72MB (more than 40%).

Some unnecessary assets were removed from the bundle, together with java-based plugins (you can still download them separately from "Plugins zip" installer in https://www.plasticscm.com/download/ page

Linux - Command-line client: Security issues addressed

Some vulnerabilities of plasticscm-client-core package were addressed, as there were some outdated third-party libraries bundled, such as Newtonsoft.Json. Either they were updated to safe versions or removed from the package.

All platforms - Desktop GUI: Advanced filters for code reviews

We added a new set of filters in the code reviews view, similar to the ones in other views like the branch explorer. You will be able to use the same saved filters you had in the other views for the date and user filters.

In addition, you can also filter reviews by the assigned reviewer and by status.

Command-line client: New variables in Review triggers.

Added new variables to the triggers related to Reviews:

PLASTIC_REVIEW_COMMENTS_COUNT: Total number of comments.

PLASTIC_REVIEW_USER_COMMENTS_COUNT: Total number of user-added comments.

PLASTIC_REVIEW_UNRESOLVED_CHANGES_COUNT: Number of unresolved changes.

PLASTIC_REVIEW_UNANSWERED_QUESTIONS_COUNT: Number of unanswered questions.

Linux - Installers: Cannot resolve libicu dependency on Ubuntu 24.04. Fixed.

Some Debian / Ubuntu distros were showing an error while installing telling that there is an unmet dependency of libicu that cannot be resolved.

Now it is fixed, since libicu74 is now set as a valid alias for libicu dependency.

All platforms - Desktop GUI: Fixed locked workspace error when performing a merge

All platforms - REST API: Remove branches with changesets using the v2 REST API

Before, if you wanted to delete a branch, you had to manually delete its changesets first. Now you can delete all the data at once with the deleteChangesets query parameter:

Bear in mind that the operation is atomic. Either all of the changesets or none of them will be removed.

Plastic SCM will prevent removing the changesets in a branch under the following circumstances:

The changeset zero is included in the operation (that is, you are trying to delete the main branch).

One or more of the changesets have children outside of the branch (this is, the branch has child branches).

One or more of the changesets in the branch are the source of a merge, and the destination changeset of the merge falls outside of the branch.

One or more of the changesets in the branch are pointed to by a label.

There are one or more shelvesets created from a changeset in the branch.

All platforms - Desktop GUI: Added advanced filters to multiple views

We added the filters panel that we already have for the branch explorer to the branches, changesets, labels and attributes views.

You can now easily filter all views by date, branch and user using the same saved filters that you had in the branch explorer.

You can also still use a custom query if you want more advanced filtering.

All platforms - Desktop GUI: Keep the code reviews filter preference after restarts

When you select a filter in the code reviews view, this filter was lost after closing the application, and you had to re-apply it the next time.

We modified the behavior so now the filter is kept across restarts.

All Platforms - Gluon: Allow to share and open folder links

In Gluon, we've expanded the sharing functionality to include folders in addition to files. Previously, users could only copy links to files for sharing, but now they can also share links to directories. This enhancement improves collaboration by allowing users to easily share and open folder links with others.

Server: SAML authentication is now enabled by default

Previously, the "SamlAuthenticationEnabled" feature flag had to be set in your server.conf in order to explicitly enable SAML authentication. Now the feature flag will be ignored. For more information on how to set up SAML authentication on your on-prem server, check the following technical documentation:

https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/SAML-auth-microsoft

All platforms - Desktop GUI, Gluon: Consistent behavior adding comments to binary files in code reviews

All Platforms - Desktop GUI: Quick Branch Switching

We've introduced a game-changing feature: Quick Branch Switching. We've added a new menu at the top that lets you easily jump between main, recent, and other branches, without losing context.

Branch popup: The top button now opens a menu with categories for main, recent, and other branches.

Better Organization: Branches are sorted into three groups to make finding them easier.

Filter: You can use a text filter to find branches quickly.

Create a New Branch: You can now create new branches right from the popup.

All platforms - Desktop GUI: Enhance refactor groups

Analyze Refactors is a really powerful feature when reviewing the changes. The refactor groups were only calculated for the entire branch mode in the diff window. Now, they are also calculated when exploring the differences changeset by changeset. The next step will be to add them to the code review window too.

Apart from that, other quality improvements have been made when computing the differences. Before you could notice some "freezes" while loading them. They are fixed now too.

All Platforms - Desktop GUI: Auto-refresh Code Reviews View

We've enhanced the Code Reviews view by implementing auto-refresh functionality. Now, whenever certain actions are performed on a code review, such as editing the title, creating, editing, replying to, or deleting a comment, modifying reviewers, changing reviewer status, or applying/discarding a comment, the Code Reviews view will automatically refresh.

Command-line client: Branch deletion

You can now remove branches with changesets using the cm command line.

Before, if you wanted to delete a branch with changesets, you first had to delete the changesets and then delete the branch. Now you can delete all the data at once with the --delete-changesets flag:

Bear in mind that the operation is atomic. Either all of the changesets get removed or none of them will.

Plastic SCM will prevent removing the changesets in a branch under the following circumstances:

The changeset zero is included in the operation (this is, you are trying to delete the main branch).

One or more of the changesets have children outside of the branch (that is, the branch has child branches).

One or more of the changesets in the branch are the source of a merge, and the destination changeset of the merge falls outside of the branch.

One or more of the changesets in the branch are pointed to by a label.

There are one or more shelvesets created from a changeset in the branch.

Command-line client: Branches can be specified by guid

We added a new branch spec that allows to use the branch guid to refer to a specific branch through the command line.

More info can be found in the 'cm objectspec' command.

Windows - Wwise plugin: Plugin upgraded to SDK 2023

The Wwise plugin was upgraded to use the latest version of the Wwise SDK (2023.1.3.8471). This new version will allow users to continue using our version control integration in Wwise 2023. You can find the new plugin under the installation path "client/plugins/wwise/PlasticSCMWwisePlugin2023.dll".

All platforms - Desktop GUI: Improved history view filters

The history view has a filter that allows you to see only the revisions that belong to the specified branches.

In addition to this, we added a user filter that lets you specify the author of the revision.

These filters now have the same design as the ones in the branch explorer view.

On top of that, both views share the saved filters list, so you can create one filter from the branch explorer and use it from the history view.

All clients: Removed transformable workspaces support

Transformable workspaces support was added long time ago. However, they were actually never used or fully supported by the system (i.e. not supported by Partial workspaces or Incoming Changes operations). The feature was removed from the system.

Windows - Wwise plugin: Plugins moved under a common folder

From this release on, all versions of the Wwise plugin are moved under a common installation folder "client/plugins/wwise".

All Platforms - Server: 'Collection was modified' error using LDAP

The Novell.Directory.Ldap version that the server used (3.4.0) had a bug related to a collection that was not thread safe. This issue was fixed in the version 3.6.0: https://github.com/dsbenghe/Novell.Directory.Ldap.NETStandard/commit/7f8f45e6df33c7ac4acafb0a481c9682cb0d1964

Now, the server uses the version 3.6.0, so the issue doesn't happen anymore.

All platforms - Desktop GUI: Fixed exception in changeset code review

All platforms - Desktop GUI: New option to group or not group pending changes by category

A new option has been introduced in the Pending Changes View to enhance user flexibility. Users can now toggle between displaying pending changes grouping or not-grouping categories (added/changed/moved/deleted).

The new option is available in a new tab called "Visualization" in the Pending Changes View options. Also moved the options "Group changes in change lists" and "View as a tree" to that new tab.

Note that when "Group changes by categories" is disabled, the category icon is displayed in the status column to help classify each change by category.

An example of the behavior for each of the three options is shown below.

Group changes in "change lists":

Group changes by categories:

Note it is also possible to combine the options at will:

All platforms - Desktop GUI: Fixed "Item with the same key already been added" error in the Pending Changes view

There was a way to end up with a path both "locally removed" and "removed" at the same time, inside the pending changes view. This caused an "Item with the same key has already been added" error.

The following sequence reproduced the error before the fix:

Remove 'foo.txt' from UVCS (as a result, you get 'foo.txt' as removed, controlled).

Create a new 'foo.txt' file using the same path.

Add the new 'foo.txt' to UVCS.

Delete from disk the foo.txt (as a result, you get 'foo.txt' as locally removed)

All Platforms - Desktop GUI: View branches as a tree hierarchy

Now it is possible to switch between a flat (list) view and a hierarchical (tree) view of the branch list.

In the new mode (tree mode), each branch node is collapsible, allowing it to hide and show its children.

There are context menu options for collapsing all and expanding all branches in tree view mode.

All platforms - P4Sync: Added support for branches with a ':' character.

The mappings between the UVCS branches and the P4 branches are stored in a text file.

The previous parsing of this file didn't support the character ':' in the P4 branch name, so it failed with the following error:

Now, it properly supports P4 branches that contain the character ':'.

All platforms: Allow to disable the SSL certificate revocation list check

By default, the certificate revocation list (CRL) is checked during SSL authentication. This is an online check that could delay the establishment of a new connection due to a network restriction, a network configuration issue, or an issue with the certificate.

This delay on each connection heavily damages the user experience, especially when using the command line, where each command needs to create a new connection.

You can disable the SSL certificate revocation list check by adding the following setting to your client.conf:

Working distributed, the same issue could happen to the server when it needs to connect to the remote server, so you can disable check on the server too by adding the following setting to the server.conf:

All platforms - WebUI, GUI: Comments in code reviews are now sorted by creation date

Previously, code review comments were sorted by modification date. That moved comments to the top of the list after being edited, which was unintuitive. From now on, code review comments will keep their creation date, maintaining their original position in the list.

Cloud Server - Changed the internal sub repositories ID sequence to avoid collisions.

Before, when a new sub-repository was created, it used the first following available ID. Still, this mechanism did not consider the IDs already used by removed sub-repositories, leading to a collision at some operations.

Now, new sub-repositories will use a unique ID that has not been used before.

macOS - SemanticMerge failed to start as a standalone application

An issue in the framework prevented SemanticMerge to start as a standalone application. It led to an immediate crash since version 11.0.16.8405. Now it's fixed.

Remember that you can run SemanticMerge independently using the "semanticmerge" argument.

All Platforms - Gluon: Fix sorting items by size

When sorting the table by size, the sorting was incorrect. Instead of sorting directories followed by files based on size, the sorting appeared random, with sizes not matching any discernible order. Now it's fixed.

All platforms - Desktop GUI: Re-request review for "Rework required"

We introduced the Re-request review feature back on version 11.0.16.8486, but it was only available for "Reviewed" status, not for "Rework required" status. Now it's fixed. The button is visible for both statuses.

All platforms - Desktop GUI, Command-line client: Improved the way to handle credentials for different servers

In some scenarios you may use the same credentials to authenticate on different cloud organizations. These credentials are stored independently, and can also expire at different times.

We improved the way we handle the authentication, so now when one of the credentials expire, we try to use the others instead of failing the authentication.

As a result, you will be less likely to be asked to re-enter credentials when trying to connect to a server that you haven't used for a while.

All platforms - Desktop GUI: Fixed Index out of range error in Sync View

Users encountered an error when attempting to exclude branches in the Sync View. Right-clicking on a branch and selecting "Exclude Branch" resulted in an index out-of-range error. Now it's fixed.

All platforms - Desktop: Fixed branch explorer loading using the global config

All platforms: Re-request review feature added

Previously, re-requesting a review was not possible, causing workflow challenges when creators needed to make changes.

Now, authors can re-request reviews for certain users after making all requested changes, indicating readiness for review again.

All platforms - Desktop: Fixed a tree performance issue for the workspace explorer view

All platforms - Desktop GUI: Enhanced filters in Branch Explorer

We are excited to introduce a powerful new feature in our Branch Explorer: Filters. These filters have been designed to streamline your workflow and enhance your user experience. Here's a breakdown of the key improvements and functionalities:

The interface for changing date filters has been revamped for simplicity and ease of use.

Users now can quickly select predefined date ranges such as last week, last 15 days, month, or 3 months.

Additionally, users can still manually select a specific date or date range from the calendar.

A new branch filter feature has been implemented to help users focus on specific branches without having a cluttered interface.

Users can easily filter branches based on their working preferences, select specific branches, and save filter configurations.

The user filter option simplifies the focus on individual work by highlighting the user's changes in orange.

Changes from other users are displayed with reduced opacity, allowing users to concentrate on their tasks effectively.

A new filter excludes already merged branches, enabling users to focus solely on pending work items.

Related Branches Option: The related branches feature enhances diagram comprehension by including parent, children, and merged connected branches in the view.

All Platforms - Server: Changes in code reviews will update its modification date.

Before this task, due to the new code reviews window, there were several changes which were not affecting its last modification date, such as changes in the comments or the reviewers status, among others. Now, every change in a code review or other fields related to it, should update the last modification field to the current date.

All platforms - Desktop GUI: Mirrored TGA files preview

Update ImageMagick Library: Upgraded ImageMagick library to version 13.6.0, resolving the issue of flipped images during preview generation.

Cache Invalidation: Incremented the preview datastore version to invalidate the preview disk cache, ensuring that previously incorrect previews are discarded.

All platforms - Gluon: lock status info for legacy locks is not shown anymore

In 11.0.16.8101, we announced Smart Locks as the replacement for legacy locks, which allows users to work in sequence making changes, and knowing who has an asset locked at any time. This lets multiple users collaborate while retaining the lock on the task branch throughout development and protecting the file from parallel changes.

Legacy locks were still supported for a while. However, as of this version, Gluon will no longer show the status info related to the legacy locks in the explorer workspace view.

You can find more information about Smart Locks in the release notes and the official documentation:

https://docs.unity.com/devops/en/manual/smart-locks

https://www.plasticscm.com/download/releasenotes/11.0.16.8101

All platforms - Desktop GUI: Improved the way to handle errors when signing in

When there is an error during the sign in process, in some scenarios we were not displaying the error message to the user (e.g., due to the connection with the server or an issue saving the credentials on disk). This was not optimal because the only way to see what went wrong was checking the log files.

All platforms - Desktop GUI: Relayout branches in the branch explorer

We added a new option in the branch explorer that allows you to relayout branches at your wish, so you can manually move a branch up and down, instead of letting the branch explorer automatically find a spot for it. This features is available from the context menu when a branch is selected. You can also move multiple branches at a time, or clear all the relayout data if you are not satisfied with the result.

Additionally, some keyboard shortcuts are also provided (for Windows and Linux / for macOS):

Ctrl+Up Arrow / Cmd+Up Arrow: move selected branches up.

Ctrl+Down Arrow / Cmd+Down Arrow: move selected branches down.

Ctrl+Shift+Up Arrow / Cmd+Shift+Up Arrow: move selected branches to the top.

Ctrl+Shift+Down Arrow / Cmd+Shift+Down Arrow: move selected branches to the bottom.

Ctrl+Shift+C / Cmd+Shift+C: clear selected branches relayout data.

All Platforms - Desktop GUI: unexpected error refreshing code review window

When refreshing the code review window, if the selected difference was an xlink difference, an unexpected error appeared. Now it's fixed.

All Platforms - Desktop GUI: Enhanced diff visibility in Dark theme

Users reported difficulty in seeing the new GUI diff colors in the dark theme. To address this concern, several changes have been applied to enhance visibility:

The base colors are now more solid and clear in the dark theme.

A slight decrease in the diff alpha value increases the contrast between diffColor and insideDiffColor.

The diff alpha value was also increased inside lines.

Windows - Desktop GUI, Gluon: Improved ignored.conf for Unity projects

An ignore.conf file is automatically generated for the workspace when it contains a Unity project in order to set up the files that should be ignored.

Now, we have included a new rule to ignore some internal Unity files that are created and deleted constantly under certain circumstances.

Windows - Desktop GUI, Gluon: Improved the auto-refresh for pending changes view

We improved the mechanism used to detect if there are new changes to check in the auto-refresh operation for the pending changes view.

Now, it's able to detect when there are only changes that affect ignored files, avoiding launching the auto-refresh operation in these cases.

Windows - Command-line client: diff and merge commands now uses the new merge tools

Previously, when you ran a diff from the CLI or a merge with conflicts, we were using the legacy GUI to show the diffs or merge conflicts. We updated this behavior to match macOS and Linux, and the new GUI is used.

Linux - Command-line client: Added support for lightweight platforms without libicu

Now you can run the command-line client (cm) in minimal distros without a valid globalization support library (libicu) installed in the system.

To do that, set the DOTNET_SYSTEM_GLOBALIZATION_INVARIANT environment variable to 1 in order to run the cm application.

More info about the configuration options for globalization can be found here

All Platforms - Command-line client: Allow revspecs collections on getfile | cat command

Before, it was possible to download file revisions one by one using the getfile command along with the --file option to specify the destination. Now, it is also possible to download a bunch of files by defining a whitespace-separated list of semicolon-separated pairs of revspec and destination.

All platforms - Desktop GUI: Fix incorrect text in resolve conflicts button when doing a "merge-to"

When performing a "merge-to" operation that involves resolving manual conflicts, the button at the top incorrectly displays "Checkin merge!". The expected behavior is now restored: the button initially says "Resolve conflicts," allowing users to address conflicts. After resolving conflicts, the button appropriately changes to "Checkin merge!"

All Platforms - Desktop GUI: Fix crash when previewing JPEG images greater than 1024px.

A crash issue in Gluon occurred when attempting to preview JPEG images with a width or height exceeding 1024 pixels in width/height. On Mac, it led to an immediate crash, while on Windows, it resulted in freezing and then crashing after a few seconds. Now it's fixed.

All platforms - Desktop GUI, Gluon: Don't request the user to login when loading repositories

All Platforms - Desktop GUI: Enhanced Undo performance by 25%

Previously, undoing a large number of files (15k) in the GUI took longer compared to the cm undo command.

The GUI was sluggish because it sent all paths directly to the operation, triggering a platform path resolution for each. This process expanded and made paths canonical while resolving symlinks. On the other hand, the CLI combined and calculated paths after executing an unco operation. Since the GUI always uses pre-resolved platform paths, the path resolution step becomes unnecessary and can be skipped.

Following these adjustments, the undo operation is now 25% faster.

Before the change: 48 seconds for 10,000 paths on the Windows platform.

After the change: 36 seconds.

All platforms - Desktop GUI: Enhancements for clearer Diff Viewer comparisons

We've addressed an issue in this release to ensure a more straightforward experience during comparisons. Here's what you need to know:

Before this update, selecting 'Ignore Whitespaces' or 'Ignore EOLs' would retain the 'SkipFormatChange' setting. If 'SkipFormatChange' was set to "true," no format differences were displayed. This caused confusion as users expected differences when choosing these options.

We've modified the behavior to align 'Skip Format Changes' with 'Ignore EOLs and Whitespaces' in the x-merge.

'Recognize All': Disables 'Skip Format Changes'

'Ignore EOLs and Whitespaces': Enables 'Skip Format Changes'

'Ignore Whitespaces': Disables 'Skip Format Changes'

'Ignore EOLs': Disables 'Skip Format Changes'

This adjustment ensures a more intuitive experience during comparisons.

All platforms - Desktop GUI, Gluon: Tree mode in Pending Changes view

We added a new option in the Pending Changes view to visualize your changes as a directory tree instead of as a list.

This lets you see the changes organized by the directory structure and select all the changes under a directory with a single click.

You can choose the way to visualize the changes in the Options dialog, under the "What to show" tab:

All platforms - Desktop GUI, Gluon: Added 2 spaces tab option

We added a new option in the Code Editor preferences that allows you to visualize tabs as 2 spaces

All-Platforms - Command-line client: Unexpected standard output for machinereadable

When performing a checkin with update and machinereadable options enabled, there were some unexpected lines in the standard output which have been removed. Now every message displayed is properly formatted as expected.

On a workspace with the selector behind the head of the branch, (checkin would need to have option --update to succeed), perform some changes in any item and then run the following:

Before you would get the following:

Now all output messages follow the machine readable output specs with no standard output pollution.

All platforms - Desktop GUI: Don't show the "Close review change" button when loading the Pending Changes view

The Pending Changes view has a "Close change requested in review" button to specify that the checkin is fixing a change requested in a code review. This button should only be visible when the current branch or changeset has a code review with pending changes, but we were always showing it when loading the Pending Changes view.

We fixed this behavior, and now the button is not shown by default and only appears when it's needed.

All platforms - Webadmin: Now the period can be used as separator for the mergebots and plugins at the webadmin

Previously, having periods as separators in mergebots and plugin names led to an error when clicking on start/stop buttons, making them unusable. According to https://www.w3.org/TR/html4/types.html#type-name, now we support period separators in mergebots and plugin names.

All platforms - CLI: Unexpected encoding for output in XML format

Some commands assumed an incorrect encoding for the XML output. Now, by default, "UTF-8" will be used in case no encoding has been specified when calling the command with the "--xml" option.

Linux - Server: Authentication in NameWorkingMode works again in modern GNU/Linux distributions

For some time now, the NameWorkingMode authentication mode (which is the default one when installing Unity Version Control on-premise) did not work. This was because system call getpwent returned ENOENT after retrieving the last passw entry, which is not documented (man getpwent) but that seems to be standard behavior in modern GNU/Linux distributions using systemd.

All platforms - WebUI, GUI: Avoid re-sorting code reviews comments after editing them

All platforms - Desktop GUI: Conversation panel and multiple reviewers for code review

We have redesigned the code review window to include the all new conversation panel. It shows the timeline of the code review, including comments, change requests, questions and status changes all in one place. From this view you can start conversations, or reply to other comments. You can also navigate to the code and see the specific line where a comment was created, or see the changeset where a change request was applied.

Along with this change, we added support for multiple reviewers in a code review. You can now add or remove reviewers from this conversation panel, either specific users or groups. Each reviewer will have their own status, and the global status of the code review will be calculated among all the reviewers.

All Platforms - Desktop GUI: Improved Code Review view list and filters

The code review list has enhancements to better accommodate multiple reviewers and improve the overall user experience.

Status Icon in Code Review list: A status icon is now displayed in the status column of the code review list, aligning with the design in the WebUI.

Filter improvements: The "Assigned to me" filter now supports code reviews with multiple reviewers. Also, it now considers reviews that are in both "rework required" and "under review" statuses (it previously considered only the "rework required" status). This aligns with the Unity Dashboard UX.

Column adjustments: The unnecessary reviewer column has been removed from the code reviews view. Default column widths have been optimized for a more visually appealing and user-friendly layout.

All Platforms - Desktop GUI: Enhanced Code Review avatar display

The code review interface now provides an improved visual experience by incorporating avatars for reviewers and changeset owners in various panels:

All platforms - Dekstop GUI: Remove dynamic behavior on diff window when changing object selection

Previously, if you selected an object in the branch explorer, branches view or changesets view while having a diff window open, we had a dynamic behavior that updated the diff window's contents with the diff of the new selected object. This feature could be annoying in some situations, for instance when trying to open two separate diffs for different objects.

We decided to remove this behavior, and now when changing the selection from any view, the diff window will remain static.

All platforms - Desktop GUI, Gluon: Allow copy of the diff window branch/changeset/label name

The diff window title, which contains the name of the branch/changeset/label, has been made selectable and copyable.

DevOps: Trunkbot queue processing improvements

We improved the branch queue in the Trunkbot to play nicely with a higher number of enqueued branches.

Before, processing cycles were spaced out when branches were not ready to be tested yet. This was done for performance reasons and also to not stall remote APIs, but it could lead to high unnecessary wait times for branches at the end of the queue.

Now, the Trunkbot is smarter and spaces out the processing of each branch independently of any other. As a result, branches that are ready are dispatched much faster and the Trunkbot is much more responsive and streamlined.

All platforms: Improved the file conflicts merge with Smart Locks.

Now, merge allows to solve file conflicts if the source revision of the conflict matches the head revision (the revision loaded in the Smart Locks destination branch).

It eases the rebase of branches with file conflicts after some related locks were manually deleted or edited.

This is a server side change.

All Platforms - CLI: Circular dependencies on groups solved

There was a bug when listing users from a group with a circular dependency to another group. For instance, group1 contains 2 users and group2; group2 contains 1 user and group1. That circular dependency caused the CLI to get stuck when listing users from either group1 or group2. Now it is fixed, listing the 3 users as expected.

All Platforms - Gluon: File conflicts are properly filtered in partial update.

Before, all the file conflicts were processed in the workspace although only a single folder was specified (it ignored it completely).

Now, it only processes the file conflicts of the specified folder. It means, 'cm partial update /doc' will only process the file conflicts under '/doc'.

All platforms - Desktop GUI: Fixed wrong context menu when right-clicking on branch explorer

In certain situations, when right-clicking on an object in the branch explorer, we were showing the wrong options for the context menu. So when right-clicking on a branch, the context menu for a changeset would appear. This resulted in unexpected exceptions when using the menu.

We fixed this issue, and now right-clicking will always show the correct menu for the currently selected object.

All platforms - Desktop GUI: Fix shortcuts when opening subviews

Sometimes after opening or closing a subview, like the Shelves view in the Pending Changes, the keyboard shortcuts stopped working.

All Platforms - Desktop GUI: Added changeset numbers to the history view

Changeset numbers have been added to the details displayed on items in the History View. This addition allows you to see and filter by changeset numbers for quick navigation to the corresponding changeset.

All platforms - Desktop GUI, Gluon: Paths with white spaces are formatted with percent-encoding

All platforms: Faster deletion under folders with lots of files

Improved heavily the time deleting a big number of files when they are under a folder that still loads lots of files.

In our tests, the time deleting 5.000 files under a folder that contained 15.000 files is around x4-x15 times faster, depending on the operation.

This improvement applies to different operations:

Running an Incoming Changes operation from Desktop GUI or command line (x6 times faster).

Running a merge operation from Desktop GUI or command line (x6 times faster).

Running an apply local changes (checkout) operation from Desktop GUI or command line (x4 times faster).

Running a 'cm rm' operation from the command line (x15 times faster).

All Platforms - Desktop GUI: Enhanced support for Asian languages and much more!

We've updated the UI framework to Avalonia 11, and this brings a slew of improvements. Here are the key highlights:

A new Composition Renderer for enhanced visual capabilities and performance.

Advanced text rendering with rich text features.

IME support for diverse input methods.

Accessibility improvements to ensure inclusivity.

These enhancements make our desktop GUI even better!

All Platforms - Desktop GUI, Gluon: Improved Delete Operation performance

To enhance the GUI's performance, a significant improvement has been made to the delete operation. Instead of processing deletions one by one, it now performs the delete operation in a block by providing a list of paths. Deleting a large amount of files is now 6x faster.

Additionally, progress is now reported meaningfully, indicating the current items processed out of the total items.

All platforms - P4 importer: Symlinks are ignored

Symlinks changes are ignored when importing changes from Perforce through the 'cm sync' command. Before, the operation failed if the symlink target didn't exist in disk.

All platforms - Desktop GUI: Improved Sync View usability

When you have a sync view with a lot of repositories to sync or a lot of branches in them, it may take some time to load. If this is the first sync view on the list, and you want to check a different one, you would have to wait until it finishes loading before changing to a new one.

We modified this behavior so that you have to manually click Refresh in order to start loading the sync view. This way, if you want to check a different one, you can first select it and then click Refresh, without waiting for the first one to load

We also updated the behavior of the Push/Pull buttons, which now will only be enabled when there are actual changes to push or pull

All platforms - Desktop GUI: Exclude merges from a parent branch in Code Review window

Added a new "Show pending to integrate" button to the Code review window. This button can filter the merged differences from the branch to be reviewed. When this button is checked, all merges pending to be integrated in the main branch will be excluded from the list of changes.

All Platforms - Desktop GUI: 'Index was out of range' error on workspace creation

Fixed an “Index was out of range” error when selecting a repository for a workspace about to be created.

All platforms - P4 importer: 'Index was out of range' error with big p4 output

The reading of the p4 command output could throw the error 'Index was out of range. Must be non-negative and less than or equal to the size of the collection. (Parameter 'chunkLength')' if the output was too big. Fixed.

macOS, Linux - Gluon: Newly added items appeared as incoming changes

In macOS and Linux, when you performed a check-in of private items from Gluon, adding them to the version control for the first time, we were wrongly showing them in the incoming changes view after the check-in operation. To clear the incoming changes view and the notification, you had to manually perform an update on the workspace.

We fixed this issue, and now nothing appears in the incoming changes view after performing the check-in.

macOS - Desktop GUI: Select previous check-in comments on server-side merges

When performing a server-side merge with the "merge from this branch/changeset to" option, we show a dialog to enter the check-in comment. Instead of typing it, you can select a previous check-in comment from a drop-down menu. This menu wasn't working properly on macOS, so we improved it and now it behaves as expected on all three platforms.

macOS - Desktop GUI: Input lag in server-side merge comment text box

All clients: GitSync doesn't push empty folders anymore.

GitSync doesn't push the empty folders that are present in Unity VCS to Git anymore since some Git applications could struggle with them.

All Platforms - Desktop GUI: Improved Workspace Explorer Performance

The GUI now handles directories with over 30,000 items smoothly. Expanding nodes and scrolling are now much faster, ensuring a seamless user experience.

All Platforms - Desktop GUI: Fix selected changeset movement in Branch Explorer

The selected changeset disappeared in some scenarios when navigating the Branch Explorer with the arrow keys. This happened when the destination changeset was out of bounds but close to them.

All Platforms - Desktop GUI: GUI Freezes with a large selection

When attempting to select all 7,000 files in the pending changes view, and then refreshing the view, the GUI became unresponsive for approximately 20 seconds. Now it's fixed.

All platforms - Desktop GUI, Gluon: Missing progress in pending changes while refreshing

Show the refresh progress while the pending changes are loading over the empty state message.

All Platforms - Gluon: Fix sorting items by Size in Configure workspace view

All platforms - Desktop GUI: Null error running a server-side merge

All platforms - Server can checkin directories with lots of direct entries.

The server used a buffer of 5M to calculate the hash of the directory entries. This was not enough for folders with more than 150.000 entries, so the checkin failed. Now, this limit is much bigger.

All platforms: Greatly improved the performance while finding locally removed files.

Removed an unneeded check for moved files when the workspace only contains locally removed items, no private or ignored files.

Example: In a working copy with 14K locally removed files, the search took 20 seconds to complete; now it takes 500ms.

Also, improved the search operation for moved items. Before, we downloaded all the locally deleted content to attempt a move-match with private file candidates. Now, we only download those whose size will be a valid match for the existing candidates.

All clients: Client-side check-in triggers support added to partial workspaces

If you configure a client-side check-in trigger, it will now run for partial workspaces:

All platforms - Desktop GUI: Improved checkin operation startup time

In the check-in operation, we have made an enhancement to optimize startup time. Previously, the operation included a phase where paths were resolved to expand them and make them canonical, as well as resolving symlinks. However, it was observed that the GUI doesn't require this step. Therefore, we have decided to skip it, resulting in a faster check-in operation.

All platforms: Faster workspace status calculation with added items.

Improved heavily the time to calculate the workspace status when a big number of items were added under the same folder. This is only noticeable if the number of files is greater than 1.000.

In our tests, the workspace status calculation of 8.000 added files goes from 9s to 0.15s.

The workspace status calculation is performed when running the 'cm status' command or refreshing the pending changes from Desktop GUI & Gluon.

All platforms - Desktop GUI/CLI: Delay in visual feedback during large check-ins

When performing a large check-in, there was a noticeable delay between initiating the check-in and receiving visual feedback through the UI or CLI. This delay became especially prominent during very large check-ins. We were missing notifying visual feedback during the "Assembling check-in data" phase. Now it's fixed.

All Platforms - Desktop GUI: Improved performance expanding nodes in the Workspace Explorer

Previously, expanding a node in the Workspace Explorer that contained 18k items took a variable amount of time, ranging from 6 to 15 seconds. This performance issue was impacting the user experience.

Expanding 18k nodes is now significantly faster (about 750ms), enhancing overall usability.

All platforms - Desktop GUI: Show notification dialog when pending changes in diff window

The Unsaved changes dialog will be shown in Diff window after a new branch/changeset selection is done and exist any pending changes to save/discard in the diff view.

All platforms - Desktop GUI: Super-slow check-in of many deleted files.

The pre-processing time of the checkin operation (when launched from Desktop GUI) was super-slow when the changes to checkin included lots of files deleted under a folder that still loaded lots of files.

Let's see a scenario where it happened: there is a folder '/Assets' with 20.000 files. If we deleted 10.000 of them and tried to check them in from the Desktop GUI, the check-in operation took more than one hour to start. Now, it only takes around 50s. This means x100 times faster.

As a workaround for this slowness, you could disable symlink support on Windows in the client.conf file: <EnableSymlinkSupportOnWindows>no</EnableSymlinkSupportOnWindows>.

All platforms: Faster checkin of added items in partial workspaces

Improved heavily the time to check added files in when a big number of them are located under the same folder. This is only noticeable if the number of files is greater than 5.000.

In our tests, the improved step when checking 50.000 files in goes from 250s to 0.25s. The overall check-in time could go from 270s to 20s (depending on the files size to upload).

macOS - Desktop GUI: Fixed preferences dialog getting the UI stuck

If you try to shelve or checkin some changes with an empty comment, a dialog appears by default asking for confirmation. In that dialog, there's a link to open the preferences dialog in case you want to prevent that warning from appearing in the future.

Command line client: Faster full checkin in partial workspaces

Improved heavily the time calculating the changes to checkin in partial workspaces with lots of added items.

In our tests, the time calculating the changes to checkin for 300.000 files goes from 180s to 1s.

All platforms - Gluon: Configuration tree didn't refresh properly

The configuration tree in Gluon didn't allow to change the check status of items that were changed previously when a refresh was done. For example, when any file/folder was marked to unload and then the refresh button was clicked, it was not possible to switch back this status to load again and an error message was displayed on the bottom.

All Platforms - Desktop GUI: Replace shortcut to open a workspace from the Home view

In the Home view, the shortcut to open the selected workspace in a new window was Shift+O. This shortcut was being executed when trying to type Shift+O in the filter text area.

We changed the shortcut to Ctrl+O

All platforms - Desktop GUI] Improved horizontal scrolling speed

Previously, scrolling horizontally (SHIFT + mouse wheel) in the Branch Explorer was noticeably slower compared to the legacy GUI. To address this problem and enhance the scrolling experience, we have increased the horizontal scroll size from 10px to 250 pixels and also the vertical scroll size from 10 pixels to 32 pixels.

These changes should result in significantly improved horizontal scrolling performance in the Branch Explorer, making it more in line with user expectations.

All platforms - Desktop GUI: Fixed memory leak in DiffWindow/DiffViewer/DiffControl

All platforms - Desktop GUI: Show icon when permissions are marked as overridden

A new icon will be displayed when any permission from the Permissions dialog is selected to be overridden, it will be applied to the selected column "Allowed" or "Denied".

All platforms - Desktop GUI, Unity Plugin: Use the same default organization for the Desktop GUI and the Unity Plugin

Now, if you select an organization after doing the onboarding in the Desktop GUI or the Unity Plugin, the selected organization will be saved by default for both places.

All platforms - Desktop: New Cloak options for browsing a changeset

Now, when browsing a changeset in a workspace, users will be able to add and remove items from the cloak filter using the context menu on the files or directories.

Click here for more info about cloaked files: https://docs.plasticscm.com/book/#_ignoring_private_files_with_ignore_conf

Command-line client: cm listuser --group now fails if the group does not exist

If you set a group that does not exist, the command will explicitly notify you about it.

Command-line client: cm patch command fails unexpectedly

The patch command failed with the following error message in certain scenarios involving permission changes.

Now those cases are handled gracefully, and the command will run to completion.

Command-line client: cm checkout message does not belong to the machine-readable output

The following message was wrongly shown by the checkout command when using the --machinereadable option:

All platforms: Improved merge file conflicts with Smart Locks

A file is always checked-out when solving a conflict. It doesn't matter the type of resolution chosen (merge, keep source or keep destination). This prevents the creation of parallel changes while a merge is being processed in a workspace.

Before, when solving a file conflict with an existing lock in Retained status, the destination of the merge had to always be the retained revision. This implied running an extra merge (rebase) from the destination branch (/main) to the branch to integrate (/main/task) before integrating the branch into /main. Now, the branch that contains the Retained revision (/main/task) can be directly integrated into the destination branch (/main) so the file conflicts are solved there without any extra step.

All platforms - Plugin for JetBrains IDEs: Fixed wrong diff calculation after applying a shelve

The UVCS plugin for JetBrains IDEs calculated the wrong diffs for items that were checked out in the workspace as a result of applying a shelve using a UVCS client (GUI/CLI) outside the IDE. Now it's fixed.

Command-line client: Partial check-in progress bar glitches

When running a partial check-in operation, the progress bar line and the results were overwriting each other in the command line.

Now both are displayed properly.

Command-line client: Switch and partial switch will now take into account the workspace repository

Before, running the "cm switch" or "cm partial switch" commands under a Xlinked directory, the default repository was the Xlinked one. This behavior was confusing, and it could produce unexpected changes in the workspace:

Now, the top-level repository is used by default for these commands. If you really need to switch to a different repository, you can still achieve it by explicitly typing the destination repository:

All platforms: Merge didn't release locks for file conflicts with keep destination resolution

The lock was ignored after solving a file conflict with the keep destination resolution. So, if there was a lock related to that merge, the lock could get out-of-dated. This happened for client-side merge and server-side merge. Fixed.

All platforms - All clients: Fixed the update progress message in Japanese

We applied a more accurate wording in the Japanese localization for the message that gets displayed while updating a workspace.

All platforms - Desktop GUI: Added ScrollViewer to the initial login window

Previously, when launching the GUI with no configuration (no accounts) and resizing the window to a minimal height, the controls were being cut off, and a scrollbar was not displayed as expected.

Now, we have introduced a ScrollViewer to the view. This means that when the contents do not fit within the screen height, a scrollbar will automatically appear, allowing users to access all controls even in smaller windows. Screenshot:

All Platforms - Text Merge Tool: Comparison Method options cannot be deactivated

All platforms: Server-side merge failed with locks.

The server-side merge (merge-to) operation failed when processing a file that was only modified on the source if it was under lock rules. It could fail with both legacy locks and Smart Locks. This has now been fixed.

macOS - Desktop GUI: Opening bad links no longer closes the app

After opening a link that pointed to an unreachable server, the application closed automatically when the user dismissed the message popup that appeared.

All platforms - Desktop, Gluon: Improved handling of purged revisions in the GUIs

Several views can now detect a purged revision.

In the views that show a list of revisions (such as the History view) the purged revisions now have a trash icon and a different visual style. A tooltip also indicates purged revisions from the list.

In the Differences view, a message indicates the revision was purged. This Differences view appears in different places within the application: the History view, the Diff window, the Code Review window...

All platforms: Restrict code review status changes to reviewers

From now on, only a reviewer will be able to update the review status.

When there is no reviewer assigned to a code review, the GUI will allow updating its status by any user, as before.

All platforms - Triggers: The "edit review" trigger includes the reviewer edition action

Now, the add reviewer, update reviewer, and remove reviewer actions also run the edit-review triggers and set the following info on the PLASTIC_REVIEW_ACTION and PLASTIC_REVIEW_ACTION_INFO variables

** PLASTIC_REVIEW_ACTION -> add reviewer

** PLASTIC_REVIEW_ACTION_INFO -> James

** PLASTIC_REVIEW_ACTION -> remove reviewer

** PLASTIC_REVIEW_ACTION_INFO -> James

** PLASTIC_REVIEW_ACTION -> update reviewer

** PLASTIC_REVIEW_ACTION_INFO -> James:Reviewed

All platforms: Server-side merge takes into account the exclusive check-out rules

Before, the server-side merge (merge-to) operations ignored the exclusive check-out rules (lock rules). This happened both for Smart Locks and the legacy lock system. This misbehavior could lead to file conflicts although the lock rules were in place.

Now, the exclusive check-out checks & operations run from merge-to too. The operation now behaves the same as if you run the merge from the client side, and can not lead to file conflicts.

All Platforms - Client Command Line: The cloaked configuration is now taken into consideration in encrypted organizations

When working on an encrypted organization, the encryption key is stored in the client for security reasons - it never reaches the server.

Because of this, the server could not apply the cloaked filter stored in the server (apply the cloak before even attempting the download). It could only use the cloaked filter stored in the workspace, which could be out of date.

Now the server can read the cloaked.conf stored in the server without compromising the security. For encrypted organizations, the client first downloads the cloaked.conf in the server. This way the client can use the latest version, regardless of its encryption status.

All platforms - Desktop GUI: Fixed an exception when removing all accounts

The GUI could throw an error under some circumstances when removing all accounts. Now if you remove all accounts you will see the onboarding again, as if you had a clean setup.

All platforms - Desktop GUI: Fixed an exception when pressing Ctrl+F

All platforms - Desktop GUI: Text displacement when scrolling in help panel

There was an issue with the help panels that had long text lines: when scrolling through the text and making the long lines invisible, the whole text was horizontally moved to one side. We fixed this issue, and now scrolling in the panel doesn't affect the alignment of the text inside it.

WebAdmin: Wrong results when diffing branches

All platforms: Introducing Smart Locks

There are many kinds of files that present a challenge for merging content changes:

Images and texture maps

It is quite easy to see how important it is to apply changes to these assets sequentially and always iterate over their last revision. The creation of parallel histories usually means that some changes are discarded and redone down the line, since conflicts in these files cannot be merged.

So far, you could set up these lock rules to guarantee that nobody else made changes to the same file at the same time. When you were done, changes were checked in — or unchecked out — and the lock was removed. This "legacy" lock system was devised mainly for artists that work on a single branch, forcing the user to work on the last revision of the branch.

However, protection did not extend to multi-branch scenarios, allowing the creation of parallel changes in different branches:

Alice made some changes to player_icon.jpg at /main/level_12. The scene is waiting to be integrated, and the file is not locked anymore.

Bob is working on its own branch (/main/level_11) and makes a quick change to the same file too.

Yes, both are using the last revision on their branch, but they don't take into account new revisions in other branches.

Now introducing Smart Locks.

Smart Locks are the mechanism that Unity DevOps Version Control uses to track which branch retains an asset for edition, and it works as a baton pass or as a "torch". Even if the file is not exclusively checked out right now, task branches retain the lock and prevent developers from checking out an outdated revision in a different branch.

Moreover, locks are not retained by the users who created them. As long as they keep working with the last revision, other developers can still exclusively check out the file you just checked in! This is true even for multi-branch scenarios.

In other words, Smart Locks ensure a single line of development for assets among different branches while enabling collaboration between developers. Long gone are the days when you needed to keep a physical token on your desk to let your colleagues know that you were holding an asset: Unity DevOps Version Control keeps you covered.

== CREATING SMART LOCKS ==

Smart Locks are here to replace legacy locks, and the new version of the server already uses them from the get go (see details in the 'COMPATIBILITY' section). If you were already using locks, you probably just need to upgrade.

First of all, you need to set up the lock rules (if you don't already have them!):

Note that there are two new optional fields available in the lock rules:

The "destination branch" — br:/main by default — is the source of truth when creating a new lock: the revision loaded here is considered the last revision. Locks created in other branches are not released until they get integrated back into the destination branch.

Some "excluded branches" where the lock rules are ignored. Note that you can use wildcards at the beginning and at the end. Excluded branches are matched by name, so bear it in mind when renaming branches!

After setting up the rules, you can create a task branch and try to check out a file. The "lock list" subcommand will help you to inspect which locks are in place and their current status:

Within the Desktop GUI, the Workspace Explorer now tells explicitly which files are locked by other users, and they are represented with special icons for clarity.

Also, a new panel was added to the Desktop GUI and Gluon to display the Smart Locks that currently exist in the workspace repository. Since there, you can release or remove the locks too:

Moreover, this panel is available in both, the Workspace Explorer and the Home View, so you don't even need a workspace to manage the locks of a repository.

Likewise, the same functionality is provided by the WebUI:

Remark: note legacy locks as they are not truly tied to specific repositories, so they cannot be visualized this way. Running "lock list --anystatus" shows all the server locks by default, so you can use it to find them if necessary.

See in detail how to configure exclusive check-out using an on-prem server in our administrator guide:

https://docs.plasticscm.com/administration/plastic-scm-version-control-administrator-guide#Chapter7:Configuringexclusivecheckout(Lock)

Smart Locks do not travel across replicas.

Replicas might add newer revisions to the repository, leaving the lock outdated.

Some scenarios involving changeset deletion might leave the lock outdated for obvious reasons.

Merge-to does not support locks — neither legacy nor smart ones —... yet! Stay tuned.

Even if you bump into such scenarios, none of them are unrecoverable. See the following section.

== REMOVING AND RECREATING LOCKS ==

You might land in a situation where a lock must be forcefully unlocked — maybe somebody locked an asset and forgot to release it, or maybe a lock was invalidated for some other reason.

You can use the Desktop GUI, Gluon, or the WebUI to release or remove the lock. Alternatively, you can also use the "lock unlock" subcommand:

By the way, if you really need to remove a lock entirely, you might want to recreate it somewhere else. You can use the "lock create" subcommand for that. Lock rules already determine which is the destination branch, but you still need to explicitly specify the holder branch, like so:

Before, lock rules allowed a lockserver field (although this was barely used and could introduce some issues). It won't be supported anymore.

Old versions of the client can perform exclusive check outs over files, but they won't be able to release Smart Locks, only legacy ones. If you try, you will be prompted to upgrade in order to continue.

After upgrading, legacy locks already in place will stay as they are. But as soon as files get checked in or unchecked out, the legacy lock will be gone. The next time you check out such files, they will start using the new system.

There could already be parallel versions of some files (coming from legacy locks, if they were used this way). In this case, some manual operations could be needed to continue working with these files during this transition to Smart Locks. 'cm lock unlock' and 'cm lock create' are here to help.

Legacy locks will still be supported, at least for a while. Indeed, you can disable the new behavior in the server by adding the following key to the server.conf:

You can find more information in the official documentation:

https://docs.unity.com/devops/en/manual/smart-locks

Command-line client: cm update now has its own update report

The update command usually does not show an update report. Instead, it shows a progress bar (if used interactively) or all the relevant events that happen on items as they are updated (a behavior intended for tool automation).

However, the progress bar does not clearly communicate errors. Now using cm update interactively features an update report at the end, which helps to better understand what happened:

All platforms - Desktop GUI, Gluon: Links not properly formatted in release notes

Command-line client: cm checkin --silent option not working properly

Before, progress text was shown even when the --silent mode was specified. Now it won't be shown anymore.

All platforms - Desktop GUI, Gluon: Test Issue tracker connection failing

An error message was shown when trying to test a valid issue tracker connection, now the green tick will appear if the connection is correct.

All platforms - WebAdmin: Fix Lock Rules section

Opening the Configuration / Lock Rules section failed with a "something went wrong" error. This happened since 11.0.16.7995. Now it's fixed.

Windows, All clients: Path errors when mounting drives as directories

When drives are mounted as directories in Windows, a junction mount point is created for it. Unity DevOps Version Control was overzealously solving their target paths, leading to some errors and glitches.

All platforms: Trim your repository size with Purge

Real-time 3D projects can grow substantially in storage size. The iterative nature of development leads to the creation of multiple revisions of large files that, by design, are kept safely stored in Unity Version Control. Although we keep this behavior as the standard, we also want to provide our customers with flexibility so they can choose how to better manage their data.

We are excited to introduce Purge. You'll have the power to permanently delete those old, unused revisions and trim your repository data, leaving room for the ideas that lie ahead. You'll be able to select a specific period of time and file extensions you want to remove, and in a few steps, you'll get your repository shrunk.

Important note: This operation is destructive and irreversible. While we want to give users the flexibility to have the ability to control their repositories, we also don’t recommend purging your repositories. Unity Version Control is designed to keep the history of your project fully registered as long as it lives, and the use of purge means that you are losing data.

== A feature with safety features in mind ==

While this operation is destructive and irreversible, we designed it to preserve the most vital revisions. This ensures that you will always have stable checkpoints inside your repository.

The purging process calculates the scope of your requests, skipping those revisions loaded at the head of a branch or if they exist in a changeset with a label. These simple safety features guarantee that you can always return to any label or branch head.

== Try now on your CLI ==

Purge is only available through the command-line interface, where you can calculate, execute, and consult the history of your operations. Don’t forget to set permissions for it and to keep it as an administrator-only functionality.

First, you will need to request a purge. This is done using the “cm purge register” command, specifying the file extension and the ‘before’ date when to apply the purge.

The register command will return you a purge GUID, this value can be used to check its status via the “cm purge show” command:

Once you are sure you want to run the purge operation, you will need to use the “cm purge execute” command, specifying the purge GUID you want to execute.

You’ll need to confirm the request to safeguard the process.

Lastly, you can use the command “cm purge history” to check the specific status of one purge or previously executed purges.

== Check out the complete CLI documentation and learn more about Purge ==

Since we are talking about CLI, we recently updated and brought the documentation to the web, making it easy for everyone to find, search, and learn about every available command and the extensive list of capabilities from Unity Version Control.

https://docs.unity.com/devops/en/manual/uvcs-cli/version-control-cli

You can visit our webpage and download the latest version right now:

https://www.plasticscm.com/download

Please note that this feature is only available through the Unity Version Control CLI for Cloud customers. Only new Cloud organizations will have the new ‘purge’ permission enabled by default for the “Administrators” group. If you want to start using this feature, make sure you grant the ‘purge’ permission first.

If you are not a customer or want to start using Unity DevOps for free, you can subscribe here:

http://www.unity.com/products/unity-devops

All platforms - Desktop GUI: Pending merge links were not visible with no pending files

All platforms - Desktop GUI, Gluon: Updated to Avalonia UI v11

In this release, we updated the apps to use the new version of Avalonia UI framework, which includes clear type rendering for Windows and some improvements in the Asian languages support for the edition.

In addition, Avalonia UI v11 carries the most substantial changes in their API to date, setting it up for a thriving future to ensure a more robust and reliable UI.

All platforms - Desktop GUI, Gluon: Empty state when view has no items

The empty state message will be displayed when no element is found for the current main view. This empty state message has been added for all Unity VCS main views except for the Branch Explorer, Branches and Changesets views, and for all Gluon main views except for the Changesets view. The context menu will be available for some of those views in this empty state, in order to use some basic actions.

Windows - All clients: Symlink support is now enabled by default

Windows symlink support was released in Plastic 11.0.16.6979 on May 19th, 2022. That's quite a while!

Now symlink support is enabled by default for all machines running Windows 10.0.14972 or newer. You can check which Windows version you have by running cmd.exe:

To actually use this feature, you need to enable Developer Mode in Windows. To do so, you just need to type 'Developer Settings' into the Cortana search box, in the taskbar, and switch the 'Developer Mode' toggle on:

https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development

If for some reason you are not allowed to enable it and your repository contains symlinks already, you might want to keep the old behavior. To achieve that, you can simply disable the feature by setting the following configuration key in your client.conf file:

If you already have some symlinks in your repository, your workspace will have placeholder files loaded in the tree.

To upgrade an existing workspace, you just need to remove those files from the disk (for instance, using Windows Explorer) and undo your changes in Unity DevOps Version Control immediately after. This will force it to recreate the items as proper symlinks.

== HOW TO CREATE SYMLINKS ON WINDOWS ==

You can use the same Unity DevOps Version Control commands and options you would use on Linux or macOS:

Conversely, if you want to enable the feature using an older version of Windows, you can set the same configuration key explicitly:

Mind you, this implies an advanced usage and involves running Unity DevOps Version Control with the administrator account. Whereas such usage is discouraged for obvious reasons, it is allowed.

All platforms - Command-line client: "cm log" command learns "--dateformat" parameter

The cm log command is now able to set a date format to print the log entries with the specified date format.

Example (will print the dates in universal sortable dateformat):

All platforms - Unity DevOps Version Control, Gluon: Shelves improvements

We improved the discovery for the Shelves view by opening it the first time you use the app.

The state of the Shelves view is remembered as a user preference in order to be shown or not when you open the application again.

Also, we implemented an empty state to appear if the user doesn't have shelves, or if the user executes a query without results.

All platforms - Desktop GUI: Workspace Explorer search crashes

All platforms - Desktop GUI, Gluon: New option to display cloaked files in pending changes

As part of the pending changes options, we added a new option to display cloaked items. Now, you can see any cloaked file with changes in the pending changes view enabling this new option.

All platforms - All clients: Files modified only on source are checked-out in cherry picking.

Now, cherry picking, subtractive and interval merge checkout the files that are modified only on source before applying the change in the workspace.

This way the lock mechanism is respected for these kind of merges to avoid creating file conflicts for non mergeable files easier.

All platforms - Desktop GUI: Home view refresh doesn't keep the selected organization

If you changed the selected organization in the Home view, the next time the window was activated the selected organization was changed to the first value in the list.

We fixed this issue and the selected organization now is preserved.

All platforms - Desktop GUI, Gluon: Shelve empty comment warning configuration issue

The ShowEmptyShelveCommentWarning configuration setting just needs to be updated only when it's changed from the 'Preferences' window or when the 'Don't ask me again' option is checked in the 'Shelve empty comment' dialog.

Linux - Installers: Cannot resolve libicu dependency. Fixed.

Some Debian / Ubuntu distros were showing an error while installing telling that there is an unmet dependency of libicu and cannot be resolved.

Now it is fixed, since "libicu72" is set as a valid alias for libicu dependency.

All platforms - Desktop GUI: Improved undo behavior after creating a shelve

After a new shelve is created, we show a dialog asking if the user wants to undo the changes or keep them in the pending changes. Now this dialog appears before the shelve is created, and it can be closed to cancel the whole shelve operation.

We also added a checkbox that allows to remember the selected option. This behavior can be changed at any time from the preferences

All platforms - Desktop GUI, Gluon: Improved the style of the sign-in dialog

New layout modifications have been done in the sign-in dialog.

The Unity Version Control CLI documentation is now live on the web!

Previously, we were missing the complete documentation with all commands, and the only way to access it and understand how to use the command line was through internal help. Now there’s a comprehensive guide available for everyone!

You can find the documentation here:

https://docs.unity.com/devops/en/manual/uvcs-cli/version-control-cli

It’s packed with detailed explanations, examples, and usage instructions for all the Unity Version Control CLI commands. Whether you’re a seasoned pro or just getting started, this resource will be invaluable.

Keep in mind that this is the first published version. While it’s a significant milestone, we recognize that there’s always room for improvement.

Stay tuned for more updates on the online CLI help!

All-platforms - Command-line client: New mvbranch trigger

We added a new type of trigger, which is called before/after the renaming of a branch. Along with the trigger, we added two new environment variables:

These can be used in combination with previous environment variables for automation purposes (see below).

For instance, it would be possible to create a trigger with the following command:

This script could contain the following - indeed, you can try something like this to set the trigger up and test it!

And then, when executing a rename in the branch, the result file would have the following content:

As always, the usual environment variables are also available when running the trigger:

All platforms - Desktop GUI: Fixed exception deleting text in Merge Tool.

All platforms - Desktop GUI, Gluon: Preferences menu icons on hover

Changed the color of the menu item icon when the mouse is over the item.

Windows, Linux - Desktop GUI, Gluon: Shortcut to open preferences dialog

Handled the "Ctrl+," keyboard shortcut to open the Preferences window in Windows and Linux.

All platforms - Desktop GUI, Gluon: Improve empty comment warning

We updated the dialog that appears when you try to check in some changes without entering a comment. Now the dialog has a check box that allows you to remove this warning for future check-ins. There's also a link to the view in the preferences where you can change this setting later.

Also, now the warning is also shown when creating shelves

Windows - PlasticFS: Serveral improvements in symlink support

PlasticFS now uses its own reparse point solver. Now relative symlinks are allowed to freely reach the mount point and outside the workspace.

Some additional corner cases involving junctions are now fixed too.

== SYMLINKS LIMITATIONS ==

This feature is in an early stage of development, so you can expect minor bugs to happen.

PlasticFS always creates symlinks as files. By trying to access them, they will be automatically solved and converted to directories. However, this step might confuse external programs that do not expect it.

This happens anytime you create a new workspace or under some special conditions involving "undo" and "update" operations.

Windows Explorer will force this conversion, but you might have to refresh the window the first time it shows a symlink.

All platforms - Desktop GUI, Gluon: Standardize zoom controls

The image diff viewer zoom controls have been replaced by new ones with same look&feel of the Branch Explorer zoom controls.

All platforms - Desktop GUI: Fixed exception when closing Merge Window too quickly

Clicking "Save and Exit" on the Merge Window before the merge was calculated resulted in an unexpected error. We fixed this by disabling the button until the merge calculation completes.

All platforms - Desktop GUI: Back button appears on user account change

All platforms - All clients: Faster workspace tree (plastic.wktree) update

Clients using super-huge trees (more than 1M items) will experience a performance improvement.

A single file checkout/checkin/undo operation in a workspace of 7M of items is now x10 times faster!

Before, it took around 6 s to write the workspace tree.

Now, it only takes 600 ms to write the workspace tree.

This change is only available for clients with the following client.conf setting enabled (see "Remarks"):

Enabling this setting could cause trouble if there are older Unity DevOps Version Control installations (including older versions of the Unity Plugin) in the same machine. Be careful!

In this first step, this smart update is only enabled when there are not structural changes or xlink editions to write. We will improve this in the future.

This optimization is geared to workspaces with more than 1M of items, it won't be noticeable for smaller workspaces.

Details about the change:

Before, the entire workspace tree file was rewritten each time its metadata was modified (through a checkin, checkout, switch, etc. operation) even if only a few files were touched. Now it only re-writes the modified entries, which makes it much faster for big workspaces.

All platforms - Desktop GUI, Gluon: Added Attributes view for shelves

Now you can see and edit the attributes of a shelve when seeing its differences. There's a new button at the top that lets you open the list of attributes, from where you can add, remove or modify them.

All platforms - Desktop GUI: "Close merge view and open pending changes" set by default

As of this release, "Close merge view and open pending changes" Preferences option will be set by default to all new users.

All platforms - Desktop GUI: Code Review comments Reply button disabled after it's clicked

In code review window the Edit and Reply buttons has been disabled from comments and questions list while the new comment is in edition mode. This is done to avoid discarding the changed text when this button is clicked instead of the Comment button.

Linux - Desktop GUI: Updated app icon

As part of the ongoing rebranding to Unity Version Control, we replaced the 'Plastic SCM' icon with 'Unity DevOps Version Control' one in the app for the Linux platform.

Windows - Wwise plugin: Prompt for checkout on edit is now supported

Implemented support for the VCS setting "Prompt for checkout on edit", allowing users to checkout the affected files as part of the saving process.

Windows - PlasticFS: Upgrade to WinFSP 2023

Plastic FS now uses WinFSP 2023 as the minimum supported version. If you already have WinFSP 2023 Beta 1, the upgrade process will be easier than ever.

You can find the WinFSP release notes in https://github.com/winfsp/winfsp/releases.

All platforms - Desktop GUI: Issue tracker repo list is unsorted

In the Preferences window, the repositories list from Issue Trackers view will be sorted alphabetically.

All platforms - Desktop GUI: Pending Changes - Selected items number not updating

Fixed text update in Pending changes tree, when the items were checked/unchecked the displayed category text wasn't updated properly.

All platforms - Desktop GUI, Gluon: Fixed misaligned links position

In the app, links and texts on the same line could appear vertically misaligned. We fixed this issue

All platforms - Desktop GUI: After-checkin trigger errors now shown in GUI

Notifications about failures when running after-checkin triggers were being shown in the command line tools, but were not being shown in the GUI.

Now, we display the error in a dialog to ensure that you are alerted when a trigger fails to run.

All platforms - Desktop GUI: Fixed null exception when resolving merge

We fixed an exception that could be thrown while processing file conflicts one at a time during a merge, where the merge involved writeable xlinks but there were no conflicts in files under the xlink. The exception didn't affect the merge, but the error dialogs made it look like there was a problem.

All platforms - Gluon: Details Panel showing incorrect characters under Spanish localization

Gluon Details Panel show incorrect characters in fields "Tamaño" and "Último acceso" in Spanish localization.

Windows - Desktop GUI: The legacy Plastic SCM GUI has been deprecated

Please update your installation to the latest version. Continuing to use any older version may result in reduced support for your operation.

The new GUI has been the default since version 11.0.16.7105 and is fully capable of upholding your Unity Version Control workflows, please don't hesitate to contact us to provide additional feedback so we can continue improving it.

All platforms - Desktop GUI: New design of the shelves view

We improved the design of the shelves view. The old table style was replaced with a new list that displays all the relevant information about each shelve in a cleaner way.

Also, we rearranged the buttons to create a new shelve and see the shelves list in the pending changes. Check it out:

All platforms - Desktop GUI, Gluon: Shelve diffs shown in the pending changes view

Now when showing the diff of a shelve, instead of opening it in a separate diff window, we show it integrated in the pending changes view. You can close the diff to go back to the pending changes or select a different shelve to view its differences.

We also redesigned the header of the diff window to match the new style of the shelve diff.

All platforms - Desktop GUI, Gluon: Added option to automatically open shelves

We added a new option in the Shelves view that, when enabled, allows you to automatically open the selected shelve in the current window, every time you change the selection. If you disable this feature, you can work as before, by double-clicking on each shelve to open the diff in a separate window.

Windows - Desktop GUI: Enabled SemanticMerge by default

As of this release, the SemanticMerge tool will be the default tool for new Windows users instead of the legacy SemanticMerge tool.

All Platforms - Desktop GUI: Enhanced Shelve view toolbar

Users will now see new "Apply" and "Delete" buttons in the toolbar, (and the previously existing context menu equivalent options). By prominently displaying these actions in the toolbar, we aim to improve the visibility and ease of use of these options for users.

All Platforms - Desktop GUI: Improve notifications

We replaced the old transient notifications in the status bar, with window notifications for a better experience.

Windows - Desktop GUI: Removed "Switch to Legacy GUI" menu option

The legacy Plastic GUI for Windows is no longer being supported as of this release.

In Unity VCS, the "Switch to Legacy GUI" menu option has been removed, and the executable will soon no longer be part of the installation package.

Also, "Welcome to new GUI" message panels were removed

All platforms - Desktop GUI: Updated 'Sign in' dialog layout

We updated the 'Sign in' dialog in order to highlight the Unity ID auth because now it is the main one.

All platforms - All clients: Fixed an error that could result in corrupted downloads because of a socket timeout when using SSL

Under some circumstances, downloading revision data from the UVCS server to the disk - typically a workspace update operation - might fail, leaving partial content on the disk (files not completely downloaded, or not downloaded at all).

The message error you would see in this situation is:

Now there is a higher timeout in place both for send and receive operations, which reduced timeouts by more than a 90%. This results in fewer retries overall for every user, and fewer chances of facing this error, even without updating your client version. Nevertheless, we encourage you to also update your client to this version, as now it is properly detecting unexpected EOF's at SSL to retry the operation automatically.

All platforms - Desktop GUI, Command line client: Allow complete a merge keeping the local changes with the files locked

Previously, the merge operation needed to access all the files in conflict, no matter the selected resolution for those files.

Now, when you want to keep your local changes during the merge (keep destination resolution), this access is not needed.

It is useful when your IDE locks the file you are working on and for which you want to keep your changes, such as an asset of the Unreal Engine.

All platforms - Desktop GUI: Fixed exception when navigating to "Find in files" result in large file

In some circumstances, navigating to a "Find in files" result after previously selecting a file large enough to show the "large file" warning, could result in an error being shown. We fixed that.

All platforms - Desktop GUI: Fixed branch explorer multilabel issues

An error was obtained when double clicking a multilabel shape in the branch explorer, now the browse repository view will be displayed after this user action. The displayed properties from the Options panel were not consistent with the current selection when a multilabel was selected, now no Properties will be displayed for this kind of labels.

An issue has also been fixed regarding the branch explorer view, when the browse repository view was closed the branch explorer was not in normal mode because it had the panning mode activated.

All platforms - Command line client: Fix client configuration for Unity ID authentication

The cm configure command was wrongly setting the LDAP working mode, when configuring your client to work directly against the cloud server using the Unity ID authentication.

As a result of this misconfiguration, when you try to access a different server, which was not used before (without a profile for it), the client fails with the error "Invalid parameters for LDAP in client config file."

Now the cm configure command sets the right SSO working mode. Also, when the misconfiguration is detected is fixed automatically without having to configure the client again.

All Platforms - TeamCity plugin: Added a timeout so now plugin is able to reset if it hangs up on the shell initialization

Plugin was some times getting stuck on cm shell version command for some Agent operations. We added a timeout for those operations and now if it hangs we are able to get rid of it and fail.

All platforms - Server: TrunkBot Mergebot (DevOps) was throwing an error on a race condition

All Platforms - Unity DevOps Version Control: Organization creation redirect.

Previously, it was possible to create organizations directly from the GUI, but now, organization creation has been moved to the Unity Dashboard.

So when you try to create a new organization from the GUI, you'll now be redirected to the Unity Dashboard.

All platforms - Plastic, Gluon: New Code Editor and Language settings in Preferences

A new settings tab has been added to Preferences window to allow Code editor settings management. In this new view we can modify some of the settings related to the code editor as the font or number of tab spaces, and also the values can be restored from the default configured values.

The app language selection has been also added to the Other options view from Preferences window. When a new language selection is done and saved, a new popup message will be displayed asking for the application restart. The new language will be applied in GUI only if the application is restarted.

All platforms - Unity DevOps Version Control: Updated app icons

As part of the ongoing rebranding, "Plastic SCM" icons were replaced by "Unity DevOps Version Control" icons in the app.

All Platforms - Unity DevOps Version Control: "Checkin" grammar revision

"Checkin" grammar revision was made in all text strings.

For instance, the "Checkin" button was changed to "Check in" in the Pending Changes View.

All platforms - Unity DevOps Version Control: fixed exceptions in Home view when user has no organization

We fixed a couple of issues in the Home view where exceptions were thrown when the user has no organization. The exceptions were thrown when the show deleted repositories option was toggled, and when text was entered in the filter.

All platforms - Unity DevOps Version Control: Localization broken

All Platforms - Unity DevOps Version Control: Color Picker: Removed alpha channel slider

In this release, alpha channel slider was removed for Color Picker controls

Server: Allow to see the branch changes pending to integrate when it doesn't fulfill the merge rules.

The diff --integration (e.g., 'cm diff br:/main/task --integration') allow to see the pending changes to integrate for the given branch. But, when the branch doesn't fulfill the merge rules defined on the server (e.g., you need to review the branches prior to merge them into /main), you get the error "Cannot perform the merge because of the Merge Rules. Review the branch '/main/task' to merge it to '/main'." when you try to see the changes pending to integrate on a branch without a code review.

Now the diff --integration works, no matter if the server has any merge rule enabled or if the branch fulfill those rules.

All platforms - Unity DevOps Version Control, Gluon: Improve visibility of current changeset or branch

We added some visual cues to the Branches and Changesets view so that you can more easily see which is your current branch or changeset.

We also applied the same style change to the item history view in Gluon.

All platforms - Unity DevOps Version Control, Gluon: Highlight path changes for moved items

We added highlighting to the paths for moved items so that you can more easily see which parts of the path were changed.

This applies to the Pending Changes, Merge, Diff and Incoming Changes views in Unity DevOps Version Control and Gluon.

All platforms - Unity DevOps Version Control: Notification added to invite users to try the new Code Review experience.

We have added a notification bar that invites users to try out our enhanced Code Review experience from the Unity Dashboard:

All platforms - Command line client: Revamped the client configuration from the command line.

We improved the way of configuring the client interactively from the command line client (cm configure).

The first change is that now you are not asked for the repository server specification in different steps. Take this as an example - this is what you had to do before to configure a SSL server:

You had to specify a plain TCP port despite the server might not be even listening on one. Then you were asked whether or not you wanted to use SSL, and only then you could specify the port you really wanted to use. This process was both slow and error prone.

This is what you need to do now to achieve the same:

Additionally, if your server requires connection credentials (User and password, or email and password), the command line client checks that the credentials are correct before saving any configuration - letting you retry if you fail to type in your user or password.

And last but not least the cm configure command now supports configuring your client directly against a Cloud organization (using email and password, Unity ID, or any other Single Sign-On mechanism you might have configured). Before these changes, only email and password were allowed for configuring your client directly against the Unity DevOps Version Control Cloud servers.

Windows - Wwise plugin: New location for the Wwise plugin

From this version on, the Wwise plugin compatible with version 2021 and below can be found in the PlasticSCM installation folder, under the path "client/plugins/wwise".

Windows - Wwise plugin: New plugin for Wwise 2022

We are pleased to announce the first release of the Unity DevOps Version Control Plugin for Wwise compatible with version 2022.

This new plugin can be found in the PlasticSCM installation folder, under the path "client/plugins/wwise2022".

Command-line client: Update command improved for automation

Now moved files will be also regarded when option --xml is specified. On top of that, a new field "ChangeType" has been added in order to make the output more understandable and easier to parse. For instance, if we are 1 changeset behind the head and within the last changeset we renamed a file "math.c" to "stats.c" and moved "dice6Tex01.png" into "textures" folder, then we changed the content of dice6Tex01.png. When updating the workspace to the head, we could see something similar to the following:

See --usage for details:

Special considerations:

Have in mind that every operation performed on an item will appear as different UpdatedItem nodes. As seen in the previous example, the file "dice6Tex01.png" is both relocated and changed in the same changeset, so it appears twice (one per operation) in the XML output.

If a controlled file has been deleted and added again with the same name (either with the same or different content), it will be reported both as a delete and an add operations. This is, the item will appear twice in the report, the same as it works in other commands such as 'cm partial update'. Before this code change, when the content of the file was identical, the file was not reported at all. When the content of the file was different, it was only reported as a change.

If a file has the exact content of the revision we are updating it to (i.e. for revision X and revision Y the content of the file is "hello", and we are updating the file from revision X to revision Y), it is reported as a changed item. Before this code change the file was not reported as changed because Unity DevOps Version Control didn't need to download data from the repository server (the hashes from both revisions match).

Server: Configure generates server.conf in one line

Breaking changes in the underlying .NET serialization library were removing indentation from the configuration file.

https://github.com/dotnet/runtime/issues/64885

A different approach was used to avoid the issue.

All platforms - Gluon: Fixed error when workspace was on a label

If you switch your workspace to a label on Unity DevOps Version Control and then try to convert it to a partial workspace to work on it from Gluon, we were showing an error and the workspace couldn't be updated. We fixed this issue, and now you can convert the workspace to partial and vice-versa without issues

All platforms - Unity DevOps Version Control: Eliminated file not found error launching diff from visual diff

When launching a method diff from the visual diff panel a "file not found" error would be shown. There was no actual error, and the diff would be shown correctly. We stopped that erroneous error from appearing.

All platforms - Unity DevOps Version Control, Gluon: Improved the way we classify files with unknown extensions

All platforms - semantic merge: Moved buttons to options menu

We moved the "Visual merge", "Run text merge" and "Restart merge" buttons to the options menu

All platforms - Unity Version Control: Improved the Search Panel for the source code editors:

Users can now use the Replace functionality if the editor is writable.

Search queries now support Match Case, Match Whole Word, and Regular Expressions.

A tag has been added to inform users if matches have been found and to display their current match index out of the total number of matches.

The total number of matches found is also displayed.

The search result colors have been improved for both light and dark themes.

All platforms - Unity Version Control: Ported configuration dialog to semantic merge

A Configuration dialog has be ported to the new semantic merge, it is accessible from options menu, and contains preferences and configuration options pertaining to semantic merge.

All platforms - semantic merge: Added options menu

We have stated populating the options menu in the semantic merge window. So far it looks like this

All platforms - semantic merge: added Explain Move button

We added an "Explain move" button for move conflicts to the semantic merge outline panel here .

Clicking it opens up a visual depiction of the move.

All platforms - Unity Version Control: Renamed "DevOps user profile" preferences tab

We have renamed the "DevOps user profile" tab in Preferences to "Mergebots".

All platforms - Unity Version Control: Removed Plastic SCM logo

As part of the ongoing rebrand to Unity Version Control we have removed the Plastic SCM logo.

All platforms - Unity Version Control, Gluon: New options context menu

The options context menu navigation and look&feel has been improved.

The items from the menu have been rearranged.

The margins between icons and texts have been adjusted.

New options have been added: Documentation, Unity Version Control Web UI (just for Cloud edition)

Simplified the theme selection.

All platforms - Unity Version Control, Gluon: Modify the sign-up process to redirect users to Unity DevOps purchase flow.

We removed the ability to sign up for Plastic SCM credentials and redirect users to the checkout page for Unity DevOps. When landing on this page, they’ll be invited them to create a UnityID first. Once this is done, they can continue the purchase on the checkout page.

Windows - Unity Version Control: Rename Start Menu shortcuts

As part of the ongoing rebrand to Unity Version Control, Plastic SCM shortcuts in Start Menu have been renamed.

Also, a new shortcut was added in this menu: "Unity DevOps Version Control"

All platforms - Unity Version Control: Fixed a crash restoring diffs in the diff viewer.

Previously, restoring a diff with search results focused in the right text editor could cause the GUI to crash. We have fixed this issue so that it no longer occurs.

All Platforms - Unity Version Control: Fixed Encoding comparison issue

Sometimes we faced wrong results performing the encoding comparison. Now it's fixed.

All Platforms - Unity Version Control: Inconsistent Display of Encoding Differences

The display of encoding differences has been updated to consider the "effective" encoding.

If the left contributor is detected as UTF-8 and the right encoding is detected as NONE, but the system encoding is also UTF-8, the encoding differences will not be shown.

The BOM will also be considered when displaying encoding differences.

These changes will improve the accuracy of encoding detection and the display of encoding differences.

Windows, Linux - Unity Version Control, Gluon: Fixed 'Open With' operation if the path contains whitespaces

The 'Open With' operation failed if the item path contains whitespaces, preventing the item from being opened.

All platforms: Plastic SCM is now Unity Version Control

Plastic SCM is now rebranded as Unity Version Control.

We have also updated our end-user license agreement (EULA). You will find it in the installer.

All platforms - SemanticMerge: UI improvements.

Added a UI refresh for the semantic merge tool. These are the main points:

Use camel case for buttons and labels.

Moved the "Process al merges" button to the conflicts header.

Improve each conflict resolution text readability.

Use buttons instead links for match/unmatch actions.

Fixed the encoding string in the contributor headers.

Unify some margins and paddings.

All platforms - Plastic: Undo checkouts options

Added a new option in the pending changes view that lets you undo the checked-out files while keeping the local changes. This is the same as using the --keepchanges option when executing the cm undo command.

We also reorganized the buttons in the pending changes view.

All platforms - Plastic: Removed the license expires soon reminder for non-trial licenses.

We removed the license expires soon reminder for all non-trial license users to avoid disturbing users who have monthly subscriptions.

The license notification will still appear for those users when their license fully expires.

This notification panel doesn’t appear anymore in the app:

All Platforms - SemanticMerge: Fixed wrong content for resolved conflicts.

When resolving a manual conflict, if the merge resolution text was exactly the same as the base contributor text, it caused the semantic merge tool to wrongly choose the destination text for the result. Now it's fixed.

All platforms - Plastic: Fixed null exception using Find in files in Plastic Link.

When you use Find in files in a Diff or Code Review Plastic Link, a null exception is thrown.

All platforms - Plastic: Semantic diff viewer.

Launching semantic merge as a standalone tool displayed the text-based differences. Now the semantic-based differences are displayed.

You can try executing the semantic merge standalone tool:

All Platforms - Plastic: Add codepage encodings to the encoding menu.

We've added all the available codepage encodings to the Encoding dialog.

The encoding list now shows EncodingName, WebName, and CodePage for easy identification.

All platforms - Plastic, Gluon: Find in files feature added to diff window

You can now do a text search in all files in a diff or code review.

Just press the "Find in files" button to open the Find in files dialog.

You can choose if the search is case sensitive. You can also choose to search only the source, or destination contributor. You can choose to search all files in the diff, just currently filtered files, or just the currently selected file. Also, you can filter the results by file extension.

Search results will appear at the bottom of the window.

Selecting a result will open the relevant file and show the matching line.

All Platforms - Plastic: Fixed an encoding issue in merge.

For a file that was encoded as UTF8 but contained invalid bytes, the merge process could raise the following error:

All platforms - Plastic: Fixed 'Label all writable xlinked repositories' option

There was an issue with 'Label all writable xlinked repositories' option for the 'label this changeset' dialog, the app always created the label in the xlinked repositories too. We fixed this issue.

All platforms - Plastic: Added Visual Diff button to Semantic Merge

The "visual diff" button has been added to allow viewing the differences in a "visual" way, it's accessible via the outline panels on semantic merge.

All platforms - Plastic: SemanticMerge parsing error dialog

Added a new functionality to display any parsing error that semantic merge has detected.

P4/Git importers: From now on, running import operations is restricted to users with the change owner permission

The Plastic import operation sets the original P4/Git objects author to keep the repository history intact.

Creating branches, labels, revisions... as a different user is something the importer, under an account with change owner permission, should do to reduce the risk of impersonating objects.

If you have a periodic sync operation ongoing, please make sure that the user running the "cm" command has the change owner permission enabled for the repository

All platforms - Plastic: Added Restart Merge and Run Text Merge buttons to Semantic Merge

A new set to buttons is now available on semantic merge, "Restart Merge", and "Run Text Merge".

Server: More resilient check-in to out-of-date workspace due to cloaked

Now the check-in operation returns a meaningful error when you try to check in an out-of-date item that is no longer loaded on the server:

This problem can happen when you remove the cloaked rules for an item, this item remains out of date, and you modify it. See an example:

James - Cloak '/code' directory

Mary - Delete '/code' & check in the change

James - Update his workspace

James - Uncloak the '/code' directory

James - Move '/code/botlib/l_memory.h' to '/l_memory.h'

James - Delete '/code'

James - The check-in will fail with the error above because '/l_memory.h' no longer exists on the repository.

All platforms - Plastic, Gluon: Added conflict resolution text label in Semantic Merge

We have added a new text label in Semantic Merge. This label will inform the users of resolved conflict status

All platforms - Plastic: New "Show pending to integrate" option for branch diffs

We added a new option in the diff window for branches, that lets you see the branch changes pending to integrate into its parent branch. This is the same as using the recently added --integration option in the cm diff command.

All Platforms - Plastic: Fixed wrong color of Semantic Merge on dark themes

When launching Semantic Merge via command line and using a dark theme, the color combination of a highlighted section that contains a code comment would make the section unreadable, this has now been fixed.

All Platforms - GitServer: Failure running 'git pull' using HTTP protocol.

After certain repository size, the 'git pull' operations could fail with the 'fatal: protocol error: bad pack header' error. This happened only when using the http:// protocol.

The Plastic GitServer was implemented long time ago and it doesn't support the multi_ack_detailed & no-done capabilities that most Git clients do. So, we rely in the original protocol without these extra capabilities leading to some weird behavior in some cases. This will be improved in the future.

With the fix done, the 'git pull' operation will download the Git package (and it will not fail anymore like it did), but, sometimes, it will not update the local references. Thus, an extra 'git pull' command execution could be needed to upload the repository references (that will download nothing).

All Platforms - GitServer: HTTP server thread crashed with unexpected error.

Server: Make check-in more robust to client errors

Added protection to the check-in operation to prevent a not uploaded file ends stored on the repository with a wrong revision.

All platforms - PlasticX: Cloud Repositories view removed

We removed Cloud Repositories view from Plastic because this functionality is now available through the Home view.

Also, we added the "Create new sync view (push/pull)" context menu option, which was missing, in the Home view.

All platforms - PlasticX, GluonX: Protect the delete repo operation when a workspace is in use

We protected the delete repository operation to take into account if there is a workspace in use that points to it. In this way, we prevent error messages due to the missing repository for the current workspace.

The app now shows a message to notify you about this scenario:

macOS, Linux - Plastic: New binary merge tool configured by default

Now the binary merge tool is set as the default tool to fix binary conflicts on macOS and Linux. So when you try to diff or merge a binary file, like an image, the new tool will be used

Windows - Gluon: Removed legacy Gluon GUI from the installer

The "legacygluon.exe" won't be available anymore. Use "gluon.exe" instead if you aren't already!

This release marks the end of support for the legacy Gluon GUI for Windows.

All platforms - Plastic: Shelveset merge summary updates when toggling items

When applying a shelveset to your workspace you can use the checkboxes to choose which changes to take from the shelveset. We now update the summary at the top of the view according to the selected changes.

macOS, Linux - Plastic: New semantic merge tool configured by default

Now the semantic merge tool is set as the default tool to fix semantic conflicts on macOS and Linux. So when you try to diff or merge a semantic file (C#, VisualBasic or Java), the new tool will be used.

Command-line client: ACL commands warn about objects without ACL

Updated the help of the ACL command to remove those objects without an ACL. Also, the ACL command warns about those objects that are invalid.

Windows - PlasticX, GluonX: Updated Avalonia version

In this release we've updated Avalonia, our cross-platform UI framework

This update addresses an issue that affects dialogs for Windows users (showing a message dialog after a dialog could throw a null exception).

PlasticFS: The executable is signed from now on

Previous versions of Plastic contained an unsigned version of PlasticFS. In some places, restrictions apply over unsigned executables rendering PlasticFS unusable.

Now they are signed to overcome this limitation and make it easier to use.

All platforms - Plastic: Binary merge, can't close error message

An issue has been fixed which prevented an error message, due to invalid arguments, from being closed.

Windows - Plastic: Fixed null exception in Merge Options Dialog

In Merge View, a null reference exception appeared when you saved the merge options in Merge Options Dialog with at least one solved directory conflict, not allowing the user to cancel or recalculate the merge. We fixed this issue and now it works correctly.

All platforms - Plastic: Optimized refresh operation after saving Merge Options

In Merge View, after saving Merge Options, merge view was always refreshed.

In this release, we only refresh the view when a merge recalculation is needed.

macOS - Plastic: Fixed tool config for server-side merge operation

In the previous release we had an issue with the server-side merge operation, where the merge tool that appeared in the default configuration couldn't be launched for text conflicts on macOS.

All Platforms - Gluon/GluonX: Incoming Changes only checks-out local changes involved in conflicts.

Before, the Incoming Changes applied all the local changes in the workspace before running the operation. It didn't matter whether these local changes were in conflict with the changes to update/merge or not.

This could end up locking exclusively some files that were only locally modified (unrelated to update operation) and preventing other users to modify those files due to an undesired lock.

Now, only the local changes that are in conflict with the server changes to update/merge are applied in the workspace.

Command-line client: Partial update command improved for automation

Several adjustments have been made to the partial update command:

There was no --xml option in the partial update command. Now it is available.

--xml option can be used in a pipeline.

Using the --xml option implies --silent. Informative output gets trimmed.

Using the --silent option removes informative output only. Warning and error messages are still written through standard error output. You can silence those messages by using output redirection.

All platforms - Plastic: Diff images available for binmerge tool

Now you can specify two arguments to the "plasticgui binmerge" command, the source and the destination contributors, to diff them instead of performing a merge. Both files must be images:

All Platforms - Plastic: SemanticMerge match/unmatch

Ported match/unmatch functionality to new GUI for SemanticMerge.

All platforms - Plastic: Fixed issue applying directory conflict resolutions from shelveset

When applying the changes in a shelveset you can choose which of the changes you wish to apply. There was a bug which meant that if you chose to apply only resolved directory conflicts you would be told that no changes were selected and you would not be able to apply those changes. We fixed this, so now you can apply your directory conflict resolutions without issue.

All platforms - Plastic: App hang on closing if Pending Changes View is refresing

Plastic didn't respond if the user closed the GUI or switched to another Workspace when Pending Changes View was running a "finding changes in the workspace" operation.

All platforms - Command-line client: Flag to print just the root spec

Now the shelve creation is able to print just the shelveset spec of the root repository, skipping other "xlinked" shelvesets created this way. This is useful for automation purposes.

All platforms - DevOps: Trunkbot now also sends trunk branch in a property

The trunkbot now also sends the configured trunk branch (usually the /main branch) to the underlying Continuous Integration system in a property named "PLASTICSCM_MERGEBOT_TRUNK_NAME".

Windows - Gluon: Removed "Switch to Legacy GUI" menu option

This release marks the end of support for the legacy Gluon GUI for Windows.

We removed the "Switch to Legacy GUI" menu option in Gluon, and soon the executable won't be included in the install package.

All platforms - Plastic: Unified the style of the color pickers

We unified the style of all color pickers that are shown in the application. This is how they look now:

Linux - Plastic: Allow changing the editor font.

For Windows and macOS you could change the font of the diff/merge:

Now you can also do it on Linux

All platforms - Plastic: Unified the look of the overlapped views

Sometimes when opening a view that requires all the space in the window, we open it on top of the current view. Overlapped views show a header at the top, that you can also use to close the view go back to the previous one.

We unified the style of these headers, and now all overlapped views in the application have the same look.

MacOS - Plastic: Update default merge tool

We updated the merge tool that is used by default to solve file merge conflicts. Now, unless you change it manually, the name of the new cross-platform merge tool will be used, instead of the legacy platform-specific one

Command-line client: Merge command improved for automation

Several options have been added, mirroring the update command: --xml and --encoding:

See --usage for details:

All Platforms - Plastic: Merge files from command line with Binary Merge

A quick way to get started is to run Plastic with a single argument:

For example, To merge two files with a common base file:

[plasticgui|plastic] binmerge -s=fileA.txt -d=fileB.txt -b=base.txt

In order to determine if a merge was successful, Plastic will return 0 or 1 as the application exit code. 0 means a merge was successfully performed and the result file has been save, 1 means that a merge has been aborted or not saved.

All platforms - Plastic: Corrected Merge View title when applying shelveset

When applying a shelveset the view title is now "Apply shelveset sh:".

Windows - Gluon: Legacy merge tool opening for shelveset conflicts

Windows - PlasticFS: Upgrade to WinFSP 2023 Beta1

Among other changes, the next version of WinFSP does not require to reboot for upgrading.

You can find the WinFSP release notes in https://github.com/winfsp/winfsp/releases.

Windows - PlasticFS: Junction support for dynamic workspaces

We added support for junctions to PlasticFS! Tools that create temporary junctions on disk can now run on dynamic workspaces.

In PlasticFS, junctions have the same limitations and capabilities that symlinks have, with the following exceptions:

Junctions, they can only be used with directories. The flip side is that, unlike symlinks, junctions always have the right type.

Junctions only support absolute paths.

Plastic itself does not distinguish between "junctions" and "symlinks". Adding a junction to source control will eventually replace it with a symlink.

Besides PlasticFS, you might want to enable symlinks in the GUI and the command-line interface.

To do so, add the following to your client.conf:

This feature is in an early stage of development, so you can expect minor bugs to happen.

Currently, junctions are not allowed to point to the dynamic workspace directory nor anything outside it.

All clients: Incoming Changes only checks-out local changes involved in conflicts.

Before, the Incoming Changes & merge operations applied all the local changes in the workspace before running the operation. It didn't matter whether these local changes were in conflict with the changes to update/merge or not.

This could end up locking exclusively some files that were only locally modified (unrelated to the merge/update) and preventing other users to modify those files due to an undesired lock.

Now, only the local changes that are in conflict with the server changes to update/merge are applied in the workspace.

This new behavior applies to PlasticX, Plastic and the command line client (it's not available or partial/Gluon workspaces yet).

All platforms - PlasticX, Command-Line Client: Triggers are not accepting URIs on Windows servers

Due to the possibility of working cross-platform, sometimes Plastic is performing paths correction to fit the different OS's syntax. Therefore, anything that might be considered as a path can be altered by replacing slashes with backslashes on Windows. That was affecting the trigger commands, which can receive arguments. Usually, these arguments are expected to be paths, many times the executable itself, but it is also possible to use Internet addresses and endpoints. These addresses were being altered when parsing the command arguments (replacing the slash). That was leading to unexecutable triggers on Windows servers.

Now it is fixed and it will be possible to create triggers receiving valid URIs as arguments.

When creating the command on a Windows machine, it will fix the "./secret.key" path to convert it to ".\secret.key" but the localhost endpoint will remain the same.

This allows new possibilities of interaction through triggers on Windows machines.

NOTE: to be able to distinguish between local paths and external URI, it is advisable to use absolute URIs.

A known limitation for this would be the following syntax:

Under the hood, Plastic will modify the "unity.com/amazing" and use the "unity.com\amazing" endpoint instead, because the literal complies with the local path formation rules.

The way to avoid the issue would be to use the absolute URI referring to the same endpoint: "https://unity.com/amazing", which will remain unaltered.

Command-line client: status command now gives changed/unchanged info for checkouts

Unlike in the GUIs, the command line was only able to show an item as either checked-out or changed, but not both at once. This made hard to tell if a file was actually modified or not:

Now, additional detail is given when changes are found:

The "--compact", "--xml" and "--machinereadable" options don't display these details by default. It is so to not break existing integrations/automations. You need to combine them with the "--iscochanged" option to see the additional information.

Note that this information is only provided when the status command is searching for changed items (see the --changed option in --help for details). For instance, in case you only need to find whether items are or not checked-out, you can filter the search by using the --checkout option. That way, those details will be omitted as before.

Server: Incoming Changes failed with path permissions and a cloaked rules.

From 11.0.16.7656, the Incoming Changes failed and didn't appear when certain conditions were met: 1) there were set path permissions, 2) no cloaked.conf in the client and 3) a cloaked.conf loaded on the head tree of the branch (it contains a /cloaked.conf file). Now, it's fixed.

All platforms - GluonX: Null exception on clicking the Get Plastic link button in Checkin view

All platforms - Command-line client: the diff command allows now to see the branch changes pending to integrate

You can use the new diff option --integration (e.g.: 'cm diff br:/main/task --integration') to see the branch changes pending to be integrated into its parent branch.

See some scenarios when it's useful:

You are working on a child branch, and you make a rebase, a merge from /main. The regular 'cm diff br:/main/task' command will show the child branch changes combined with the rebased changes. Now, with the 'cm diff br:/main/task --integration', the command will skip the rebased changes. You will see a cleaner, more focused view of the actual branch changes.

You are working on br:/main/task and you merge it into br:/main. Then you realize that you need additional changes in the branch and make them. The 'cm diff br:/main/task --integration' command will show those additional changes that you didn't merge yet.

All platforms - All clients: Pending changes: "Copied" items are now listed in "added" category

A "copied" is an existing item that is copied from a source changeset into the current one where it doesn't exist. It could happen due to a merge or revert operation.

Previously the copied changes were inside the modified category:

Now they are inside the added category, as the item is a new one on the current changeset even if it already exists on the repository:

All platforms - All clients: New "change - not loaded" conflicts for cherry-picking merge & apply shelve

The old "change - delete" conflicts were replaced by the new "change - not loaded" conflicts for the cherry-picking merge, and apply shelve, where the changed item is not deleted on the destination, it's simply not loaded.

These new conflicts give a more accurate description and actions for these types of conflicts:

All platforms - PlasticX, Command-Line Client: Basic Auth now working with webtriggers

Webtriggers requiring basic authentication were not supported. There was a workaround to create a script with the call (using curl for instance inside a *.bat or *.sh file) including the authentication and then wrapping that script call within a regular trigger. Now it is possible to directly use webtriggers with basic authentication instead.

For example, imagine you have a configured Jenkins with a job named "MyProject" and you would like to call Jenkins to build the project after a check-in has been successfully completed. You could create a trigger like the following:

All platforms - Plastic, Gluon: Added new arguments

The following arguments were available in legacy Windows GUI. Now we added them to the new cross-platform GUI:

--clientconf: Lets you use a custom client.conf file, instead of the one at the default location

--branchexplorer: Opens the branch explorer view of the specified workspace

--preferences: Opens the preferences view when Plastic starts

--createworkspace: Opens the dialog to create a new workspace when Plastic starts

In addition, arguments used to open the legacy GUI are now passed to the new GUI when clicking the "Try new GUI" button

All platforms - Plastic, Gluon: Provided better description in User Profile Tab

We renamed Preferences "User Profile" tab to "DevOps User Profile" to avoid confusion with "Connection Profiles"

Also, a explanation text and additional help hyperlinks were added, improving the documentation of this tab and giving better descriptions to the users

macOS, Linux - Plastic: Cross-platform semantic merge tool enabled by default

From now on, in macOS and Linux, when there is a non-automatic merge conflict on a code file, the cross-platform semantic merge tool will be launched to solve the conflict. Until now, you had to manually enable it by adding a flag in the client.conf file.

On Windows the native tool is still the default one, so you need to add the flag in client.conf if you want to use the new cross-platform tool:

All platforms - Plastic: shelvesets can now be filtered

We've improved the shelving workflow in Plastic by adding flexibility when applying a shelveset to your workspace. Now you can pick and choose individual files from a shelveset and apply only those that you want.

Shelvesets are chosen from the Shelves view, accessed using the "Show Shelves" button on the Pending Changes view, in the usual way:

Check the files in the shelveset that you want to apply to your workspace. Unchecked files will be ignored:

All platforms - Plastic, Gluon: Page Up/Down keys navigation fixed

We've fixed in this release Page Up/Down keys navigation for all Tables and Trees

All platforms - Plastic: Fixed exception when using the semantic icons bar

When clicking on "Diff changed code..." from the semantic icons bar in a changed portion of a file, an exception was thrown. We fixed this issue and now the diff window is opened correctly

All platforms - Command-line client: Failing to create an Xlink leaves a private directory

So far, trying to create an Xlink to a non-existent item still created a a private directory in the workspace.

Now, the item is solved before the xlink command can tinker with the workspace.

All platforms - IntelliJ: IntelliJ plugin diff does not display properly

DevOps: TrunkBot now deletes shelvesets for Xlinks

When merging a task, the TrunkBot creates a shelveset that gets deleted when done. If the repository contains Xlinks, shelves are potentially created for each "xlinked" repository.

Before, the TrunkBot only removed the shelveset of the root repository, so the shelves of the "xlinked" repositories were left behind.

Now server and TrunkBot were improved so all shelvesets are properly cleaned.

Command-line client: Automatic shelve before switch (with pending changes).

The 'cm switch' and 'cm partial switch' commands now ask about shelving the workspace changes before continuing with the switch operation when there are pending changes in the workspace.

If the answer to the question is yes, it automatically shelves and undo your local changes before continuing with the switch operation.

This new behavior only happens if the following option is set in the client.conf configuration file.

The shelve question can be skipped if the switch commands are executed with the '--noinput' option. In this case, the shelve + undo are run by default before the switch operation.

MacOS - Plastic: Automated update workflow

The update workflow has been improved on MacOS! It automatically downloads the latest release and executes it, whenever an update is available, and the user wishes to update.

All Platforms - Plastic/PlasticX/GluonX: Semantic supports C# 9, and 10 versions!

We modified Semantic Diff/Merge to support the new features introduced in the C# (9, and 10), and VB (16.9) languages for all platforms.

Here is a sample for C# 9 files with target-typed new expressions, and top-level statements (program without Main method):

Here is a sample for C# 10 files with global using, file-scoped namespace, and constant interpolated strings:

All platforms - PlasticX, GluonX: Removed the repositories view from the switcher window

When you clicked on the workspaces drop down at the top and selected "View repositories..." you would see the switcher window with a list of all the repositories you can access. This information was redundant, because you can also see the repositories from the home view. We removed the repositories view from the switcher window, and now it only displays the list of your workspaces

All Platforms - Plastic: Check for update option

You can now to check for a new update at any time, by selecting it from the application context menu.

All platforms - Plastic, Gluon: Home shows error message selecting repo with read permission denied

Plastic app could show a "An unexpected error has occurred" message in Home View if a repository with no read permission was selected, we fixed this issue

All platforms - Plastic, Gluon: Home will show public directories in repos with root path permission denied

We fixed the following scenario:

If an admin account denied all root permissions to another user accounts, but some subdirectories are public, HomeView would show empty repository to these users

This is the full repo an admin user could have:

And this will be the Home View normal users will now see in this scenario:

Windows - Visual Studio 2022 plugin: Prevent private files from showing CodeLens information

Previously to this change, private files were showing "Private" for every method and class and an empty tooltip. Now we are hiding useless information.

Command-line client: status --short option not providing a list of files

Before, the status command didn't provide a list of files as the help said. It couldn't be used in a pipeline without some workarounds.

Now it is possible to use it as expected:

All platforms - Plastic, Gluon: Home View Path permissions created with \ instead of /

In the Home View, if we browse a file o directory to add a Path Permission, backslashes were used instead of forward slashes, we fixed this issue

Command-line client: Update command improved for automation

Several adjustments have been made to the update command:

Using the --xml option was not meant to be used in a pipeline.

Using the --silent option was meant to trim all output.

Using the --xml option with no file implies --silent. Informative output gets trimmed.

Using the --silent option removes informative output only. Warning and error messages are still written through standard error output. You can silence those messages by using output redirection.

All clients: Incoming Changes respects the cloaked rules.

Before, the Incoming Changes operation downloaded the files/directories although they were under cloaked paths. This was inconsistent with the update operation behavior and with the cloaked semantics themselves.

Now, the changes under cloaked paths are skipped like the update operation does.

The Gluon Incoming changes is not affected by this behavior (cloaked rules don't make sense in Gluon) since the operation works in a different way.

All Platforms - DevOps: Jenkins plug now shows the link to the build job

The Jenkins plug now notifies the URL to the build job. This way users are able to get the details about what failed while building the task in Jenkins.

Find below a sample of this notification using a local Jenkins plug with a TrunkBot mergebot on Slack:

Command-line client: Switch command improved for automation

Several options have been added to the switch command, mirroring the update command: --silent, --verbose, --xml and --encoding.

See --usage for details:

Command-line client: Undo controlled changes and preserve local content

Added the option -k | --keepchanges to the cm unco & cm partial unco to allow undo checkout and preserve all local changes.

It could be very useful when you have a checked-out file with some changes for testing that you don't want to check in. So, now, you can undo the checkout (that releases the lock), and preserve local changes just to continue with your local tests.

The unco -k command can be applied to all kinds of controlled changes, turning them into local changes. This is complementary to using the checkout command to promote local changes into controlled ones.

*Added are left as private

*Checked-out are left as changed

*Deleted are left as locally-deleted

*Moved are left as locally-moved

Note this option is incompatible with dynamic workspaces.

All platforms - Plastic, Gluon: Improved app stability

We've improved app stability in some scenarios, preventing the app from crash when an exception is thrown

Command-line client: Update --xml now includes deleted items

Before, the --xml output of the update command was meant to only report items with added or updated revisions.

Deleted items are now included:

All platforms - Plastic: Disabled Semantic History option for unsupported text files

We've disabled Semantic History menu option in Annotate View for all unsupported text files in semantic history (for example, .txt files)

macOS - Plastic: Removed mono-based GUI's

We finally removed the mono-based GUI's that were deprecated months ago, in favor of net(core) based counterparts: plasticgui and gluon.

This way we ease the setup of the Plastic SCM GUI applications, since no more "mono/xamarin" and related dependencies will be a requirement anymore.

All platforms - Plastic: Fixed exception in diff when selecting files outside of refactor group

We fixed an error that was causing an exception to be thrown when selecting an item in the diff window that is not inside a refactor group.

Command-line client: Unrelated conflicts when applying a shelve.

The 'shelveset apply' command could show some directory conflicts that were not related to the changes/paths specified in the command.

This happened when 1) only some changes were specified to be applied from the shelveset and 2) there were more than one directory conflicts involved in the shelveset application.

The problem came because the filter used to apply only the specified changes was not applied again after resolving a directory conflict. Fixed.

Command-line client: Update command --xml and --silent options are incompatible

Before, using the --silent option allowed the XML output to be printed but affected to the contents themselves.

All platforms - PlasticX, GluonX: Updated Avalonia version

In this release we've updated Avalonia, our cross-platform UI framework, to the latest public release

This update brings many stability improvements under the hood, and also addresses the following macOS issues:

Sometimes a dialog could hang the app, this issue is fixed

Merge links are now clickable again in Branch Explorer

Fixed strange issue where buttons could disappear

Fixed flickering in the Home View

All Platforms - PlasticX: Jira task details on branch explorer

You can now see and navigate to a Jira task when using the Jira extension to create a branch.

All platforms - PlasticX: Launch Semantic Merge as standalone

The Semantic Merge tool could be launched from the command line using:

For unsupported file formats the merge tool will be launched instead of semantic merge. If the base argument is missing in the command line, the diff tool will be launched instead.

All platforms - PlasticX: Clarification message for deleted repositories

Improved description of how long repositories are kept in storage after being deleted.

All platforms - PlasticX: Branch options not working in Merge diagram

When the merge diagram was opened from the Merge view, some of the available actions from the branch context menu were not working as expected.

Command-line client: Misleading diff result message

When requesting a diff of a private file or non-existent file, the message tries to indicate that there is nothing to compare it with.

However, this feature includes a misleading message:

Now this is corrected:

All Platforms - Command-Line Client, PlasticX: Codereview creation with triggers fails.

Having an "editreview" trigger enabled, the creation of a code review through PlasticX fails.

This happens becase, when creating a code review with the CLI or with the PlasticX application, the reviewer might not be specified in the command and it is not set by default in PlasticX when the creator of the code review is the same user who created the branch.

All platforms - PlasticX: Corrected semantic outline for multi-file moves

We corrected the information displayed in the semantic outline when we detect that code has been moved from one file to another.

All platforms - PlasticX: Check-in button disabled during the check-in operation

We've disabled the Pending Changes view Check-in button until the check-in operation is complete

Windows 10: We disabled the possibility of negotiating TLS 1.3 connections on Windows 10

This TLS version is experimental on Windows 10 and, although it can be enabled and forced through registry hacks, it is not officially supported (as per Microsoft documentation) and won't work when trying to connect to Plastic SCM Cloud nodes.

By doing this, we re-enabled TLS 1.3 support on Windows 11, Windows Server 2022, and all other platforms that support it.

All platforms - GluonX: Error sorting columns in the Workspace Explorer view

If a user tries to sort by the Changeset column in the Workspace Explorer view and one item has no revisions (for example, a newly created file), the operation throws an exception.

We've fixed this issue.

All platforms - GluonX: Shelve and undo changes, fixed null exception error message

We've fixed the following scenario in GluonX:

All platforms - DevOps: TrunkBot adds tasks' title to the check-in comment when merging

Now TrunkBot mergebot will add the task' title from the configured issue tracker to the check-in comment when a merge is successfully performed. If there is no configured issue tracker, it will add the branch comments instead.

All platforms - Server: Deleting an object now deletes the associated code review data.

Now, when deleting a changeset, a shelve, or a branch, all the associated code review data gets deleted as well. This means that all code reviews targetting a changeset or a shelve, as well as all the code review comments made on a changeset or a shelve, will be deleted along with the changeset or shelve. When deleting a branch, all the code reviews targetting the branch will be deleted too.

Until now, the only thing that happened (regarding code reviews) when deleting a changeset was that all the change requests applied on said changeset were marked as not addressed. Now, the cleanup is complete.

All platforms - Command line client: Now you can create code reviews for shelves!

If you want your colleagues' feedback on some code, but don't want to actually check in the changes, now you can create a shelve and ask them to review the changes with the integrated code review functionality! Bear in mind that creating the code review only works (from now) from the cm command line client, but once created, you can open the code review from the GUIs.

To do so, you will need the shelve ID of your shelve. You can obtain that from the "ID" column in the "Show shelves" view in the GUIs, or by running a cm find command:

Then, create the code review specifying the shelve:

The code review can then be opened and edited from the GUIs.

Server: Deny temporary access for some specific users

Now you can deny access to certain users. To do so, create a deniedusers.conf file inside the server directory and add a user per line.

You don't need to restart the server, but note it might take some seconds until the server reloads the list of users with access denied.

Note users might look different, as it depends on the configured authentication:

Windows - PlasticX: PlasticX is now the official GUI on Windows

We are happy to announce that our new, cross-platform, GUI is now the official GUI on Windows.

To launch the new GUI simply run plastic.exe as before. The old windows gui has been renamed to LegacyPlastic.exe.

Windows - PlasticFS: Symlink support for dynamic workspaces

We added support for symlinks to PlasticFS!

Now symlinks are supported everywhere in the Plastic ecosystem: Windows, Linux, macOS and PlasticFS.

To do that, add the following configuration setting to your client.conf:

Be sure to read the LIMITATIONS section before using.

== HOW TO USE THEM ==

You can use mklink as usual to create some symlinks:

Note that, unlike with static workspaces, you don't need to enable Developer Mode to make it work!

This feature is in an early stage of development, so you can expect minor bugs to happen.

PlasticFS always creates symlinks as files. By trying to access them, they will be automatically solved and converted to directories. However, this step might confuse external programs that do not expect it.

This happens anytime you create a new workspace or after undoing a placeholder file (see REQUIREMENTS section).

Windows Explorer will force this conversion, but you will have to refresh the window the first time it shows a symlink.

All platforms - PlasticX: View deleted repositories on home view

You can now see the recently deleted repositories on the home view!

It is accessible by clicking on the cog icon near the search bar.

To restore a deleted repository, simply right click on the deleted repository and select the "undelete" option

Windows - Visual Studio 2022 plugin: Fixed issue when opening Pending Changes

After uploading Visual Studio 2022 to version 17.2.0 or higher, if the solution contained a solution's folder, Visual Studio plugin was prompting the error:

"GetSccFiles must be called on the UI thread"

It was preventing the Pending Changes view from working properly.

The issue has been fixed and now Pending Changes is fully usable in any situation.

All platforms - PlasticX: Flicker issue in the pending changes refresh

The refresh operation for the pending changes view launched different operations to calculate the review comments to apply and the pending changes which caused a flicker issue. We unified those operations to avoid this issue.

All platforms - PlasticX: Missing success message after creating a shelveset

After creating a shelveset the success message was shown in the status bar but it was immediately hidden due to an issue in the pending changes refresh operation that overwrote the message with the progress. Now it's fixed.

All platforms - PlasticX: Fixed slow pending changes category checkbox

We improved the performance of toggling a pending changes category checkbox when the category contains a very large number of items.

For example, toggling a category containing 30,000 items used to take about 20 seconds, and now takes less than half a second.

Cloud Server: Fixed deadlock with concurrent checkins in the same repo.

The cloud server uses locks to handle concurrent access to the Jet files and to the internal caches. There was a race condition where concurrent checkins (in the same repo) that added new files to the repo could get stuck forever due to a deadlock between the previous mentioned locks. Fixed.

This was a corner scenario since the race condition was not easy to reproduce without the right debugging.

All platforms - GluonX: Details Panel could not be resized.

We found a rare scenario in the Details Panel where this subview couldn't be resized anymore. We fixed this issue

Also, we have also set minimum width to the Workspace Explorer and Checkin Views when Details Panel is shown to the users

All platforms - PlasticX, GluonX: Skip format changes not working properly

There's an option in the pending changes view and diff view that allows you to skip format changes when diffing two versions of a file, such as line endings or spaces. This option was not being initialized correctly, and even when it was enabled, it appeared as disabled in the GUI. This issue is now fixed

All platforms - PlasticX: Diff/Merge Window crash after Cut empty text

All platforms - Plastic: Semantic Visual Differences are here!

We ported the Visual Diff feature from the Windows Legacy GUI to the new (multiplatform) GUI, which means that now, the Visual Diff feature is available on three platforms, Windows, macOS, and Linux!

The Visual Diff is a diagram that helps to understand the changes made to a file, in a semantic way. Visual Differences are available for those file formats that support semantic differences (.NET, Java, PHP, C, C++). When the semantic differences are calculated, the Visual Diff displays a graphical representation of them. The diagram displays, classes, usings, methods, members, fields, etc, and some decorations indicating if an entity was added, changed, moved, or deleted. It also helps to display the differences between them.

The Visual Diff is available in three places:

1- The Diff Control (note that we also implemented a couple of options for the semantic diff):

Skip format changes: This option ignores the indentation and EOL changes when the semantic diffs are calculated.

Reformat: This option automatically reformats the source code:

2- The Diff Window, when clicking a Refactor Group when using our "analyze refactors" feature:

3- The Semantic Merge tool:

All platforms - PlasticX: Visual diff window new design

Some colors and layout design has been changed for the Visual diff window in order to improve legibility and visibility for both themes.

Linux - Plastic: removed mono-based GUI's

We finally removed the mono-based GUI's that were deprecated months ago, in favor of netcore-based counterparts: plasticgui and gluon.

This way we ease the setup of the Plastic SCM GUI applications, since no more "mono" and related packages will be a requirement anymore.

The final goal is to support newer distros, and for that goal, this removal of mono-based applications is a must.

REMARK: The package name was renamed from plasticscm-client-gtk to plasticscm-client-gui, but your package manager should care automatically of this renaming.

Linux - Client and Server: Added support for Ubuntu 22

Now you can install Plastic SCM on Ubuntu 22 using the package manager! Instructions here, "Ubuntu" tab.

Easy to say, long road until we made it! This Ubuntu 22 support pulls some relevant changes in the Plastic SCM software stack:

Mono removal: We don't require installing mono runtime anymore. We now rely on .NET specific OS-targeted self-contained executables for all Plastic SCM applications, even client-GUI applications (server was already compiled this way since early 2021).

Legacy GUI's removal (gtkplastic, gtkgluon, gtkmergetool). Since they were based in mono, they need to be removed and replaced by .NET counterparts: plasticgui and gluonx (mergetool is now part of plasticgui application and can be launched using plasticgui xmerge).

Move server from .NET 5 to .NET 6

All these changes were required in order to meet dependencies needs for Ubuntu 22, specially on ssl libraries and graphical toolkit libraries.

All platforms - PlasticX, GluonX: Damaged image file won't show error pop up in Pending/Checkin Changes Views.

Selecting a damaged image file won't show error pop up message in Pending Changes/Checkin Changes Views.

The error message will still be visible to the user as a label notification, and also in the Details Panel (GluonX only)

All platforms - GluonX: Visual feedback when cutting items

When cutting items from the workspace explorer view, now there is a transparency effect in the icon of the elements that have been cut.

This feature was already available on Plastic, and now it's on Gluon too.

All platforms - Plastic: Allow changing the editor font.

Now, the diff/merge font can be changed.

NOTE for windows users. The default monospaced font in Windows OS (if available) is Cascadia Code, which enables font ligatures, so if you want to disable them, you can change the font to use Cascadia Mono, or other available font in your system.

All platforms - Plastic: Full Unicode support and IME.

Previous versions of Plastic didn't fully support double-byte languages (Chinese, Korean, Japanese, etc ...). This Plastic version supports, not only double-byte languages and emojis, but also supports IME (Input Method Editor) for these languages, and right-to-left input support for Arabic and other languages.

NOTE for Open Suse Linux users: After this changes, Open Suse 15.2 is no longer supported. An upgrade to Open Suse 15.3 is required in order to run Plastic.

Server - Merge and Incoming Changes are much faster tons of ChangeDelete conflicts.

The calculation of the merge or the incoming changes was very slow when there were tons of ChangeDelete conflicts involved in the operation.

In the studied case, 2 million of items were added in the source of the merge but all of them were added under a deleted directory in destination. It initially took more than 2 hours to calculate the merge. Now, the same scenario takes less than 15 seconds to complete it. So, it's 500 times faster.

All platforms - PlasticX: added tooltip to Branch Explorer

Branches, changesets and labels on the Branch Explorer now have a tooltip which looks something like this:

Clicking the links on the tooltip will open a diff of the specified branch or changeset.

All Platforms - Command-Line Client: New information to display on revision history command

A new option has been added: --limit. It displays the N last revisions regarding the specified items. If N is bigger than the number of available revisions, it will display the existing ones (limit will take no effect); if N = 0, it will display every revision; if N < 0 the displayed list will be empty; if 0 < N < numRevisions will display the N most recent revisions, sorted by date and changeset id.

Will display the path and itemid regarding the last 5 revisions of foo.c and bar.c

Note that, in the example, foo.c only has 2 revisions.

All platforms - PlasticX: Changes in Semantic Merge Window

We changed the Semantic Merge Window icon, now the window will now show legacy Semantic Merge tool icon

We added MinWidth and MaxWidth properties to the window

All Platforms - Command-Line Client: New information to display on revision history command --format

Two more fields have been added to the revision history command in order to display information such as the revision size in bytes and the revision hash code. The --long option will also regard these new fields.

Now it is possible to use both {size} and {hash} in order to display that information along with the --format option.

Will display the review history of both foo.c and bar.c files, outputting the item id, the size of the file at each specific revision and, in between parenthesis, the hash code identifying the content of each revision.

In addition, the --long format will also display the new fields:

Will display something like the following, considering bar.c file had only 1 revision:

All Platforms - PlasticX, GluonX: Application Zoom Support

You can now apply a zoom level to the whole application!

Change it via the ⋮ (triple vertical dot) menu on the top right corner -> Zoom or by pressing Ctrl + Plus, Ctrl + Minus, to increase or decrease the application zoom.

All platforms - Plastic: Added text editor options.

Now, the diff tool and the merge window have new options to customize the text editors. Those options allow to:

Show/hide the tabs and the whitespace.

Show/hide the line ending (EOL) characters.

Convert tabs to spaces while editing.

Customize the indent size (tab size) to 4 or 8 characters.

Command-line client: New env variables in codereview edit

Previously there was no way to create a [before | after]-editreview trigger and retrieve

information about what editing was being done: the assignee or the status or both of them.

Now there are two new environment variables related to [before | after]-editreview triggers:

PLASTIC_REVIEW_ACTION: edit assignee or edit status or both separated by ';')

PLASTIC_REVIEW_ACTION_INFO (detailing "previous value" "->" "new value" for the assignee, the status or both, separated by ';').

Mind that only when editing the code review from the CLI both fields can be edited at the same time.

For instance, if you have a script which is dumping the environment variables passed as arguments to an output file (DumpEnvVars.exe), the following trigger creation:

And you do a code review edit like this one:

The script would write a file with the following content:

All platforms - PlasticX: Error in skip merge tracking

An unexpected error was displayed when skipping merge tracking in diff window for big number of differences (>50).

All platforms - PlasticX, GluonX: fixed issue selecting damaged image files in Pending/Checkin Changes Views.

When selecting a damaged image file in Pending Changes/Checkin Changes Views, if the user had selected previously another image file, image panel still showed to the user the last viewed image, we fixed this issue.

All platforms - PlasticX: Attributes panel resizing

The attributes panel was not showing the relevant info, the attribute name, when resizing. A fix has been added in order to adapt panel items sizes proportionally to the available space/width when resizing the panel horizontally.

Server: The REST API to download revisions had a memory leak.

The endpoint to download a file revision content (api/v1/repos/repName/revisions/revId/raw) had a memory leak when the '?version=2' query parameter was specified.

We already fixed a memory leak related to this endpoint in the version 11.0.16.7372, but a different one still happened. Fixed.

All platforms - Semantic Merge: Fixed diff color palettes for the dark theme.

The colors used to display differences were unsuitable for the dark theme (they had low contrast). Now it's fixed. This is how it now looks:

All platforms - PlasticX: Fixed empty buttons in pending changes

There was an issue with the "Save" and "Discard" buttons that appear in the pending changes view when you modify a file from Plastic. Sometimes, when changing the selection of the file, these buttons appeared without any content, until moving the cursor over them. We fixed this issue, and now the buttons work as expected

Windows - PlasticX: Fixed issue when opening files with custom tool

When trying to open a file with a custom tool from the workspace explorer on Windows, there was an exception preventing the new process from starting. We fixed this issue, and now the custom tool launches as in the other platforms

All platforms - PlasticX, GluonX: Preview was being calculated even when it's not visible.

We optimized the Details Panel behavior. Now, the app will only calculate the Preview data when the panel is visible to the user.

All platforms - PlasticX: Fixed issue when requesting credentials

When you try to perform an action on a server for which you don't have valid credentials, we show a dialog asking you to authenticate. There was a bug that made this dialog appear multiple times overlapped. We fixed this issue and now the dialog only appears once

All platforms - PlasticX: Merge view issues

Avoid error loading conflicts from a merge in Merge view and converted multiline texts in one single line for Comments column.

All platforms - PlasticX, GluonX: Tool command not properly refreshed

In Preferences window when the Diff or Merge Tools were opened, the Tool command text field was not properly updated with the current selected tool command line.

All platforms - PlasticX: Fixed DNS error for cloud.plasticscm.com

We fixed an issue in the Plastic onboarding where a DNS error was shown after creating a new organization. This issue only appeared for new accounts that didn't have any organizations and created a new one after the sign up.

All platforms - PlasticX: Help not displayed for empty list of code reviews

The help panel wasn't displayed after clicking the Help button in "Code Reviews" view when the list was empty, now the general query views help will be shown for this case.

All Platforms - PlasticX: SemanticMerge hangs

An issue has been fixed in which when resolving a conflict with the argument "--process-all-merges"

macOS - PlasticX: Fixed loading of Polarion extension

When trying to load the Polarion issue tracker exception in macOS, an error was thrown because a missing dependency. We fixed this issue, and now you can use the extension on macOS as in the other platforms

All platforms - PlasticX: Fixed issue when showing merge tracking colors

We fixed an issue with the merge tracking colors menu, which was only visible when diffing branches that didn't have xlinks.

Now it's also available for diffing changesets and labels, which can contain changes in xlinks

All platforms - GluonX: Details Panel didn't clear data when no row was selected in Checkin View.

We fixed an issue in the Checkin View Details Panel. Now, the app will always clear previous data when no row is selected or if the Checkin View is empty.

All platforms: TLS1.3 temporarily disabled.

TLS1.3 is not supported on Windows 10. We identified some software that enables and forces it through registry editing, forcing Plastic SCM secure connections to use it, and failing to connect both to Enterprise and Cloud servers.

All Platforms - PlasticX: Incorrect theme on ⋮ (options menu)

An issue has been fixed in which sometimes would show the incorrect theme selected on ⋮ (options menu) -> Theme.

All platforms - GluonX: Hide open repository button

In order to avoid opening not loaded repositories, the open repository button won't be available from Home view in Gluon app.

All platforms - Plastic: Allow restoring default font in the text editors.

The dialog that allows changing the editor font didn't show the "Select default font" button. Now it's fixed:

macOS - PlasticX: Fixed hang when discovering new servers

There is an option when adding new accounts to auto discover Plastic servers in the local network. If the discover operation is cancelled while it is running, the application hangs, and needs to be killed.

We fixed this issue, and now the operation can be cancelled without issues

All platforms - Plastic: Fixed syntax lines are not colored sometimes.

In some scenarios, some lines were not colored when loading a file in the diff viewer. Now it's fixed.

All platforms - Plastic: The diff scrollbar was not visible under some circumstances.

A recently added option in the diff viewer that allows scrolling below the document caused the scrollbar not to be visible sometimes. Now it's fixed.

All platforms - Plastic: resolved issue where long running merge processes could accumulate on the server

The Plastic client checks the server for incoming changes in some operations that can affect them. This can trigger the server to calculate a merge. If this calculation took a long time, the calculation would be triggered again by other operations and these processes could accumulate, pointlessly using server resources.

We fix this by ensuring that the calculation will not be requested if another calculation is already in progress.

Windows - PlasticX, GluonX: Dynamic Workspaces checkbox not visible

The dynamic workspaces checkbox visibility status was not properly refreshed from Create Workspaces dialog. When "plasticfs" process is running the checkbox should be visible so the user can create a dynamic workspace, otherwise it shouldn't be available.

MacOS - PlasticX: Cannot switch to plastic from gluon

An issue has been fixed that prevented switching from gluon to plastic via the '...' menu.

Windows - PlasticFS: msys2 redirection overwrites files (append mode)

Trying to concatenate content through shell redirections overwrote files due to a bug related to opening files in append mode:

This has been corrected:

All platforms - PlasticX: Error loading branch explorer

Fixed error trying to load a workspace in partial mode in Branch explorer view.

All platforms - PlasticX: Error reviewing image files

In the code review window, an error was raised trying to select image files, it's because the diff icons bar is not available for image files, the file differences couldn't be loaded properly, and an error message was displayed. Now it's fixed.

All platforms - Plastic: Go to moved code buttons not drawn.

If you selected "Go to moved code" in the diff viewer, then the action buttons in the destination are not drawn until you mouse-over the column. Now it's fixed.

All platforms - PlasticX, GluonX: Infinite progress after creating a shelveset

All platforms - PlasticX: Edit accounts

We added a new option in the home panel that lets you modify on-prem servers accounts. When using it, you will be able to authenticate again to the server, updating the stored credentials

All platforms - Command line client: Now you can list group members from cm!

Doing so is easy: just specify the group name in the --group option of the cm listusers command.

If a group is a member of a group, the command will solve its users recursively too.

So take this scenario as an example: Users 'sergio' and 'brenda' are part of the Developers group. User 'paula' is part of the QA group, and so is the Developers group. So QA users are 'paula' and 'Developers', and 'Developers' users are 'sergio' and 'brenda'. By solving groups recursively, the command output will look as follows:

All platforms - PlasticX: License notifications

Plastic will display user notifications about the license status. An information message will be shown when the current license is going to expire indicating the remaining days and how to renew it. On the other hand, when the license has been expired then an error message will be shown.

For extended trial licenses the notification panel will allow users to start the license registration process, so users could extend their licenses for 30 days.

All platforms - Command-line client: Better cm status with tables!

Modern times arrive for our command line, with a much better way to display workspace changes: cm status --pretty

Check how it looks like now:

And compare with how it looked like before:

Now also check how it looks like in Windows Terminal:

And the good old cmd.exe:

Command-line client: Apply only the desired changes from a shelve

From now on, the cm allows you to choose which changes do you want to apply from a shelve. You no longer need to apply all the changes done on the shelve.

You can see which changes are going to apply by the shelve without applying them using:

You can apply only the desired changes indicating the changes paths to apply:

All platforms - PlasticX: Fixed issue obtaining changesets from old server

Some time ago we modified a method in the Plastic server that was called from the client. This change made the client throw an exception when trying to execute the method on an old server:

"The method GetChangesetsInfoByNumber is not supported"

We fixed this issue, and now the client will work with modern and old versions of the server.

All platforms - PlasticX: Fixed issue with code review comment selection

Opening a code review comment for a file which had additional changes made to it after the code review comment was created was not working correctly. We fixed this.

We also corrected an issue where items in the file list were not being marked as viewed when they should have been.

All platforms - PlasticX: Non-editable username when authenticating in Name working mode

When signing in to a server using the Name working mode, you were able to modify the username used to authenticate. This was wrong - on Name working mode the username must always be taken from the system

All platforms - PlasticX: Diffs multiple selection issue

When an item is marked as viewed it changes the text style from bold to normal. The diffs list must mark items as viewed just when a single selection is done, items won't be marked as viewed on a multiselection.

All platforms - PlasticX: Annotate View splitter

All platforms - PlasticX: Disable context menu items for empty lines in the "Annotate" view.

Trying to execute some menu context menu actions for empty lines In the Annotate view, caused the UI to show an error, but now it's fixed. When a menu item cannot be executed, it's just disabled.

The affected menu items are:

Annotate before these changes

Show semantic history

Diff with previous selection

Windows - PlasticX: Exception when diffing symlinks

An exception that occurs when trying to diff a symlink file on windows has been fixed, along with a bunch of minor visualization bugs.

macOS - PlasticX: fixed assembly load error when configuring issue trackers

Linux, macOS - PlasticX, GluonX: removed "Switch to Legacy GUI" option for Linux and macOS users

This release marks the end of support for the legacy (pre-avalonia framework) Linux and macOS GUIs for all users.

We have removed the "Switch to Legacy GUI" option for Linux and macOS users, and soon their executables won't be included in the package

All platforms - PlasticX, GluonX: Added merge tracking colors to diff view

When you are seeing the differences of a branch with merges, sometimes is difficult to know where each change came from. To make this easier, we added colors to the diff view to differentiate between source, destination, and conflict changes. You can modify these colors and even show/hide them depending on what you want to see.

This feature was already available for Windows users in the legacy GUI. Now it's available in all platforms in the new Plastic GUI.

All platforms - PlasticX: Added ESC key close shortcuts in overlapped Browse Repository and Changesets Views

We've added new ESC key close shortcuts in the following overlapped views in PlasticX

*Changesets (only when Changesets View is called as a overlapped View)

All platforms - Command line client: 'cm rm controlled' now removes items in block.

Removing a controlled item involves a few operations: locking the workspace, starting a new workspace transaction, look for the item in the tree metadata, removing said node, checking out the parent (if necessary), removing the content from disk (if necessary), and finally commiting the transaction and unlocking the workspace.

Before, the command cm rm controlled would do all of these steps for each item, regardless of them belonging to the same workspace. This would incur on a big overhead when trying to delete many items in a row.

Now the command deletes all items belonging to the same workspace in block.

However, this forced some changes in how cm rm controlled reports removed items through standard output. If you use this command in an automation script or plugin, and you don't use the --format or --errorformat flags, you might need to consider these changes.

Consider the following scenario: we are going to delete a controlled directory (src), a private file (ignore.conf), and a file that is outside of the workspace (README.txt). This would be the output in previous Plastic SCM versions:

sergio:/wkspaces/Project$ cm rm ignore.conf src ../README.txt

/wkspaces/Project/ignore.conf is not in a workspace.

Item ./src/ has been removed

/wkspaces/README.txt is not in a workspace

Now paths are reported in the following order: first, all the paths that were correctly removed. Then, all the paths that were skipped because of an error (for example, the item not being in a workspace). Finally, all the paths that were skipped because they are not in a workspace. Now we also always use the item's full path:

sergio:/wkspaces/Project$ cm rm ignore.conf src ../README.txt

Item /wkspaces/Project/src/ has been removed.

/wkspaces/Project/ignore.conf is not in a workspace.

/wkspaces/README.txt is not in a workspace.

We honor the behavior of the --format and --errorformat flags.

sergio:/wkspaces/Project$ cm rm ignore.conf src ../README.txt --format="{0} - DELETED" --errorformat="{0} - NOT DELETED"

/wkspaces/Project/src/ - DELETED

/wkspaces/Project/ignore.conf - NOT DELETED

/wkspaces/README.txt - NOT DELETED

We also honor the command's exit code. Before, if an item could not be removed for whatever reason, command's exit code was 1. The same behavior applies here.

All Platforms - PlasticX: Merge files from command line with XMerge

You can now use PlasticX for merging and diffing any files using XMerge!

A quick way to get started is to run PlasticX with a single argument, xmerge. As shown below:

[plastic|winplasticx] xmerge

Now, some quick examples

[plasticgui|winplasticx|plastic] xmerge -s=fileA.txt -d=fileB.txt

[plasticgui|winplasticx|plastic] xmerge -s=fileA.txt -d=fileB.txt -b=base.txt

In order to determine if a merge was successful, PlasticX will return 0 or 1 as the application exit code. 0 means a merge was successfully performed and the result file has been save, 1 means that a merge has been aborted or not saved.

All platforms - PlasticX: Open Merge view from command line

The merge-to view could be open from command line to solve the branches merge conflicts, it can be invoked like this: plasticx --merge=/main/task001@myrep@myserver:8084 --to=/main@myrep@myserver:8084

This command has 2 arguments, "–-merge" for indicate the source branch and "–to" for indicate the destiny branch in merge.

When this command is executed from command line a new plastic window will be displayed with the merge view opened, and the merge conflicts will be shown in this view.

All platforms - PlasticX, GluonX: Proxy configuration

When connecting to an on-premises server for the first time, we added an option to use a proxy. This option was already available on Windows, and now you can use it on the three platforms from the new GUI:

Learn more about proxy servers here: https://www.plasticscm.com/documentation/administration/plastic-scm-version-control-administrator-guide#Chapter4:Usingaproxyserver

All platforms - PlasticX: show code moves between files in diff window

Plastic can detect code refactors where code blocks have been moved from one file to another.

When you diff a branch or changeset a notification will be shown in the Diff window if such a refactor is detected.

Clicking the Show button will group the changes related to the refactor in the diff window file list.

If the diff contains a large number of items, rather than run a potentially long calculation, we show a notification with the option to run the refactor analysis.

Server: The REST API to download revisions could fail for encrypted data

Version 2 of the endpoint to download a file revision content (api/v1/repos/repName/revisions/revId/raw?version=2) fail to download an encrypted big file content (over 4MB) when the file content cannot be compressed.

All platforms - PlasticX: Allow annotate on a not checked-in file

An exception was thrown when trying to annotate a not checked-in file, now an empty annotate view will be displayed.

Server: Avoid reloading users & groups multiple times

The users and groups are reloaded periodically from the authentication provider. But due to an error, on each periodic reload, the reload was done multiple times. Now it's fixed

All platforms - PlasticX: Mark viewed files on Comments selection

Some files from diff items panel were not marked as viewed in code review window when a comment was selected from comments list, this files came from the diffs for a previous revision. It has been fixed and now all the files will be marked as viewed when any new comment selection were done.

All platforms - GluonX: fixed Gluon plastic links to a file not opening

In some cases, when trying to open Gluon plastic link to a file, Gluon tried to open that file in a new workspace and failed, we fixed this issue

Also, we improved the design of "Get Plastic link" button in Gluon Workspace Explorer Details

All platforms - PlasticX, GluonX: Cannot configure a custom diff tool

The file type extension data (FileType) has been removed from configuration (client.conf) for diff tools with custom extension.

All platforms - PlasticX: Fixed layout when searching in Browse Repository

Search panel in Browse Repository expanded when searching, we fixed the layout

All platforms - PlasticX: Fixed duplicated control is Issue trackers preferences

All platforms - DevOps: TrunkBot learnt to pass user defined branch attributes to the CI plan.

Now it is possible to configure the TrunkBot mergebot with a list of user-defined branch attribute names. When TrunkBot processes a branch, it will calculate the branch attribute values and it will forward them to the underlying Continuous Integration plan, triggered to build & test the branch being processed, as key-value parameters (attribute name-attribute value).

See how this feature looks like:

1- First of all, let's open the configuration of an instance of a TrunkBot mergebot, "CI Integration" section.

Here you can see new text fields where you're able to specify a comma-separated list of branch attribute names to forward to both the build & test plan and, if defined, to the "after-checkin" plan if the branch is successfully merged.

In the example above, 'product-type' and 'arch' attributes will be considered for the build & test plan, whereas the after-checkin plan will consider the 'deploy-type' attribute.

REMARK: The TrunkBot won't create any of these attribute names in the repository automatically. This has to be done by the user or the repository administrator.

These attributes can be easily created throught the attributes view of the Plastic SCM GUI:

2- Now let's create some changes in the repo monitored by the TrunkBot instance. Let's create branch 'main/scm003', submit a new changeset, set some values for the user-defined branch attributes we're using in this example, and finally mark the branch status as 'resolved', enabling the TrunkBot instance to process it and try to merge it to the specified 'trunk' branch: the 'main' branch:

3- We're using Jenkins in this example as the CI system. When the TrunkBot processed branch 'main/scm003', it forwarded the 'product-type-to-build' and 'arch' attributes and their values on 'main/scm003' to the execution of the 'build-tools-plan' we have defined in Jenkins (see step #1):

This way, the 'build-tools-plan' is able to read these properties and customize its steps depending on these values, if required.

4- Let's suppose the 'build-tools-plan' ran successfully for 'main/scm003' and the branch got merged into the defined 'trunk' branch: the 'main' branch:

We also defined a plan to run after a successful merge of a branch in the "CI Integration" section of the TrunkBot instance (see step #1).

In this example, it will pick the 'deploy-type' attribute value of branch 'main/scm003' just merged, and will forward it to the plan to run after checking a branch in, named 'deploy-tools-plan':

In case the attribute does not exist, or a branch does not have such attribute set, the trunkbot will create and sent the property with empty value to the CI plan anyway. Each CI system may behave differently when a plan is triggered and a property is set to an empty value.

Also notice that Jenkins will add the 'PLASTICSCM_MERGEBOT_' prefix to the property name (the name of the attribute).

Windows - PlasticFS: New WinFSP version improves Python support

Some Python scripts failed when trying to solve virtual paths with Pathlib.

This happened as the implementation relies on the Windows Mount Point Manager to solve the path, but WinFSP didn't support registering virtual file systems in that facility... until now!

To use this feature, you will need to uninstall WinFSP, reboot your computer and start PlasticFS as usual. The new version of the WinFSP driver will be automatically installed.

Windows - PlasticFS: New WinFSP version fixes Visual Studio "Go to file"

Using "Go to file" (Ctrl+T) in Visual Studio didn't work reliably inside dynamic workspaces, not returning results or even freezing the IDE from time to time. Now it works consistently.

All platforms - PlasticX: Filter code reviews

A new combobox has been added to Code reviews view in order to apply filters to the displayed items list.

All platforms - PlasticX: Added "Close merge view and open pending changes view" preferences option

We have added a new option in Diff and Merge Preferences: "close merge view and open pending changes view when a merge is completed"

If this option is checked, when a merge is completed, the Merge View will be

automatically closed and Pending Changes View will be shown, improving the user workflow.

Also, when a merge is completed and this new option is not checked, we modified the "merge finished" message adding two links in order to open Pending Changes View or open Preferences Window.

Command-line client: Creating workspaces is simpler than ever

Until now, to create a workspace using cm you had to give it a name and indicate the path and the repository:

Often, the three are named the same. For that reason, now it is possible to use a shortened syntax:

This command will create a workspace infering the name and path from the repository spec you pass as argument!

And advanced use of the command also allows you to specify a different server:

All platforms - PlasticX: Fixed exception when showing semantic history for item checked out

Showing the semantic history (available from the Annotate view) for an item checked out no longer causes an error.

Server: Fixed access violation exception

The server could crash due to an access violation exception sending the response to the client on a corner case of concurrent usage of the client's connection.

All platforms - PlasticX: Disable History menu option for added files

All platforms - PlasticX, GluonX: Mark unviewed diffs in bold

The list of differences in Diff window will display viewed items in normal text style and non viewed in bold text style. It'll apply just to the path column for each difference from the list.

All platforms - PlasticX: Added new semantic history view

We added a new view to PlasticX: the semantic history. From this view you can see the history of individual methods or classes inside each file. This view was available on the Windows legacy GUI, and now you can use it from every platform in PlasticX. Check it out:

All clients: GitSync doesn't fail anymore if it cannot access to a revision data.

GitSync won't fail anymore if for whatever reason it can't access the contents of a given revision. It will add an empty revision in the Git package instead.

This way we allow syncing with Git even if an old revision is not present due to any old or weird issue.

All platforms - PlasticX: Code review skip merge tracking

A new button to group the diffs by merge has been added to Code review window. This button will be available only when the selected branch/changeset has merges in the differences list.

All platforms - PlasticX, GluonX: Added "Scan network" button

Added a new "Scan network..." button below the server entry, when connecting to an on-premises server. This button will show a dialog that allows you to easily find Plastic servers in your local network

All platforms - PlasticX: Issue trackers not configurable without workspace

A created workspace is required to configure any issue tracker from the Preferences window. For this reason the view controls will be hidden and a message will be displayed when no workspace is loaded.

All platforms - PlasticX: Linked tasks browse broken

Browse button from Linked tasks panel in Pending changes view didn't open the correct task URL in the web browser. The task Id format has been fixed in order to open the URL properly.

Server: The REST API to download revisions had a memory leak.

The endpoint to download a file revision content (api/v1/repos/repName/revisions/revId/raw) had a memory leak when the '?version=2' query parameter was specified. Fixed.

All platforms - PlasticX, GluonX: only show empty comment warning if user wants it

We were failing to save your preference for not re-showing the empty comment warning if you cancelled the warning dialog.

PlasticX: Unexpected directory conflicts after solving selected file conflicts

Unexpected new directory conflicts appear after merging the selected file conflicts. Now, after merging the selected files only the pending file conflicts remains.

Also, the check-in of the previous merge result, with the reappearing directory conflicts, could fail with an item loaded twice error. Now that the merge is working properly the result can be checked in properly.

All platforms - PlasticX: fixed exception scrolling diffs in diff window

We have fixed an unexpected exception that appeared when scrolling Xlinks diffs in diff window

Also, we will always show in normal font style the merge and changes categories

All platforms - PlasticX: Restore a in-progress merge on restart

Now when Plastic is restarted, if there are pending links, the in progress merge is restored. In this case, the Merge tab will be available from the startup and the loaded merge will be the last in-progress merge before the app is closed.

All platforms - PlasticX, GluonX: Fixed authentication issue when changing the server working mode

If you had a stored profile for a server, and the server changed its working mode, you were not able to update the the existing profile to authenticate to the server.

We fixed this issue - now when the server changes the working mode, the old profile is removed, and we ask for new credentials to save a new profile

All platforms - PlasticX: Fix code review comment navigation.

When double-clicking a code review comment in the Code Review Window, the left textbox didn't navigate to the proper line, so the DiffViewer scroll got de-synchronized. Now it's fixed.

All platforms - PlasticX: Linked tasks panel layout improvements

Some layout adjustments has been included to improve Linked Tasks panel.

A new button has been also added to Pending changes view at the top header area. This button "Show Tasks" will allow to show/hide the Linked Tasks panel when it'll be available.

Linked tasks are available when an issue tracker was previously configured with bind by changeset option selected.

All platforms - PlasticX, GluonX: Made dialog button order consistent

Some 3 button dialogs had the Cancel button in the wrong position. We reviewed all dialogs and made the button order consistent with platform guidelines in each case.

All platforms - PlasticX: fix exception when subtractive merge returned no results

We have fixed a exception when you tried a subtractive merge that returned no results (for example, a subtractive from a not connected branch)

All platforms - PlasticX: Fixed dynamic view location issues

There were some issues with the location of the dynamic views, such as the annotate, history or semantic history, where they appeared in the wrong place of the screen, or partially cut.

All platforms: Moves with changes are now reflected by after-checkin and after-clientcheckin triggers

When you modify a file on the top of moving it, both changes are reflected in the workspace status and in the Pending Changes view. However, the checkout was not notified to triggers:

We added that information to the input data:

Linux - PlasticX: Open with dialog was not displayed.

All platforms - PlasticX, GluonX: Delete current workspace could throw non-controlled exceptions

If the user deleted the current workspace in use in the GUI (using the GUI or delete workspace command), further operations with that deleted workspace would throw non-controlled exceptions that could close the program; we fixed this issue.

All platforms - PlasticX: Show warning when the user tries to delete changeset involved in a pending merge

We now show a warning message and stop the delete changeset operation if you try to delete a changeset that is the source of a pending merge link. We do it because deleting the merge source puts you in an invalid state where you cannot later check in the merge.

All platforms - All client applications: Upgraded interface assembly consumed by issue tracker extensions

We support connecting any client application to an issue tracker to retrieve a user's list of assigned tasks, create a proper branch, or open a task in the issue tracker.

We provide built-in connectors for many issue trackers, such as Jira, Bugzilla, etc.

And we also published an interface so you can write your own connector for a custom issue tracker. This interface is located at issuetrackerinterface.dll file, in the client binaries folder of a Plastic SCM installation.

We've upgraded the issuetrackerinterface.dll and now is compiled in netstandard2.0 (instead of net framework 2.0). This will enable further improvements in the issue tracker subsystem of plastic.

Just in case you have a custom extension compiled in net framework 2.0, you will have two options:

Upgrade your custom extension and compile it in net framework 4.0 or above

Use the legacy issuetrackerinterface.dll compiled in net framework 2.0, located at client/extensions directory of a windows installation of Plastic SCM

All platforms - PlasticX, GluonX: added warning for an empty check-in comment

We have added an optional warning if you accidentally try to check in with no check-in comment. It looks like this.

You can activate it in Preferences -> Comments:

Command-line client: 'cm history' shows if the revision was archived.

The 'cm history' command shows whether the revision's data was archived. It adds a new entry for each history entry specifying the data status. The possible values are 'Available' or 'Archived'. The value is empty for the moved/removed history entries.

Long output (--long):

All platforms - PlasticX: Branch filtering on new history view

Further improving the new history view, a dedicated branch filtering popup has been added!

Filtering by one or as many branches as needed is now possible. You can try it out by viewing the history of any file or directory and clicking the 'branch' button near the search bar.

All platforms - Plastic, PlasticX, Gluon, GluonX: pending changes check status preserved when Incoming changes applied

Previously, pending changes you had unchecked in the Pending Changes view (or Check-in view in Gluon) were being checked when Incoming Changes were viewed or applied. We now preserve your chosen checked state.

Note, that merging can still check previously unchecked items. This is because all items involved in a merge must be checked in together. To help you avoid issues trying to check in a subset of a merge we automatically check all the items involved in the merge.

All platforms - PlasticX: Create button not refreshed in create branch dialog

The Create button status needs to be refreshed depending on the content of the text fields of the current displayed tab in "Create branch dialog". When an issue tracker was previously configured, two ways of creating a new branch will be available, Manual and From task. The branch name will be mandatory to create a new branch.

Command-line client: A workspace created with 'cm wk mk' unexpectedly points to the default repository

When creating a workspace there is no need to specify a repository. A default one will be selected instead.

If a non-existent repository is specified when creating a workspace, the command was silently falling back to picking a default repository. This behavior was misleading.

Now, the command just fails and shows an error:

Command-line client: The 'cm wk mk' subcommand does not always accept the 'rep:' prefix

Creating a workspace pointing to a repository specified with the 'rep:' prefix failed silently if a server address was not specified.

All platforms - PlasticX: corrected GUI hang when switching during Undo

Attempting to switch to another workspace while a long Undo operation was in progress would cause the GUI to hang.

Now, if an operation is in progress, we inform the user and don't allow the switch until the operation has been completed.

All platforms - PlasticX: Fixed changeset -1 exception

There was an exception thrown when selecting the Home changeset in the Branch Explorer when there was a diff view in the background.

All platforms - PlasticX: exception thrown if pending merge source changeset not found

If the source changeset of a pending merge link could not be found (probably because it was deleted), an exception was thrown in the Pending changes view. Now, in this case, we display some helpful text in the merge link description, letting you know you will not be able to check in the merge (because the source changeset is missing).

All platforms - PlasticX: Hide the "add" repository button before org is created

Fixed issue that allowed the user to click 'add' repository button. The 'add' repository button has been hidden when a user is not part of an organization yet.

Windows - PlasticX, GluonX: allow file rename changing case only

All platforms - GluonX: Remark current loaded revision

The current loaded history revision will be remarked in bold style in the History Panel.

All platforms - PlasticX, GluonX: Issue tracker configuration

A new preference option has been added to the Preferences window for the issue tracker configuration.

Some features will be available if this preference is enabled:

Create new branch from a existing task.

Checkin operations record attached to tasks.

Automatic status transitions.

Display linked tasks in pending changes view.

All platforms - Server: GUIDs storage is 5 times faster

We improved the performance of reading GUIDs in our Jet backend. Now reading a GUID is 5 times faster than before!

Taking into account that many objects in the Plastic SCM data model contain a GUID, almost all read operations (and especially those in bulk) will take advantage of this improvement. But not only that, the new method of reading GUIDs does not allocate any memory at all - so we also (slightly) reduced the memory footprint of the Plastic SCM Server. Good news overall!

Command-line client: GetWorkspaceFromPath command now displays workspace type

Workspaces can be of two different types: regular or partial (Gluon). In addition to that, Windows users can choose between static or dynamic workspaces (virtualized with PlasticFS).

Now, the GetWorkspaceFromPath command can display this extended information if the option --extended is provided to the command:

It is also possible to get this information through the --format option by using the 'type' and 'dynamic' keywords:

More information in the help (cm [gwp | getworkspacefrompath] --help)

Server - DevOps: Code Review gating for Multiliner mergebot

The built-in multiliner-bot is now able to use embedded Plastic code reviews to drive the CI/CD lifecycle.

Enable the following "Process reviewed branches only" toggle button in multiliner-bot configuration to activate this feature:

The feature works as follows:

When a code review of a tracked branch(*) is created, or its status changes, the task branch is queued in multiliner-bot.

Then, multiliner-bot will eventually dequeue this task branch. But before continue its processing in the CI cycle, multiliner-bot will check whether there is at least a "Reviewed" code review for this branch. Otherwise, the branch processing is skipped, and the branch is queued again at the end of the queue.

If there are more than a code review linked to this task branch, all of them need to be approved before processing the task branch.

If all the code reviews are approved, the task branch continues its processing by the multiliner-bot:

a)If the merge fails (manual conflicts detected), or the branch build in the configured CI system fails, the status of the linked code reviews of the branch will be set to "Under review".

b)If the merge succeeds and the branch build succeeds too, the task branch is merged, and the "status" attribute of the branch is set to "merged" (these fields must be filled in the multiliner-bot configuration).

((*) tracked branch: those that starts with the configured branch prefix in multiliner-bot config)

All platforms - PlasticX: Checkin & Undo shortcuts

Checkin and Undo operations from pending changes view will be now available using key gestures, Alt+I for Checkin button and Alt+U for Undo button.

All platforms - PlasticX, GluonX: Fix date formatting for languages different than English

When the system language was not set to English, we were forcing some date and number fields to the English formatting. We did this to fix some issues with Turkish characters.

We addressed each issue individually, so now we can take the system language for date fields again, instead of forcing it to English.

All platforms, PlasticX, GluonX: Various diff improvements

Updated the syntax highlight grammars to the latest version, which brings the latest language features for major languages like C#, Python, Java, etc...

fixed some syntax highlight exceptions registered in the log coloring some documents.

Improve the behavior when changing a file in the pending changes view or the diff view. Previously, when selecting another file, the diff viewer scrolled to the first line, and then it went to the first diff. Now the first line is not scrolled. See before and after:

All platforms - PlasticX: Create top-level branch

A new menu item has been added to branches context menu in Branches view and Branch explorer. This new option will allow to create new branch in level 0, a top-level branch.

All platforms - PlasticX: Color changesets by server in the Branch Explorer.

We ported the "Color changesets - replication source" functionality, already existing in the Legacy GUI, to the new GUI. It allows to set up custom colors for all the changesets belonging to a certain server.

This is how it works:

All platforms - PlasticX: Color changesets by user in the Branch Explorer

We ported the "Color changesets - users" functionality, already existing in the Legacy GUI, to the new GUI. It allows to set up custom colors for all the changesets created by a certain user.

This is how it works:

All platforms - PlasticX, GluonX: Automatically detect local server

When configuring Plastic for the first time, if you select the on-premises mode, you will see an empty server field that you must fill with the server you want to connect to.

Now, if there is a local server running on a well-known port, this field automatically filled:

All platforms - PlastiX, GluonX: Object GUID in Diff window

The object GUID has been included in diff window as diff metadata.

All platforms - PlasticX: Branch name shown incorrectly when branch explorer filtered

We fixed an issue where the branch name was being displayed incorrectly in the Branch Explorer when you filtered the view to show just the current and related branches. (You can do this from the context menu on a branch, from the "Branch Explorer" submenu).

macOS - PlasticX: Show History shortcut hides app

Cmd+H shortcut is currently used by the system to hide apps, so it can't be used in PlasticX to show the history view.

For this reason, the "Show history" shortcut has been changed to Cmd+Y and the Redo shortcut has been also changed from Cmd+Y to Shift+Cmd+Z.

Command-line client: PlasticLink arguments wrongly processed as option arguments

If you use a PlasticLink as argument for the command line, the command failed with a cryptic error message:

All platforms - PlasticX: Auto-refresh Sync to Cloud view after opening

In Plastic X, when selecting "Sync to Cloud" view, the view was not refreshed. Now it's automatically done, helping to improve the workflow.

All platforms - PlasticX, GluonX: Removed Plastic SCM prefix from release name

All Plastic releases have a release name, which is a song name and the artist. This name can be seen in the about window.

A few releases back we added a "Plastic SCM" prefix before this name. We removed it, so now you see just the name as before.

All platforms - PlasticX: Improved history view

We re-wrote the history view from scratch. The new history view has the following features:

Improved the revision list layout. Now it optimizes the horizontal space. We also display the avatar for the revision creator (note that it displays the Gravatar image when the username is an email).

Setup a new panel that allows displaying diffs/annotate for the selected revision.

Support history for text, image, binary, and directories revisions.

Note that in this version of the history view, we display the changeset comment for the moved and removed revisions (previously the comment was not displayed).

We also improved the way we display the changeset comments in the details panel. Long comments are split in two chunks, and the second chunk can be expanded/collapsed.

Note that you can still use the legacy history view by setting up the following setting in the plasticgui.conf file, placed in the user config folder:

All platforms - PlasticX: Added Merge options

We brought back this feature from the legacy GUI to PlasticX

This feature will allow PlasticX users to define merge options for each merge:

*Merge from both contributors, or only from one side

*Automatic merge conflict, or manual merge conflict (always launch the merge tool event with 0 unsolved conflicts)

*Ignore Merge Tracking

*Advance options: ancestors

Command-line client: Annotate command options update

The command to annotate files (cm annotate) was using, among others, the --ignore option, with (eol | whitespaces | "eol&whitespaces" | none) as possible values. Due to other commands are using another interface, it has been decided to homogenize them all. Now, --ignore will become --comparisonmethod and its regarding options will be (ignoreeol | ignorewhitespaces | ignoreeolandwhitespaces | recognizeall).

Old syntax will be deprecated, but it is still working. Therefore, scripts or other programs using this command will continue working as before. Despite of this, we encourage to update its usage to the new interface. More details in the command help.

Example: in case we want to annotate a foo.c file which has been created and checked-in on a unix system and after that some changes were done and checked-in on a Windows platform, we might want to ignore the EOL:

Command-line client: Diff command options update

The command to show differences (cm diff) was using, among others, the --ignore option, with (eol | whitespaces | "eol&whitespaces" | none) as possible values. Due to other commands are using another interface, it has been decided to homogenize them all. Now, --ignore will become --comparisonmethod and its regarding options will be (ignoreeol | ignorewhitespaces | ignoreeolandwhitespaces | recognizeall).

Old syntax will be deprecated, but it is still working. Therefore, scripts or other programs using this command will continue working as before. Despite of this, we encourage to update its usage to the new interface. More details in the command help.

Example: in case we want to check a foo.c file which has been created and checked-in on a unix system and after that some changes were done and checked-in on a Windows platform, we might want to ignore the EOL:

Command-line client: Shelveset apply command options update

The command to apply shelvesets (cm shelveset apply) was using the --comparisonmethod with (ignoreeol | ignorewhitespaces | ignoreeolwhitespaces | notignore) as possible values. Due to other commands are using another interface, it has been decided to homogenize them all. Now, "ignoreeolwhitespaces" will become "ignoreeolandwhitespaces" and "notignore" will become "recognizeall".

Old syntax will be deprecated, but it is still working. Therefore, scripts or other programs using this command will continue working as before. Despite of this, we encourage to update its usage to the new interface. More details in the command help.

Example: in case we want to apply a shelveset and, when comparing actual with previous contents for merging the changeset, we might want to ignore the EOL and whitespaces:

Command-line client: Diffmetrics command options update

The command to print metrics of differences between two revs (cm diffmetrics) was using, among others, the --ignore option, with (eol | whitespaces | "eol&whitespaces" | none) as possible values. Due to other commands are using another interface, it has been decided to homogenize them all. Now, --ignore will become --comparisonmethod and its regarding options will be (ignoreeol | ignorewhitespaces | ignoreeolandwhitespaces | recognizeall).

Old syntax will be deprecated, but it is still working. Therefore, scripts or other programs using this command will continue working as before. Despite of this, we encourage to update its usage to the new interface. More details in the command help.

Example: in case we want to see how many added, modified and deleted lines in a foo.c file and compare them with its version from a different branch, recognizing all, including EOL and whitespaces:

Server: Server backups no longer block read-only web calls

The web calls were not allowed while the server was running a backup. Now the web calls that are read-only calls are allowed during the backup. This applies to the web client, the web admin, and also mergebots.

Command-line client: After-checkin trigger payload: move operations were not displaying move reference information

Previously, after-checkin triggers were generating a JSON content with several variables. One of these variables is named INPUT, which contains information about the changes checked in. These changes might be one of the following: AD, CH, DE and MV, indicating the type of operation which was performed regarding one item. MV operation has a particularity, as it involves not only one file but two.

Now it has been fixed and displays both source and destination of the moved file in the proper order (src->dst).

For example, let's imaagine we have a workspace with the following controlled contents: "./foo.c" and "./FooFolder" and we perform the following operations:

The INPUT variable will now display:

As you can see, there are two changes corresponding the changes in the root directory and the change in the fooFolder and a MV operation, which now details both source file and destination file of that operation, separated by a "->" operand and both displaying all the information re the change.

Therefore, for the move operation, the specification will become:

IMPORTANT NOTE: it is possible that users already parsing this output will perceive their parsers start to fail. We are sorry for any inconvenience this might cause. We balanced different options and finally decided to give you more information for you to use, despite of it might be needed to retouch existing parsers at this moment.

Command-line client: Changelist wrongly removed by cm status with filter

Running the command from above, non-persistent changelists only containing local changes are expected to be omitted from output. However, the command was actually erasing the changelist. Now, doing the same preserves the changelist intact.

All platforms - PlasticX: Fixed error in branches explorer dialog

Opening the branches explorer dialog would, in some cases, for example performing the "Merge from this changeset to ...", trigger an unexpected exception. We fixed that.

All platforms - PlasticX: Focus items list after search

In Plastic X, using the items search and selecting a search result using the "Enter" key, caused the items list to not grab the keyboard focus. Now it's fixed.

All platforms - GluonX: Fixed comments textbox losing the focus.

After doing a check-in or undo checkout operation in GluonX, a bug prevented the check-in comments textbox to preserve the keyboard focus while typing. Quite annoying. Now is fixed.

All platforms - PlasticX: Fixed exception in workspace explorer

There was an exception that was thrown sometimes while navigating through directories in the workspace explorer. This issue is now fixed

All platforms - PlasticX: Null exception closing shelves view

All platforms - PlasticX: New Details panel in Workspace Explorer

The Details panel has been added to the right side of the Workspace Explorer in PlasticX. This panel contains the image preview and properties of the selected item in the workspace tree, so it will be refreshed on every new selection. It is a collapsible panel, by default it's collapsed and can be expanded by using the new button "Show details" at the top right.

All platforms - PlasticX: Added comments auto-text feature

We added comments auto-text feature to Plastic. This allows the user to use predefined variables (Date, UserName, Branch Name) or a custom string in the comments textbox in Pending Changes view:

Also, the icons in Preferences Window were updated.

Command-line client: Upgraded changelist command now allows specifying files for the name and the description.

Changelist command has been upgraded with new verbs for management ("create" and "delete" substituting "add" and "rm"). Now it is possible to use new options in changelist commands: --namefile, --descriptionfile, --newnamefile. These options allow to replace the literals used to specify the name of the changelist or its description and to use a path to a file containing the changelist name or description instead.

Or also could be updated to

Or you could also rename a pre-existing changelist with something like the following:

Old command syntax is still working but tagged as deprecated and the help has been updated. If you have automated scripts using this command, they will work, but we encourage you to update those and test the new amazing functionalities

You can still use the same literals or use the options, whatever the combination that best suits your needs (options + literals, literals + options, all options, all literals).

The --namefile and --newnamefile options do not allow invalid files or content (non-existing file, empty or multilined texts); in addition, if an non-existing file is supplied to --descriptionfile, it will also fail, but no content validity will be done.

DevOps: Remove branches from Trunkbot processing queue

If you accidentally set the status attribute to a branch, your Trunkbot might enqueue it and eventually merge it.

Before, you could remove it from the processing queue by changing the value of the attribute to something else. Now, removing the attribute from the branch will have the same effect.

Server: Edit cset comment now checks branch perm

When you edit the comment of a changeset, the “change comment” permission needs to be set in the branch that contains the changeset.Before this change, the repo permission was checked, which wasn’t as good solution as checking the permission in the branch.

All platforms - PlasticX: Remark current working item

The bold text style has been applied to the current working item, for the "Name" column of the Changesets and Branches views tables, in order to indicate which item on the list is currently loaded.

Command-line client: Configure data encryption for remote servers

As the owner of a Plastic server, you can configure encryption when trying to pull data from repository inside a remote encrypted server for the first time.

This was true for the Plastic GUIs, but now it is also possible within the command line:

All platforms - PlasticX, GluonX: GUI asked for credentials unnecessarily

When adding a new account belonging to several organizations, the UI unnecessarily asked for credentials for every organization belonging to that account. Now it's fixed.

All platforms - PlasticX: CPU remains active after a replication operation

When finishing a replication operation, the progress panel caused the UI to consume CPU even though the panel was not displaying any animation. Now it's fixed.

Windows - Client zip bundle: The command-line bundle some plugins such as Jenkins used lacked the zlib64.dll library. It is now fixed.

This affected only machines without a full Plastic SCM set up on them. Machines that had at least a setup with the complete Plastic SCM client or server did not encounter this issue, as at least one copy of zlib64.dll was in the DLL search path.

WebAdmin: Fix mergebots daily report

Opening the daily report of a mergebot throws a "something went wrong error". This happened since 11.0.16.7118. Now it's fixed.

All clients: Private files should not be cloaked

Before, private items could be matched by the cloaked filters set up in the 'cloaked.conf' file, so they didn't appear as simple private changes. From now on, only controlled items can be regarded as cloaked.

To keep the old behavior, you can also add the filters to your 'ignore.conf'.

Command-line client: Ls --tree for a file was not returning its path

When running the 'cm ls' command to get the content from a repository tree ('--tree option') and using a file as an argument, the {path} format field was empty:

Now it is evaluated to the file path, as expected:

Windows - PlasticFS: Workspace directory already exists

Before, opening a dynamic workspace when PlasticFS is not running could create an spurious workspace directory. When restarting, PlasticFS was forced to set it aside in order to mount the workspace:

Now Plastic behaves more kindly when the workspace is still not mounted on its path.

All platforms - PlasticX: Null exception closing differences view

In PlasticX, when opening more than one Differences View in Pending Changes View, closing a second or latter Differences View threw "a unexpected error has occurred" message

All platforms - GluonX: Fix in History Panel

All platforms - PlasticX: Added search textbox in MergeView

We added a new search textbox in MergeView, now it is possible to filter results

All platforms - PlasticX, GluonX: Fixed issues with Turkish language

When the system language was set to Turkish, there was some issues like unhandled exceptions and bad arrangement of controls in the GUI.

We fixed this issue, and now everything works in the same way, regardless of the system language.

All platforms - PlasticX: Fix subviews close button not visible

In PlasticX, when shrinking a subview (for example, annotate view), text header would eventually hide the close button

We fixed this issue in all subviews, close button won't disappear anymore. Also, text trimming was added to the header text.

Cloud Server: Backups could block access to a repository indefinitely.

When the Plastic SCM server puts a repository in read-only mode before backing it up, it first stalls new write operations and then waits for already running write operations to finish. There is a long-running read operation that was wrongly identified as a write operation. Because that long-running operation could be active for days, the server was unable to finish the repository backup, while still rejecting new write operations.

This is now fixed. First of all, this long-running operation is now correctly identified as a read operation, so it doesn't prevent the backup of the repository. And to prevent something like this from happening in the future, the server now has timeouts when waiting for write operations to end.

Plastic, PlasticX: Fixed users & group resolution on permissions working with multiple servers

The permissions dialog resolved the users and groups on the default server (the one used to configure the server). When the permissions dialog was shown from a different server and that server used an Active Directory authentication, the user and groups were not properly resolved. The SID was shown instead. Now, the users and group names are correctly shown.

All clients: find owner='me' condition works fine with multiple servers.

The shelve view didn't show your shelves in the workspaces that pointed to a different server than the default one (the default server is the one set in the client configuration). It happened only when the servers have different authentications.

All platforms - PlasticX: Expandable symlinks directories

Symlinks that points to a directory are now expandable from plastic itself!

This feature allows for easier navigation when the workspace contains symlinks. If a symlink points to a directory that is inside the workspace, it behaves like any other directory in the workspace, however if a symlink points to a directory that is outside the workspace, actions like "add to source control" are disabled for these files.

All platforms - Plastic, Gluon: Better error handling for plastic links

When opening a plastic link, if there are any issues while processing it (because it's in the wrong format, or the server specified can't be accessed) we were just exiting the application without showing any error report.

We improved this behavior, and now we show a message with the reason why the plastic link could not be opened.

All platforms: Added "Plastic SCM" prefix to assembly product name metadata

Before we were just setting the Release song name as "Product name" field in the assembly info of all the applications. Now we add the "Plastic SCM" prefix so some antivirus security reports using this "Product name" field can identify in a snap they belong to Plastic SCM.

All platforms - PlasticX, GluonX: Fixed selection in home view

There was an issue with the selection in the home view: when exploring the contents of a repository, if you selected a file or directory in the tree, and then clicked on a different repository, we were selecting a random item in the new tree.

We fixed this issue, and now when changing the repository, the tree selection is cleared

Cloud: Fix the permissions issue with the case of the letters on the email

The permissions set for a single user were only working when the user logged in using the same case of the letters on the emails. For example, you allow jame.webb@telescope.com to see a repository, but when James logs in using James.Web@telescope.com cannot see the repository. Now it's fixed.

All platforms - DevOps: Mergebots and plugs not running due to missing log4net dll

All Platforms - PlasticX: Added context menu actions to Code Editor.

The Code Editors displayed in the DiffViewer, the File Content Viewer, Annotate view and the Merge view, now have available the following extra context menu actions:

Note that all the actions can be executed using the shortcuts.

Note that Undo/Redo/Cut/Paste/Delete actions are not available in the AnnotateView since it's always a read-only editor.

All clients: Only the *.xxx rules are considered as extension rules.

Before, we considered the .xxx as an extension rule. This could lead to weird behaviors when trying to ignore a folder that started with . such as .vs.

Now, the .vs rule only matches files / directories with that exact name. It doesn't match paths with the .vs extension like project.vs

This applies to all files that use path rules (ignored.conf, cloaked.conf, etc.)

All platforms - GluonX: Added shelves view

Now you can create and view shelves from the Gluon GUI.

There is a new "Shelve" button in the "Checkin changes" view that lets you create a shelveset with your pending changes in the same way as you do in Plastic.

There's also a "Show shelves" button that opens a side view with the list of shelves, from where you can diff, remove or apply them to your current workspace.

Windows - Plastic, PlasticX: auto-upgrade enabled for DVCS Edition

Auto-upgrade was previously only available for Enterprise and Cloud Edition. Now it is also available for Dvcs Edition. When a new version of the client is available, you will receive a notification in the help panel, with a link to initiate the upgrade.

All platforms - PlasticX, GluonX: Improve readability of disabled text boxes.

The contrast between the background and the foreground colors was not good enough for disabled textboxes. Now it's better:

All platforms - GluonX: Improve UI for recent check-in comments.

We moved the "check-in recent comments" button inside the textbox. This way we clear a bit the pending changes toolbar.

This is how it looks now:

Windows - PlasticX: Added diff arguments

In the legacy GUI you could open Plastic specifying arguments like the following:

When switching to the new GUI this feature was lost. We fixed this issue and now you can specify the arguments in both GUIs

All platforms - Server: Add extra protection to the server's Accept Loop.

The Accept Loop is the entry point of every single connection to the Plastic SCM Server. It is at the very heart of our custom network protocol (plasticpipe), and it can handle thousands of new connections per minute. But if the Accept Loop exits for whatever reason, the server is unable of accepting new requests. And a server unable of attending to new requests is useless.

Now the accept errors are handled and the loop is restarted if needed. If the accept loop cannot be started on 3 tries the server will exist in a safe way.

This is beneficial not only to your local and Enterprise Plastic SCM setups but also to the Plastic SCM Cloud Regional Servers.

All platforms - PlasticX: Query field not behaving properly

An issue was fixed that prevented correctly typing a new query into any query filter field after deleting all its content.

All platforms - PlasticX: Annotate before these changes reported wrong revision.

Some customers reported that found a bug with "Annotate before these changes" button on PlasticX. Annotate before a given changeset, ended up annotating a wrong changeset. Now it's fixed.

macOS - PlasticX: Strikethrough lines were not visible.

The Mergetool displays some lines as strikethrough in the result text editor. A bug prevented those lines to be displayed as strikethrough in macOS. Now it's fixed.

All clients: Partial shelveset could fail to be applied when involving fs protection changes.

The 'partial shelveset apply' operation failed with an "Object reference not set to an instance of an object." error when these two conditions happened together:

The shelveset to apply contained fs protection changes for a directory.

This same directory contained controlled changes in the workspace before applying the shelveset.

All platforms - PlasticX, GluonX: Preferences couldn't be opened

Command-line client: Shelvesets can be applied to partial workspaces.

Previously, it was not possible to apply a shelveset in partial workspaces (such as Gluon workspaces). Now we fully allow them (from the creation to the application).

The apply operation tries to apply all the shelveset changes in the workspace if possible. However, changes can be skipped if they are related to items that are not configured in the workspace (they are silently ignored) or if they collide with local workspace changes (they are properly reported)

For more examples, you can check the help:

cm partial shelveset apply --help

Server: Log the web call in the ChannelCall

Now the Server monitors and log all the web calls too, so you can see those call with their stats on the ChannelCall log as you see for any other Plastic call. See a new log sample:

See an example of how it was before:

2022-06-02 09:14:33,868 INFO ChannelCall - conn: 9 protocol:plasticproto sec:none recb: 912|rect: 134|sentb: 3645|sendt: 0|queuedt: 0|prt: 361|th: 65|dest: 0|mt: 158|sert: 0|zip: 0|cpu: 0| 127.0.0.1|user:tester|GetLockRule

2022-06-02 09:14:33,869 INFO ChannelCall - conn: 11 protocol:plasticproto sec:none recb: 809|rect: 162|sentb: 3612|sendt: 0|queuedt: 0|prt: 317|th: 67|dest: 0|mt: 2|sert: 0|zip: 0|cpu: 0| 127.0.0.1|user:tester|CheckRepositoryExists

2022-06-02 09:14:34,197 INFO ChannelCall - conn: 7 protocol:plasticproto sec:none recb: 913|rect: 126|sentb: 3742|sendt: 0|queuedt: 0|prt: 719|th: 63|dest: 0|mt: 489|sert: 0|zip: 0|cpu: 0| 127.0.0.1|user:tester|GetBranchInfoByName

2022-06-02 09:14:34,198 INFO ChannelCall - conn: 5 protocol:plasticproto sec:none recb: 793|rect: 447|sentb: 3680|sendt: 0|queuedt: 0|prt: 1269|th: 61|dest: 0|mt: 792|sert: 0|zip: 0|cpu: 0| 127.0.0.1|user:tester|GetRepositoryInfoByName

All Platforms: Command-line client

To list with the "--tree" option now displays the result regardless of some selector cannot be resolved

Previously, if several arguments were fed to the ls command in order to display their related trees, if one of them was not able to resolve the selector (i.e., there was a typo), the other trees were not displayed either. Now it is fixed and, regardless of the validity of each selector, it will display the results.

As you can see, the CommandResult will remain 1 (error), but the output will be dumped accordingly.

All platforms - all clients: display language no longer overriden on APAC systems

Previously, when the configured language was English "en" but the system language was Chinese, Japanese or Korean, we would force the client to use the system language.

We no longer do this, and the configured language is always used.

Windows - Plastic, PlasticX: Auto-upgrade enabled in Enterprise Edition for non-admin users

For a while the auto-upgrade feature has been available for all Cloud Edition users, but administrators in Enterprise Edition. We have now made auto-upgrade available for all users in all editions.

You will be notified of available version upgrades in the help panel:

If you click on the Download link, the installer will download:

Simply click 'Restart and Upgrade' to install the latest version:

Command-line client: Shelvesets can be deleted from partial workspaces.

Previously, it was not possible to perform a shelve operation in partial workspaces (such as Gluon workspaces). Now we fully allow every operation (create/apply/delete).

It is possible to delete an existing partial shelveset with shelveset id 3 doing the following

Mind there is no confirmation message. In case you would like to see it was deleted you can execute the following command to list every existing shelve created in the repository:

The creation subcommand (create | mk) is the default operation, so bear in mind that, if no subcommand is specified, it will try to perform the creation of a new shelveset.

For more examples, you can check the help:

cm partial shelveset --help

cm partial shelveset delete --help

All platforms - PlasticX, GluonX: Added select all shortcut

Added a new shortcut to select all rows in the tables and trees where the multiple selection is allowed:

Ctrl + A (Windows and Linux)

Due to conflicts with existing keyboard shortcuts, the following shortcuts have been modified:

"Annotate" shortcut, replaced with Ctrl + T (Windows/Linux), Cmd + T in MacOs

"Apply label to workspace content" shortcut, replaced with Ctrl + L (Windows/Linux), Cmd + L in MacOs

All platforms - PlasticX: Restored status bar position in switcher window

We restored the correct status bar position in switcher window, now it will appear at the bottom again

Command-line client: Partial checkin allows --private option

Previously, it was not possible to use --private option in a partial checkin command. Now it is available and ready to use.

For more examples, you can check the help:

cm partial checkin --help

Command-line client: Shelvesets can be applied to partial workspaces

Previously, it was not possible to apply a shelveset in partial workspaces (such as Gluon workspaces). Now we fully allow them (from the creation to the application).

The apply operation tries to apply all the shelveset changes in the workspace if possible. However, changes can be skipped if they are related to items that are not configured in the workspace (they are silently ignored) or if they collide with local workspace changes (they are properly reported)

For more examples, you can check the help:

cm partial shelveset apply --help

Windows - Plastic: Enable changelists for locally modified files

You can now move locally modified (changed, moved, deleted) files into user-defined changelists.

All platforms - PlasticX, GluonX: Enable changelists for locally modified files

You can now move locally modified (changed, moved, deleted) files into user-defined changelists.

All platforms - Command line client: Server connection profiles management reaches the command line!

We added the new cm profile command. It has three subcommands that allow you to manage your server connection profiles from the command line client.

The command 'profile list' lists the connection profiles you have configured:

The 'profile list' command has several formatting options. Check cm profile list --help for further information.

The command 'profile remove' helps you to remove a configured connection profile. It works by specifying the profile index provided by cm profile list:

And 'profile create' helps you to create a new connection profile, either interactively or specifying all the necessary information through options:

Check cm profile create --help for further information about the options you can use to create profiles.

Windows - PlasticX: PlasticX is now the official GUI on Windows

When you perform a clean installation of Plastic on a Windows machine, PlasticX will be the default GUI to open after the installation. Also, plastic links will be handled with this GUI.

When upgrading from a previous version, the last used GUI will still be the one that opens when running the Plastic executable

All platforms - PlasticX: Case insensitive filter on home view

On the home view, the repository and workspaces filter are now case insensitive

All platforms - PlasticX, GluonX: Unified Open Menu options in applications

We unified Open Menu right click context menu behavior across all views in PlasticX and GluonX

All platforms - PlasticX: Changes in changeset comments

In the "changeset by changeset" mode for the diff and the code review windows, if a changeset comment started with an empty line you couldn't see it in the changeset list. We fixed it.

Also, we improved this panel, now more text will be shown in the changeset names Panel

All platforms - GluonX: Save details panel user preferences

GluonX will remember the following settings about the details panel for the Workspace Explorer view and the Checkin view, giving the user more personalization

*Details Panel visibility

*Preview Image height

Also, if no user preference is found, this panel will be visible by default.

All platforms - Web UI: Fix issue with directories with hashes in them

You are now able to navigate into and view files inside directories that contain hashes in their name.

All platforms - Plastic, PlasticX, Gluon: No profiles led to workspace metadata corrupted when co private files

If no profiles were set up, when doing a checkout operation on a private item (add the item) from the Pending Changes view, there was no "owner" of the revision. That caused metadata to become corrupted and, after restarting the GUI, made everything in the workspace appear as private. Now it is fixed.

All platforms - GluonX: Search files dialog unexpected error message

In GluonX, when pressing spacebar key in the search files dialog not in configuration mode, a "unexpected error has occurred" message appeared, we fixed this issue

macOS - PlasticX: Fixed library not found issue when loading extensions

There were some issue tracker extensions that could not be loaded on PlasticX because of an issue with dynamic libraries. The affected extensions were jira, codebeamer and ontime

We fixed this issue and now you can load the extensions in the same way as in the legacy GUI

All platforms - PlasticX, GluonX: Corrected display of recent comments containing underscores

We fixed an issue where comments containing underscore characters were not displayed correctly in the list of recent comments in the Pending Changes and Check-in views of PlasticX and GluonX respectively.

All platforms - PlasticX: Fixed repeated display of permissions warning in Branch Explorer

Users without the "applyattr" permission would get an error dialog informing them to the fact every time they clicked on any object in the branch explorer.

We moved this intrusive error message to the Attributes panel in the Branch Explorer options side panel.

Here is the text in a dialog:

And here is the text in the Attributes panel:

All platforms - PlasticX: Fixed code review plastic links

Command-line client: Shelvesets can be created from partial workspaces

Previously, it was not possible to perform a shelve operation in partial workspaces (such as Gluon workspaces). Now we are about to fully support shelves in partial workspaces, and we started with the creation of shelves.

Note that cm partial shelveset apply and cm partial shelveset delete subcommands are coming up.

Now it is possible to create a partial shelveset of foo.c

With the shelveset created, now we could apply it seamlessly to a regular workspace targeting the same repo:

The creation subcommand (create | mk) is the default operation, so bear in mind that, if no subcommand is specified, it will try to perform the creation of a new shelveset.

For more examples, you can check the help:

cm partial shelveset --help

cm partial shelveset create --help

All platforms - Plastic: Added support for legacy plastic links

Some time ago we introduced the plastic links feature, which lets you click on links to directly open diffs or code reviews. A plastic link looks like the following:

plastic://codice@cloud/repos/codice/branches/main/scm24652/diff

Before this new feature, we already had another, more limited implementation of plastic links, that looked like the following:

plastic://showbranch=br:/main/scm24652@codice@codice@cloud

The latter was deprecated, and new versions of Plastic could not handle the old format.

We fixed this issue, and now you can open both legacy and new plastic links seamlessly

All platforms - Bamboo plugin: New plugin for Bamboo 8 is available!

We released a new plugin for Bamboo 8 that enables you to use Plastic SCM as source control for your build processes. You'll find it in the client installation dir, under plugins/bamboo81plugin.

The former plugin (under plugins/bambooplugin) only supports Bamboo 7.x or older.

Windows - Plastic: Open plastic links with last used GUI

When clicking on a plastic link, we were showing a dialog to ask the user whether to use the Legacy Plastic or the new PlasticX GUI to open it. We removed this dialog, and we will automatically open it with the last used GUI.

On macOS and Linux PlasticX is the official version, so plastic links are always opened with PlasticX

Command-line client: Undo command skips deleted or moved files

Using cm undo over a directory didn't restore files that were not actually there. Now it works as expected.

All platforms - Server: Fix the update operation with a controlled cloaked.conf file

Working with a controlled cloaked.conf (a cloaked.conf that was checked-in), the update could be wrongly downloading some cloaked content. Usually, it could be downloading the cloaked items affected by the last cloaked rule in the file. Now it's fixed.

macOS, Linux - PlasticX, GluonX: New Merge tool for binary files

The new cross-platform Binary Merge Tool that we recently added to PlasticX and GluonX on Windows is now available on macOS and Linux.

The Binary Merge Tool allows the user to choose which version of a binary file to keep when there are conflicts during a merge.

All platforms - PlasticX: Use expanders for the Branch Explorer options

Previously, the branch explorer options used splitters to display the configuration. This caused two major usability issues:

Too much information visible at once.

Little space to interact with some views.

Now those panels are collapsible, so users can interact better with panels that need more vertical space.

All platforms - PlasticX, GluonX: ImageDiff now launched from Diff Window and Merge View

Diffing image files from the Diff Window and the Merge View will now launch the ImageDiff tool.

For example, you can launch the diff from the merge using these menu options:

Here is the Image Diff Tool:

All platforms - PlasticX: Enable/disable rules in Branch Explorer

Now the UI allows to enable or disable Filter and Conditional format rules in the Branch Explorer:

All platforms - PlasticX: Restored right-click menu options for labels in Branch Explorer

In Branch Explorer, after we recently added the 2 label diff feature, single label right click options stopped working. We fixed this issue, sorry about that!

All platforms - PlasticX: Error closing Create Account Dialog in the new Home Menu

In Plastic X, when creating an account from the new Home Menu, closing the dialog threw an error, we fixed this issue

All platforms - PlasticX: Fixed diff scroll "jumps"

Every time the right file in the diff viewer was edited, caused the scroll to jump 1 line up. Now it's fixed.

All platforms - PlasticX: Fixed diff summary after editing diffs.

After editing diffs, the diff summary (the label that indicates which is the current difference and how many differences there are), was not updated properly. Now it's fixed.

All platforms - PlasticX: Code Reviews changeset column should grow

In Plastic X, when reviewing a code review changeset by changeset, in some cases after resizing the panel the column text didn't grow when expanding

We permanently fixed this issue:

Windows - Plastic: Check out local changes is 300 times faster

Now, checking out local changes is much faster. For example, selecting 135 thousand private and checking them out now it takes less than 4s vs the almost 19 minutes that it took before.

All clients: Fixed 'unable to sort' error working with local changes

You could get the error "Unable to sort because the IComparer.Compare() method returns inconsistent results" trying to check out, checkin, or undo the pending local changes. It happened due to complex dependencies among the local changes when there were locally moved involved. Now it's fixed.

All platforms - Command-line client: Paths described in trigger variables can now include whitespaces.

Previously, plastic variables used in triggers such as PLASTIC_BIN_PATH, WKSPACE_PATH and GLOBAL_CONFIG_PATH were not resolving paths with white spaces. That led to wrong command formats when executing. Now, these paths are being wrapped inside double quotes when needed.

You can have the following scenario:

Have the directory where the Plastic SCM command line client is installed:

And inside it, you are planning to store your triggers in a subfolder, something like:

So, you could declare a trigger using the following scheme (in Windows cmd shell, for instance):

And it will solve the white space in PLASTIC_BIN_PATH to C:\Program Files\PlasticSCM\client when executing the trigger.

Bear in mind that, as the path already has a whitespace ("after update" in the example above), you should add escaped quotes to it to specify the executable because we also support arguments. No extra quotes will be added in this case. Here we were considering cmd shell, so quotes are escaped with an extra double quote.

You can also use commands with arguments and both command paths and arguments will properly resolve white spaces:

In case you have a workspace such as C:\my wkspace you could create a trigger like the following:

In this case, the whitespaces are going to be inserted in the plastic variable. This trigger will execute python, calling the file named script.py located in your workspace and passing to it an argument which is also resolved to the same path, something like executing:

Find below examples of the same two commands to create triggers but in three different shells:

2- Windows PowerShell

All platforms - Server: Fixed slow connection issues

We fixed a bug that caused the server to close connections over SSL if the client did not start the second method call in under 10 seconds from the connection establishment.

This bug was because of a wrong tracking of the connection status from server side and could cause killing long-running operations (such as big check-ins) over slow networks with the error message "An existing connection was forcibly closed by the remote host".

Command-line client: Fixed null error undoing moved files

The "cm unco" could fail when there are pending moved files to undo. It could fail when the source and the destination directories are different directories, but both are under the same directory. Now it's fixed.

All platforms - PlasticX: New cross-platfrom mergetool

Resolving conflicts in text files during merges will now launch a new cross-platform merge tool.

When the merge tool window is opened, it tells you how many conflicts require user intervention. For each conflict, you can choose to take contribution from the remote version, your local version, or the base of the merge, by clicking the checkbox by each change.

Step back and forth through the remaining unresolved conflicts using the arrows at the top of the screen. You can also step through all conflicts - unresolved, ones you've already resolved, and ones which were resolved automatically.

The result of the merge is shown in the bottom panel. Once all conflicts are resolved, click Save and Exit to return to the merge.

Here is an example conflict resolution.

Before the resolution:

And after the resolution. I chose to keep the local changes:

Windows - PlasticX: New Merge tool for binary files.

We ported our legacy binary merge tool (only available in Windows GUI) to PlasticX.

The binary merge tool allows the user to choose a version when all the versions in a merge, are changed. When resolving the merge, the chosen version will be the resulting file after the merge.

When the content of the merged file can be previewed (any PlasticX supported image type), the preview is displayed. Otherwise, the OS file icon is displayed.

The tool allows to "Open" or "Open with..." each version to allow the user to compare them. Also, some properties, such as file size or date modified, are displayed to help the user to choose a version.

This is an example of merging a Word document:

And this is an example of merging a png image:

All platforms - PlasticX: Repository Empty State

On home view, when a repository contains no files or directories, an "empty state" was added to what would otherwise be a blank panel.

All platforms - PlasticX, GluonX: Added undelete and undelete to the specified path

Added the 'Undelete revision' and 'Undelete revision to specified path...' options to the context menu for the diff window. It can be used to restore a single or multiple deleted items in PlasticX and GluonX.

All platforms - Plastic: Added explanatory text to the welcome window

When you open Plastic for the first time, you are asked to choose the GUI to work with. We added an explanatory text at the bottom of this window, which lets you know that you can change the GUI flavor at any time:

All platforms - Eclipse: Could not merge with writable xlinks

Eclipse plugin (and other Plastic SCM java plugins with merge capability) were unable to perform a merge from a branch when writable xlinks are involved in the merge operation. A Unable to cast object of type ... error was thrown instead. Now it is fixed.

Command-line client: Cannot check out through symlinks

When symlinks contain '.' and '..' elements in their target paths, some commands failed to walk through them:

$ cm co links/linkedfile.txt

The element /wk/links/../content/file.txt is either a private file or it is already checked out in the current workspace.

Now they work as expected.

Windows - Plastic/Gluon: Fixed slow open files from dynamic workspaces.

Some applications (like notepad) start much slower when they are started specifying a working directory that is a network path (UNC path). To work around this, Plastic & Gluon now use the local path (instead of the network path) before opening a file.

This problem was only reproduced when the dynamic workspace was mounted using a network path.

Windows - Plastic/Gluon: Fixed "Open in Explorer" menu option for dynamic workspaces.

This "Open in Explorer" menu option didn't work for dynamic workspace mounted with a network path. Now, it works as expected opening the right directory in a new Explorer window.

All platforms - PlasticX, GluonX: Display cache status for Dynamic Workspaces.

We continue with improvements to better support Dynamic Workspaces in the GUI. This time we display the cache status of each file in the Status column.

The "cloud" icon means the file content never was downloaded to the disk, helping to save disk space.

The "tick" icon means the file was opened or accessed at least once, so it was already downloaded to the shared cache. This also helps to save disk space since the revision contents are shared across the different workspaces. So if have more than one Dynamic Workspace, the revision contents are re-used across them.

All platforms - PlasticX: Remove user profile

A new option has been included into the home view accounts combo box. It allows for removing the selected user profile from the list.

All platforms - PlasticX: Better trackpad support in the differences viewer.

Now, when using the laptop trackpad to scroll the differences view, the movement is smoother. Check this demo:

All platforms - PlasticX: Added directory conflict overlay icon

Added two new directory conflict overlay icons when a directory conflict is detected in PlasticX

*When a directory conflict is unsolved

*When a directory conflict is solved

All platforms - PlasticX, GluonX: Unified credentials dialog

When trying to perform an operation on a server without being authenticated, we were asking the user for credentials by using a custom dialog, which was different depending on the authentication method.

We modified this behavior, and now you will see the same dialog that is shown when creating a new account:

All platforms - Plastic, Gluon: New browse repository dialog

When adding a new path permission on PlasticX, you had to manually type the path of the object you wanted to apply the permissions on. Now, we added a new dialog that shows you the repository tree on the main branch, so you can just select the item on the tree without having to type the full path:

All platforms - PlasticX, GluonX: Spacebar to check/uncheck items in Update Reports

Now is possible to use spacebar key to check/uncheck items in Update Reports dialogs in PlasticX and GluonX.

This feature will also now affect .meta files, selecting the associated .meta file too.

Linux - Server: Enable setting WebAdmin port under 1024

The server can now be configured to start the WebAdmin in ports below 1024.

To do that, edit the /opt/plasticscm5/server/server.conf and change the default values (ports 7178 and 7179) for the new ones at your convenience on the following configuration keys:

All platforms - PlasticX: Add diff selection to text editor

New option to check differences from selected lines in text editor has been added:

All platforms - PlasticX, GluonX: Open files on Enter key pressed

The Enter key pressed will open the selected files from Workspace explorer tree.

All platforms - PlasticX: New icon for dynamic workspaces.

We designed a new icon for Dynamic Workspaces. So now, those workspaces that are dynamic use a new icon so the user can be differentiated from the standard workspaces.

NOTE: Dynamic Workspaces are available only on Windows platforms for now.

All platforms - PlasticX: Add help link for dynamic workspaces.

When creating a workspace, we added a link label to our blog explaining what Dynamic Workspaces are, and what are they for.

All platforms - Plastic, Gluon: Improved sign in to cloud server on on-premises mode

When you selected the on-premises mode for the sign in, and entered a cloud server, we were showing a dialog with the sign-in options available for that server.

We integrated this view inside the same dialog that is used to create the account, so the process is cleaner.

All platforms - PlasticX: Workspace explorer symlinks

A few issues have been fixes related to symlinks on the workspace explorer:

Checkout, undo checkout, lock and checkout now support symlinks

Symlinks are now represented by the correct native icon

All platforms - PlasticX: Code review didn't navigate to the comment correctly

Windows - Plastic: file plastic links now open in GluonX

Opening a file plastic link will now launch GluonX rather than Gluon.

All platforms - Cloud server: Now the Plastic SCM Cloud Server won't abort write operations if there is a backup in progress.

There is a small chance that the Cloud server can start backing up one of your repositories while you are working on it. This chance is small because the Cloud server analyzes repository usage tendencies to predict the best time to backup data without interrupting your work. However, no prediction is perfect. If you encountered that unfortunate scenario you are familiar with this error message:

This is now fixed. If you try to perform a write operation on a repository that is undergoing a backup, your operation will wait a grace period for the backup to finish before throwing an error back to you.

All platforms - GluonX: New GUI announcement

We are happy to announce that our new, cross-platform, GUI for artists, "GluonX", is now the default on all platforms.

GluonX has all the functionality of the legacy Gluon applications across all platforms wrapped in a modern new interface. It also includes support for changelists in the Check-in view, and easy switching between light and dark modes.

Here's how it looks in dark mode:

Note, you can switch back to the legacy GUI at any time by selecting the option from the menu:

IDEA Plugin: IntelliJ IDEA 2022 support

We've updated our plugin and it supports IntelliJ IDEA 2022.x now!

All platforms - Partial update fails when a file was replaced

If a file was moved somewhere else and a second file with the same path was then added, going back and trying to do a partial update over a third file would fail to apply all changes and an error message was shown.

Windows - Jenkins: The command line client used by the plugin couldn't run.

The Jenkins plugin automatically downloads a Plastic SCM command line client bundle to perform VCS operations. But the application ("cm.exe") didn't start properly due to a missing .dll file. Fixed.

All platforms - PlasticX, GluonX: fixes and added new keyboard shortcuts

*Pending Changes View: added missing keyboard shortcut for "Checkout"

*History Panel: Added new keyboard shortcuts in HistoryPanel, for Open and Diff with previous revision

*Browse Repository: Added new keyboard shortcuts in "Browse repository in this label" and "Browse repository in this changeset", for "Open", "Diff with previous revision" and "View History"

*Workspace Explorer View: fixed existing keyboard shortcuts not working, added events

*Workspace Explorer View: added missing keyboard shortcut for "Add to source control"

*Workspace Explorer View: added missing keyboard shortcut for "Add directory tree to source control"

*Workspace Explorer View: added missing keyboard shortcut for "Undo checkout"

Workspace Explorer View: fixed open in explorer name ("Open in explorer" in Windows/Linux,"Reveal in Finder" in Mac)

Workspace Explorer View: added missing keyboard shortcut for "Open in explorer"

*Checkin View: fixed open in explorer name ("Open in explorer" in Windows/Linux, "Reveal in Finder" in Mac)

*Checkin View: added missing keyboard shortcut for "Open in explorer"

*Checkin View: added missing keyboard shortcut for "Checkout"

*History Panel: Added new keyboard shortcuts in HistoryPanel, for Open and Diff with previous revision

All platforms - PlasticX, GluonX: Spacebar to check/uncheck items

Check/Uncheck all selected nodes from tree views with checkable items on spacebar key down.

Windows - PlasticX: Dynamic Workspaces configuration

A new tab option has been added for "Dynamic workspaces" in the Preferences window. This new view contains the status of the plasticfs process (running/not running) and allows user to install this feature if it's not running. Turning on the plasticfs, the dynamic workspaces functionality is automatically enabled and ready to be used.

Link to the video: https://imgur.com/cnSpjPl

All platforms - PlasticX: file plastic links now open in GluonX

Opening a file plastic link will now launch GluonX rather than Gluon.

All platforms - Plastic, Gluon: Improved enterprise edition onboarding

We unified the onboardings in the cloud and enterprise edition. Now both use the same view, and you can connect to an on-premises server or to a cloud server from both editions. This is how it looks:

All platforms - PlasticX: Compact the UI.

Reduce the overall margins/paddings to make the UI a little bit more compact, so more content is visible in the display. We compacted the following UI elements.

PlasticX/GluonX: Compact the TreeDataGrid node height.

PlasticX/GluonX: Compact the Switch Workspace button paddings.

PlasticX/GluonX: Compact the PlasticX Topbar height.

PlasticX/GluonX: Compact the Home view toolbar panels.

PlasticX: Compact the left SideBar item height.

GluonX: Compact the Tab bar.

All platforms - PlasticX, GluonX: handle .meta files

Selecting an asset for check-in in the Pending Changes view in PlasticX and the Check-in view in GluonX will now automatically selected the associated .meta file too. This also applies to the Incoming changes view and the Workspace Configuration view of GluonX.

Windows - Command-line client: Symlinks are now supported

We added support for symlinks on Windows! The long awaited feature is now here for command line only (GUI fixes coming soon).

Symlinks created previously on Linux and macOS were replaced on Windows by placeholder text files containing the linked path.

Now, the Plastic command line supports Windows symlinks as well.

To create symlinks, Windows 10 build 14972 or newer is required. You also need to enable Developer Mode (https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development).

== HOW TO ENABLE THE FEATURE ==

Symlink support will be enabled by default in forthcoming versions. For now, you can add the following key to your client.conf:

Note 1: GUI support is still in progress. By enabling the feature and using symlinks you might experience glitches in the GUI.

Note 2: PlasticFS still does not support symlinks and this feature might interfere with its proper behavior. You might need to mount your workspace right under a volume specifier. For instance:

Note 3: If you enable this feature, symlinks placeholders will eventually be promoted as private files. If you still have any in your workspace, you can remove them and let Plastic to recreate them as actual symlinks.

Note 4: If you disable this feature, dangling symlinks in your workspace might deceive the Plastic client. Remember to erase them immediately after.

== HOW TO CREATE SYMLINKS ON WINDOWS ==

You can use the same Plastic commands and options you would use on Linux or macOS:

All platforms - PlasticX: fixes in GUI help

Fixed broken links in GUI help

*Link:https://plasticscm.com/download/help/ignored-hidden-etc.html broken, replaced with: link:https://plasticscm.com/download/help/ignored-hidden-etc

*Link:https://plasticscm.com/help/recursivemerge broken, replaced with:link:https://plasticscm.com/download/help/recursivemerge

Fixed "You can also customize the query by clicking Advanced" links in Changesets View and Labels View help, the links now works correctly

All platforms - PlasticX: Fixed an "unexpected error" in the diff view.

During the view initialization, sometimes clicking the diff view raised an "An unexpected error has occurred". Now it's fixed.

All platforms - Gluon: Corrected text to switch to Plastic

In the top right menu of Gluon there's an option to switch to the Plastic SCM GUI. When opening the menu from the home view, the text of this option said "Switch to Gluon", which was incorrect. We fixed this issue:

Windows - Visual Studio 2022 plugin: Performance improvements!

Improves startup by asynchronously performing the initialization process.

Command-line client outputs its version as log's first line

Now the cm will store the cm version at the top of the log

Server - Merge and Incoming Changes are much faster with pending added

The calculation of the merge or the incoming changes was slow when the workspace had several pending added items in the same directory.

In the reported case, a workspace with 384000 added files in the same directory took over 3 hours to calculate the incoming changes. Now, the same scenario takes less than 2 seconds to complete it. Now, it's 5000 times faster.

Linux - Installers: Updated GPG keys to install plasticscm packages

We updated the GPG keys of plasticscm.com for Linux packages downloading, so you can safely install Plastic SCM in your Linux distro.

Depending on the distro you are using, a reminder of new GPG key found may appear.

All clients: Global config not working with cloaked rules.

The global configuration was not properly read/updated if there was a cloaked.conf file in the users configuration folder. This file is automatically created from the GUIs when adding a file/folder to the cloaked list with the "Apply rules to all my workspaces" option checked.

The global configuration repository is internally downloaded by using the fast-update operation which doesn't work if there are cloaked rules defined. However, it doesn't make sense to take into account the cloaked rules for global configuration workspaces, so they are just ignored.

Windows - Visual Studio 2022 plugin: Multiple bugs fixed

Fixes toolbar and menu controls that now are enabled/disabled correctly depending on version control found or not.

Fixes workspace not being initialized in some cases by detecting if the solution was already opened before the plugin is initialized and acting accordingly

Fixes Visual Studio getting frozen by removing views restoration in the situation where the solution is already opened (e.g. double-clicking on the .sln file to open a solution)

Wildcard expansion not working for paths with white spaces

Some commands failed when using wildcards involving paths with white spaces:

Now these commands work as expected.

All platforms - PlasticX: New onboarding experience!

Link to the video: https://i.imgur.com/mcVJvWk.mp4

This is what comes with the new "home" section:

Now it's much easier to join to an existing organization or create a new one.

A single place to manage all the accounts, cloud organizations, repositories and workspaces.

One single way to do the entire onboarding.

Always available to return to it, not just like the old onboarding that was only present at the beginning and hard to find after that.

We encourage you to try the new "home" view, and send us your feedback (via https://forum.plasticscm.com/). Remember that if you want to try it the Windows Platform, you need to use the new Plastic X GUI.

All platforms - Plastic, PlasticX, Gluon, GluonX: Handle recent comments per workspace

The applications now save and display the recent comments per workspace.

All platforms - PlasticX, GluonX: ComboBox on focus border color

The comboboxes border color will change when get the focus.

All platforms - PlasticX: Diff between labels

It has been added 2 new diff options to labels context menus, "Diff selected labels" and "Diff with another label", these options can be found in context menus of Labels view and Branch explorer.

"Diff selected labels" will open the diff window with the diff data between labels

"Diff with another label" will open a new explorer dialog with the list of the existing labels. Once one label is selected in this dialog the diff between the selected labels could be requested.

It has been also added the color effect on labels multiselection in Branch explorer.

All platforms - PlasticX, GluonX: improved scroll when deleting an added item

We improved scroll when deleting an added item or a changelist item in pending changes view/ checkin view, now the program should scroll and focus better the nearest item

All platforms - GluonX: implemented native menu on Mac

We implemented the macOS native menu for GluonX.

All platforms - PlasticX, GluonX: enabled menu on Switcher window on Mac

We enabled the macOS native menu on the Switcher window.

All platforms - GluonX: Fix null exception

If you tried to create a file or a directory in a private directory, a null exception appears

All platforms - PlasticX, GluonX: Fix small bug in changelists

If you tried to move a changelist to another changelist with similar name, the changelist name didn't appear, we fixed this issue.

All platforms - GluonX: Fix convert to partial workspace

Sometimes, if you tried to convert a Plastic workspace to a Gluon workspace, the update button didn't work.

All platforms - PlasticX: fixed issue where branch not shown for xlinks

The branch name was not being displayed in the Workspace Explorer for xlinks in the root of workspace. We corrected the issue.

All platforms - PlasticX: Code Reviews changeset column should grow

In Plastic X, when reviewing a code review changeset by changeset, the column text didn't grow when expanding.

macOS - GluonX: "Try new GUI" failed in Cloud Edition

When clicking the "Try new GUI" button on Gluon, and opening the new GluonX, we were asking the user for credentials again. This only happened in cloud edition.

All platforms - Plastic: Fix error when running git sync with UTF-32 files

When performing a git sync with UTF-32 files, sometimes the error "Encoding error Unicode (UTF-32)" was encountered. The git sync should now be able to complete without issue.

All platforms - PlasticX,GluonX: Save expanded and selected items

The application will now remember the following workspace configurations

*Horizontal and Vertical scroll position

GluonX Workspace Explorer:

*Horizontal and Vertical scroll position

Command-line client: New environment variable to track the merge info during an 'after-clientcheckin' trigger

The after-clientcheckin trigger will now fill a new environment variable named PLASTIC_MERGE_LINKS with info about the merge links (if any) introduced in the checkin operation (i.e. checking in a merge from another branch).

The value of the PLASTIC_MERGE_LINKS environment variable would be like this format (just one merge link):

And if there are several merge links in the checkin operation, they will be separated by semicolon ';' char:

Please refer-to the client checkin triggers documentation site for further info.

Server: New environment variable to track the merge info during an 'after-checkin' trigger

The after-checkin trigger will now fill a new environment variable named PLASTIC_MERGE_LINKS with info about the merge links (if any) introduced in the checkin operation (i.e. checking in a merge from another branch).

The value of the PLASTIC_MERGE_LINKS environment variable would be like this format (just one merge link):

And if there are several merge links in the checkin operation, they will be separated by semicolon ';' char:

Please refer-to the server checkin triggers documentation site for further info.

All platforms - Command-line client: New 'cm configure' command replaces 'clconfigureclient' tool.

The clconfigureclient tool was a mono/netframework application, and it had troubles configuring a client with a server using ssl on linux and macOS. This was caused due to unmatched security protocol for the ssl connection between the clconfigureclient process and the plastic server.

To fix this, we have removed the clconfigureclient application, and created a subcommand for the regular command-line-client of Plastic SCM (that runs on netcore, and thus accepts enhanced security protocol, enabling a correct ssl handshake with the plastic server).

The new command is cm configure command, and does the same as clconfigureclient application.

Issue cm help configure to show the command help for further info.

All platforms - Gluon: Try the new Gluon GUI!

You are cordially invited to try out the new Gluon GUI, codenamed GluonX. GluonX has all the functionality of Gluon across all platforms, and additionally includes support for changelists in the Checkin view.

To make it as easy as possible, we have added a button to the existing Gluon GUIs which will launch the new GUI. Note, you can switch back at any time using the "Switch to legacy GUI" option in the menu at the top right of the new GUI.

Switch to new GUI on Windows:

Switch to new GUI on Mac:

Switch to new GUI on Linux:

When GluonX is launched you will be presented with this welcome screen:

Switch back to original GUI:

Please give the new Gluon GUI a try and share your thoughts with us.

Command-line client: Creating a branch no longer allows empty branch names

Previously when creating a child branch it was possible to create one with an empty name. It now will return an error message instead.

All clients: The fast-update operation failed with after-update triggers.

The fast-update operation failed with an "Object reference not set" exception when running the after-update trigger if the workspace was already up-to-date (it means, if it already pointed to the branch head).

This operation is internally used to update changes from the global configuration repository (plastic-global-config), so it also made the application of the global configuration in the workspace fail.

All clients: Some trigger environment variables were not properly set for fast-update.

The PLASTIC_INITIAL_CHANGESET and PLASTIC_FINAL_CHANGESET environment variables were not set for the fast-update operation when running before/after-update triggers. Now it is fixed.

All platforms - PlasticX, GluonX: Loading spinner in Diff window

When the diff window is opened a progress spinner will be displayed while the diff data is loading.

All platforms - PlasticX, GluonX: Save user columns preferences

PlasticX will remember user columns width, sort column, and sort column order preferences every time we open the program, giving the user more personalization options

Also, we decreased default column size in columns "status", "created by" and "repository" in Items View

All platforms - PlasticX: Permission dialog is now resizable

We added the option to resize all permissions dialogs in PlasticX

All platforms - PlasticX, GluonX: version in client logs.

"plasticx.relevant.log.txt" and "plasticx.debug.log.txt" log files will include program version as the first log trace (INFO).

Windows - PlasticX: Added SemanticMerge to solve conflicts for supported languages

We added SemanticMerge tool to be launched automatically to solve conflicts during the merge operation for csharp, vb.net, and java languages.

Now you have the semantic power by default in the merge without having to configure it.

All platforms - GluonX: added Plastic Link button!

You can now copy Plastic Links into the clipboard and share file links with your colleagues.

A Plastic Link is like a URL that points to a file in a Plastic repository. You can send links to controlled documents to other people, and when they click on the link, the document will be downloaded into their workspace.

Click the Copy button in the Details panel to copy a file link into your clipboard:

All platforms - PlasticX: Diff changeset by changeset

Added a new mode for diff branches, the diff changeset by changeset mode which allows to get differences for every changeset from a branch.

Both diff modes "Diff entire branch" and "Diff changeset by changeset" will be available in the Diff window and could be switched between each other, the "Diff entire branch" mode will be displayed by default.

The "Diff entire branch" mode will display:

The branch diff changed files.

The selected file diff panel.

The "Diff changeset by changeset" mode will display:

The list of changesets panel for this branch.

The selected changeset comments panel.

The diff changed files for the selected changeset.

The selected file diff panel.

All platforms - PlasticX: fixed Japanese text truncation on Sync view buttons

The fixed an issue where the text of the buttons on the Sync view was being truncated in Japanese.

All platforms - PlasticX: Error 'CloudLocalAccount' was not found

Command-line client: New variable to track the branch name during an 'update' trigger

When creating an update trigger, the environment variable PLASTIC_FINAL_BRANCH is now available to track the branch of the final changeset.

For further info about 'update' triggers click here

REMARK: The PLASTIC_FINAL_BRANCH value when switching to an empty child branch will be the parent branch, since the loaded changeset when switching to this empty branch is located at the parent branch.

Cloud Server: Improved x1000 the time cleaning the Jet caches.

The time cleaning the Jet caches could take around 40-50s. This created a lock contention that caused most requests got stuck until the process finished. After this, the server continued working normally.

This code has been improved and it now takes around 50 ms instead 30-50 s (it's 1000 times faster).

IntelliJ: VCS controls were not available if the repo contained multiple subprojects.

Now VCS controls are available when a subproject is opened in the IntelliJ IDE (IDEA, Rider and so on) as it now tracks the path upwards until it finds repo info within .plastic directory.

Server: Fixed attribute values not updating in the audit log

Previously when attribute values were changed, the previous version would be written to the audit log. Now the current value of the attribute will be written out.

All platforms - PlasticX: Custom context menus for Directory conflicts

New context menus will be available in Merge view for each type of directory conflict detected during the merge process.

All platforms - PlasticX: Unify configuration data

Configuration data has been moved from guiclient.conf to plasticgui.conf in order to unify configuration in just one file. The moved config parameters are: ComparisonMethod, ResultEncoding, Encoding, MergeResolutionType, EnableCreateDynamicWorkspace, ErrorPendingChangesOnSwitch, WarnMergeWithChangedItems.

All platforms - PlasticX, GluonX: Changed column order in History Panel

We changed the column order of History panel in this release, the new column order will be:

-Size (PlasticX only)

All platforms - PlasticX, GluonX: Typing alphanumeric keys will focus selection

We improved keyboard usability, now, when typing alphanumeric keys (a-z, A-Z, 0-9) in any list, selection will focus to the typed item

All platforms - PlasticX: added support for changelists

We have added changelists to PlasticX.

What are changelists?

Changelists are logical groupings of files in the Pending Changes view. They allow you to group your pending changes as you wish, and perform actions only on the files within a group.

For example, you might group changes into a "Core" changelist and a "Tests" changelist. You can then check in or undo the changes in "Core" or "Tests" independently.

You can enable Changelists using the following setting, accessed by clicking Options in the Pending Changes view:

When first enabled, all changes will appear in a "Default" changelist. You can add new changelists from the context menu accessed by right clicking on a changelist name in the pending changes list.

Creating a changelist:

A changelist can be persistent or transient. A persistent changelist will remain in the pending changes list even if it contains no changes. Otherwise, the changelist is automatically removed when all it's changes have been checked in or undone.

You can move checked-out files into a changelist by selecting "Move to changelist" from the context menu for that item.

Moving an item to a changelist:

Here is an example with multiple changelists configured:

All platforms - PlasticX: Added open menu options in Diff window

We added Open and OpenWith right click context menu options in Diff Window and Code Review Windows

All platforms - Branch Explorer search navigation

The search results navigation order was not properly followed in branch explorer, it should be:

All platforms - GluonX: Solved Enter shortcut in Search files dialog

When Enter key is pressed the selected file in the results table has to be selected and focused in the explorer workspace view from the workspace window.

All platforms - PlasticX: Diff window opens minimized

Sometimes, if you wanted to diff a branch or a changeset, the diff window hid itself to the background

We have mitigated the issue in this release

All platforms - PlasticX: Move changesets path TextBox was disabled

Move changesets to a different branch dialog: "Selected branch" TextBox was disabled when the "Selected an existing branch ..." checkbox is checked.

Windows - PlasticFS: Don't ask to remove Windows Defender rules

All platforms - PlasticX: Help panel for code reviews

Added Help button and panel to:

Watchdog: Added monitoring for the Plastic Server tcp ports.

The watchdog opens periodically connections against the tcp ports of the Plastic Server instances it started (unsecured tcp & ssl if configured). If the connections cannot be opened by any reason, it will recycle the instance.

Watchdog: Added monitoring for the Plastic Server https endpoint.

The watchdog runs periodically requests against the https endpoint of the Plastic Server instances it started (if configured). If the request cannot be completed by any reason, it will recycle the instance.

Cloud: Fixed a concurrency issue with the storage version when creating organizations.

Each time a new organization was created in the Cloud server, it tried to write the storage version file. This could lead to a file access exceptions if two calls tried to write to the file at the very same time.

Now, the storage version is only written once, and the access is protected.

All platforms - PlasticX: Added “Browse repository in this label” action

We added a new right click context menu action in Branch Explorer View (when selecting a label) and Labels View

When you click in “Browse repository in this label”, a new Split View will appear where you will be able to browse the repository from the selected label’s changeset

All platforms - PlasticX: Fix filter in Code Reviews

We fixed an issue where executing a filter in Code Review, now you can filter using the field "Reviewer"

All platforms - PlasticX: New keyboard shortcuts

We added more keyboard shortcuts in PlasticX

Now you can use Ctrl + F (Windows/Linux) or Cmd + F in macOS, to move focus to search filter in all dialogs

All platforms - PlasticX: Fix scroll issue in pending changes

In PlasticX, when you had a large number of elements to be added in Pending changes, if you deleted a item the scroll always focused the first element.

Now this behaviour is fixed, the scroll will remain after a delete operation

All platforms - PlasticX: Added 'Comment' column in the Merge/Incoming Changes views

We completed those views by adding the 'Comment' column in order to show the changeset comment where the revision of each merge/incoming change was created.

For Incoming Changes view:

All platforms - GluonX: Added 'Comment' column in the Incoming Changes view

We completed this view by adding the 'Comment' column in order to show the changeset comment where the revision of each incoming change was created.

All platforms - PlasticX: Added recent comments dropdown to Comments dialog

New dropdown button has been added to Comments dialog in order to allow the selection of any comment used previously.

All platforms - PlasticX: Error displayed creating a new Workspace

In Create Workspace dialog, when trying to choose a repository and the repositories combobox was empty, the app displayed an error message. This error occurs when the repository list wasn't completely loaded.

All platforms - GluonX: fixed directory expansion issue in workspace explorer

We fixed an issue where subdirectories would sometimes become un-expandable after refreshing the view.

All platforms - GluonX: selected search results now highlighted in explorer and configuration view

When you double click on a search result, that item should be navigated to and selected in the item view. This was only happening if the item was already visible. Now, we expand the parent directories of the selected item so it can be shown and selected.

All platforms - PlasticX: Fix text in Merge View

Merge result text overlapped the panel in Merge diagram, now this issue fixed.

Windows - PlasticFS: Support Defender exclusions on Windows 11

Starting PlasticFS for the first time on Windows 11 with Windows Defender enabled could show the following error:

This happens if the user accepts to add initial exclusion rules to Windows Defender required by PlasticFS to improve its performance.

Now it is fixed, and the error message is gone:

All platforms - PlasticX: fixed GUI hang during long branch diff calculation

All platforms - DevOps: Email plug html body messages

Before this version, emails were sent as plain-text. From now on, the email plug can send messages with html content and render them properly.

To do that, just enable the following switch in your email plug configuration (Server's web admin > DevOps > Configure button of your email plug):

All platforms - Plastic, PlasticX: Improvements to Workspace Explorer search

Ctrl+F (Command+F on Mac) to focus on the search field now selects existing text in the field. Also, toggling the "Include private items" checkbox now updates the search results panel if it is open. You can also close the results table by pressing Enter.

All platforms - Server: The plugs and mergebots processes could exit immediately on server startup. Although this issue was easier to reproduce in Linux, it affected all platforms.

An easy way to reproduce this is by restarting the plasticscm-server service on Linux. Once the server is up and running again, you can see that your plugs and mergebots are still offline.

This was because of a race condition when initializing the server. The Plastic SCM server first starts REST APIs, DevOps WebSocket for events… and then it starts the plugs and mergebots.

But the server was still initializing Web services by the time the plugs and mergebots tried to connect to them. This would cause the plug or mergebot to think that the server is offline, forcing them to exit.

The server now checks that these processes are still alive after a grace period. The server will also restart the processes if they exit within this grace period.

Windows - Visual Studio Extension: Fixed issues with views not being displayed correctly

Now menu buttons in views are displayed correctly at scales greater than 100%.

All platforms - GluonX: New cross-platform GUI available!

We are pleased to announce the availability of a new cross-platform version of Gluon, code-named GluonX!

We would love for you to try out the new GUI and give us some feedback. GluonX will eventually replace the existing Gluon GUI on all platforms, so this is a great opportunity for you to help shape the future of the application.

This release of GluonX is fully functional, and has great, modern look and feel. It also comes with light and dark theme on all platforms.

Here is how you can launch GluonX:

On Windows, run the following in a command window:

On macOS, run the following a terminal window:

On Linux, run the following:

Here are a few screenshots to whet your appetite.

Workspace explorer view (dark theme):

Checkin view (dark theme):

File search (light theme):

Please try it out and let us know what you think!

All platforms - GluonX: Added support for Changelists

We have added changelists to GluonX.

What are changelists?

Changelists are logical groupings of files in the Checkin view. They allow you to group your pending changes as you wish and perform actions only on the files within a group.

For example, you might group changes into a "Core" changelist and a "Tests" changelist. You can then check in or undo the changes in "Core" or "Tests" independently.

You can enable Changelists using the following setting, accessed by clicking Options in the Checkin view:

When first enabled, all changes will appear in a "Default" changelist. You can add new changelists from the context menu accessed by right clicking on a changelist name in the pending changes list.

Creating a changelist:

A changelist can be persistent or transient. A persistent changelist will remain in the pending changes list even if it contains no changes. Otherwise, the changelist is automatically removed when all its changes have been checked in or undone.

You can move checked-out files into a changelist by selecting "Move to changelist" from the context menu for that item.

Moving an item to a changelist:

Here is an example with multiple changelists configured:

All platforms, macOS - PlasticX: Improved keyboard shortcuts

We made several improvements, fixes and changes in PlasticX keyboard shortcuts

For example, DELETE shortcut was not working if previously a item that couldn't be deleted was selected. Now this issue is fixed

All platforms - PlasticX: Fixed the focus for workspace window

Now, we set the focus on the workspace explorer view when the workspace window is opened. So, you can use directly the keyboard to navigate or execute a shortcut (e.g Ctrl+F / Cmd+F to search).

All platforms - PlasticX: Add support for portable versions

The theme folder can be located in execution root or parent paths. It will be needed in portable versions where all the assemblies and resources are packaged in the same location.

Windows - PlasticFS: Enable start on user's logon

Now it is possible to start PlasticFS automatically on user's logon by issuing a plasticfs.exe --install.

The plasticfs.exe --install creates a shortcut (a link file) on user's startup program group.

It is located by default at the following directory:

All platforms - PlasticX: Text fields overexpanding when pasting text

When pasting a text that contains end of line character into a single line text field it behaves like a multiline text field instead.

This issue is now fixed, all end of line characters are now replaced with a space character.

All platforms - PlasticX: Improved clarity of link icon

Link icon present on code review, and diff window now uses the theme colors for dark and light themes, this change improves clarity of this icon on dark theme.

All platforms - PlasticX: Drawing improvements in the Branch Explorer.

The parent link arrows were drawn over the branch captions. Now they are drawn behind.

All platforms - PlasticX: Error loading invalid formats in image preview

Command-line client: Updated the help of the PLASTICEDITOR environment variable available for some commands.

We updated the description about using the PLASTICEDITOR environment variable. You can use this option with the following commands: branch create, label create, partial checkin, shelveset create, archive and checkin.

Windows - Visual Studio 2022 plugin: We've made some visual improvements

Plastic CodeLens now shows real icons instead of ASCII or emoji.

Changesets marked as "Merged and Changed" are now hidden from the history list avoiding duplicate records.

Changesets are now ordered by date (and not by the object id).

All platforms - PlasticX: Added reveal password button

User will be able to display entered passwords for password text boxes.

Visual Studio 2022: CodeLens shows renames greatly!

CodeLens now uses short names rather than fully qualified names for renamed actions to improve legibility.

Server: Improve server stats log

Now the server stats included the queued work and the thread count for the thread pool. See example about what they look like:

All platforms - PlasticX: Support navigating trees with left/right arrow keys.

All the tree views in PlasticX/GluonX now support navigation using left/right arrow keys:

Right arrow key: If a node is not expanded, it expands it. If it's already expanded, it navigates to the first child.

Left arrow key: If a node is expanded, collapses it. If it's not expanded, it navigates to the parent node.

All platforms - PlasticX: Checkboxes inside tables/trees not visible enough.

Increased the contrast colors to make them more noticeable, especially when the checkboxes were unchecked:

Command-line client: Add option to include delete & move operations in command line history

Using the flag --moveddeleted will now show delete & move operations when running cm history

Command-line client: cm finds nothing when involving unsolvable objects

Before, a query involving inexistent find objects gave zero results and didn't report any error.

Now queries run as expected:

All Platforms - PlasticX: Fixed error adding a new Code Review comment.

When opening a Code Review from a PlasticLink, and then trying to add a new comment, the UI displayed an "An unexpected error has occurred" error message. Now it's fixed.

All platforms - PlasticX: Fixed text editor's search box visibility.

When you change a file in the diff viewer (both pending changes view and diff window), and the text editor's search box was visible, the search box was wrongly hidden, and it couldn't be displayed again. Now it's fixed.

Command-line client: Archive can use an external text editor for comments.

Some commands use the PLASTICEDITOR environment variable to specify an editor for entering comments. If the PLASTICEDITOR environment variable is set, and the comment is empty, the editor will be automatically launched to allow you to specify the comment.

The 'cm archive' command disclaimed this was possible, but it didn't work. Now it is fixed.

We also fixed the help of other 2 commands (merge and create attribute), which also allowed this functionality, but it was not documented.

All platforms - PlasticX: Added diff selection differences

We added "diff selection" and "diff with previous selection" right-click context menu events in all Diff windows.

Now you can easily compare your custom selected code lines differences in a separate window

All platforms - PlasticX: Flat button background

All platforms - Server: Migrate database from SQLServer/MySQL to Jet

We enabled the database migration from supported SQL backends (MySQL and SQLServer) to Jet using the server's WebAdmin utility.

We plan to deprecate the SQL backends soon. So, if you're still running your on-prem Plastic Server with MySQL or SQLServer as database backend, we strongly recommend to migrate to Jet backend soon (our own embedded, super-fast repo storage).

To access to the migration tool, just open the Plastic Server's WebAdmin (Usually on http://localhost:7178) >> Configuration >> Repository Storage

And then, click on Change storage

(You will only see this option if your server is using MySQL or SQLServer as database backend)

And finally, while migrating, you should see a screen like this:

Command-line client: Edited the help of the transformed formatting option of the ls command.

The transformed formatting option now includes a note about reading the Administrator guide to learn more about Transformable workspaces.

Windows - Proxy: Service management using plasticd proxy subcommands.

Now it is possible to install, uninstall, start & stop Plastic Proxy service by using plasticd proxy subcommands:

plasticd proxy --installservice -> installs the "Plastic Proxy" service (it does not start it up)

plasticd proxy --start -> starts the "Plastic Proxy" service

plasticd proxy --stop -> stops the "Plastic Proxy" service

plasticd proxy --restart -> restarts the "Plastic Proxy" service

plasticd proxy --status -> prints the status of the "Plastic Proxy" service

plasticd proxy --uninstallservice -> stops and uninstalls the "Plastic Proxy" service

For further info about the Plastic Proxy see this link

For the proper way of working of the proxy server, remember creating a plasticcached.network.conf config file in the Plastic SCM server installation directory.

Example of C:\Program Files\PlasticSCM5\server\plasticcached.network.conf :

(You can find a copy of this example config file in C:\Program Files\PlasticSCM5\server\config_samples directory).

macOS - PlasticX: Plastic links are handled by PlasticX

Now, when clicking on a plastic link, it will be directly opened in PlasticX, without asking you with which version of Plastic you want to open it.

Command-line client: Updated the help by removing the {type} format option of the gettaskbranches command.

Because all Plastic SCM branches are of type "smart" since a long time ago, we removed the {type} format option of the gettaskbranches command. This type displayed if a branch was "smart" or not.

Command-line client: Edited the help of the log, ls, and history commands.

We added a note in the help of the log, ls, and history commands to let you know that the options --xml and --format cannot be combined. These commands will ignore the --format option if you run them using both options.

All platforms - Command-line client: The 'cm changelist' command could not add removed items to a changelist. That now works OK.

Say for example you have a changelist named "TODO", and a removed item named "license.txt". The command below did not work:

All platforms - Plastic, PlasticX: corrected handling of multiple arguments in custom tools

External tools configured with multiple arguments were incorrectly having their arguments grouped into a single argument. We fixed that and now the arguments are correctly sent to the target executable.

All platforms - Web UI: Fixed issues with repo names with forward slashes

Fixed an issue where WebUI would hang when it encountered repo names that include forward slashes

Cloud Server: Fixed finding archived revisions.

The cm find revs where archived='T' command didn't return anything if executed against a Cloud repo. It didn't matter if achived='T' or ='F' was specified, it returned zero results in both cases.

Now, it behaves like on-premise servers and it returns the right results according to the specified find conditions.

Bear in mind that these changes will affect only those files archived from this version. Old archived ones won't be affected and therefore not displayed as results.

All platforms - PlasticX: Preserve Properties and Attributes when refreshing the Branch Explorer.

When refreshing the Branch Explorer, PlasticX lost the properties and attributes for the selected branch/changeset/label. Now it's fixed.

All platforms - PlasticX: Implemented Branch Explorer display options.

Included the following options in the Branch Explorer:

Display branches: Allows to enable/disable the visualization of branches.

Display full branch names: Display the full-path/name-only for child branches (/main/new-feature/task5531 vs task5531).

Display merge links: Allows to enable/disable the visualization of merge links.

Display cross-branch changeset links: Allows to enable/disable the visualization changeset parent links that start in a branch and end in a different branch.

Display labels: Allows to enable/disable the visualization of labels.

Display branch task info: If enabled, Plastic SCM the task info from the issue tracker next to the branch name. If Plastic SCM is not connected to an issue tracker, the branch description is displayed.

We also improved the text layout when the option "Display branch task info" is enabled. The branch name is displayed in bold text and the task info is displayed on grayed smaller text, to improve readability.

All platforms - PlasticX: Visual feedback when cutting items

When cutting items from the workspace explorer view, now there is a transparency effect in the icon of the elements that have been cut:

Also, now you can clear the cut elements by pressing the Escape key.

PlasticX: Support over 100 image formats for Image Differences.

We added ImageMagick support for our "preview generators". That means that now we can display differences for over 100 major image file formats.

All platforms - PlasticX: Updated behavior of show shelves view button

We updated the behavior of the "Show shelves" button in the pending changes view. Now, when the view is visible, the button is activated, and clicking on it again will close the view.

All platforms - PlasticX: Improved keyboard shortcuts

We added a new shortcut in Workspace Explorer: now you can use Shift+Ctrl+S in Windows/Linux, or Shift+Cmd+S in Mac, if you want to quick access Open In Explorer

We also exchanged shortcuts for Open and Checkout operations:

Open: Shift+Ctrl+O in Windows/Linux, Shift+Cmd+O in Mac

Checkout: Ctrl+O in Windows/Linux, Cmd+O in Mac

All platforms - PlasticX: Tabs styling

Tab styling has been modified to improve visibility of selected item and have a better look and feel on high resolution screens

All platforms - PlasticX: Cannot close preferences without signing in

An issue that affected enterprise users that uses SSO Authentication could not close the preferences window unless the user is re-authenticated.

All platforms - PlasticX: Fixed context menu display on empty tables

All platforms: Plastic 11 is out!

Plastic SCM reaches major version 11. It's been almost 16 years since Plastic initial release and here we go for another big milestone.

== What was released during the last year ==

Plastic Server and Command Line fully ported to the newest .net framework. Good bye to Mono and .Net framework, hello to .net 6! :)

Added plastic links support for Code Reviews. 10.0.16.5338

Added plastic links support for Gluon in macOS. 10.0.16.5432

New Code Review experience in WebUI. 10.0.16.5338

Huge merge calculation performance improvements in the server. 10.0.16.5362

Greatly improved workspace metadata format for great performance. 10.0.16.5574

TeamCity plugin: Versioned settings. 10.0.16.5574

Wildcard support in repo trigger filters. 10.0.16.5615

Improvements in visual studio plugin. Sln and csprojs not modified anymore. 10.0.16.5664

Version auto-upgrade for the client. 10.0.16.5668

Checkin performance greatly improved by setting multi-thread defaults. 10.0.16.5710

Improved Active Directory security and performance. 10.0.16.5816

Wake On Lan support added to clients. 10.0.16.5859

Gluon: custom actions for changesets. 10.0.16.5859

Dynamic workspaces released in alpha. Dynamic workspaces for windows

GitSync now supports LFS when syncing from Github Enterprise servers, GitLab and Bitbucket! 10.0.16.5975

Added support to install Plastic SCM in Debian 11. 10.0.16.6112

Triggers can now run from Global Config. 10.0.16.6141

Single Sign On support in Plastic Cloud.

Added parallel download for big files. Much faster workspace updates. 10.0.16.6241

Greatly reduced memory footprint during workspace update. 10.0.16.6241

Plastic Cloud can now archive revisions. 10.0.16.6241

New cross-platform desktop GUIs released in alpha. 10.0.16.6363

Support for Visual Studio 2022. 10.0.16.6419

New "cm api" client-side REST API replaces the old plasticapi and introduces tons of improvements, including support for partial workspaces.

Added --machinereadable flag to many commands to ease automation. 10.0.16.6443

And the new cross-platform GUI made official for macOS and Linux. 10.0.16.6621

Greatly improved "pending changes" performace. 10.0.16.6621

Visual Studio 2022 plugin gains CodeLens support. 10.0.16.6656

Besides hundreds of bugfixes, usability improvements, better localization in asian languages, and many more.

Windows - Visual Studio 2022 plugin: VS CodeLens improvements

This new release improves the relevant information shown in CodeLens for an annotated element.

Fixes the management of local changes, showing them as the most relevant ones if exist.

Shows incoming changesets available in the codelens message

Improves the history list ordering it by date and tagging current changeset and incoming changes with representative icons.

Note: This feature is installed as part of the Visual Studio 2022 Plastic SCM extension if you select the option during the Plastic SCM installation process. Once installed, the Plastic SCM CodeLens provider can be enable/disable from Tools > Options > Text Editor - All Languages - CodeLens > Show Plastic SCM

All platforms - Server: Migrate database from SQLServer/MySQL to Jet

We enabled the database migration from supported SQL backends (MySQL and SQLServer) to Jet using the server's WebAdmin utility.

We plan to deprecate the SQL backends soon. So, if you're still running your on-prem Plastic Server with MySQL or SQLServer as database backend, we strongly recommend to migrate to Jet backend soon (our own embedded, super-fast repo storage).

To access to the migration tool, just open the Plastic Server's WebAdmin (Usually on http://localhost:7178) >> Configuration >> Repository Storage).

And then, click on Change storage

(You will only see this option if your server is using MySQL or SQLServer as database backend)

And finally, while migrating, you should see a screen like this:

All platforms - Plastic, Gluon: Modified message when adding ignored rules

We updated the text in the check box inside the ignored rules panel.

Now it's clearer that the rules will be applied only to the user's local workspaces, and not to everyone's.

All platforms - Web UI: Fixed issues with repo names with parenthesis

Fixed an issue where WebUI would hang when it encountered repo names that include parenthesis.

All platforms - DevOps: Trunkbot auto enqueue branches when new changes in dst branch.

Back in release 10.0.16.6621, we published this new feature: If new changesets reach your trunk branch (i.e., '/main' branch) while a merge changeset -changes of your own branch and the trunk branch- is being built & tested, trunkbot would queue again the branch, repeating all the branch processing, including the last changes from trunk branch in a new merge changeset.

But we missed to queue the branch again in the scenario where the trunkbot activates the "Process reviewed branches only" setting. Now it is fixed and affected branch will be queued again also with this configuration.

Remember enabling the auto-queue branches that failed due to changes detected in the trunk branch in the trunkbot configuration:

Server: Do not stop accepting client connections if something fails.

The connections accept loop was protected in the server so if there is something wrong handling a client connection, the whole accept thread doesn't stop working.

All platforms - PlasticX: The syntax highlight was lost switching the diff mode.

When switching from "Text differences" to "Semantic differences" and vice versa, the syntax highlight colors were lost for text editors. Now it's fixed.

All platforms - PlasticX: The GUI was stuck when pasting text in the right diff editor.

In this scenario, the GUI got stuck sometimes:

Copy text to the clipboard from another text source.

Go back to Plastic SCM.

Select Ctrl + A to select all text in the diff's right editor.

Hit Ctrl + V to paste that text.

**Examples:**

Example 1 (unknown):
```unknown
network.conf
```

Example 2 (unknown):
```unknown
# network.conf
[
  {
    "port": 8088,
    "security": "ssl"
  }
]
```

Example 3 (unknown):
```unknown
# network.conf
[
  {
    "port": 8088,
    "security": "ssl"
  }
]
```

Example 4 (unknown):
```unknown
The specified item is no longer valid. It may have been deleted from the keychain.
```

---

## Unity Gaming Services Use Cases

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/Welcome

**Contents:**
- Unity Gaming Services Use Cases#
    - A/B testing#
    - Battle Passes#
    - Cloud AI mini game#
    - Command batching#
    - Daily rewards#
    - Idle clicker game#
    - In-game mailboxes#
    - Loot boxes#
    - Loot boxes with cooldown#

This Unity Gaming Services (UGS) Use Cases project contains a collection of samples designed to demonstrate how to use multiple UGS products in a single Unity project to solve common game development challenges.

Download the Unity project and interact with its sample use cases in the Unity Editor, and follow the documentation to understand the setup mechanics of each scenario. You'll observe examples of:

The following sample use cases are available in the project, along with detailed documentation:

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/privacy/apple-privacy-survey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Cloud Save is available from version 3.2.0.

The following code sample contains the PrivacyInfo.xcprivacy manifest for Cloud Save. This file is also available in the SDK. To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
				<string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
				<string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
</dict>
</plist>
```

---

## WORKSPACE DELETE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/workspace-delete

**Contents:**
- WORKSPACE DELETE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

cm workspace | wk delete | rm [<wk_path> | <wkspec>] [--keepmetadata]

This command deletes a workspace, specified by path or spec. If no arguments are specified, current workspace will be assumed.

(Removes current workspace.)

cm wk delete c:\workspace

cm workspace rm /home/danipen/wks

cm wk rm wk:MiWorkspace

cm wk rm wk:MiWorkspace@DIGITALIS

**Examples:**

Example 1 (unknown):
```unknown
cm workspace | wk delete | rm [<wk_path> | <wkspec>] [--keepmetadata]
```

Example 2 (unknown):
```unknown
cm workspace delete
```

Example 3 (unknown):
```unknown
cm wk delete c:\workspace
```

Example 4 (unknown):
```unknown
cm workspace rm /home/danipen/wks
```

---

## Release Notes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/release-notes/overview

**Contents:**
- Release Notes#
- Unity Version Control 11.x#
- Unity Version Control 10.x#
- Unity Version Control 9.x#
- Unity Version Control 8.x#
- Unity Version Control 7.x#
- Unity Version Control 6.x#
- Unity Version Control 5.x#
- Unity Version Control 4.x#
- Unity Version Control 3.x#

This document contains all Unity Version Control release notes, organized by major version. Each major version file contains all releases for that version, ordered from newest to oldest.

Versions: 11.0.16.9692 - 11.0.16.6683 Releases: 128

Release Period: 2025-10-16 - 2022-03-10

Versions: 10.0.16.6656 - 10.0.16.5328 Releases: 51

Release Period: 2022-03-03 - 2021-04-08

Versions: 9.0.16.5315 - 9.0.16.4057 Releases: 76

Release Period: 2021-04-05 - 2020-03-10

Versions: 8.0.16.4054 - 8.0.16.2951 Releases: 82

Release Period: 2020-03-09 - 2019-01-30

Versions: 7.0.16.2937 - 7.0.16.1857 Releases: 81

Release Period: 2019-01-24 - 2017-12-18

Versions: 6.0.16.1832 - 6.0.16.804 Releases: 53

Release Period: 2017-12-06 - 2017-01-23

Versions: 5.4.16.918 - 5.0.44.522 Releases: 221

Release Period: 2017-03-22 - 2013-01-28

Versions: 4.1.10.622 - 4.1.10.529 Releases: 9

Release Period: 2014-11-13 - 2014-03-17

Versions: 3.0.187.40 - 3.0.187.37 Releases: 2

Release Period: 2014-07-17 - 2012-11-12

---

## Reservation flow

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/beta/reservation-flow

**Contents:**
- Reservation flow#

Warning: This feature is in closed beta and accessible by permission only.

A reservation is a retroactive request by a server to notify Multiplay Hosting that the server is in use. Reservations are similar to allocations for customers who can't use allocations because they don't use a matchmaker, for example.

Reservations work well with games that use a server browser model, which is a model where players choose which server they want to join rather than have a matchmaker decide for them. In this case, customers use Multiplay Hosting for its scaling technology and infrastructure management.

The following steps outline the reservation process.

---

## MERGE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/merge

**Contents:**
- MERGE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - To really perform the merge, '--merge' option is added#
    - To define the merge source, the following specs can be used#
    - This is the list of conflict types the merge command supports#
    - Check the following link to learn more about merge conflicts#

Merges a branch with another branch.

cm merge <source_spec> [--merge] [--cherrypicking] [--forced] [--mergetype=(onlyone|onlysrc|onlydst|try|forced)] [--interval-origin=<csetspec> | --ancestor=<csetspec>] [--keepsource | --ks] [--keepdestination | --kd] [--automaticresolution=<conflict-types>[;...]] [--subtractive] [--mount] [--printcontributors] [--noprintoperations] [--silent] [(--to=<brspec> | --destination=<brspec>)[--shelve]] [--no-dst-changes] [-c=<str_comment> | --commentsfile=<comments_file>] [--resolveconflict --conflict=<index> --resolutionoption=(src|dst|(rename --resolutioninfo=<strname>)) --mergeresultfile=<path> --solvedconflictsfile=<path>] [--nointeractiveresolution] [--machinereadable [--startlineseparator=<sep>] [--xml] [--encoding] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

This command is used to merge changes between two branches or between a label and a branch. The destination of the merge must be always a branch. The merge source is specified as an argument. Destination is the current content of the workspace. For example, to display the elements that will be merged from branch task001 to the main branch, the selector must point to the main branch, the workspace must be updated, and then:

cm merge br:/task001 --merge

To automatically resolve directory conflicts, use '--automaticresolution' option and specify the type of conflict followed by the contributor (source or destination) that must be selected during the merge operation. (Separate each "type of conflict"-"contributor" pair by a semicolon (;).) For example:

cm merge cs:2634 --merge --automaticresolution=eviltwin-src;changedelete-src

(The merge operation from changeset 2634 resolves the "eviltwin" and "changedelete" conflicts by keeping the source ("-src") contributor in both cases.)

The "all" value overrides the other options. In the following example, "eviltwin-dst" will be ignored:

cm merge br:/main/task062 --merge --automaticresolution=all-src;eviltwin-dst

https://www.plasticscm.com/download/help/directorymerges

Set the PLASTICEDITOR environment variable to specify an editor for entering comments. If the PLASTICEDITOR environment variable is set, and the comment is empty, the editor will be automatically launched to allow you to specify the comment.

(Use 'cm help objectspec' to learn more about specs.)

(Does not merge, just prints items to be merged.)

cm merge br:/task001 --merge

(Does merge from branch 'task001'.)

cm merge cs:5 --merge --cherrypicking --interval-origin=cs:2

(Cherry pick from the changeset interval (2,5].)

cm merge cs:8 --merge --subtractive --keepdestination

(Subtractive merge from changeset 8, keeping destination changes for those elements with conflicts.)

cm merge br:/main/task001 --to=br:/main --merge -c="Integrated new UI"

(Does server-side merge, a.k.a. merge-to, from branch 'task001' to branch 'main' and sets a comment.)

cm merge br:/main/task001 --to=br:/main --merge --shelve

(Does server-side merge from branch 'task001' to branch 'main' and leaves the result on a shelve.)

cm merge sh:2 --to=br:/main --merge --no-dst-changes

(Applies the shelve 2 into 'main' only if it was created from the current 'main' head')

cm merge --machinereadable --startlineseparator=start@_@line --endlineseparator=new@_@line --fieldseparator=def#_#sep --mergeresultfile=C:\Users\Borja\AppData\Local\Temp\2tmp4D6C.tmp --solvedconflictsfile=C:\Users\Borja\AppData\Local\Temp\2tmp4D6D.tmp --resolveconflict --conflict=1 --resolutionoption=rename --resolutioninfo=bin_dst br:/main/task --merge

(Example for plugins and integrations)

**Examples:**

Example 1 (unknown):
```unknown
cm merge <source_spec> [--merge] [--cherrypicking] [--forced] [--mergetype=(onlyone|onlysrc|onlydst|try|forced)] [--interval-origin=<csetspec> | --ancestor=<csetspec>] [--keepsource | --ks] [--keepdestination | --kd] [--automaticresolution=<conflict-types>[;...]] [--subtractive] [--mount] [--printcontributors] [--noprintoperations] [--silent] [(--to=<brspec> | --destination=<brspec>)[--shelve]] [--no-dst-changes] [-c=<str_comment> | --commentsfile=<comments_file>] [--resolveconflict --conflict=<index> --resolutionoption=(src|dst|(rename --resolutioninfo=<strname>)) --mergeresultfile=<path> --solvedconflictsfile=<path>] [--nointeractiveresolution] [--machinereadable [--startlineseparator=<sep>] [--xml] [--encoding] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
cm merge br:/task001
```

Example 3 (unknown):
```unknown
cm merge br:/task001 --merge
```

Example 4 (unknown):
```unknown
cm merge cs:2634 --merge --automaticresolution=eviltwin-src;changedelete-src
```

---

## Events

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/events

**Contents:**
- Events#

Most relationships don’t change often, but when there are changes, users want to know about them as soon as possible. The Friends SDK fetches all a user's relationships at startup, then keeps the list up-to-date using events.

The SDK sends events as soon as changes occur. User relationship changes that trigger an event include:

You can attach callbacks to the following events within the FriendsService:

**Examples:**

Example 1 (unknown):
```unknown
FRIEND_REQUEST
```

Example 2 (unknown):
```unknown
FRIEND_REQUEST
```

Example 3 (unknown):
```unknown
FRIEND_REQUEST
```

Example 4 (unknown):
```unknown
FriendsService
```

---

## GETTASKBRANCHES

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/gettaskbranches

**Contents:**
- GETTASKBRANCHES#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Output format parameters (--format option)#
    - The output parameters of this command are the following#
  - Examples#

Gets branches linked with a task.

cm gettaskbranches | gtb <task_name> [--format=<str_format>] [--dateformat=<date_format>]

This command accepts a format string to show the output.

cm gettaskbranches 4311

cm gtb 4311 --format="br:{name}"

cm gtb 4311 --format="br:{name} {date}" --dateformat="yyyy/MM/dd HH:mm:ss"

**Examples:**

Example 1 (unknown):
```unknown
cm gettaskbranches | gtb <task_name> [--format=<str_format>] [--dateformat=<date_format>]
```

Example 2 (unknown):
```unknown
cm gettaskbranches 4311
```

Example 3 (unknown):
```unknown
cm gtb 4311 --format="br:{name}"
```

Example 4 (unknown):
```unknown
cm gtb 4311 --format="br:{name} {date}" --dateformat="yyyy/MM/dd HH:mm:ss"
```

---

## Unity Lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/unity-lobby-service

**Contents:**
- Unity Lobby#

The Lobby service provides a way for players to discover and connect to each other to accomplish a variety of multiplayer gaming scenarios. Some common examples of this are:

The Lobby can persist for the duration of the game session to provide a mechanism for users to re-join an existing game session or facilitate host-migration after an unexpected disconnect.

Visit the Support page to learn how to contact the Unity Lobby support team.

---

## Differential updates

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/differential-updates

**Contents:**
- Differential updates#

Multiplay Hosting automatically uses differential updates to distribute your build updates efficiently.

A differential update (also known as a partial or delta update) is an update that has only the differences between the earlier build version and the new build version. Differential updates are helpful when you want to update a build as fast as possible. Because they contain less data than full updates, Multiplay Hosting can distribute the differential build across your fleet faster than a full update.

Tip: It's best practice to use the same build machine to create new build versions to reduce the possible changes between builds. You might consider using a build server, such as Build Automation.

---

## GitServer limitations

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gitserver/gitserver-limitations

**Contents:**
- GitServer limitations#
- Avoid fast-forward, rebase, and deleting GitHub commits#
- Security isn’t enforced in GitServer#
- Disable deltification on Git repositories#
- GitServer doesn’t support shallow clones#
- The GitHub push command doesn’t show progress#
- Annotated tags#
- Branch names and hierarchies#
- Supported GitHub protocols#
- Storage restrictions#

Manage potential issues or differences in expected behavior when you use GitServer.

If you use GitServer, there are restrictions on some GitHub operations ,such as fast-forward, rebase, and commit deletion, and how GitServer doesn't enforce security. This page also covers important configuration options, such as to disable deltification on your GitHub repository, and functional limitations such as the lack of support for shallow clones and progress indicators for git push commands.

GitServer also has differences in how you handle annotated tags and branch hierarchies, which protocols it supports, its impact on storage, and the correct procedure to follow if you need to recreate the GitServer mapping folder.

Rebasing and deletion of commits are already restrictions when you push to a regular GitHub server. The fast-forward restriction is caused by the fact that in GitHub, a single commit can be in more than one branch. In UVCS, every changeset links to a single branch, and can’t be on more than one branch simultaneously.

GitServer doesn’t perform security checks for exported repositories. GitHub clients can download the entire repository content and push changes to the repository. To restrict the repositories that are visible to GitServer, use the export.repo entry in the gitserver.conf file.

GitServer doesn’t support deltified GitHub packages. This is a performance restriction to speed up metadata and data conversion between the two systems. To disable deltification on the Git side, run the following command on your Git repository:

If GitServer receives a pack with deltas during a push, GitServer displays the following error message:

The message includes clear instructions on how to repack the Git repository to disable deltas:

GitServer doesn’t support shallow clones. Depending on the Git client version, the following error message will be displayed:

The git push command doesn’t show progress while you import objects into UVCS.

Annotated tags import correctly to UVCS, but if you clone them again from GitServer into GitHub, they export as lightweight tags.

Branch names with multiple levels can be different in GitHub and UVCS. For example, a branch named /main/Fix-5.0/scm003 converts to main-Fix-5.0-scm003` in GitHub.

You can access GitServer through both git:// and http:// protocols. GitServer doesn’t support SSH.

When you export a repository with GitServer, you duplicate the file contents of that repository so it exists both in the UVCS format inside the database, and the GitServer storage folder.

If you need to recreate the GitServer mappings folder, the new GitHub SHAs might not match the old ones. The following actions are examples that create new GitHub SHAs that don’t match the old ones:

This means that after you recreate the GitHub mappings, you always need to create a new GitHub repository and clone it from UVCS. If you reuse the previous GitHub repository, it can cause duplicated commits and also duplicate changesets when you push changes back to UVCS.

**Examples:**

Example 1 (unknown):
```unknown
export.repo
```

Example 2 (unknown):
```unknown
gitserver.conf
```

Example 3 (unknown):
```unknown
git config --global pack.window 0
```

Example 4 (unknown):
```unknown
git config --global pack.window 0
```

---

## Matchmaker limitations

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/matchmaker-rate-limits

**Contents:**
- Matchmaker limitations#
- Rate limits#
- Matchmaker requests limitations#
- Queue and pool limitations#
- Matchmaking configuration#

Review the key limitations and rate limits that apply to the Matchmaker service.

Matchmaker has several restrictions on configuration properties and settings to help you design and optimize your integration.

The Matchmaker service uses rate limits to help control network traffic by restricting the number of requests received by the API within any given second.

The following table shows the rate limit for each Matchmaker service request for Players and Service Accounts:

Ticket creation requests are limited to 25 KB.

The matchmaking ticket properties have the following size limitations:

The limit for queues is 10. The limit for pools is 10 pools per queue.

The following table shows the matchmaking configuration limits:

---

## Authentication lifecycle

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/unreal-engine-sdk/authentication-lifecycle

**Contents:**
- Authentication lifecycle#
- Signed out#
- Signing in#
- Authorized#
- Expired#

Since Unity Authentication is a volatile, session-based system, the state of an authorized player changes as time goes on. The possible states of a player's authentication session are as follows:

This is the default state of a player’s authentication session, and the state a player returns to after they successfully sign out. When signed out, a player can sign in anonymously, with an existing session token, or via a third-party service provider.

This is an intermediate state, meaning that the player has sent a sign-in request but has not yet received a response from the server.

When a player session becomes Authorized, the server has sent a success response and the player has successfully signed-in. From here, the player can choose to authenticate with other third-party providers via account linking, or choose to sign out.

A player's session becomes Expired when the expiry time for the retrieved authentication token has been passed. When a session has expired, the player can either choose to sign back in, or sign out.

---

## Set up budget alerts

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/set-up-budget-alerts

**Contents:**
- Set up budget alerts#

Set up budget alerts to monitor your Analytics monthly spending limits and receive email notifications when your spending approaches your maximum budget amount. The budget amount resets each month.

To create budget alerts:

---

## DTLS encryption

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/dtls-encryption

**Contents:**
- DTLS encryption#

Warning: Secure connections using DTLS are only available with Unity Editor versions 2020.3 (starting at 2020.3.34), 2022.1, and above.

Relay supports DTLS encryption of all UDP communication to and from the Relay servers. DTLS encryption doesn't change the authentication flow apart from adding an extra step for increased security.

The client must configure their DTLS library to use the key it received from the Allocations service as the Pre Shared Key (PSK) value. The PSK used for DTLS encryption is the same key provided by the Allocations service for HMAC authentication.

When initiating a DTLS session with the Relay server, the client must set the PSK hint for the DTLS handshake to the canonical string representation of the allocation ID. After the handshake, the Relay message protocol is fully encapsulated by DTLS. The Relay operations and messages are the same with or without DTLS. Check out Enable DTLS encryption for an example.

Note: Enabling DTLS encryption only enables encryption of message. Other Relay behavior, such as timeouts, remains the same.

---

## LABEL CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/label-create

**Contents:**
- LABEL CREATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Applies a label to a changeset and creates the label if required.

cm label [create] <lbspec> [<csetspec> | <wk_path>] [--allxlinkedrepositories] [-c=<str_comment> | -commentsfile=<comments_file>]

Set the PLASTICEDITOR environment variable to specify an editor for entering comments. If the PLASTICEDITOR environment variable is set, and the comment is empty, the editor will be automatically launched to allow you to specify the comment.

cm label create lb:BL001 cs:1203 -commentsfile=commentlb001.txt

(Creates label 'BL001' attached to changeset 1203, and applies the comment in the 'commentlb001.txt' file.)

cm label BL002 cs:1203 -c="first release"

(Creates label 'BL002', with a comment, and attached to changeset 1203.)

**Examples:**

Example 1 (unknown):
```unknown
cm label [create] <lbspec> [<csetspec> | <wk_path>] [--allxlinkedrepositories] [-c=<str_comment> | -commentsfile=<comments_file>]
```

Example 2 (unknown):
```unknown
cm label create lb:BL001 cs:1203 -commentsfile=commentlb001.txt
```

Example 3 (unknown):
```unknown
cm label BL002 cs:1203 -c="first release"
```

---

## Undo changes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/undo-changes

**Contents:**
- Undo changes#
- Undo changes in the GUI#
- Undo changes in the CLI#
  - Undo all changes in a workspace#
  - Filter the undo#
  - Undo a single change#
  - Undo changes on specific paths#

To undo pending changes, use the Unity Devops Version Control application or the CLI. For more flexibility and specificity with the way that you undo changes, use the CLI.

You can undo changes in the Pending Changes tab of the UVCS desktop application:

If you select the arrow on the Undo button, you have two additional options:

You can delete all of your pending changes and start from your original workspace.

To remove your pending changes, use the cm undo -r command. The -r executes the undo operation recursively.

By default, the undo operation applies to all changes, but you can use filter options to restrict the undo to specific change types. In the following example, you have changed, added and deleted files:

You can use the following filters to undo the addition and deletion of files but keep the changes in the modified files:

The filtered undo leaves you with the following status:

To undo a single change, you run the undo command and specify the path.

Note: To view your changes and their paths, run the cm status command.

For example, you might have the following changes:

To undo only the changes to cg_main.c, run the following command:

To undo changes only under a specific path, use the cm undo command and specify the path.

For example, if you have the following changes in your workspace:

The following command undoes the changes in the code folder but keeps the changes in the merge folder:

Note: To filter more precisely, you can also use wildcards. For more information, refer to the CLI reference undo examples.

**Examples:**

Example 1 (unknown):
```unknown
>cm status
/main/fix-1342@quake@localhost:8084 (cs:575 - head)

Changed
Status     Size           Last Modified    Path

Changed    49.23 KB       2 hours ago      code\bsp-renamed.c
Changed    23.42 KB       2 hours ago      code\cgame\cg_drawtools.c
Changed    61.23 KB       9 minutes ago    libs\cmdlib.h
Changed      398 bytes    8 minutes ago    libs\str.h

Deleted
Status     Size       Path

Removed    12.41 KB   code\bsp-temp.c

Added
Status    Size       Last Modified     Path

Added     4.42 KB    17 seconds ago    code\bsp-experimental.c
```

Example 2 (unknown):
```unknown
>cm status
/main/fix-1342@quake@localhost:8084 (cs:575 - head)

Changed
Status     Size           Last Modified    Path

Changed    49.23 KB       2 hours ago      code\bsp-renamed.c
Changed    23.42 KB       2 hours ago      code\cgame\cg_drawtools.c
Changed    61.23 KB       9 minutes ago    libs\cmdlib.h
Changed      398 bytes    8 minutes ago    libs\str.h

Deleted
Status     Size       Path

Removed    12.41 KB   code\bsp-temp.c

Added
Status    Size       Last Modified     Path

Added     4.42 KB    17 seconds ago    code\bsp-experimental.c
```

Example 3 (unknown):
```unknown
>cm undo --added --deleted -r
 c:\Users\pablo\wkspaces\quake_path\code\bsp-experimental.c unchecked out correctly
 c:\Users\pablo\wkspaces\quake_path\code\bsp-temp.c unchecked out correctly
```

Example 4 (unknown):
```unknown
>cm undo --added --deleted -r
 c:\Users\pablo\wkspaces\quake_path\code\bsp-experimental.c unchecked out correctly
 c:\Users\pablo\wkspaces\quake_path\code\bsp-temp.c unchecked out correctly
```

---

## Player data

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/player-data

**Contents:**
- Player data#
- Currency balance#
- Inventory instances#

After setting up your in-game economy and integrating it with your game, you can look at the status of a player’s game currency balances and inventory items.

To view a player’s information:

Economy displays the stored information for that player, separated into Currencies and Inventory.

If you are unable to find a player, ensure that you enter the exact player ID in the search box, and that the player has had at least one interaction with the game API (interactions such as initialized currency balances, or created an inventory item instance).

The Currency tab lists each currency stored against a player, along with the respective balances. The name of each currency is clickable, allowing you to view and edit the configuration for the selected currency.

The Inventory tab lists any instance of inventory items that the selected player owns. A player can potentially own multiple instances of the same item (for example, two copies of the same sword).

The Inventory tab lists the following information about an item:

Each instance of an inventory item can have different instance data. For example, two swords that are otherwise identical could have Instance data associated with the player's instance, giving each of them different “damage” values.

The Player Instance of an Inventory item has a reference to the configuration Custom Data and its own Instance Data.

Player's instances of an Inventory item are created with no instance data by default.

---

## Dashboards

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/Dashboards

**Contents:**
- Dashboards#
- Game performance#
- Retention#
- Revenue#
- User acquisition#

Dashboards show your most important metrics (using line and bar charts) so you can monitor how well a game performs at a glance. Dashboards are predetermined, and you can't customize them. To make your own dashboards, refer to Custom dashboards.

There are three dashboards available that show: Game Performance, Retention, and Revenue. Dashboards can be filtered by country, version, platform, and Audience.

You can export each dashboard's visualization as a PNG image or CSV file. Select the information icon (i) on each visualization for more details about what it shows.

The game performance dashboard gives you an overview of your game's health. It has charts that show how active your game is, how many new players have started recently, and how long they're playing for.

The retention dashboard shows which players are still playing your game after installing. Measuring retention is useful for seeing how well your game is doing, according to the number of days it takes for a player to stop playing. A gradual curve suggests rising retention, whereas steep drops suggest players stop at a certain point in your game.

A player who sends any event is considered active.

Revenue measures the money spent in your game on in-app purchases (IAP) over various time windows. These charts are powered by the transaction standard event so make sure you're recording those to get the best out of this dashboard. Transactions can be recorded automatically by the Unity IAP package (version 4.2 or higher) or manually through the Analytics SDK.

The user acquisition dashboard shows you a breakdown of your data split by ad network provider. Use the acquisition filter at the top to choose between providers. This will show a chart that you can further filter by date range, country, platform, device version, and audience.

These charts are powered by the acquisitionSource standard event which must be sent manually, so make sure you're recording those to get the best out of this dashboard. For more information, refer to track user acquisition tutorial.

**Examples:**

Example 1 (unknown):
```unknown
transaction
```

Example 2 (unknown):
```unknown
acquisitionSource
```

---

## Glossary

**URL:** https://docs.unity.com/ugs/en-us/manual/game-overrides/manual/Glossary

**Contents:**
- Glossary#

A/B testing is a feature within Game Overrides that splits your Override into variants you set to see what impact they make on your game. For example, you might believe starting players are given too many coins and are progressing through your game too quickly or stop playing too early, missing IAP (in-app purchases) opportunities. You’d set two (or more) starting balances: the control, and the variant.

An end-to-end data and analysis solution designed to support your entire studio. Analytics lets studios easily understand game performance and player behaviors. Use Analytics with Game Overrides to report on the impact of your changes, and target players with Audiences.

Average revenue per daily active user.

Players that are grouped by criteria such as player behavior or location. Audiences can be targeted to personalize their game journey.

By using Unity's Cloud Content Delivery to write stateless server-side code on a fully managed infrastructure, you can focus more on developing your game logic. Cloud Code automatically provisions server capacity based on load so you can ensure that your players receive a good experience without any lag or downtime.

Content in-game, such as lives, weapons, and power ups.

A control variant is the original version of the game which new versions (with changes) are tested against. For example, if you try out a new level design, the control variant is the existing level players are used to.

A currency in Economy defines virtual money that exists within your game. When defining currencies, there is the option to set an initial balance (the amount a player receives when you initialize the currency), and a maximum currency balance (the limit to how much of that currency a player can have). For each defined currency, Economy stores a balance against each player account, which the game manages.

Daily play time per DAU

Average daily play time per daily active user. For example, a daily playtime per DAU of 3 minutes means your active players, on average, play 3 minutes per day.

Up-to-date bar and line charts that show you how well your Overrides perform at a glance.

Unity’s Economy service provides a way to create, manage and publish an economy system to be used in your game. Includes Currency, Inventory Item, Configuration, and Publication.

Player groups fall into predetermined categories based on criteria. Also known as variants.

In-app purchases are items in-game that are bought with real money, such as gems, lives, or weapons.

A virtual item the player has in their inventory, for example, a weapon.

JEXL (Java EXpression Language) conditions are evaluated against a variety of factors in each request. This method uses contextual data attributes to define the audience for which you want a Rule to apply.

Minimum detectable effect

Within a mobile game experimentation platform, the Minimum Detectable Effect is the smallest difference or change (in metrics such as player engagement, time spent in the game, etc.) that the experiment is designed to spot between the control and the variant groups. For instance, if you test a new level difficulty, the MDE would be the smallest increase in player completion rates significant enough to implement the change for all users.

Game Overrides give Unity developers the ability to create personalized in-game player experiences and understand their impact.

A p-value determines if a change in the game (like a new character design) did improve player engagement or if the observed improvement was due to chance. If you see more players using the new character and the p-value is low, it suggests that players likely prefer the new design.

Peeking checks the results of a game test before it's fully completed, risking hasty decisions.

Power analysis determines how many players you need to test a new feature on to decide if it's beneficial or not. Before introducing a new in-game purchase, for instance, power analysis can help decide how many players should be exposed to this feature to gauge its success.

A purchase made by the player with real currency.

Remote Config is a cloud service that you can use to tune your game design without deploying new versions of your application. It consists of a set of namespaced Key-Value parameters, and you can optionally define a set of values that override or add to these parameters.

If you’re using Unity Analytics, you can see the impact your changes have on your KPIs. On the Details page, select Reporting. You can select a KPI and the dates (today, last seven days, last 14 days, last 30 days, last quarter) to view your data.

Rate of players that come back to your game.

Sample ratio mismatch

When different versions of the game are exposed to unintended unequal numbers of players. For example, if you want 500 players each to try out two different game backgrounds, but due to a glitch, 700 players see one background and only 300 see the other.

Samples are a subset of players selected to test new game features or changes. Instead of rolling out a new enemy character to all players, the game company might first introduce it to a sample of 1,000 players to gather feedback. The more samples in an experiment, the less likely it is for results to be due to chance.

Choose when you want to run your Override. You can start immediately and run indefinitely.

A seasonal event provides themed content for your players. For example, you may run a winter campaign with items related to snow, Christmas, and presents.

Simulation Experience

Use Simulation Experience to understand what a given Audience or player’s experience will be with your configured Game Overrides. In addition, you can add user IDs and their attributes, view the keys that would be overridden through Game Overrides, and look into any relevant conflicts.

Statistical significance

Statistical significance tells us if observed changes, like increased game time or in-app purchases, are because of the new feature or by chance. If a new game tutorial leads to statistically significant increases in level completions, it means the tutorial likely had a positive effect.

The group of players you want to reach.

The type of key used in key-value pairing: int, string, float, JSON, or long.

A purchase bought in-game,

---

## Get scores for other players

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-score-other-player

**Contents:**
- Get scores for other players#

Using GetScoresByPlayerIdsAsync is not supported on leaderboards with buckets configured.

Get the scores for other players in the specified leaderboard with the GetScoresByPlayerIdsAsync method:

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetScoresByPlayerIdsOptions configuration object:

**Examples:**

Example 1 (unknown):
```unknown
GetScoresByPlayerIdsAsync
```

Example 2 (unknown):
```unknown
GetScoresByPlayerIdsAsync
```

Example 3 (unknown):
```unknown
public async void GetScoresByPlayerIds(string leaderboardId)
{
    var playerIds = new List<string>{ "abc123", "abc456" };
    var scoresResponse = await LeaderboardsService.Instance
        .GetScoresByPlayerIdsAsync(leaderboardId, playerIds);
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 4 (unknown):
```unknown
public async void GetScoresByPlayerIds(string leaderboardId)
{
    var playerIds = new List<string>{ "abc123", "abc456" };
    var scoresResponse = await LeaderboardsService.Instance
        .GetScoresByPlayerIdsAsync(leaderboardId, playerIds);
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

---

## Create an attribute

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/attributes

**Contents:**
- Create an attribute#

Every object in UVCS (branches, changesets, and shelves) can have attributes. Attributes are metadata that can serve any purpose.

For example, you can use attributes to indicate when a branch is ready to be integrated, or that a branch is no longer necessary. You could call this attribute ARCHIVED, and it will have two values: false for when the branch is still in use, and true for when you want to remove the branch.

You can create a new attribute from the Attributes tab of your repository in the UVCS Cloud dashboard. You can also view, rename, and delete existing attributes.

To create a new attribute:

**Examples:**

Example 1 (unknown):
```unknown
default: value_one, value two, value3, valueN
```

---

## Integrate using C++

**URL:** https://docs.unity.com/ugs/manual/matchmaker/manual/unreal-engine-sdk/integrate-using-cpp

**Contents:**
- Integrate using C++#
  - Add the Matchmaker SDK as a dependency#
  - Matchmaker Client Subsystem#
    - CreateTicket#
    - GetTicketStatus#
    - DeleteTicket#
  - Matchmaker Server Subsystem#
    - CreateBackfillTicket#
    - ApproveBackfillTicket#
    - DeleteBackfillTicket#

The following section shows how to integrate with the Matchmaker SDK using the Unreal Engine Subsystems.

The Unity Gaming Services SDK offers two matchmaker interfaces:

Matchmaker Client Subsystem

Matchmaker Server Subsystem

Before continuing, add the MatchmakerSDK as a public dependency of your module, then include the plugin header files in your classes as shown below.

Add MatchmakerServer and MatchmakerClient to your module's dependencies to your Unreal project build file (YourProjectName.Build.cs):

Include the plugin header files you want to access in your classes:

Note: Before accessing the Matchmaking Client Subsystem, ensure that you set up Authentication.

The Matchmaker Client Subsystem controls the client portion of matchmaking and finding matches. This includes creating, deleting, and polling matchmaking tickets.

You can access the Matchmaker Client Subsystem by getting a reference to the UMatchmakerClientSubsystem subsystem. UMatchmakerClientSubsystem is a UGameInstanceSubsystem you can retrieve from UGameInstance.

Use the CreateTicket() method to start the matchmaking process by creating a matchmaking ticket for the clients.

Calling this method adds all valid players in the Players array to the matchmaking queue as a group and joins a match as part of the same team.

There are multiple parameters you can pass in, but the only required parameter is the Players list (with a minimum of one player using a valid ID). Other optional parameters include Queue Name, Qos Results, and custom data for players.

You can handle the response from the SDK using THandler which accepts a FCreateTicketResponse.

Poll for a client's ticket status against the matchmaker service by using the GetTicketStatus() method.

You should poll continuously in a loop until you retrieve a response indicating either a success or failure of the matchmaking process.

To achieve this, use FTimerDelegate to start a timer as in the following example:

Then your poll match function would look similar to the following example:

You can handle the response from the SDK using a THandler which accepts a FGetTicketStatusResponse.

Use the DeleteTicket() method to delete a matchmaking ticket and cancel matchmaking. This is typically done after a match is found (successfully or not) or when a client no longer wants to be considered for the matchmaking process.

You can handle the response from the SDK in a response handler which accepts a FDeleteTicketResponse.

You can handle the response from the SDK using a THandler which accepts a FDeleteTicketResponse.

The Matchmaker Server Subsystem controls the server portion of matchmaking. This includes creating, approving, deleting, and updating backfill tickets.

Before you can use the UMatchmakerServerSubsystem, you must retrieve it as shown in the following code snippet:

Note: Matchmaker is at the time of writing expected to be used solely with Multiplay Servers and as such it is important to note that the following server functions are expected to be used with some of the Multiplay SDK functionality.

See Allocation Payload for more details (access with GetPayloadAllocation() with Multiplay’s Subsystem). This is used to initially fill MatchProperties.

You need to create a new backfill ticket when a player or players leave a full match, and the server needs to fill in the empty slots. To create a new backfill ticket for the server, use the CreateBackfillTicket() method.

The following code snippet shows how to create a new backfill ticket:

You can handle the response from the SDK using a THandler which accepts a FCreateBackfillTicketResponse.

To approve a backfill ticket after creation, use the ApproveBackfillTicket() method. Approving a backfill ticket allows new players into the server.

It's recommended to approve backfill tickets no faster than once a second. The Unity Matchmaker deletes tickets if they haven’t been approved in 20 seconds.

The following code snippet shows how to approve a backfill ticket:

You can handle the response from the SDK using a THandler which accepts a FApproveBackfillTicketResponse.

Delete a backfill ticket when a match becomes full, and you no longer need the server to accept new players. You should also do this after a match concludes and you no longer want the server to receive new players. To stop backfilling on a server, use the DeleteBackfillTicket() method.

The following code snippet shows how to delete a backfill ticket:

You can handle the response from the SDK using a THandler which accepts a FDeleteBackfillTicketResponse.

To update a server's current backfill ticket, use the UpdateBackfillTicket() method.

Update a backfill ticket anytime a player leaves the server or anytime a player joins the server from outside of matchmaking logic. This can include (but isn't limited to) party invites, direct connections, and friend invites.

You should update backfill tickets no more than once every three seconds or after an approved backfill ticket sees a change in the backfill ticket to ensure that a matchmaking cycle has passed. Updating a backfill ticket too often can cause players to never backfill into the match. See Matchmaking Logic Sample to learn more.

**Examples:**

Example 1 (unknown):
```unknown
MatchmakerSDK
```

Example 2 (unknown):
```unknown
MatchmakerServer
```

Example 3 (unknown):
```unknown
MatchmakerClient
```

Example 4 (unknown):
```unknown
YourProjectName.Build.cs
```

---

## Request a code review

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/request-code-review

**Contents:**
- Request a code review#
- Respond to comments and resolve questions#
- Resolve change requests#
  - Resolve the change request in the Unity Dashboard#
  - Resolve the change request in the desktop client#
- Merge a completed code review#
- Additional resources#

You can request a code review on a branch or changeset within your repository:

After you have opened a code review, collaborators or team members can comment and request changes. In the Unity Dashboard, you can view and respond to comments, and resolve questions:

To resolve a change request, you have to make the changes in the code.

You can check-in changes through your normal method, then manually resolve the change request in the Unity Dashboard:

You can also make your changes in your UVCS desktop client, and automatically resolve the change request when you check-in the changes:

This adds the GUID of the change request to the checked in changes. The change request then automatically displays as Resolved in the Unity Dashboard, and shows link to the changeset that you checked in.

Once your reviewer marks your code review as Reviewed, you can select Merge to merge in the changes.

---

## LIST

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/list

**Contents:**
- LIST#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - The default format string is#
    - Output format parameters (--format option)#
    - The output parameters of this command are the following#
  - Examples#

Lists the contents of a tree.

cm ls | dir [<paths>[ ...]] [--format=<str_format>] [--symlink] [--selector[=<selector_format>]] [--tree=<obj_spec>] [-R | -r | --recursive] [--xml[=<output_file>]] [--encoding=<name>]

"{size,10} {date:dd/MM/yyyy} {date:HH:mm}\ {type,-6} {location,-12} {checkout,-5} {name}\ {symlinktarget}"

This command accepts a format string to show the output.

You can customize the 'ls' format setting the PLASTIC_LS_FORMAT environment variable.

cm ls c:\workspace\src

cm ls --format={name}

(Displays information about the symlink instead of the target file or directory.)

cm ls code --selector

(Shows the content of the 'code' subdirectory from the current workspace selector.)

cm ls /code --selector="rep 'myrep' path '/' branch '/main'"

(Shows the content of the '/code' subdirectory on the specified selector. Note that the path is specified in server format.)

cm ls /code --tree=44@myrep@denver:7070

(Lists the '/code' subdirectory at changeset 44 at repo 'myrep' at server 'denver:7070'.)

cm ls /code --tree=br:/main/scm13596@myrep@denver:7070

(Lists the '/code' subdirectory at the latest changeset in branch '/main/scm13596' at repo 'myrep' at server 'denver:7070'.)

cm ls /code --tree=ae1390ed-7ce9-4ec3-a155-e5a61de0dc77@myrep@denver:7070

(Lists the '/code' subdirectory at changeset ae1390ed-7ce9-4ec3-a155-e5a61de0dc77 at repo 'myrep' at server 'denver:7070'.)

**Examples:**

Example 1 (unknown):
```unknown
cm ls | dir [<paths>[ ...]] [--format=<str_format>] [--symlink] [--selector[=<selector_format>]] [--tree=<obj_spec>] [-R | -r | --recursive] [--xml[=<output_file>]] [--encoding=<name>]
```

Example 2 (unknown):
```unknown
cm ls c:\workspace\src
```

Example 3 (unknown):
```unknown
cm ls --format={name}
```

Example 4 (unknown):
```unknown
cm ls --symlink
```

---

## Set up Data Access

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/set-up-data-access

**Contents:**
- Set up Data Access#
- Access your Analytics data in Snowflake#
- Useful resources#

You can follow this process to share Analytics data to an existing Snowflake account.

The Analytics Settings page now displays your Data Access account.

To create and to access the database from this share in Snowflake, click the Shares icon in the menu bar. You'll see the share listed in the view. Shares can be viewed by using an SQL command. This lists the shares available for the Snowflake account.

To access the shared data you need to create a database from the share and grant the account admin role for the database:

This creates a database where you can query the shared data.

Alternatively, you can create a database for the share using the following SQL in Snowflake:

To view the created databases in Snowflake, select Data > Databases. Alternatively, you can view the list of databases via the SQL command: Show databases;

To view a list of views and tables within the share, run a describe share <sharename> SQL query in the worksheet. The Origin column in the database table displays the share names.

For more information on how to consume Snowflake shared data, refer to the Snowflake documentation.

**Examples:**

Example 1 (unknown):
```unknown
SHOW SHARES;
```

Example 2 (unknown):
```unknown
CREATE DATABASE "SFSHARETEST" FROM SHARE UNITYLIVEOPS."UNITY_ANALYTICS_PDA";
GRANT IMPORTED PRIVILEGES ON DATABASE "SFSHARETEST" TO ROLE "ACCOUNTADMIN";
```

Example 3 (unknown):
```unknown
CREATE DATABASE "SFSHARETEST" FROM SHARE UNITYLIVEOPS."UNITY_ANALYTICS_PDA";
GRANT IMPORTED PRIVILEGES ON DATABASE "SFSHARETEST" TO ROLE "ACCOUNTADMIN";
```

Example 4 (unknown):
```unknown
Show databases;
```

---

## PROFILE CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/profile-create

**Contents:**
- PROFILE CREATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Creates a new server connection profile.

cm profile [create | mk]

(Creates a new profile interactively.)

cm profile [create | mk] --server=<server_addr> --username=<username> --password=<password> --workingmode=<workingmode>

(Creates a new server connection profile using a user/password authentication mode.)

cm profile [create | mk] --server=<server_addr> --username=<username> --token=<token> --workingmode=SSOWorkingMode

(Creates a new server connection profile using Single Sign On authentication mode.)

When using this command interactively (without options), the client will try to connect to the server to obtain the working mode and check the credentials. This guarantees that the resulting profile is correct.

When specifying the options, the client will generate the connection profile without connecting to the server. This is useful when creating connection profiles for automation purposes.

(Creates a new connection profile interactively.)

cm profile create --server=plastic.domain.com:8087 --username=sergio --password=thisissupersecret --workingmode=LDAPWorkingMode

(Creates a new connection profile to connect to 'plastic.domain.com:8087' using user 'sergio' and password 'thisissupersecret' through LDAP working mode.)

cm profile create --server=plastic.domain.com:8087 --username=sergio --token="TOKENAMoKJ9iAA(...)12fssoprov:unityid" --workingmode=SSOWorkingMode

(Creates a new connection profile to connect to 'plastic.domain.com:8087' using user 'sergio' and the specified token through Single Sign On working mode.)

**Examples:**

Example 1 (unknown):
```unknown
cm profile [create | mk]
```

Example 2 (unknown):
```unknown
cm profile [create | mk] --server=<server_addr> --username=<username> --password=<password> --workingmode=<workingmode>
```

Example 3 (unknown):
```unknown
cm profile [create | mk] --server=<server_addr> --username=<username> --token=<token> --workingmode=SSOWorkingMode
```

Example 4 (unknown):
```unknown
cm profile create
```

---

## Block lists

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/block-list

**Contents:**
- Block lists#

A block relationship is a one-way connection between two users that indicates that one user would like to avoid communicating or interacting with the target user.

A block can also refer to the action a user performs to add another user to their block list, which is a list of users that the current user has blocked. Adding a user to the current user's block list creates a block relationship between the current user and the user they blocked.

Blocked users can't interact with a user who has a block relationship targeting them. The blocked user will be unable to see their presence, and will be unable to send them notifications. Additionally, the game client may use the list of blocked users to improve the player's experience by preventing other in-game interactions between the two players.

Blocking a user that is on the current user's friends list doesn't automatically remove that user from their friends list. The Friends service will return both a FRIEND relationship and a BLOCK relationship for that user. However, the SDK will not include blocked friends in the list that it exposes. If the user is unblocked, they will immediately reappear in the friends list on the client.

Situations in which the current user might want to block another include:

---

## Profile

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/concepts/profile

**Contents:**
- Profile#

Profile refers to the user's metadata handled by the system. Profile data is attached to the Member object, which is part of any Relationship.

A user's profile name is their set name within the service. There are two ways a user can set their username:

---

## Integrate with Unity Editor

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/write-configuration/unity-editor

**Contents:**
- Integrate with Unity Editor#
- Prerequisites#
  - Link project#
  - Install required packages#
- Authoring within the Unity Editor#
  - Create a configuration#
  - Edit a configuration#
  - Deploy a configuration#
- Deployment window#

The Remote Config authoring module allows you to optionally author and modify Remote Config key/values directly within the Unity Editor. You can then upload those remote configurations from the Unity Editor to the Dashboard by using the Deployment package.

Authoring of Remote Config configurations in the Unity Editor is only supported in Unity 2021.3 and above.

To use Remote Config file configurations in the Unity Editor, you must first install the Remote Config SDK and link your Unity Gaming Services project to the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

To create Remote Config file configurations within the Editor, you must install the following packages:

Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

To install these packages and add them to your list of available packages:

The Remote Config Authoring module allows you to create, edit, and deploy Remote Config file configurations directly within the Unity Editor.

Follow these steps to create a Remote Config file configuration using the Remote Config Authoring module:

The new configuration is now visible in the Project window, and in the Deployment window, accessible by selecting Window > Deployment.

For more information on how to create and modify Remote Config files, refer to Remote Config file.

To edit an existing Remote Config file configuration, double-click the file in the Project window. Remote Config configurations are in .json format and use the .rc file extension.

You can deploy a configuration through the Deployment window. For more information, refer to Deployment package.

The Deployment window is a core feature of the Deployment package. It allows all services to have a single cohesive interface for deployment needs, and allows you to upload cloud assets to their respective cloud services.

For more information, refer to Deployment package.

**Examples:**

Example 1 (unknown):
```unknown
UnityEditor.CloudProjectSettings.projectId
```

Example 2 (unknown):
```unknown
com.unity.services.deployment
```

Example 3 (unknown):
```unknown
com.unity.remote-config
```

---

## Buckets

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/concepts/buckets

**Contents:**
- Buckets#

Use buckets to group players into cohorts, segmenting players to give them a better sense of competition.

For example, if you have a leaderboard with a million players configured with a bucket size of 100, each player will only access the scores for the other 99 players assigned to the same bucket.

When used together with tiers, the rules for tiers apply to each bucket, so if you have a "top 10%" tier, each bucket will have a unique "top 10%" of scores.

In addition to using buckets you can also get a range of scores centered around a player.

Unlike other options for leaderboards, buckets must be configured when a leaderboard is created and buckets cannot be modified or removed later. To use buckets in a game with an existing leaderboard you will need to create a new leaderboard with buckets configured.

---

## CONFIGURE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/configureclient

**Contents:**
- CONFIGURE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Languages#
    - Working modes#
    - Client configuration#
    - AuthParameters#

Configures the UVCS client for the current machine user to work with a default server.

cm configure [--language=<language> --workingmode=<mode> [AuthParameters] --server=<server> [--port=<port>]] [--clientconf=<clientconfpath>]

The cm configure command cannot be used on Cloud Edition or DVCS Edition of UVCS. Use 'plastic --configure' instead.

If this parameter is not specified, the default directory for 'client.conf' file would be '%LocalAppData%\plastic4' on Windows or '$HOME/.plastic4' on linux/macOS.

(runs the interactive UVCS client configuration command)

cm configure --language=en --workingmode=LDAPWorkingMode --user=jack --password=01234 --server=plastic.mymachine.com --port=8084

(configures the UVCS client with the specified parameters and creates the 'client.conf' configuration file in the default directory)

cm configure --language=en --workingmode=NameWorkingMode --server=plastic.mymachine.com --port=8084 --clientconf=clientconf_exp.conf

(configures the UVCS client with the specified parameters and creates the 'client.conf' configuration file in the specified path)

cm configure --clientconf=c:/path/to/myclient.conf

(Specified path will be used to create the client configuration file)

cm configure --clientconf=myclient.conf

(File myclient.conf inside default config directory will be used)

cm configure --clientconf=c:/exisitingDirectory

(Default filename, client.conf, in specified directory will be used) configuration file in the specified path)

**Examples:**

Example 1 (unknown):
```unknown
cm configure [--language=<language> --workingmode=<mode> [AuthParameters] --server=<server> [--port=<port>]] [--clientconf=<clientconfpath>]
```

Example 2 (unknown):
```unknown
cm configure
```

Example 3 (unknown):
```unknown
cm configure --language=en --workingmode=LDAPWorkingMode --user=jack --password=01234 --server=plastic.mymachine.com --port=8084
```

Example 4 (unknown):
```unknown
cm configure --language=en --workingmode=NameWorkingMode --server=plastic.mymachine.com --port=8084 --clientconf=clientconf_exp.conf
```

---

## Multiplay Hosting SDK for Unreal Engine

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/sdk/game-server-sdk-for-unreal

**Contents:**
- Multiplay Hosting SDK for Unreal Engine#

The Multiplay Hosting SDK for Unreal Engine includes all the functionality necessary to leverage Multiplay scaling and game server services in your game.

For more information about using Unity Gaming Services products with Unreal Engine, refer to Multiplay Hosting SDK for the Unreal Engine, which contains Multiplay Hosting, Matchmaker and Authentication in one convenient package.

Refer to Get started (UGS for the Unreal Engine) to download and install the SDK.

Note: Refer to Multiplay Hosting SDK for Unity if you’re using the Unity Engine to develop your game.

Important: The Multiplay Hosting SDK for Unreal Engine is incompatible because it's now included in the UGS SDK. If you're already using the Multiplay Hosting SDK for Unreal Engine, delete it to resolve the migration. No code change is required.

---

## Connection to other services

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/integrations

**Contents:**
- Connection to other services#
- Lobby#
- Matchmaker#
- Build Automation#

Multiplay Hosting is engine agnostic and only deals with your game's hosting and server-side aspects. You can use Multiplay Hosting with the Unity Engine, the Unreal Engine, or an entirely custom engine.

Additionally, as part of the Unity ecosystem, Multiplay Hosting integrates well with other Unity products, including:

The Lobby service allows you to connect players before or during a game session with public or private lobbies. You can use the Lobby service to group players together in a lobby before starting a game session. Refer to the Lobby documentation.

Warning: A lobby created using Multiplay Hosting is automatically deleted when the server leaves the lobby, or stops.

Unity Matchmaker is Unity’s highly customizable matchmaker. You can use Matchmaker with Multiplay Hosting to group players into game sessions based on rules, configurable filters, custom queues, and backfilling. Refer to the Matchmaker documentation.

Tip: Refer to the Dedicated game server sample, which uses Netcode for GameObjects and Matchmaker to demonstrate the structure of a project with the dedicated server, and the tools that you can use to configure it.

Unity Build Automation is a continuous integration that automatically creates multiplatform builds in the Cloud in minutes. You can point Build Automation toward your version control system to:

You can use Build Automation to automate creating builds to deploy your Multiplay Hosting servers. Refer to Build Automation.

---

## About Crash and Exception Reporting

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/CrashandExceptionReporting/AboutCrashandExceptionReporting

**Contents:**
- About Crash and Exception Reporting#
  - What’s next?#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Crashes and exceptions can have many different causes and effects. Some are noticeable to players while others are not. For example, one issue may cause your game to briefly freeze when trying to load a level. A more noticeable issue may prevent a multiplayer game from connecting to the server or cause the game to crash altogether. An issue might be caused by a bug in your code, such as a missing asset or an updated API for an online service. The more you know about an issue, the quicker it can be fixed.

When Cloud Diagnostics is enabled with your made-with-Unity project, use the Unity Dashboard to view real-time data about any crashes and exceptions your players may experience. View information about possible issues in your app, such as how many users are affected or what platforms and devices an issue occurs on. Investigate log messages, stack traces and view metadata about individual crashes or exceptions. This detailed information about the cause and effect of issues in your app helps you to identify, prioritize, and fix any problems which may arise.

---

## BRANCH

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/branch

**Contents:**
- BRANCH#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to manage branches.

cm branch | br <command> [options]

cm branch <command> --usage

cm branch <command> --help

cm branch /main/scm21345

cm branch create /main/scm21345

cm branch delete /main/scm21345

cm branch rename /main/scm21345 scm21346

cm branch history /main/scm21345

cm branch showmerges file.txt

**Examples:**

Example 1 (unknown):
```unknown
cm branch | br <command> [options]
```

Example 2 (unknown):
```unknown
cm branch <command> --usage
```

Example 3 (unknown):
```unknown
cm branch <command> --help
```

Example 4 (unknown):
```unknown
cm branch /main/scm21345
```

---

## 

**URL:** https://docs.unity.com/authentication/en/manual/initialize-sdk

---

## Matchmaker SDK for the Unreal Engine

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/unreal-engine-sdk/overview

**Contents:**
- Matchmaker SDK for the Unreal Engine#
- Unity Matchmaker#

The Matchmaker SDK for Unreal Engine contains all the functionality necessary to leverage the Unity Matchmaker service within your game.

Note: See Unity Matchmaker SDK if you’re using the Unity Engine to develop your game.

Explore the following pages to learn more:

---

## Upload new items

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/upload-new-items

**Contents:**
- Upload new items#
- Add a new item#
- Upload to source control#

Add new items to your workspace and upload them to source control.

When you add a new item, the files are private because they exist in your workspace but you haven’t added them to your version control yet.

The Checkin changes tab shows the added and private files:

Note: To upload file or directory to source control with the command line, run the cm partial add -R command. Then run the cm partial checkin command to check in the changes. When you add a new item, the files are private because they exist in your workspace but you haven’t added them to your version control yet.

**Examples:**

Example 1 (unknown):
```unknown
cm partial add -R
```

Example 2 (unknown):
```unknown
cm partial checkin
```

---

## Use SAML authentication with Microsoft Entra

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/SAML-auth-microsoft

**Contents:**
- Use SAML authentication with Microsoft Entra#
- SAML tokens#
- SAML Authentication workflow#
- Prerequisites#
- Configure Azure#
  - Create an app registration#
  - Set up endpoints#
  - Create a new secret#
  - Set permissions#
- Configure your Plastic server#

You can use Security Assertion Markup Language (SAML) protocol to integrate Microsoft Entra’s Azure AD SSO as a new identity provider for Unity Version Control On-Prem. This authentication method allows you and your team to use their existing Microsoft credentials to authenticate with Plastic through both the console, the graphical user interface, and the web application. You can use the Microsoft Graph API to configure Plastic users and groups with access to Entra.

After configuration, Unity Version Control uses an internal token system that periodically checks the token against user credentials based on an absolute session expiration date.

Note: SAML authentication with Microsoft Entra is available from Unity Version Control On-Prem version 11.0.16.8622. This version enables SAML authentication by default and ignores the SAMLAuthenticationEnabled feature flag.

For more information, you can refer to SAML authentication (Microsoft) and SAML protocol (Microsoft).

Note: SAML protocol is intended for a web environment, so Unity Version Control handles sessions in a slightly different way to the standard SAML workflow.

When you authenticate and generate a token, you can use that token to perform authenticated operations against your on-premises Unity Version Control server. This token is internal and allows you to operate for a set amount of days, which is the absolute session duration. You can also set a maximum time period for these tokens in your Plastic server settings.

To renew a token, you need to use the standard SAML process and authenticate against Microsoft Entra through your web browser. The GUI automatically prompts you to renew your token when it expires, and the CLI displays a link in the console that you can open to renew.

If a user isn’t active in Azure, or changes their password while in an active Plastic session, the token automatically revokes.

To set up the Unity Version Control SAML integration with Microsoft Entra, you need the following items:

There are several thing you need to configure in your Azure portal in order to set up this integration. You need to create an app registration, set up the endpoints and permissions, and get the authentication details.

This gives you the Application (client) ID and the Directory (tenant) ID. To view all of the endpoints that Azure generates for this application, select the Endpoints tab.

Note: The Azure account administrator needs to authorize these permissions, so you may need to contact them.

You need to configure SAML mode in your Plastic server. You can do this through the Web interface, or through the CLI.

SAML authentication is enabled by default and the Plastic authentication interface displays the option to choose SAML as your preferred working mode. You can configure your SAML mode in the SAML details section, and select Save. This modifies your server.conf file with your new configuration parameters.

This modifies the configured SAML parameters in your server.conf file.

You need to configure SAML mode in your Plastic client. You can do this either through the CLI, or through a graphical user interface.

To configure the client, configure and initiate the server in SAML mode:

With a correctly configured client, when you log in, you generate an internal token in the tokens.conf file. This file also contains a session token with the data you configure on the server.

If you open the Plastic GUI without a client configured, the GUI displays a window to connect to a new server:

**Examples:**

Example 1 (unknown):
```unknown
SAMLAuthenticationEnabled
```

Example 2 (unknown):
```unknown
https://localhost:7179/account/saml-callback
```

Example 3 (unknown):
```unknown
Group.Read.All
```

Example 4 (unknown):
```unknown
User.Read.All
```

---

## Vivox Unity SDK documentation

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/Unity

**Contents:**
- Vivox Unity SDK documentation#
- Vivox features#
- Safety add-ons#
  - Safe Text#
- Vivox versions#
- Unity sample projects#
- Additional resources#

Note: This documentation is for the Unity Vivox SDK v16. This version of the SDK has substantial changes from previous versions. If you're migrating from a previous version refer to the Upgrade Guide.

The Vivox SDK is a voice and text chat system that brings in-app communications to your project. Use and review text analysis through the Unity Moderation platform to manage your community and players.

Game developers can integrate these capabilities directly into game clients and companion applications by using the Vivox SDK.

Vivox offers additional features for speech-to-text transcriptions and text-to-speech for better accessibility for users. It also offers additional safety features through Safe Text to help reduce in-game toxicity.

Vivox has built-in support for Safe Text, a test moderation tool that helps to build more welcoming communities in your game. This tool gathers text evidence of inappropriate behavior, allowing moderators to review what happened.

Safe Text is a suite of safety tools you can use to tailor in-game communications rules, filter harmful messages, and collect evidence on toxic players.

Get started with Safe Text with the Safe Text documentation.

If you're looking for Vivox documentation for the Core or Unreal SDK, refer to the following links:

Test out Vivox functionality by using any of the following sample projects.

---

## HISTORY

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/history

**Contents:**
- HISTORY#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Output format parameters (--format option)#
  - Examples#

Displays the history of a file or directory.

cm history | hist <item_path>[ ...] [--long | --format=<str_format>] [--symlink] [--xml[=<output_file>]] [--encoding=<name>] [--moveddeleted]

This command shows a list of revisions for a given item, and label, branch, and comment info for each revision.

This command accepts a format string to show the output. The output parameters of this command are the following:

cm history file1.txt "file 2.txt"

cm hist c:\workspace --long

(Displays all information.)

cm history link --symlink

(Applies the history operation to the symlink file and not to the target.)

cm history serverpath:/src/foo/bar.c#br:/main/task001@myserver

(Retrieves the revision history from a server path in a given branch.)

cm history bar.c, foo.c --long --limit=2

(Retrieves the 2 last revisions for the bar.c and foo.c items.)

**Examples:**

Example 1 (unknown):
```unknown
cm history | hist <item_path>[ ...] [--long | --format=<str_format>] [--symlink] [--xml[=<output_file>]] [--encoding=<name>] [--moveddeleted]
```

Example 2 (unknown):
```unknown
cm history file1.txt "file 2.txt"
```

Example 3 (unknown):
```unknown
cm hist c:\workspace --long
```

Example 4 (unknown):
```unknown
cm history link --symlink
```

---

## CLI help

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/cli/help

**Contents:**
- CLI help#

There are several ways that you can use the command line to get more information about different commands.

To find out what other commands are available, run cm showcommands. To view the built-in documentation of the options for a specific command, run cm <command> –usage. For comprehensive help with examples for a specific command, run cm <command> –help

If the CLI isn’t behaving as you expect, you can contact the UVCS support team. To help the team to diagnose your issue, you can use the cm support command to create a .zip file with diagnostic information:

**Examples:**

Example 1 (unknown):
```unknown
cm showcommands
```

Example 2 (unknown):
```unknown
cm <command> –usage
```

Example 3 (unknown):
```unknown
cm <command> –help
```

Example 4 (unknown):
```unknown
>cm support bundle c:\supportbundle.zip
Creating a new support bundle...
Adding clientinfo.txt...
Adding clientprocessinfo.txt...
Adding client.conf...
Adding filetypes.conf...
Adding guiclient.conf...
Adding mergetool.conf...
Adding plastic.uisettings.conf...
Adding plasticgui.conf...
Adding syncviews.conf...
Adding logs\plastic.debug.log.txt...
Adding logs\plastic.relevant.log.txt...
Support bundle created at c:\supportbundle.zip
CommandResult 0
```

---

## Data Explorer V2 example reports

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/data-explorer-v2-examples

**Contents:**
- Data Explorer V2 example reports#
- Analyze new users by country#
- Analyze vegetables harvested in the last 30 days#
  - Steps#
- Analyze harvested vegetables since install, rather than by calendar date#
  - Steps#

For a complete list of all the available measures and metrics available in Data Explorer V2, please see the measures and metrics page.

The goal of the report in this example is to understand the distribution of new users across different countries to identify regions with high growth potential and optimize user acquisition strategies accordingly.

This report uses the following configuration:

To hide items from your chart visualization, select the item in the legend.

The goal of the report in this example is to analyze the distribution of harvested vegetables in a farming game over the last 30 days in order to understand recent player preferences and optimize in-game features accordingly.

This report uses the following configuration:

The goal of the report in this example is to analyze the distribution of harvested vegetables in a farming game by the number of days since the player started, in order to understand player behaviors and optimize in-game features accordingly.

**Examples:**

Example 1 (unknown):
```unknown
vegetableHarvested
```

Example 2 (unknown):
```unknown
vegetableName
```

Example 3 (unknown):
```unknown
vegetablePlanted
```

Example 4 (unknown):
```unknown
vegetableName
```

---

## Check out a file

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/check-out-file

**Contents:**
- Check out a file#
- Check out a file in the GUI#
- Check out a file in the CLI#
- Additional resources#

To check out a file on the Workspace Explorer tab, right-click the file and select one of the following types of checkout:

Read more about checkouts and why you might want to use them.

The cm ci command checks in any checked out files in your workspace. To check in all changes, add the --all modifier.

Note: UVCS considers any files that you move with the cm mv command checked out.

**Examples:**

Example 1 (unknown):
```unknown
>cm co q3radiant\Bmp.cpp
The selected items are about to be checked out. Please wait ...
Item q3radiant\Bmp.cpp was correctly checked out
```

Example 2 (unknown):
```unknown
>cm co q3radiant\Bmp.cpp
The selected items are about to be checked out. Please wait ...
Item q3radiant\Bmp.cpp was correctly checked out
```

Example 3 (unknown):
```unknown
>cm ci -c "changed bmp and moved aselib"
The selected items are about to be checked in. Please wait ...
Assembling checkin data
Validating checkin data
Uploading file data
Uploaded 0 bytes of 9.26 KB (0%)
Confirming checkin operation
Modified c:\Users\pablo\wkspaces\quake_path\q3radiant\Bmp.cpp
Created changeset cs:577@br:/main/fix-1342@quake@localhost:6060 (mount:'/')
```

Example 4 (unknown):
```unknown
>cm ci -c "changed bmp and moved aselib"
The selected items are about to be checked in. Please wait ...
Assembling checkin data
Validating checkin data
Uploading file data
Uploaded 0 bytes of 9.26 KB (0%)
Confirming checkin operation
Modified c:\Users\pablo\wkspaces\quake_path\q3radiant\Bmp.cpp
Created changeset cs:577@br:/main/fix-1342@quake@localhost:6060 (mount:'/')
```

---

## Support

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/support

**Contents:**
- Support#

You can contact the Unity Matchmaker Support team using one of the following methods:

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal data collected about app users/game players#
- Relationship under privacy laws#
- Legal basis for processing#
- Consent#
- Data subject requests#
- Dependencies#
- Data retention#
- Child privacy#
- Privacy policy requirements#

Cloud Content Delivery is an end-to-end service for live game updates that combines powerful asset management, cloud storage, and a reliable content delivery network (CDN). Cloud Content Delivery supports content management with buckets, releases, and badging for asset bundles.

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected (always collected in order for the product to work):

Optional Personal Data Collected (personal data which may be collected at choice/action of the end user/Developer):

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As Unity is the Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

This product does not have a consent service. If the Developer determines they need to obtain consent, or provide an opt-out, they must implement it client-side in a way determined by the developer.

N/A - Data is not retained in an identifiable format in our system.

This product has no dependencies on other Unity products impacting player data and privacy. External dependencies include Akamai as the CDN for CCD.

It is often used with Addressables, though this is not a dependency. Please see the documentation for Addressables if utilizing this package in conjunction with CCD.

Data is not retained in an identifiable format in our system.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

Unity DPA applies to the transfer of data for this product.

---

## MOVE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/move

**Contents:**
- MOVE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Format#
  - Examples#

Moves or renames a file or directory.

cm move | mv <src_path> <dst_path> [--format=<str_format>] [--errorformat=<str_format>]

This command moves or renames an item in the repository. Changes are done in the local filesystem too.

If the source path is a file, the destination path can be a file or a directory. In the first case, the file is renamed; otherwise, the item is moved.

If source path is a directory, the destination path must be a directory.

The item to move or rename must exist.

cm move file.txt file.old

cm mv .\file.old .\oldFiles

(Moves 'file.old' to 'oldFiles'.)

(Renames a directory.)

**Examples:**

Example 1 (unknown):
```unknown
cm move | mv <src_path> <dst_path> [--format=<str_format>] [--errorformat=<str_format>]
```

Example 2 (unknown):
```unknown
cm move file.txt file.old
```

Example 3 (unknown):
```unknown
cm mv .\file.old .\oldFiles
```

Example 4 (unknown):
```unknown
cm move .\src .\src2
```

---

## Overview

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/overview-and-community-health

**Contents:**
- Overview#
- Available metrics#

The Moderation platform monitors various metrics related to the usage Safe Text.

The Moderation metrics dashboard is on the Overview page of Safe Text, under Vivox on the Unity Dashboard.

On the Overview dashboard page, users can inspect metrics related to Moderation.

The following metrics are available on the Moderation tab:

You can also view high risks incidents that haven't been actioned by moderators in the Action center on this page.

You can filter these metrics by the last 7, 15, or 30 days.

---

## Cloud Code

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual

**Contents:**
- Cloud Code#
- Solutions with Cloud Code#
- Cloud Code samples#
- Use Cloud Code with modules and scripts#
- Cloud Code interfaces#
- Take the next step#

Cloud Code is a serverless compute service that allows you to write and run code in the cloud. You can use Unity's Cloud Code to write stateless server-side code on a fully managed infrastructure. Cloud Code is a fully managed service that automatically scales to meet your traffic demands. You can focus on the development of your game logic and isolate it from the client to prevent cheating.

Cloud Code is fully compatible to integrate with other Unity services, such as Remote Config, Cloud Save, Economy and Leaderboards.

Use Cloud Code with other Unity services to create a complete game backend, and to deploy solutions such as in-game economy, storage for player data, and dynamic settings configuration, while you keep your game logic secure.

Cloud Code C# modules cannot use classes from the UnityEngine namespace or anything else in the Unity's scripting API. This is because Cloud Code uses the open-source .NET runtime. This is separate from the Unity runtime and does not rely on any of its scripting backends.

The following tutorials show how you can use Cloud Code triggers in combination with other UGS products for specific outcomes.

Note: For more advanced sample projects, you can refer to the UGS use cases sample project.

To call Cloud Code from games, you can use integrated Unity SDKs or use the Cloud Code Client API if you need to work outside of Unity Editor.

Cloud Code supports two types of code: Cloud Code C# modules and Cloud Code JavaScript scripts.

We recommend C# modules to get the most out of Cloud Code, as our Best practices documentation highlights several key benefits.

To choose which method fits your needs, review the following outline .

Cloud Code C# modules cannot use classes from the UnityEngine namespace or anything else in the Unity's scripting API. This is because Cloud Code uses the open-source .NET runtime. This is separate from the Unity runtime and does not rely on any of its scripting backends.

There are multiple ways to integrate and manage your application with Cloud Code:

To understand how to deploy and run your code, follow one of the options in the Take the next step section.

Cloud Code C# modules

Write server-side code with a type-safe programming language and powerful .NET components. Consume other content you need in the project bundling dynamic link libraries (DLLs) with tools like NuGet.

Get started with Cloud Code C# modules.

Cloud Code JavaScript scripts

Write server-side code with a easy to iterate language. Take the advantage of using the same ecosystem if you come from a JavaScript frontend background. Bundle your code with reusable pieces through CommonJS and ECMAScript module systems supported out-of-the-box with the Cloud Code command line.

Get started with Cloud Code JavaScript scripts.

**Examples:**

Example 1 (unknown):
```unknown
UnityEngine
```

Example 2 (unknown):
```unknown
UnityEngine
```

---

## Cloud Save

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual

**Contents:**
- Cloud Save#
- Concepts#
- Get started#
  - Pricing#
- Additional resources#

Use Cloud Save to store Player Data and Game Data for your games.

Because it's cloud based, players can access their data anywhere and across devices, which can mitigate data loss when a player changes devices or re-installs a game. Cloud Save enables players to interact with the game world and with each other, even if players aren't online at the same time.

You can use Game Data with Cloud Code to add features like guilds or clans, community goals or battle passes, or to store the state of items and NPCs in multiplayer games.

You can create Indexes to query data, Access Classes to control what data players can read and write and use Triggers to run code in response to changes to data (for example, to send push messages to connected clients).

The Get started guide explains how to add Cloud Save to your Unity project.

The Unity SDK tutorial has examples of how to use Cloud Save with Unity.

You get an allowance of free data with Cloud Save and if you exceed that limit, you pay for any extra usage as you go. For more information and up to date pricing, refer to UGS pricing.

Download the Unity Gaming Services Samples project to learn how to solve common game development challenges with Cloud Save:

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/use-public-repository

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/ApplePrivacySurvey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

The privacy manifest for Economy is available from version 3.4.0.

The following code sample displays the contents of the PrivacyInfo.xcprivacy manifest file for Economy. This file is also available in the SDK.

To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
PrivacyInfo.xcprivacy
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 3 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
	<array>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeCoarseLocation</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeUserID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeDeviceID</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAnalytics</string>
			</array>
		</dict>
		<dict>
			<key>NSPrivacyCollectedDataType</key>
			<string>NSPrivacyCollectedDataTypeOtherDataTypes</string>
			<key>NSPrivacyCollectedDataTypeLinked</key>
			<true/>
			<key>NSPrivacyCollectedDataTypeTracking</key>
			<false/>
			<key>NSPrivacyCollectedDataTypePurposes</key>
			<array>
				<string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
			</array>
		</dict>
	</array>
	<key>NSPrivacyAccessedAPITypes</key>
	<array/>
</dict>
</plist>
```

---

## Use cases

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/modules/use-cases

**Contents:**
- Use cases#

Explore different ways that you can use Cloud Code in combination with other services.

---

## Create a custom audience

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/custom-audiences

**Contents:**
- Create a custom audience#

You can create an audience from the Audiences view and from Game Overrides.

---

## SHELVESET CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/shelveset-create

**Contents:**
- SHELVESET CREATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Requirements to shelve an item#
  - Examples#

Shelves pending changes.

cm shelveset create | mk [<item_path>[ ...]] [--all] [--dependencies] [-c=<str_comment> | -commentsfile=<comments_file>] [--summaryformat]

The 'shelveset create' command stores the contents of checked out items inside the

repository. This way the contents are protected without the need to checkin the files.

If neither <item_path> nor any option is specified, the shelveset will include all the pending changes in the workspace.

The 'shelveset create' operation is always applied recursively from the given path.

Set the PLASTICEDITOR environment variable to specify an editor for entering comments. If the PLASTICEDITOR environment variable is set, and the comment is empty, the editor will be automatically launched to allow you to specify the comment.

cm shelveset create -c="my comment"

(Shelves all the pending changes in the current workspace including a comment.)

cm shelveset file1.txt "file 2.txt" -commentsfile=commentshelve.txt

(Shelves the selected pending changes and applies the comment in the 'commentshelve.txt' file. Note, 'create' is the default subcommand.)

cm status --short --changelist=pending_to_review | cm shelveset -

(Shelves client changelist. The command above lists the paths in the changelist named 'pending_to_review' and the path list is redirected to the input of the 'shelveset' command.)

**Examples:**

Example 1 (unknown):
```unknown
cm shelveset create | mk [<item_path>[ ...]] [--all] [--dependencies] [-c=<str_comment> | -commentsfile=<comments_file>] [--summaryformat]
```

Example 2 (unknown):
```unknown
cm shelveset create -c="my comment"
```

Example 3 (unknown):
```unknown
cm shelveset file1.txt "file 2.txt" -commentsfile=commentshelve.txt
```

Example 4 (unknown):
```unknown
cm status --short --changelist=pending_to_review | cm shelveset -
```

---

## Save a specific revision

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/save-revision

**Contents:**
- Save a specific revision#

You might want to save a specific revision of a file to your computer, for example, in these cases:

---

## Logging

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/logging

**Contents:**
- Logging#
- Supported services#

Logging is a feature of products within Unity Gaming Services (UGS). You can instrument your cloud environment with structured logs to detect and debug live issues. Additionally, some services automatically output logs that provide information on the state of the services used in your project.

Logs are available in the Unity Dashboard and through REST API. You can filter logs by time range, and by content using a query language.

The log schema is fully OpenTelemetry compliant.

Logging has these key features and concepts:

Note: This product is not designed to collect Personal Identifiable Information and must not be used for that purpose.

Logs are available from Cloud Code scripts, Cloud Code modules, and Triggers.

Note: Cloud Code logs are separate from Multiplay Hosting Logs.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/apple-privacy-survey

---

## UNDOCHANGE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/undochange

**Contents:**
- UNDOCHANGE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Reading input from stdin#
  - Examples#

Undoes the changes on a path.

cm undochange | unc <item_path>[ ...] [-R | -r | --recursive]

If an item is checked out or modified but not checked in and you do not want to check it in, you can undo the changes using this command. The item will be updated to the contents it had before.

The 'undochange' command can read paths from stdin. To do this, pass a single dash "-". Example:

Paths will be read until an empty line is entered. This allows you to use pipe to specify for which files to undo changes. Example:

dir /S /B *.c | cm undochange -

(In Windows, undoes the changes of all .c files in the workspace.)

(Undoes changes of the files on the current directory.)

(Undoes changes of the files recursively on the current directory.)

cm unc file1.txt "file 2.txt"

(Undoes changes of the selected files.)

cm unc c:\workspace\file.txt

(Undoes changes of the selected file.)

**Examples:**

Example 1 (unknown):
```unknown
cm undochange | unc <item_path>[ ...] [-R | -r | --recursive]
```

Example 2 (unknown):
```unknown
cm undochange -
```

Example 3 (unknown):
```unknown
dir /S /B *.c | cm undochange -
```

Example 4 (unknown):
```unknown
cm undochange . -R
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/dsa-notifications

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/overview

---

## Service Account Roles

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/authentication-roles

**Contents:**
- Service Account Roles#
- Project roles#
  - Multiplay Allocations Admin#
  - Multiplay API Editor#
  - Multiplay API Fleet-Admin#
  - Multiplay API Manager#
  - Multiplay API Viewer#
  - Multiplay Registry Editor#

Project roles grant a service account permission to perform actions authorized by the project role type. For example, the Multiplay Allocations Admin project role allows a service account to manage Multiplay allocations.

There are six Multiplay project roles:

The Multiplay Allocations Admin project role grants permission to list, get, create, and delete allocations.

The following table has descriptions of all permissions available to the Multiplay Allocations Admin project role.

The Multiplay API Editor project role grants permission to view and edit Multiplay resources. It doesn't grant permission to delete resources.

The following table has descriptions of all permissions available to the Multiplay API Editor project role.

The Multiplay API Fleet-Admin project role grants permission to manage fleets, providers, and projects.

The following table has descriptions of all permissions available to the Multiplay API Fleet-Admin project role.

The Multiplay API Manager project role grants permission to view and manage Multiplay resources.

The following table has descriptions of all permissions available to the Multiplay API Manager project role.

The Multiplay API Viewer project role grants permission to list resources and information about resources.

The following table has descriptions of all permissions available to the Multiplay API Viewer project role.

The Multiplay Registry Editor project role grants permission to push to the Multiplay registry.

Note: This project role doesn't have permission to view the registry catalog. Use the Multiplay API Manager to view the registry catalog.

The following table has descriptions of all permissions available to the Multiplay Registry Editor project role.

---

## Create a network allow list

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/network-allow-list

**Contents:**
- Create a network allow list#

As an administrator, you can add specific internet protocol (IP) addresses to the allow list.

To create a network allowlist:

---

## Data Explorer V2 (Beta) measures and metrics

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/data-explorer-v2

**Contents:**
- Data Explorer V2 (Beta) measures and metrics#
- Measures (y-axis)#
  - Metrics#
    - Active users#
    - Retention#
    - Revenue#
    - Sessions#
  - Events#
  - Dimension filters#
  - Aggregate filters#

For some examples on how to use Data Explorer V2, see the Data Explorer V2 example reports.

You can use Data Explorer V2 to query your game data based on the following measures in the y-axis:

You can use the following types of filters to further filter your measures:

The following tables show all of the metrics that you can use to query your game data:

You can also query your game data based on your game events. The events available consist of both standard and custom events used in your game. In addition, you can use event parameters sent with an event to filter an event measure.

To group by event measures, you can select Event parameters as a dimension.

You can apply dimension filters to the game data based on predefined metrics or events.

The following table shows the dimension filters available:

You can use aggregate filter options to further modify your game data. By default, the report aggregates the game data by the Sum of the event or metric data.

Note: You can't perform aggregation on parameter values.

Dimensions are different properties, based on either time or user properties, that you can use to group your data.

You can use the following dimensions on the x-axis of your chart:

**Examples:**

Example 1 (unknown):
```unknown
transaction
```

Example 2 (unknown):
```unknown
adImpression
```

Example 3 (unknown):
```unknown
transaction
```

Example 4 (unknown):
```unknown
adImpression
```

---

## Logical game sessions

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/logical-game-sessions

**Contents:**
- Logical game sessions#

Relay servers have no formal idea of player groups, often called game sessions. Instead, Relay uses logical game sessions.

All players within a logical game session are bound to the same Relay server but have no direct connection to each other. Relay doesn’t make any assumptions about the length of a player’s bindings and connections to the game session. It’s up to the game client to decide whether players unbind from the Relay server at the end of a session or use the same binding for multiple sessions.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/

---

## Security scenarios

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/security-scenarios

**Contents:**
- Security scenarios#
- Change the owner of your repository server#
- Deny permission to delete a repository#
- Only allow read and view access to a repository#
- Deny permission to modify specific items#
- Deny permission to modify specific items on certain branches#
- Deny permission to modify specific branches#
- Provide only read and view permissions for a branch#
- Only allow users to modify items under a specific path#
  - Grant every group read access to the root of the path#

There are many ways to configure the security permissions for your UVCS repositories. The following instructions explain how to configure permissions for specific scenarios through the Unity DevOps Version Control desktop application.

For information on how to create user groups and set permissions through the Unity Dashboard, refer to Manage users.

For security, you need to remove the ALL USERS group so that not every user has all permissions granted. To remove the group, you first need to set an owner or administrator to replace it.

This leaves the administrator as the only authenticated user in the system.

Prevent a group or user from being able to delete a repository. For example, you can ensure that any user in the Consultants group can’t delete repositories.

Give a development group read access to a repository that they are not directly assigned to.

Prevent a group from being able to change anything within a specific folder in a repository. For example, you can restrict access to the system source code for non-developers such as testers.

Prevent a group from being able to change any item in a specific folder on specific branches. For example, you might want to prevent non-developer access to any script directory on your main, development and release branches.

Prevent any user in a specific group from being able to modify any item on a specific branch. For example, your project manager might want to restrict changes in the development branch to specific approved groups.

Allow a group to read a branch, but not modify it in any way. For example, you might want to allow developers read access on a release branch but prevent any breaking changes.

Ensure a user can’t modify items except those under a specific path. For example, you might not want a new team member to be able to modify anything except a specific approved path.

Grant a group access to a specific subdirectory, but not the entire directory tree. For example, you might want to allow a tester group to be able to read only a specific subdirectory and keep the rest of the directory private.

Restrict read access to certain paths so some parts of your repository aren’t visible to certain users. For example, you might want to make sure the user can’t update your script folder in the dev and release branches.

Restrict read access to a path so that a user can’t see changes in that path. For example, you can ensure that when a user runs a diff, they can’t see changes in a secure path.

If a user doesn’t have read access to a path, and someone makes changes to a branch that they can’t see, the user can’t merge that branch.

Users can’t view the content of any revisions under a path that they don’t have read permission for.

Ensure that a group can’t add new lock rules to a specific repository. For example, you can make sure that a tester group can’t change lock rules to prevent errors in a repository.

Note: The configlocks permission controls access to the Lock and Checkout feature in UVCS and Gluon. You need server version 8.0.16.3361 or higher.

You have multiple repositories in your organization and allow a different group permissions to view and use each one. For example, you might have a core group, an art group, and a doc group, that you only want to be able to access the corresponding repositories: Core, Art and Doc.

In the web portal, you need to add the groups that you want to use. For example, Core_group, Art_group, and Doc_group. You can then add users to their corresponding groups.

For example, you can set the following permissions:

These permissions ensure that the Core_group users can access and use the Core repository, can’t view the Art or Doc repositories. The same applies to the Art_group and Doc_group accordingly.

**Examples:**

Example 1 (unknown):
```unknown
cm setowner -user=<Username> repserver:<example_uvcs_server@cloud>
```

Example 2 (unknown):
```unknown
cm setowner -user=<Username> repserver:<example_uvcs_server@cloud>
```

Example 3 (unknown):
```unknown
cm acl -group=Developers -allowed=-all -denied=-all repserver:<example_uvcs_server@cloud>
```

Example 4 (unknown):
```unknown
cm acl -group=Developers -allowed=-all -denied=-all repserver:<example_uvcs_server@cloud>
```

---

## PATCH

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/patch

**Contents:**
- PATCH#
- Description#
  - Usage#
  - Options#
- Help#
  - Limitations#
  - Important#
  - Examples#

Generates a patch file from a spec or applies a generated patch to the current workspace.

cm patch <source_spec> [<source_spec>] [--output=<output_file>] [--tool=<path_to_diff>]

(Generates a patch file that contains the differences of a branch, a changeset, or the differences between changesets. It also tracks differences of text and binary files.)

cm patch --apply <patch_file> [--tool=<path_to_patch>]

(Allows to apply the contents of a generated patch file in the current workspace.)

If the output patch file already exists, the command will not overwrite it.

When applying a patch, the command will not apply changes to modified files if they are not present on disk.

This command requires Diff and Patch tools, publicly available at http://gnuwin32.sourceforge.net/packages/patch.htm and

http://gnuwin32.sourceforge.net/packages/diffutils.htm

Once installed, it's recommended to add their location to the PATH environment variable.

cm patch cs:4@default@localhost:8084

(Prints on console the differences of cset 4 in unified format.)

cm patch br:/main --output=file.patch

(Generates a patch file with the differences of branch "main".)

cm patch br:/main --output=file.patch --tool=C:\gnu\diff.exe

(Same as above, using a custom exe.)

cm patch cs:2@default cs:4@default

(Prints on console the differences between csets 2 and 4 in unified format.)

cm patch --apply file.patch --tool=C:\gnu\patch.exe

(Applies the patch in 'file.patch' to the local workspace with a custom exe.)

**Examples:**

Example 1 (unknown):
```unknown
cm patch <source_spec> [<source_spec>] [--output=<output_file>] [--tool=<path_to_diff>]
```

Example 2 (unknown):
```unknown
cm patch --apply <patch_file> [--tool=<path_to_patch>]
```

Example 3 (unknown):
```unknown
cm patch cs:4@default@localhost:8084
```

Example 4 (unknown):
```unknown
cm patch br:/main --output=file.patch
```

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/privacy-overview

**Contents:**
- Privacy overview#
- Personal Data Collected about App Users / Game Players#
- Relationship under Privacy Laws#
- Legal Basis for Processing#
- Consent#
- Data Subject Requests#
- Dependencies#
- Data Retention#
- Child Privacy#
- Privacy Policy Requirements#

Unity Voice Chat and Text (also known as Vivox).

This documentation is intended to assist products to display their privacy compliance to Developers. It is not intended to be used as legal guidance or as a replacement to reading Unity’s Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy implications of your product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

Default Personal Data Collected (always collected in order for product to work)

Optional Data Collected (data which may be collected at the action of the end user)

While this product allows for the collection of developer defined data, we require that you not collect personal data through this mechanism. Our systems will not understand that it is personal data and so such would not be treated as such in retention processes or data subject requests.

Under GDPR, Unity is the Processor. You, the developer, are the Controller.

Under CCPA (as modified by CPRA), Unity is the Service Provider. You, the developer, are the Business.

As we are a Processor, we do not determine your legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

Privacy and wiretapping laws may require consent depending on the region in which your end-users.

To provide the user a method to opt-in, it must be implemented client-side in a way determined by the developer.

To provide the user a method to opt-out, it must be implemented client-side in a way determined by the developer.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Vivox support team with the Player ID of the end user that requested access.

This service has no native functionality to support data deletion requests. You, the developer, are responsible for actioning them. You can action them by reaching out to the Vivox support team with the Player ID of the end user that requested data deletion.

This product has no dependencies on other Unity products.

By default, the below personal data is retained for up to 30 days:

The following is ephemeral:

By default, the following is available for 7 days and can be configured to be available for up to 30 days at the Developer’s choice:

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity’s privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

The Unity DPA applies to the transfer of data for this product.

---

## Mantis integration

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/issue-tracking/mantis

**Contents:**
- Mantis integration#
- Configure the Mantis integration#
  - Configure the Mantis server#
  - Configure the client#
    - Configure the client on Windows#
    - Configure the client on Linux and macOS#
  - Mantis parameters#
- Use the Mantis integration#
  - Task on branch workflow#
    - Link a branch to an issue#

Learn how to configure and use the Mantis extension. The Mantis extension is compatible with Mantis versions 1.11.4, 1.1.0, 1.1.8 and higher.

Configure the Mantis integration to work with Unity Version Control (UVCS) for the Mantis server and the UVCS client.

To set up the Mantis extension functionality, copy the script file plastic.php (included on plasticscm_install_path/client/extensions/mantis) to the Mantis installation folder.

There are different methods to configure the client depending on your operating system:

Regardless of your operating system, you need to configure the Mantis parameters.

Set a local Mantis configuration on a Linux or macOS machine:

Note: You can also set a global extension configuration on the server.

Use the following parameters to further configure your Mantis integration:

Use one of the following working modes for your Mantis integration:

Find issue information in the Mantis Extension panel. You can open the issue in the browser, add a new issue, or delete an issue. If you select the Open issue in browser icon, or double-click on the Mantis task, UVCS opens the associated issue in a browser window.

Task on branch is the default working mode. Each Mantis task links to a branch in Unity Version Control (UVCS).

The branch name connects the branch to a Mantis issue:

The task on changeset working mode allows you to link multiple changesets to multiple branches.

Use the UVCS desktop application to link changsets to Mantis issues:

**Examples:**

Example 1 (unknown):
```unknown
plastic.php
```

Example 2 (unknown):
```unknown
plasticscm_install_path/client/extensions/mantis
```

Example 3 (unknown):
```unknown
issuetrackers/<server_port>/<repository>
```

Example 4 (unknown):
```unknown
mantis.conf
```

---

## CODEREVIEW

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/codereview

**Contents:**
- CODEREVIEW#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Output format parameters (--format option)#
    - The output parameters of this command are the following#
  - Examples#

Creates, edits, or deletes code reviews.

cm codereview <spec> <title> [--status=<status_name>] [--assignee=<user_name>] [--format=<str_format>] [--repository=<rep_spec>]

(Creates a code review.)

cm codereview -e <id> [--status=<status_name>] [--assignee=<user_name>] [--repository=<rep_spec>]

(Edits a code review.)

cm codereview -d <id> [ ...] [--repository=<rep_spec>]

(Deletes one or more code reviews.)

This command allows users to manage code reviews: create, edit, and delete code reviews for changesets or branches.

To create a new code review, a changeset/branch spec and a title are required. The initial status and assignee can be set, too. An ID (or GUID if requested) will be returned as a result.

To edit or delete an existing code review, the target code review ID (or GUID) is required. No messages are displayed if there are no errors.

The 'status parameter' must only be one of the following: "Under review" (default), "Reviewed", or "Rework required".

The 'repository' parameter is available to set the default working repository. This is useful when the user wants to manage reviews on a server different than the one associated to the current workspace, or when there is no current workspace at all.

This command accepts a format string to show the output.

Please note that the '--format' parameter only takes effect when creating a new code review.

cm codereview cs:1856@myrepo@myserver:8084 "My code review" --assignee=dummy

cm codereview br:/main/task001@myrepo@myserver:8084 "My code review" --status="Rework required" --assignee=newbie --format="{id} -> {guid}"

cm codereview 1367 -e --assignee=new_assignee

cm codereview -e 27658884-5dcc-49b7-b0ef-a5760ae740a3 --status=Reviewed

cm codereview -d 1367 --repository=myremoterepo@myremoteserver:18084

cm codereview 27658884-5dcc-49b7-b0ef-a5760ae740a3 -d

**Examples:**

Example 1 (unknown):
```unknown
cm codereview <spec> <title> [--status=<status_name>] [--assignee=<user_name>] [--format=<str_format>] [--repository=<rep_spec>]
```

Example 2 (unknown):
```unknown
cm codereview -e <id> [--status=<status_name>] [--assignee=<user_name>] [--repository=<rep_spec>]
```

Example 3 (unknown):
```unknown
cm codereview -d <id> [ ...] [--repository=<rep_spec>]
```

Example 4 (unknown):
```unknown
cm codereview cs:1856@myrepo@myserver:8084 "My code review" --assignee=dummy
```

---

## Cloud Save Game Data

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/concepts/game-data

**Contents:**
- Cloud Save Game Data#
- Access Classes#
- Limits#
- Additional resources#

Cloud Save Game Data is key/value storage for objects that are Custom Items associated with a game (this differs from Player Data, which is objects associated with a player).

You can use Custom Items for data that is player readable (but only server writeable), or for data that is only accessible from a server authoritative context (for example, Cloud Code).

You can use Custom Items with Cloud Code to add features like guilds/clans, community goals, and battle passes, or to store the state of items or NPCs in multiplayer games.

You can use the Unity Dashboard to view and edit Game Data.

Cloud Save supports 2 different Access Classes for Custom Items.

For a list of methods to write Game Data from Cloud Code, refer to the Cloud Save SDK for Cloud Code documentation.

Note: These limits are per Custom Item, there are no limits on the number of Custom Items.

For example, you can have 2000 keys of 2.5 KiB each on each Custom Item, or 1 key on a Custom Item that is 5 MiB.

---

## Apple's privacy survey

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/privacy/apple-privacy-survey

**Contents:**
- Apple's privacy survey#

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs such as this service. For your convenience, we have provided information on this service’s data collection practices below.

Important: The data disclosures below are for this service only. You are also responsible for providing any additional disclosures for your app, including other third-party SDKs used in your app.

For more information on Apple's data collection disclosure policies, including terminology definitions, see the Apple documentation.

For example, first or last name.

Including, but not limited to a hashed email address.

Including, but not limited to a hashed phone number.

Such as home address, physical address, or mailing address.

Other User Contact Info

Any other information that can be used to contact the user outside the app.

Health and medical data, including but not limited to from the Clinical Health Records API, HealthKit API, MovementDisorderAPIs, or health-related human subject research or any other user-provided health or medical data.

Fitness and exercise data, including but not limited to the Motion and Fitness API.

Such as form of payment, payment card number, or bank account number.

Such as a credit score.

Such as salary, income, assets, debts, or any other financial information.

Information that describes the location of a user or device with the same or greater resolution as a latitude and longitude with three or more decimal places.

Information that describes the location of a user or device with lower resolution than a latitude and longitude with three or more decimal places, such as approximate location services.

Such as racial or ethnic data, sexual orientation, pregnancy or childbirth information, disability, religious or philosophical beliefs, trade union membership, political opinion, genetic information, or biometric data.

Such as a list of contacts in the user’s phone, address book, or social graph.

Emails or Text Messages

Including subject line, sender, recipients, and contents of the email or message.

The user's photos or videos.

The user's voice or sound recordings.

Data generated by the user during a customer support request.

Any other user-generated content.

Information about the content the user has viewed that is not part of the app, such as websites.

Information about searches performed in the app.

Such as screen name, handle, account ID, assigned user ID, customer number, or other user- or account-level ID that can be used to identify a particular user or account.

Such as the device's advertising identifier, or other device-level ID.

An account’s or individual’s purchases or purchase tendencies.

Such as app launches, taps, clicks, scrolling information, music listening data, video views, saved place in a game, video, or song, or other information about how the user interacts with the app.

Such as information about the advertisements the user has seen.

Any other data about user activity in the app.

Such as launch time, hang rate, or energy use.

Other Diagnostic Data

Any other data collected for the purposes of measuring technical diagnostics related to the app.

*Vivox transmits analytics data containing Vivox API calls and their outcomes. Vivox SDKs determine if analytics are collected and transmitted based on a cohort determination algorithm that is driven by a hash of the identifierForVendor iOS API call.

Any other data types not mentioned.

- In-App voice and text communication

---

## Chat filter settings

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/settings/text-filtering/text-filtering

**Contents:**
- Chat filter settings#
- Severity settings#
  - Severity levels#
- Offense types#
  - Violence#
  - Sexual content#
  - Verbal abuse#
  - Identity hate#
  - Profanity#
  - Link sharing#

You can control the types of content filtered by the Chat Filter and choose the severity level to apply. Refer to Severity settings and Offense types for details on configuration options. To change these settings, contact your Vivox representative.

You can set the severity level of each offense independently. You can more aggressively restrict certain types of content while allowing different levels for others, for example, not allowing any forms of link sharing but allowing mild profanity.

These settings allow you to configure your environment for spaces that have minors or places that only have adults.

Filters out messages that contain language that implies an intention to inflict violence, pain, or wish harm upon a group or individual. There are three levels of severity for violence:

Filters out messages containing sexual language or that is violent in nature. This includes references to body parts, sexual acts, nudity, and other sexual language. There are three levels of severity for sexual content:

Filters out messages that are insulting, derogatory, or use inflammatory language targeted towards other users to make them feel unwelcome or unsafe in a space. There are three levels of severity for verbal abuse:

Filters out messages that use derogatory terms or extreme language towards an identity group, such as a group based on religion or ethnicity. There are two levels of severity for identity hate:

Filters out messages that contain vulgar or obscene language and common swear words. There are two levels of severity for verbal abuse:

Filters out messages that contain URLs to external websites.

You can create allowlists and blocklists to allow for specific website URLs.

Filters out messages containing references to illicit substances, alcohol, or tobacco.

This filter doesn’t have multiple levels. Set it to on or off.

Filters out messages that could be considered off-topic, irrelevant, or intentionally distracting, as well as messages sent in quick, rapid succession.

This filter doesn’t have multiple levels. Set it to on or off.

Filters out messages that advise or encourage others to engage in acts of self-harm or commit suicide.

This filter doesn’t have multiple levels. Set it to on or off.

Filters out messages that contain personal information that could be used to identify the player. The following types of information are filtered out: credit card numbers, bank numbers, phone numbers, physical addresses, and email addresses.

This filter doesn’t have multiple levels. Set it to on or off.

---

## 

**URL:** https://docs.unity.com/authentication/en/manual/use-anon-signin

---

## Use a nodata replica

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/nodata-replica

**Contents:**
- Use a nodata replica#
- Create a nodata replica#
- Hydrate a replica for offline use#
- Hydrate the latest changeset#

Use dehydrated nodata replicas to create low-storage, functional clones of large repositories so you don’t need to create a full local clone. Because nodata replicas only contain metadata, they are small and fast to create, even for multi-terabyte repositories.

When an operation requires file content, such as to update your workspace, UVCS retrieves the necessary data on-demand from the source repository. Unity Version Control (UVCS) uses this data for the operation, but doesn’t store it in your local replica.

When you check in new files to a nodata replica, the new data is stored locally within your replica. You can then push these changes back to the main server as with a standard replica.

For more information on partial clones and version control workflows, refer to Workflows and partial replicas.

To create a nodata replica, you can use either the UVCS desktop application or the command-line interface (CLI): To create a nodata replica in the UVCS desktop application, do the following: 1. In the Branches view, right-click a branch. 1. Select Push/Pull > Pull this branch. 1. Select the source repository. 1. Select the Do not replicate data option.

To create a nodata replica in the CLI, use the --nodata flag with the replicate command: cm pull <source_spec> <destination_spec> --nodata

The primary limitation of a nodata replica is that it requires a network connection to the source repository to retrieve file data. To work offline, you need to intentionally download the file data you need from the source repository. This process is known as hydrating the replica.

You can use the CLI pull command to hydrate a replica:

To download the data for an entire branch: cm pull hydrate <branch_name>@<repo_spec> To download the data for a specific changeset: cm pull hydrate --cset=<changeset_id>@<repo_spec>

A common and efficient workflow is to download only the data required for your current work, instead of the entire branch history. The process is as follows:

This workflow ensures that your workspace is fully functional for offline work. You have all the necessary data for your current task without the need to download the historical data for the entire repository.

**Examples:**

Example 1 (unknown):
```unknown
cm pull <source_spec> <destination_spec> --nodata
```

Example 2 (unknown):
```unknown
cm pull hydrate <branch_name>@<repo_spec>
```

Example 3 (unknown):
```unknown
cm pull hydrate --cset=<changeset_id>@<repo_spec>
```

---

## Free trial

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/pricing/free-plan

**Contents:**
- Free trial#
- Additional resources#

When you sign up for Unity DevOps, you get the following tier of free services:

5 GB in a 31-day billing cycle equates to a total of 3720 GB-Hours.

Note: These amounts can change over time, so please refer back to the official pricing page for the most up-to-date prices.

When you reach your free trial allowance for any of these services, DevOps locks you out of your DevOps project. To continue to use DevOps services, you need to upgrade your plan. If you don't upgrade, you can still access the project in read mode and the Cloud storage data for your project deletes after 30 days.

DevOps sends warning emails to the organization owner when you reach 50%, 75%, and 90% of your usage allowance for any of the DevOps services.

---

## Get started

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/getting-started

**Contents:**
- Get started#
- Video Walkthrough#
- Typical workflow#
- Prerequisites#
  - Authenticate using a Service Account#
  - Configure the UGS CLI#
  - Set up Leaderboards#
  - Optional: Add scores to the leaderboard#
- Set up Cloud Code#
  - Cloud Code C# module#

This section describes all the steps you need to get started with Triggers.

The sample below demonstrates how to use Triggers to reward players the top five players from Leaderboards with an seasonal trophy in Cloud Save using a one-time schedule event emitted by the Scheduler.

Watch the video below to see a walkthrough of the steps to create a trigger in the Unity Dashboard.

To get started with Triggers, follow these steps:

Note: You can also use the Triggers with events emitted by other services. Refer to the Events section for more information.

The steps assume you have already created a Unity Gaming Services project in the Unity Dashboard.

You must first create a service account with required access roles and configure the UGS CLI.

Before you can call the Scheduling and Triggers services, you must authenticate using a Service Account.

Add Product roles and create a key:

For more information, refer to Authentication.

Follow the steps below to get stated with the UGS CLI:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Authenticate using the Service account you created earlier. Refer to Get Authenticated.

To follow this sample, you should create a leaderboard.

You can use the UGS CLI to deploy the following leaderboard.lb file. It defines a leaderboard with ascending sort order and keeps the best score.

Run the new-file command to create a leaderboard configuration locally:

The file name corresponds to the leaderboard ID. Update the leaderboard.lb file with the following configuration:

Deploy the file using the UGS CLI tool:

Now that you have created a leaderboard, you can add scores to it.

You can run the following Cloud Code script to add scores to the leaderboard from the Unity Dashboard. Make sure to regenerate the Player ID token on every test run to generate a score for a new player.

To use Triggers, you should define a Cloud Code module or a Cloud Code script. The module or script is executed when a trigger is fired. The sample below integrates Leaderboards and Cloud Save with Cloud Code to reward the top five players from the leaderboard with a seasonal trophy.

Define a SchedulerHelloWorld module with a function that takes in string arguments key and value.

The module endpoint RewardPlayers retrieves the top five players from the leaderboard and sets the Cloud Save data for each player with the specified key and value.

Refer to Deploying Hello World to learn how to deploy a module.

Note: If you are deploying the module using the UGS CLI, don't forget to add additional Service Account role of Cloud Code Editor.

You can achieve the same outcome by creating a Cloud Code script.

Create a SchedulerHelloWorld script with required string arguments key and value:

Refer to Deploying Hello World to learn how to deploy a script.

Note: If you are deploying the script using the UGS CLI, don't forget to add additional Service Account roles: Cloud Code Script Publisher and Cloud Code Editor.

After you have defined your Cloud Code script or module, you can create a schedule to determine when the top five players are rewarded with a trophy.

The sample below defines a one-time schedule that grant players a seasonal trophy.

Run the new-file command to create a schedule configuration locally:

Update the schedule-config.sched file with the following configuration:

The payload of the event carries the Cloud Code parameters that are passed to the Cloud Code script or module. Modify the schedule field to change the date and time when the event is triggered.

Deploy the configuration using the UGS CLI tool:

You should get a response similar to the following:

Now you have a schedule that triggers an event at a specific time. However, the events are not yet connected to your Cloud Code script or module.

To connect your Cloud Code resource to the schedule, create a trigger. The trigger executes the Cloud Code module or script when the event is fired, for example, when the schedule is triggered.

Run the new-file command to create a trigger configuration locally:

If you created a Cloud Code module, update the triggers-config.tr file with the following configuration:

If you created a Cloud Code script, update the triggers-config.tr file with the following configuration:

Deploy the configuration using the UGS CLI tool:

You should get a response similar to the following:

Now you have a trigger that executes your Cloud Code script or module when the event is fired.

To validate the result, you can inspect the top players before and after the event is fired.

To validate that the player data has been updated, you can check the Cloud Save data for the player:

You can also inspect the Cloud Code logs to check that the Cloud Code script or module has been executed.

The Logs page shows log entries from the SchedulerHelloWorld module or script.

**Examples:**

Example 1 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 2 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 3 (unknown):
```unknown
leaderboard.lb
```

Example 4 (unknown):
```unknown
ugs leaderboards new-file leaderboard
```

---

## Events

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/events

**Contents:**
- Events#
- Track how players interact with your game#
- Common tracking scenarios#
  - First time user experience#
- An item is bought#
- Feature adoption#
- Player lifecycle#

An event is an action that occurs in your game, such as when the game starts, or when the player does something like find a treasure or buy an item. Events contain contextual information around that action, such as the item that was obtained, how much currency the player had, and how the item was acquired. These can be customized to suit your game and send useful information to you. Events can be used to measure player engagement, spending, and conversion through the Data Explorer and funnels.

An event is a collection of parameters that provide a snapshot of the player's state at that moment. For example: missionStarted and missionCompleted events might have the parameters missionID and missionName to describe which mission the events refer to. Over time these snapshots combine to form a complete picture of the player's behaviour.

Events are split into two categories:

Once you are happy with the shapes of your events on the dashboard, you can record them from your game.

When you design something in your game, you need to have a reason for it. Track how players interact with your game to validate your intentions and answer questions such as:

For the question "Is this level as hard as I think it is?", you could track when a player finishes a dungeon with an event called dungeonCompleted and parameters like:

These events and details can then be used to create custom dashboards or in the Data Explorer to help you answer your original questions and monitor the health of your game.

In this case you want to check how many players complete the tutorial. Use a custom event that triggers once a tutorial step is completed, such as tutorialStepCompleted with a stepID parameter to indicate which step was completed.

If you want more granularity in your tutorial analysis, you can also add an event that tracks when the tutorial begins so that you can determine if the tutorial is starting properly for all players. You can also add an event when the tutorial ends when a step is started to follow the complete player journey in the tutorial.

You can understand user drop off and where to optimize better with more custom events added to track within the first-time user experience.

For every virtual or real currency transaction in the game, you should always record a transaction event. The transaction standard event is used to populate the revenue dashboard and metrics in the Data Explorer. You can validate your revenue using the transaction event and the Unity IAP plugin. The transaction event already has many useful parameters to register what the player spent money on, how much they spent and what they received. All the parameters under productsReceived and productsSpent help you get set up.

For more information, see the record transaction events tutorial.

Use both standard and custom events to measure the success of new features within the game and how users adopt them. For example, you might want to introduce guilds into the game. This is a feature which is important for long-term engagement and player interactions, especially for RPGs. You could implement the following events to track guild engagement:

Analyzing each of these events helps you determine how active users are within the guild feature and they can also be used with existing events to see their overall engagement with the game. Try comparing users who join a guild versus those who don't; it's possible that users in guilds spend more money or play more often.

Tracking the user's lifecycle throughout the game is important to determine when they stop playing the game or to identify any other issues with the game.

You could track users with events such as:

Using a variety of events is useful to see how users are engaging with the game and if there are any dropoff points that need optimizing. Analyzing level distribution shows what level users get to before they stop playing. Additionally, tracking their transactions is important as spenders are often more engaged in the game and play for longer.

**Examples:**

Example 1 (unknown):
```unknown
missionStarted
```

Example 2 (unknown):
```unknown
missionCompleted
```

Example 3 (unknown):
```unknown
missionName
```

Example 4 (unknown):
```unknown
dungeonCompleted
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/changerevisiontype

---

## Environments

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/environments

**Contents:**
- Environments#
- Restrictions#
- Working with environments#

Unity Remote Config uses environments to group Game Overrides and Settings, and deliver specific environments to the client (Unity Runtime Instance) based on the environmentId. If no environmentId is provided in the request - the default environment, which is the environment named production is returned to that instance.

Use the Unity Dashboard to manage your Remote Config environments. Upon initialization in a new project, only the default environment is available.

The Unity Dashboard lets you create, edit, and delete environments. This functionality is also available in the REST APIs.

Each environment has the following main parameters.

**Examples:**

Example 1 (unknown):
```unknown
environmentId
```

Example 2 (unknown):
```unknown
environmentId
```

Example 3 (unknown):
```unknown
development
```

Example 4 (unknown):
```unknown
Remote Config SDK Version
```

---

## Output

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/output

**Contents:**
- Output#

The trigger script uses the result code to communicate the result of its execution. UVCS interprets these result codes as one of the following:

When a trigger fails, UVCS sends the standard output of the trigger to the client as an error message:

When a server-side trigger fails because the executable is missing, the server treats it as a non-zero exit code.

However, starting on UVCS (previously Plastic SCM) version 8.0.16.3388, when a client-side trigger fails because the executable is missing, the client treats it as a zero exit code.

The error registers as a zero exit code in case you want to distribute your client-side triggers through your repository.

Note: If triggers such as before-mkworkspace, after-mkworkspace, before-setselector, after-setselector, and before-update fail with a non-zero exit code because the trigger executable isn't downloaded to your workspace, you need to remove the trigger configuration, run the operation, and configure the trigger again.

**Examples:**

Example 1 (unknown):
```unknown
before-mkworkspace
```

Example 2 (unknown):
```unknown
after-mkworkspace
```

Example 3 (unknown):
```unknown
before-setselector
```

Example 4 (unknown):
```unknown
after-setselector
```

---

## Server Query Protocol

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/concepts/sqp

**Contents:**
- Server Query Protocol#
- Requirements#
- Reference implementation#
- Data types#
- Request types#
- Packet types#
- Headers#
  - Challenge numbers#
- Challenge packets#
  - Request format#

The Server Query Protocol (SQP) allows clients to retrieve information about a running game server using UDP/IP packets.

A client initiates queries by sending a ChallengeRequest to the server. In response, the server sends a ChallengeResponse that includes a ChallengeId. After the client receives the ChallengeResponse, it can continue to query the server for information.

The following sections describe the technical specifications of SQP, including data types, request types, and packet formats.

Game server state information that SQP supports includes:

Note: SQP works with the Multiplay Hosting game server monitoring process to make sure reports by the game server match the information in Multiplay Hosting’s database.

Before implementing SQP as the game server query protocol, you must populate the ServerInfoData object with all the game server information on the game client end. This ensures the game server reports the correct information.

Refer to go-svrquery for an example implementation of SQP. go-svrquery is a Golang client or talking to game servers using various query protocols, including SQP.

All server queries consist of five basic types of data packed together into a data stream. The following table describes each of these types. All types are big-endian.

A client can make five types of requests to a server. The following table specifies the response a client should expect from the server for each request type.

The following table has the distinct types of SQP packets.

All SQP packets, whether they're a request or a response, contain a header with the following data.

SQP uses a challenge number (which is a random 32-bit integer) to ensure the client making query requests is the same client that received the challenge number.

When a client first sends a request to a server, the server randomly selects the challenge number and includes it in the packet header. The client must then include the same challenge number in the header of all following requests.

Clients can use challenge packets to retrieve a usable challenge number for a following request.

Note: Challenge packets only have a header. There is no payload.

The following code snippet has an example of a ChallengeRequest packet:

The following code snippet has an example of a ChallengeResponse packet:

Clients can send query packets to retrieve information about a server. Multiplay Hosting only requires game servers to respond to queries with ServerInfo chunks. You can use the other request types but they're not necessary for Multiplay Hosting.

There are four different types of chunks that clients can request with a query packet. However, this documentation only includes the ServerInfo chunk type since it's the only one Multiplay Hosting supports.

The byte value of each chunk type indicates the response chunk that the requesting client expects. When a server receives a query packet, it inspects the RequestedChunks field in the request and performs a bitwise AND operation using the byte value of the chunk type. The server knows a chunk type has been requested if the result of this operation is greater than zero.

For example, the server responds with a ServerInfo chunk if RequestedChunks&1 > 0. Refer to note below.

Note: Although there are four types of chunk types available in the SQP protocol, Multiplay Hosting only supports the ServerInfo chunk type.

Note: RequestedChunks can request more than one chunk at the same time, so your implementation must be able to perform the correct bitwise checks on the RequestedChunks value.

The request format is the same for all query requests.

Note: Multiplay Hosting only requires a server to respond to ServerInfo requests. Therefore, all other request types are omitted.

The following code snippet has an example of a QueryRequest packet:

All chunk types share a standard response format for the first four fields (Version, CurrentPacket, LastPacket, and PacketLength). Information after the PacketLength field of a packet varies depending on the request type.

The following table has the part of the response that's the same for all chunk types.

The following code snippet has an example of a QueryResponse packet:

**Examples:**

Example 1 (unknown):
```unknown
ChallengeRequest
```

Example 2 (unknown):
```unknown
ChallengeResponse
```

Example 3 (unknown):
```unknown
ChallengeId
```

Example 4 (unknown):
```unknown
ChallengeResponse
```

---

## Filter and censor messages with the adaptive chat filter

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/concepts/adaptive-chat-filter

**Contents:**
- Filter and censor messages with the adaptive chat filter#
- Chat filter language handling per message#
- Speech-to-text#

This AI-powered chat filter censors words in messages based on defined, configurable content types. This feature is currently server-enabled and needs to be enabled on your account before you can use it. For more information on how to enable this feature, contact your sales representative.

Once the Adaptive chat filter is added to your project you can customize how it works in your game.

The chat filter handles messages based on the user’s set language. The chat filter expects the language to be set in each request on a per-message basis. This means that if a preferred language is set, the Vivox SDK must specify which language to use on the respective channel class or interface that sends messages to ensure that the proper chat filter is used.

The following is a code example for setting the language of a direct message. The same approach can be used on channel-based messages.

Messages produced through Speech-to-text can be filtered. Words are filtered out when the speech is converted to text. To enable this feature, contact your Vivox representative.

**Examples:**

Example 1 (unknown):
```unknown
vx_req_account_send_msg *req;
vx_req_account_send_msg_create(&req);
req->connector_handle = vx_strdup("c1");
req->account_handle = vx_strdup(".issuer-w-dev.mytestaccountname.");
req->language = vx_strdup("en-us");
req->user_uri = vx_strdup("sip:theotheruser@vd1.vivox.com");
req->message_body = vx_strdup("Hey there buddy!");
vx_issue_request2(&req->base);
```

Example 2 (unknown):
```unknown
vx_req_account_send_msg *req;
vx_req_account_send_msg_create(&req);
req->connector_handle = vx_strdup("c1");
req->account_handle = vx_strdup(".issuer-w-dev.mytestaccountname.");
req->language = vx_strdup("en-us");
req->user_uri = vx_strdup("sip:theotheruser@vd1.vivox.com");
req->message_body = vx_strdup("Hey there buddy!");
vx_issue_request2(&req->base);
```

---

## Release notes

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unreal/manual/Unreal/unreal-release-notes

**Contents:**
- Release notes#
- Release notes for 5.26#
  - Release overview#
  - Key Features and Bugs Addressed#
  - Public API Changes#
  - Known Issues#
- Release notes for 5.25#
  - Release overview#
  - Key Features and Bugs Addressed#
  - Public API Changes#

Important note: The VivoxCore.uplugin VersionName field inside of the 5.26.0.unr.0 package incorrectly specifies a version of 5.25.4.unr.0. This is purely a cosmetic error and the correct package is being distrbuted.

Version 5.26.0.unr.0 introduces comprehensive audio processing improvements with enhanced noise suppression, expanded platform support for audio processing features, and significant performance optimizations.

This release focuses on improving voice quality while optimizing resource usage across all supported platforms.

For further technical details on all the changes included in this release, refer to the CHANGELOG.md file within the SDK.

Audio Processing Improvements:

Performance Optimizations:

Platform-Specific Changes:

Implementation Considerations:

This release adds a step to iOS and macOS builds to automatically copy the PrivacyInfo.xcprivacy file to Xcode projects and a fix to LoginState returning InvalidState errors on subsequent login tries.

**Examples:**

Example 1 (unknown):
```unknown
VersionName
```

Example 2 (unknown):
```unknown
5.26.0.unr.0
```

Example 3 (unknown):
```unknown
5.25.4.unr.0
```

Example 4 (unknown):
```unknown
Error LNK1104 : cannot open file 'SceSha1.lib'
```

---

## PURGE SHOW

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/purge-show

**Contents:**
- PURGE SHOW#
- Description#
  - Usage#
  - Options#
- Help#
  - Examples#

Provides a report of the purge status and contents.

cm purge show <purge_guid> [--verbose | --server=<server>]

cm purge show be5b9145-1bd9-4c43-bd90-f2ff727bbf13

(Provides a brief report of the purge status)

cm purge show be5b9145-1bd9-4c43-bd90-f2ff727bbf13 --verbose

(Provides additional information per purged extension, including items and revisions)

cm purge show be5b9145-1bd9-4c43-bd90-f2ff727bbf13 --server=myorg@cloud

(You can specify a different server if you wish)

**Examples:**

Example 1 (unknown):
```unknown
cm purge show <purge_guid> [--verbose | --server=<server>]
```

Example 2 (unknown):
```unknown
cm purge show be5b9145-1bd9-4c43-bd90-f2ff727bbf13
```

Example 3 (unknown):
```unknown
cm purge show be5b9145-1bd9-4c43-bd90-f2ff727bbf13 --verbose
```

Example 4 (unknown):
```unknown
cm purge show be5b9145-1bd9-4c43-bd90-f2ff727bbf13 --server=myorg@cloud
```

---

## Overview

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/overview

**Contents:**
- Overview#
- Additional resources#

The trigger system in Unity Version Control (UVCS) allows you to use shell scripts, or any other operating system executable, to execute user commands at specific points in the client or server execution workflow.

The trigger system in UVCS allows the developers and admins to perform tasks such as the following:

UVCS allows you to associate several scripts to any given trigger and perform different actions in sequence. You can customize the order you execute these scripts in.

**Examples:**

Example 1 (unknown):
```unknown
before-checkin
```

---

## Rules Sample

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/rules-sample

**Contents:**
- Rules Sample#
- 1v1#
  - QoS is equivalent for all the players in the match#
- 5v5, Team Red vs Team Blue#
- 60 players#
- 20 teams of 3 players#
  - Everyone in a team has chosen a different character#
- Asymmetrical 5v1 - Human vs Monster#
  - Require some roles to be filled in the match#
- Lobby-like game server#

Here are some examples of rules that can be used to create different types of matches.

The following code is an example of ticket and player data.

The following code is an example of ticket and player data.

The following code includes two different teams. Players must have chosen the team they want to play in.

The following code is an example of compatible ticket and player data.

A 60-players match, similar to Battle Royal, with no teams.

The number of minimum players to start the game relaxes to 30 after the oldest ticket in the match is 15 seconds old.

Backfill is enabled, allowing players to join after the match is created.

The following code is an example of compatible ticket and player data.

The following sample includes 20 teams of exactly 3 players. The number of minimum teams to start the game relaxes when the youngest ticket in the match is 15 seconds old. The number of players in a team is always 3.

The following code is an example of compatible ticket and player data.

The following code is an example of compatible ticket and player data.

Every player in the Human team must have the Human value to true.

The player in the Monster team must have the Monster value to true.

These rules allow players to choose more than 1 role.

The following code is an example of compatible ticket and player data.

These rules require that the Human team contains players with the following roles:

The following code is an example of compatible ticket and player data.

These rules request a game server as soon as someone creates a ticket if no servers are running. Otherwise, backfill fills up the server that is running.

Every player in a match must have the same city. If it can't find a match with that city, matchmaker requests a new allocation for that city.

The following code is an example of compatible ticket and player data.

**Examples:**

Example 1 (unknown):
```unknown
{
  "Name": "1v1",
  "BackfillEnabled": false,
  "MatchDefinition": {
    "Teams": [
      {
        "Name": "Teams",
        "TeamCount": {
          "Min": 2,
          "Max": 2
        },
        "PlayerCount": {
          "Min": 1,
          "Max": 1
        }
      }
    ]
  }
}
```

Example 2 (unknown):
```unknown
{
  "Name": "1v1",
  "BackfillEnabled": false,
  "MatchDefinition": {
    "Teams": [
      {
        "Name": "Teams",
        "TeamCount": {
          "Min": 2,
          "Max": 2
        },
        "PlayerCount": {
          "Min": 1,
          "Max": 1
        }
      }
    ]
  }
}
```

Example 3 (unknown):
```unknown
{
    "queueName": "Default",
    "attributes": {},
    "players": [{
        "id": "swsqozxo6qxm9fmm38khh3tddv35",
        "customData": {}
    }]
}
```

Example 4 (unknown):
```unknown
{
    "queueName": "Default",
    "attributes": {},
    "players": [{
        "id": "swsqozxo6qxm9fmm38khh3tddv35",
        "customData": {}
    }]
}
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/write-configuration/unity-dashboard

---

## Metering

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/pricing-metering

**Contents:**
- Metering#
- Storage usage#
- Network usage#
- Additional resources#

CPU Core, RAM, and License usage are billed in one-hour increments, based on the number and duration of machines online.

For example, one Windows machine with two CPU cores and 8 GiB of RAM, running for two hours in us-east1, incurs the following:

There’s no License fee for machines running a Linux operating system (OS).

Note: Your scaling settings and server density in your build configurations affect the number of online machines.

Storage usage is based on the amount of storage reserved in a month. For example, 50 GiB of storage reserved in a month in us-east1 incurs the following cost:

50 x $0.195500 = $9.78

Storage costs are then prorated based on a 730 hour month. All storage prices are expressed on a per month basis. For example, 50 GiB of storage reserved for seven days in us-east1 incurs the following cost:

$9.78/730 x (24 x 7) = $2.25

Network usage is based on the amount of egress traffic and where the egress is sent from. For example, 2 GiB of total egress sent from a server in us-east1 incurs the following cost:

2 x $0.142143 = $0.28

Multiplay Hosting doesn't charge you for ingress traffic.

---

## Approaches to authentication

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/approaches-to-authentication

**Contents:**
- Approaches to authentication#
- Anonymous authentication#
- External authentication#
  - Platform-specific authentication#
  - Platform-agnostic authentication#
  - Bring your own identity#
- Code-Link#
- Recommended best practices#

Unity Authentication supports authenticating players anonymously and through external identity providers. The external providers can be divided into platform-specific and platform-agnostic providers. Each solution will have its own pros and cons depending on your use case. Refer to Best practices for general guidance.

Platform-specific providers include Google Play Games, Apple Game Center, Steam, and console-specific logins. Platform-agnostic providers include Username & Password, Facebook, Unity Player Accounts, and OpenID Connect.

Anonymous authentication is a platform-agnostic and frictionless way to implement player authentication, similar to a guest sign-in. It doesn't require players to enter credentials or create a player profile.

On sign in, the service creates a new player ID and returns the associated session token, or signs in a returning player. Refer to How to use Anonymous Sign-in and Sign in a cached player for more information.

However, anonymous authentication isn't portable across devices because there's no way to re-authenticate the player from another device. To sign in to the same game with the same player profile from a different device, players must use an external identity provider.

Note: Anonymous authentication is a way to describe the process of authenticating the player without collecting or using their personally identifiable information.

External authentication (also called third-party authentication) uses external identity providers. These identify the player based on information from an external source, either from the player directly or from the platform where the app is running. This requires you to create an identity provider configuration so that Unity Authentication can validate the player, making it possible to authenticate the same player from multiple devices. The external player identities are then linked to a Unity player ID. A player’s ID and thus experience will be consistent across devices and app installations if the player uses the same external credentials to authenticate.

Note that external identities will always be represented as being linked to a Unity player ID. The underlying Unity player ID can be created automatically by using the external provider sign-up methods in the Unity Authentication SDK, or by using anonymous authentication first and then linking the external identity. The end result will always be a Unity player ID with one or more linked external identities. For any given external identity provider, only one identity can be linked to a given Unity player ID.

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

Platform-specific external authentication providers use platform-native APIs to derive the player identity from the platform on which the app is running, and uses that to sign the player into Unity authentication. As a result it represents a form of frictionless external authentication, which is usually preferable to the non-frictionless platform-agnostic authentication solutions outlined below.

Typically the process begins when a player signs in to the platform with their email address, or their username and password. Within the app a token is then requested from the platform and sent to Unity Authentication for validation. If the token is validated successfully by the external identity provider, the token is then associated with the Unity player ID.

While the user experience of a frictionless sign in is generally excellent, platform-specific solutions might not be the best choice for advanced cross-progression requirements (tracking player state and progress across platforms).

The following platform-specific external identity providers are supported by Unity Authentication:

External platform-agnostic authentication providers require the player to manually sign in. This typically involves the player temporarily leaving your app to authenticate themselves to the external provider in a different app or web browser, and then return to the app. As a result it represents a form of challenge-based external authentication, which is usually less preferable to the frictionless platform-specific authentication solutions outlined above.

While the user experience of having to sign in externally is usually worse, platform-agnostic solutions better support more advanced cross-progression requirements (tracking player state and progress across platforms).

The following external platform-agnostic identity providers are supported by Unity Authentication:

You can use your existing authentication system by integrating a custom authentication solution with Unity Authentication. This means that you must create an identity provider configuration for your own authentication system so that Unity Authentication can validate the player, making it possible to authenticate the same player from multiple devices.

Currently, Unity Authentication supports:

The level of user friction and platform specificity when using custom authentication will depend on how your integration is implemented.

Code-Link is a feature which provides uncomplicated and fast cross-platform ID support across mobile, desktop, and consoles by generating simple codes on one logged-in device that can be used to sign in on another.

With Code-Link, you can provide your players with the flexibility to move across platforms without entering their login credentials multiple times while completely avoiding third-party sign-ins. Code-Link supports both anonymous and platform-specific sign-in methods.

For example, a player can start a game anonymously on their Android device. After reaching level 2, they decide to continue progress on their console. Opening the game on their console generates a code they can enter on their Android device. Once confirmed, they can continue playing on console.

Refer to the Code-Link page for more details.

Use the following decision flow diagram to find the best authentication approach for your app.

Learn more about anonymous authentication, and more about how best to manage a flow with anonymous authentication and linked external providers.

---

## Unity Environments

**URL:** https://docs.unity.com/ugs/en-us/manual/overview/manual/service-environments

**Contents:**
- Unity Environments#
- Supported Services#
- Managing environments#
- Switching environments for a service#
- Accessing environments within Unity projects#
- Environments Recommended Practices#
  - Configuration as Code#
  - Recommended environment strategy#
  - Environment management tooling#
    - Editor Deployment window#

Environments are logical partitions for Unity Game Services that contain data associated with your project. Examples can include game code using Cloud Code, or game configurations using Remote Config.

The following services currently support Environments:

Unity Gaming Services will continue to release Environments support for additional services.

To access a project’s Environments from the Unity Dashboard:

All projects start with a production environment. You can create up to 25 environments. To create a new environment, click Add Environment, give the new environment a name, and select Add.

Refer to Environments best practices for other tooling and recommendations.

To switch the environment for a service in the Unity Dashboard:

Use the Services Core initialization options to initialize your Unity Gaming Services in the development environment you want the player to experience. If unspecified, Unity Gaming Services will initialize in the default “production” environment.

Note: The Services Core SDK is included as a dependency for each service that supports Environments. For more information, see documentation on Services Core API.

To do this, include the Unity.Services.Core and Unity.Services.Core.Environments namespaces, then invoke the UnityServices.InitializeAsync() method with an options parameter configured to pass in the environment name. For example:

Initializing Unity Gaming Services with the "dev" environment.

If no option is specified, the Environment Selector value is used. If no Environment Selector option is present, 'production' is used as the default.

For more information, refer to Environment Selector.

Important: You must include the Unity.Services.Core.Environments namespace to access the SetEnvironmentName method.

Most UGS services support implementing Configuration-as-Code practices. Configuration as Code is the practice of treating configurations the same as code. This approach enables versioning, code review, automated deployment, and eliminates manual environment setup across your development pipeline.

It also lets you reuse configurations across projects and organizations.

The recommended best practice is to use environments as follows:

The Deployment Window is accessible through Services > Deployment in Unity Editor 2022 and later, once the package is installed. It allows you to deploy local service content to the services. It is the preferred way of iterating and working on service-enabled features.

The following services are supported:

The respective service package must be installed to enable the integration, refer to the Deployment window for details.

Any content that can be deployed via the Deployment window can be deployed to any environment.

Actions available through the Deployment window can also be used in automations using the Deployment API, such as build scripts. You can also use the Deployment API to build custom tooling to work with environments.

Use the UGS CLI to call services' admin APIs, and to deploy and fetch configurations for the following services:

The CLI also provides access to other services without config-as-code needs. For more information, refer to the CLI documentation.

You can use the deploy and fetch commands in automations to achieve common needs, such as diffing an environment and rolling back an environment with the supported services.

Use the deploy command to move content from one environment to another, with rollback:

Without source control:

Source control makes it easier to track what's being deployed, and automate deployments.

Use fetch to compare the configuration between two environments. This fetches the relevant configuration and compares it, using your preferred diff tool.

Fetch configurations from both environments and use git diff:

The Services APIs package provides simple access to most public UGS API packages. This lets you build any amount of custom tooling using the admin APIs or game APIs directly from within Unity.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.Core
```

Example 2 (unknown):
```unknown
Unity.Services.Core.Environments
```

Example 3 (unknown):
```unknown
UnityServices.InitializeAsync()
```

Example 4 (unknown):
```unknown
using Unity.Services.Authentication;
using Unity.Services.Core;
using Unity.Services.Core.Environments;
using UnityEngine;

class InitWithEnvironment : MonoBehaviour {
   async void Awake()
   {
       var options = new InitializationOptions();

       options.SetEnvironmentName("dev");
       await UnityServices.InitializeAsync(options);
       await AuthenticationService.Instance.SignInAnonymouslyAsync();
   }
}
```

---

## Matchmaker ticket flow

**URL:** https://docs.unity.com/ugs/en-us/manual/matchmaker/manual/matchmaker-ticket-flow

**Contents:**
- Matchmaker ticket flow#

This Matchmaker flow takes you through the creation of a matchmaking ticket to the allocation of a server for the match created and the ticket assignment.

---

## Google Play data safety section for Multiplay Hosting

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/GoogleDataSafety

**Contents:**
- Google Play data safety section for Multiplay Hosting#
- Data collection survey#
  - Data types#

Starting April 2022, Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Multiplay Hosting. For your convenience, Multiplay Hosting provides information on its data collection practices below.

Important: The data disclosures below are for the Multiplay Hosting SDK only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, refer to the Google documentation.

---

## Unity Environments

**URL:** https://docs.unity.com/ugs-overview/en/manual/service-environments

**Contents:**
- Unity Environments#
- Supported Services#
- Managing environments#
- Switching environments for a service#
- Accessing environments within Unity projects#
- Environments Recommended Practices#
  - Configuration as Code#
  - Recommended environment strategy#
  - Environment management tooling#
    - Editor Deployment window#

Environments are logical partitions for Unity Game Services that contain data associated with your project. Examples can include game code using Cloud Code, or game configurations using Remote Config.

The following services currently support Environments:

Unity Gaming Services will continue to release Environments support for additional services.

To access a project’s Environments from the Unity Dashboard:

All projects start with a production environment. You can create up to 25 environments. To create a new environment, click Add Environment, give the new environment a name, and select Add.

Refer to Environments best practices for other tooling and recommendations.

To switch the environment for a service in the Unity Dashboard:

Use the Services Core initialization options to initialize your Unity Gaming Services in the development environment you want the player to experience. If unspecified, Unity Gaming Services will initialize in the default “production” environment.

Note: The Services Core SDK is included as a dependency for each service that supports Environments. For more information, see documentation on Services Core API.

To do this, include the Unity.Services.Core and Unity.Services.Core.Environments namespaces, then invoke the UnityServices.InitializeAsync() method with an options parameter configured to pass in the environment name. For example:

Initializing Unity Gaming Services with the "dev" environment.

If no option is specified, the Environment Selector value is used. If no Environment Selector option is present, 'production' is used as the default.

For more information, refer to Environment Selector.

Important: You must include the Unity.Services.Core.Environments namespace to access the SetEnvironmentName method.

Most UGS services support implementing Configuration-as-Code practices. Configuration as Code is the practice of treating configurations the same as code. This approach enables versioning, code review, automated deployment, and eliminates manual environment setup across your development pipeline.

It also lets you reuse configurations across projects and organizations.

The recommended best practice is to use environments as follows:

The Deployment Window is accessible through Services > Deployment in Unity Editor 2022 and later, once the package is installed. It allows you to deploy local service content to the services. It is the preferred way of iterating and working on service-enabled features.

The following services are supported:

The respective service package must be installed to enable the integration, refer to the Deployment window for details.

Any content that can be deployed via the Deployment window can be deployed to any environment.

Actions available through the Deployment window can also be used in automations using the Deployment API, such as build scripts. You can also use the Deployment API to build custom tooling to work with environments.

Use the UGS CLI to call services' admin APIs, and to deploy and fetch configurations for the following services:

The CLI also provides access to other services without config-as-code needs. For more information, refer to the CLI documentation.

You can use the deploy and fetch commands in automations to achieve common needs, such as diffing an environment and rolling back an environment with the supported services.

Use the deploy command to move content from one environment to another, with rollback:

Without source control:

Source control makes it easier to track what's being deployed, and automate deployments.

Use fetch to compare the configuration between two environments. This fetches the relevant configuration and compares it, using your preferred diff tool.

Fetch configurations from both environments and use git diff:

The Services APIs package provides simple access to most public UGS API packages. This lets you build any amount of custom tooling using the admin APIs or game APIs directly from within Unity.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.Core
```

Example 2 (unknown):
```unknown
Unity.Services.Core.Environments
```

Example 3 (unknown):
```unknown
UnityServices.InitializeAsync()
```

Example 4 (unknown):
```unknown
using Unity.Services.Authentication;
using Unity.Services.Core;
using Unity.Services.Core.Environments;
using UnityEngine;

class InitWithEnvironment : MonoBehaviour {
   async void Awake()
   {
       var options = new InitializationOptions();

       options.SetEnvironmentName("dev");
       await UnityServices.InitializeAsync(options);
       await AuthenticationService.Instance.SignInAnonymouslyAsync();
   }
}
```

---

## PROFILE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/profile

**Contents:**
- PROFILE#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to manage server connection profiles.

cm profile <command> [options]

cm profile <command> --usage

cm profile <command> --help

**Examples:**

Example 1 (unknown):
```unknown
cm profile <command> [options]
```

Example 2 (unknown):
```unknown
cm profile <command> --usage
```

Example 3 (unknown):
```unknown
cm profile <command> --help
```

Example 4 (unknown):
```unknown
cm profile list
```

---

## Download and install the project

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/DownloadAndInstallation

**Contents:**
- Download and install the project#
- Interact with the sample scenes#
  - From the samples menu#
  - From a specific use case scene#

To download and explore the Unity sample project:

The UGS sample project is added to your projects list. Open it as you would any other Unity project.

Note: This project was tested with Unity 2020.3 for PC and Mac.

To explore all the available use cases with the project open:

To explore a specific use case with the project open:

**Examples:**

Example 1 (unknown):
```unknown
Start Here.unity
```

---

## Relay vs Lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/relay-vs-lobby

**Contents:**
- Relay vs Lobby#
- Additional resources#

Relay and Lobby are two distinct Unity services that you can use together to create a peer-hosted game with an embedded Lobby. However, due to some functionality overlap between the services, it’s important to note the distinctions.

Lobby is a grouping solution to facilitate assembling players and configuration settings before they enter a game session. Relay is a messaging solution, meant to facilitate a multiplayer game session without a dedicated game server or the complications of direct peer-to-peer (P2P) networking. The game host allocates a Relay server as an intermediary through which it routs all traffic in a P2P way, without exposing the clients' actual IP addresses.

Use Lobby and Relay together to create a game with a lobby that facilitates multiplayer game sessions without dedicated game servers.

---

## Request game data deletion

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/game-data-deletion

**Contents:**
- Request game data deletion#

You can request data deletion for a specific Unity environment. This means all your user data will be deleted, but not custom events, saved funnels, or other reports. This will only reset standard and custom event data but any configuration such as event definitions and reports won't be removed.

Open Analytics in the Unity Dashboard and select Analytics Settings, then select Request data deletion. Enter a support request specifying the environment you'd like to delete data from.

WARNING: This is a permanent change that cannot be undone.

Important: Only Organization Owners and Managers can sign up for Analytics.

We recommend development or test data should use a separate environment from your live data. Read more about environments on the environment support page.

You can expect your request to be handled within three working days. After deletion it can take a few hours for your newly ingested events to show up in the Unity Dashboard.

---

## Session operations as a host

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/session-op-host

**Contents:**
- Session operations as a host#
- Session property operations#
  - Read APIs#
  - Read a session property#
  - Write APIs#
  - Add a session property#
  - Update a session property#
  - Delete a session property#
- Player property operations#
  - Read APIs#

Manage your sessions with the operations available to you as a session host.

Note: The Multiplayer Services SDK uses sessions to manage groups of players. Sessions relies internally on different combinations of Unity Gaming Services such as Relay, Distributed Authority, Lobby, Matchmaker and Multiplay Hosting, and thus contributes to the billing of those services.

As a session host, you have access to operations that let you interact with session and player properties. Note that some host operations differ from those available to clients.

The host can read, add, update, or remove properties from a session.

The following APIs allow the host to read session properties:

The following code snippet demonstrates how to read the colour property:

The following APIs allow the host to modify session properties:

To add a property to a session, you must decide upon the visibility of the property:

After you decide the required visibility, you must create the session property, set it, and save it to the session. The following code snippet demonstrates how to add a colour property with the value red in hostSession:

The following code snippet demonstrates how to set the colour property to null in hostSession.

The following code snippet demonstrates how to delete the colour property in hostSession.

The host can read, add, update, or remove properties from any player.

The following APIs allow the host to read player properties:

The following code snippet demonstrates how to read the colour player property.

The following APIs allow the host to modify player properties:

To add a property to a player, you must decide upon the visibility of the property:

The following code snippet demonstrates how to add a colour property with the value red in firstPlayer, which is the first client in the list of clients:

The following code snippet demonstrates how to set the colour property to null in firstPlayer:

The following code snippet demonstrates how to delete the colour property in firstPlayer:

**Examples:**

Example 1 (unknown):
```unknown
IReadOnlyDictionary<string, SessionProperty> ISession.Properties { get; }
```

Example 2 (unknown):
```unknown
IReadOnlyDictionary<string, SessionProperty> ISession.Properties { get; }
```

Example 3 (unknown):
```unknown
if (clientSession.Properties.TryGetValue("colour", out var colour))
{
    Debug.Log($"The colour session property is {colour.Value}");
}
```

Example 4 (unknown):
```unknown
if (clientSession.Properties.TryGetValue("colour", out var colour))
{
    Debug.Log($"The colour session property is {colour.Value}");
}
```

---

## Deploy a Matchmaker queue

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/deployment/deploy-matchmaker-queue

**Contents:**
- Deploy a Matchmaker queue#
- Prerequisites#
- Install the required packages#
- Set up the Deployment window#
- Create a Matchmaker queue configuration#
- Edit a Matchmaker queue configuration#
- Deploy the Matchmaker queue configuration#
- Additional resources#

Use the Deployment window in the Unity Editor to deploy a Matchmaker queue.

A queue represents a predefined logical separation of matchmaking tickets within an environment. A queue has one or more pools. You can deploy a Matchmaker queue configuration directly from the Unity editor.

Before you start, ensure you have done the following:

To enable the integration between the Multiplayer Services SDK and Deployment, install the following packages:

You can deploy Matchmaker queue configurations to your cloud environment using the Deployment window. After you install the Deployment package, you can access the Deployment window from the Unity Editor by selecting Services > Deployment.

Before you can use the Deployment window, you first need to select the environment where you want to deploy. To select the deployment environment, do the following:

To create an editable Queue configuration:

To edit the Matchmaker queue configuration either directly from the Unity Editor or from an IDE of your choice, do the following:

It is the recommended best practice to configure file type associations (Unity Services Web API Docs) in your IDE to work with Matchmaker files. This makes authoring the files significantly easier by providing auto-complete functionality in your preferred IDE. Refer to the Matchmaker queue schema.

Refer to Filters for more information about the queue configuration.

To deploy the Matchmaker queue configuration:

If your configuration assets don't appear in the Deployment window, make sure you activate domain reloading.

To activate domain reloading:

**Examples:**

Example 1 (unknown):
```unknown
MatchmakerQueue
```

---

## Opt-out compliance

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/sdk-compliance-opt-out

**Contents:**
- Opt-out compliance#
- Unity 6.2 and later with Analytics SDK 6.1 and later#
- Unity 6.1 and earlier, or Analytics SDK 6.0 and earlier#

All versions of the Analytics SDK provide compliance mechanisms consistent with known regulatory customers and guidance including General Data Protection Regulation (GDPR) and California Consumer Privacy Act (CCPA).

The Analytics SDK is controlled by the Developer Data framework EndUserConsent API, present in the Unity Engine from 6.2 onwards. To start or stop data collection, you must set the consent status for AnalyticsIntent to Granted or Revoked respectively.

For specific information about granting consent with the EndUserConsent API, refer to Developer Data framework.

In regions that require you to provide an opt-out, you must provide your own logic to determine whether the player has opted out. You may call AnalyticsService.Instance.StartDataCollection() to start the SDK if the player hasn't opted out, otherwise you shouldn't call it and the SDK remains dormant.

Important: Unity Analytics requires you to implement a privacy solution separate from Unity Ads. If you're using both Unity Ads and Analytics, the Unity Ads opt-out mechanism does not apply to both services.

Note: these API methods changed in version 5.0.0 of the SDK. Please ensure you have the latest version of the SDK installed!

**Examples:**

Example 1 (unknown):
```unknown
EndUserConsent
```

Example 2 (unknown):
```unknown
AnalyticsIntent
```

Example 3 (unknown):
```unknown
EndUserConsent
```

Example 4 (unknown):
```unknown
AnalyticsService.Instance.StartDataCollection()
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/shelve-changes

---

## SUPPORT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/support

**Contents:**
- SUPPORT#
- Description#
  - Usage#
  - Commands#
    - To get more information about each command run#
- Help#
  - Examples#

Allows the user to perform support related operations.

cm support <command> [options]

cm support <command> --usage

cm support <command> --help

cm support bundle c:\outputfile.zip

**Examples:**

Example 1 (unknown):
```unknown
cm support <command> [options]
```

Example 2 (unknown):
```unknown
cm support <command> --usage
```

Example 3 (unknown):
```unknown
cm support <command> --help
```

Example 4 (unknown):
```unknown
cm support bundle
```

---

## CCD Management SDK

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/UnityCCDManagementSDK

**Contents:**
- CCD Management SDK#
- Prerequisites#
- Installation#
  - Installation with Addressables#
  - Installation without Addressables#
- Getting started#

The first thing to do is validate that your cloud project is connected to the Unity Editor. See Setting up your project for Unity Services.

If your project uses Addressables (1.19.19 and later), you can use Addressables to install the CCD Management SDK in two ways within Unity Editor:

Certain versions of Addressables only work with certain versions of the CCD SDK. If you’re using this SDK with Addressables, install it from Addressables within Unity Editor to ensure compatibility.

There are two ways to install the CCD Management SDK without Addressables:

See the Documentation for Content Delivery Management API to learn about starting up the sample window, and about what is possible with this SDK, with examples. The sample window within the package gives examples of how to list, create, and delete buckets, entries, and badges. For more information, see the scripting API documentation.

**Examples:**

Example 1 (unknown):
```unknown
manifest.json
```

Example 2 (unknown):
```unknown
"com.unity.services.ccd.management": "2.1.0"
```

---

## Quality of service (QoS)

**URL:** https://docs.unity.com/relay/en-us/manual/qos

**Contents:**
- Quality of service (QoS)#

Note: QoS currently doesn't work if you're using Relay with WebSockets/WebGL.

Relay’s quality of service (QoS) feature allows you to select a region automatically based on quality of service data by starting the NetworkDriver as a host player without selecting a target region.

Note: Not all Unity Editor versions support QoS. Make sure you’re using one of the following versions if you plan to use QoS SDK:

Creating an allocation request without specifying a region triggers the Allocations service to use quality of service data to select the best available region based on the quality of the connection between each region and the host. Relay considers both latency and packet loss. Check out the sample code below.

The diagram below shows how Relay selects a region based on QoS data between the host player client and the available regions. If Relay can't locate QoS servers or collect measurements, it uses the client's location to pick the nearest region. If the client's location can't be determined, then it resolves to the default region, which is Central US.

**Examples:**

Example 1 (unknown):
```unknown
// Launch this method as a coroutine
private IEnumerator StartRelayServer()
{

  // Request an allocation to the Relay service without a target region
  var relayMaxPlayers = 5;
  var allocationTask = RelayService.Instance.CreateAllocationAsync(relayMaxPlayers);

  while(!allocationTask.IsCompleted)
  {
      yield return null;
  }

  if (allocationTask.IsFaulted)
  {
      Debug.LogError("Create allocation request failed");
      yield break;
  }

  var allocation = allocationTask.Result;

  // Request the join code to the Relay service
  var joinCodeTask = RelayService.Instance.GetJoinCodeAsync(allocation.AllocationId);

  while(!joinCodeTask.IsCompleted)
  {
      yield return null;
  }

  if (joinCodeTask.IsFaulted)
  {
      Debug.LogError("Create join code request failed");
      yield break;
  }

  // Get the Join Code, you can then share it with the clients so they can join
  var joinCode = joinCodeTask.Result;

  // Format the server data, based on desired connectionType
  var relayServerData = HostRelayData(allocation, "dtls");

  // Create the network parameters using the Relay server data
  var relayNetworkParameter = new RelayNetworkParameter{ ServerData = relayServerData };

  // Bind and listen to the Relay server
  yield return ServerBindAndListen(relayNetworkParameter);
}
```

Example 2 (unknown):
```unknown
// Launch this method as a coroutine
private IEnumerator StartRelayServer()
{

  // Request an allocation to the Relay service without a target region
  var relayMaxPlayers = 5;
  var allocationTask = RelayService.Instance.CreateAllocationAsync(relayMaxPlayers);

  while(!allocationTask.IsCompleted)
  {
      yield return null;
  }

  if (allocationTask.IsFaulted)
  {
      Debug.LogError("Create allocation request failed");
      yield break;
  }

  var allocation = allocationTask.Result;

  // Request the join code to the Relay service
  var joinCodeTask = RelayService.Instance.GetJoinCodeAsync(allocation.AllocationId);

  while(!joinCodeTask.IsCompleted)
  {
      yield return null;
  }

  if (joinCodeTask.IsFaulted)
  {
      Debug.LogError("Create join code request failed");
      yield break;
  }

  // Get the Join Code, you can then share it with the clients so they can join
  var joinCode = joinCodeTask.Result;

  // Format the server data, based on desired connectionType
  var relayServerData = HostRelayData(allocation, "dtls");

  // Create the network parameters using the Relay server data
  var relayNetworkParameter = new RelayNetworkParameter{ ServerData = relayServerData };

  // Bind and listen to the Relay server
  yield return ServerBindAndListen(relayNetworkParameter);
}
```

---

## Relay servers

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/relay-servers

**Contents:**
- Relay servers#
- Capacity#
- Relay server lifecycle#

The Relay service facilitates multiplayer support without dedicated game servers by allowing players to communicate with each other through Relay servers. Relay servers deliver messages between connected players using low-latency datagram exchange between game clients, so no two players ever connect directly to each other. Relay servers are ideal for games that use a listen server pattern where one player (the host player) acts as the “server” and the other players (the joining players) act as “clients.”

Relay servers act as public endpoints reachable by all players. This design addresses common issues of changing networks and IP addresses, network address translation (NAT), and firewalls between players. Each player can connect to the same IP address and port (the selected Relay server’s IP address and port), and game clients can trust that the connection information remains the same throughout the game session. Through this indirection, players in a game session don't need to know each other's IP address, thereby increasing security and privacy.

The host player’s game client defines the maximum number of players the game session supports when it creates an allocation.

Relay servers are designed as long-running and multi-tenanted connection points. As a result, the Relay server lifecycle is independent of the game session lifecycle.

A Relay server disconnects a player if the player connection times out. The default time to live (TTL) before Relay disconnects a client is 10 seconds. The disconnect TTL is 60 seconds when the host in alone (after the BIND message but before a peer connects to them with a CONNECT message). To prevent an unintended timeout, the game client can send periodic PING messages to the Relay server to keep the connection alive.

A player or game client can explicitly disconnect from a Relay server at any point by sending a CLOSE message.

---

## Leave a lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/leave-a-lobby

**Contents:**
- Leave a lobby#

When players leave a lobby or get kicked out of the lobby, their player ID is removed from the players list. If the host leaves the lobby, another player in the lobby is randomly selected as the host. The host can also remove other players from the lobby. The same RemovePlayerAsync API call is used in both cases where the host simply specifies the other player's playerId instead of their own. Lobbies are automatically deleted when the last player in the lobby leaves.

The following code sample shows how to remove a player from the lobby:

**Examples:**

Example 1 (unknown):
```unknown
RemovePlayerAsync
```

Example 2 (unknown):
```unknown
try
{
            //Ensure you sign-in before calling Authentication Instance
            //See IAuthenticationService interface
            string playerId = AuthenticationService.Instance.PlayerId;
            await LobbyService.Instance.RemovePlayerAsync(lobbyId, playerId);
}
catch (LobbyServiceException e)
{
            Debug.Log(e);
}
```

Example 3 (unknown):
```unknown
try
{
            //Ensure you sign-in before calling Authentication Instance
            //See IAuthenticationService interface
            string playerId = AuthenticationService.Instance.PlayerId;
            await LobbyService.Instance.RemovePlayerAsync(lobbyId, playerId);
}
catch (LobbyServiceException e)
{
            Debug.Log(e);
}
```

---

## ATTRIBUTE RENAME

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/attribute-rename

**Contents:**
- ATTRIBUTE RENAME#
- Description#
  - Usage#
- Help#
  - Remarks#
  - Examples#

Renames an attribute.

cm attribute | att rename <att_spec> <new_name>

This command renames an attribute.

cm attribute rename att:status state

(Renames the attribute 'status' to 'state'.)

**Examples:**

Example 1 (unknown):
```unknown
cm attribute | att rename <att_spec> <new_name>
```

Example 2 (unknown):
```unknown
cm attribute rename att:status state
```

---

## Oculus (Meta Quest)

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-oculus

**Contents:**
- Oculus (Meta Quest)#
- Set up an Oculus sign-in#
- Sign in a returning player or create new player#
- Updating a player from anonymous to an Oculus account#
- Unlink Oculus account#

Minimum SDK version: 2.3.1

This article guides you through the following scenarios in setting up authentication for players in your game with an Oculus account:

To provide an Oculus sign-in option for the players in your game, create an app in the Oculus Developer Dashboard and take note of your App ID and App Secret, as well as the nonce and userId.

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

To set up Oculus as an ID Provider for Unity Authentication:

You can use the code below as an example of how to retrieve the logged in Oculus user and generate a nonce:

Note: Your Oculus headset must be put into developer mode. This can be accomplished by signing into the developer account you would like to use for development (you can create an Oculus developer account here).

You can use the SignInWithOculusAsync method to either:

If no Unity Authentication player in your project is associated with the credentials, SignInWithOculusAsync creates a new player. If a Unity Authentication player in your project is associated with the credentials, SignInWithOculusAsync signs into that player account.

This function doesn’t consider the cached player, and SignInWithOculusAsync replaces the cached player.

After you’ve set up anonymous authentication, if the player wants to upgrade from being anonymous to creating an Oculus account and sign in using an Oculus account, the game should prompt the player to trigger the Oculus login and get the session ticket from Oculus. Then, call the LinkWithOculusAsync API to link the player to the Oculus session ticket.

If a cached player exists on the SDK, you can link the cached player to the Oculus Account.

For more information about cached players, refer to Sign In a Cached Player.

Use the UnlinkOculusAsync API so your players can unlink their Oculus account. Once unlinked, if their account isn’t linked to any additional identity, it transitions to an anonymous account.

**Examples:**

Example 1 (unknown):
```unknown
using UnityEngine;
using Oculus.Platform;
using Oculus.Platform.Models;

public class OculusAuth : MonoBehaviour
{
    private string userId;

    private void Start()
    {
        Core.AsyncInitialize().OnComplete(OnInitializationCallback);
    }

    private void OnInitializationCallback(Message<PlatformInitialize> msg)
    {
        if (msg.IsError)
        {
            Debug.LogErrorFormat("Oculus: Error during initialization. Error Message: {0}",
                msg.GetError().Message);
        }
        else
        {
            Entitlements.IsUserEntitledToApplication().OnComplete(OnIsEntitledCallback);
        }
    }

    private void OnIsEntitledCallback(Message msg)
    {
        if (msg.IsError)
        {
            Debug.LogErrorFormat("Oculus: Error verifying the user is entitled to the application. Error Message: {0}",
                msg.GetError().Message);
        }
        else
        {
            GetLoggedInUser();
        }
    }

    private void GetLoggedInUser()
    {
        Users.GetLoggedInUser().OnComplete(OnLoggedInUserCallback);
    }

    private void OnLoggedInUserCallback(Message<User> msg)
    {
        if (msg.IsError)
        {
            Debug.LogErrorFormat("Oculus: Error getting logged in user. Error Message: {0}",
                msg.GetError().Message);
        }
        else
        {
            userId = msg.Data.ID.ToString(); // do not use msg.Data.OculusID;
            GetUserProof();
        }
    }

    private void GetUserProof()
    {
        Users.GetUserProof().OnComplete(OnUserProofCallback);
    }

    private void OnUserProofCallback(Message<UserProof> msg)
    {
        if (msg.IsError)
        {
            Debug.LogErrorFormat("Oculus: Error getting user proof. Error Message: {0}",
                msg.GetError().Message);
        }
        else
        {
            string oculusNonce = msg.Data.Value;
            // Authentication can be performed here
        }
    }
}
```

Example 2 (unknown):
```unknown
using UnityEngine;
using Oculus.Platform;
using Oculus.Platform.Models;

public class OculusAuth : MonoBehaviour
{
    private string userId;

    private void Start()
    {
        Core.AsyncInitialize().OnComplete(OnInitializationCallback);
    }

    private void OnInitializationCallback(Message<PlatformInitialize> msg)
    {
        if (msg.IsError)
        {
            Debug.LogErrorFormat("Oculus: Error during initialization. Error Message: {0}",
                msg.GetError().Message);
        }
        else
        {
            Entitlements.IsUserEntitledToApplication().OnComplete(OnIsEntitledCallback);
        }
    }

    private void OnIsEntitledCallback(Message msg)
    {
        if (msg.IsError)
        {
            Debug.LogErrorFormat("Oculus: Error verifying the user is entitled to the application. Error Message: {0}",
                msg.GetError().Message);
        }
        else
        {
            GetLoggedInUser();
        }
    }

    private void GetLoggedInUser()
    {
        Users.GetLoggedInUser().OnComplete(OnLoggedInUserCallback);
    }

    private void OnLoggedInUserCallback(Message<User> msg)
    {
        if (msg.IsError)
        {
            Debug.LogErrorFormat("Oculus: Error getting logged in user. Error Message: {0}",
                msg.GetError().Message);
        }
        else
        {
            userId = msg.Data.ID.ToString(); // do not use msg.Data.OculusID;
            GetUserProof();
        }
    }

    private void GetUserProof()
    {
        Users.GetUserProof().OnComplete(OnUserProofCallback);
    }

    private void OnUserProofCallback(Message<UserProof> msg)
    {
        if (msg.IsError)
        {
            Debug.LogErrorFormat("Oculus: Error getting user proof. Error Message: {0}",
                msg.GetError().Message);
        }
        else
        {
            string oculusNonce = msg.Data.Value;
            // Authentication can be performed here
        }
    }
}
```

Example 3 (unknown):
```unknown
SignInWithOculusAsync
```

Example 4 (unknown):
```unknown
SignInWithOculusAsync
```

---

## Trigger structure

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/concepts/trigger-structure

**Contents:**
- Trigger structure#
- Overlap with events#
  - Scheduled events#
  - UGS events#
  - Multiple events per trigger#

A trigger configuration defines what should be invoked when an event is fired.

It may look like this:

Triggers are associated with events. When an event is fired, the associated trigger is invoked. The event and the trigger must share the same eventName and payloadVersion configuration.

Note: The eventType maps an event to a trigger.

Given the following schedule configuration:

And the following trigger configuration:

You can associate the trigger with the event type by setting the eventType field in the trigger configuration to the eventName and payloadVersion fields in the schedule configuration.

When the schedule configuration is deployed, the schedule is triggered at the specified time, sending an event to the Triggers service, which in turn invokes the associated Cloud Code resource.

Given you want to associate a trigger with an event type from UGS, you need to specify the event type in the trigger configuration.

For example, if you want to fire a trigger on the Authentication: Signed Up event, you can create the following trigger configuration:

Every time a user signs up, the trigger is fired, invoking the my-script Cloud Code script.

You can associate the same event with multiple triggers.

Note: The current limit for the number of triggers per event type is 32.

For example, you can create two triggers that invoke when a user signs up.

The first trigger invokes the add-cloud-save-data script to add a Cloud Save data entry for the authenticated user:

The second trigger invokes the add-economy-items endpoint from Economy module to add a virtual item to the authenticated user:

Every time a user signs up, both triggers are fire and invoke the associated Cloud Code resources.

**Examples:**

Example 1 (unknown):
```unknown
{
  "name" : "example-trigger",
  "eventType" : "com.unity.services.{{SERVICE_NAME}}.{{EVENT_NAME}}.v{{EVENT_VERSION}}",
  "actionUrn" : "urn:ugs:cloud-code:{{SCRIPT}}",
  "actionType" : "cloud-code",
  "filter": "data['parameter'] == 'value'"
}
```

Example 2 (unknown):
```unknown
{
  "name" : "example-trigger",
  "eventType" : "com.unity.services.{{SERVICE_NAME}}.{{EVENT_NAME}}.v{{EVENT_VERSION}}",
  "actionUrn" : "urn:ugs:cloud-code:{{SCRIPT}}",
  "actionType" : "cloud-code",
  "filter": "data['parameter'] == 'value'"
}
```

Example 3 (unknown):
```unknown
eventVersion
```

Example 4 (unknown):
```unknown
payloadVersion
```

---

## server.conf variables

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/server-conf-variables

**Contents:**
- server.conf variables#

You can define variables in the server.conf file. Their value passes on to the trigger script or program as environment variables. To define these variables, you need to add a section called TriggerVariables to the server.conf file, which you can find in the server installation folder. The following example shows one way you can use this file:

This sample defines a variable called TRIGGERS_PATH with the value c:\\triggers. For example, you can use this variable in the script field when you create a trigger:

cm trigger create before-checkin "code checker" "@TRIGGERS_PATH\stylecheck.bat"

Note: Use @ to refer to the variable in this context.

**Examples:**

Example 1 (unknown):
```unknown
server.conf
```

Example 2 (unknown):
```unknown
TriggerVariables
```

Example 3 (unknown):
```unknown
server.conf
```

Example 4 (unknown):
```unknown
<?xml version="1.0"?>
<ServerConfigData>
  <Language>en</Language>
  <WorkingMode>UPWorkingMode</WorkingMode>
  <ServerType>ServerTypeAll</ServerType>
  
  <TriggerVariables>
    <TriggerVariable name="TRIGGERS_PATH" value="c:\triggers" />
  </TriggerVariables>

</ServerConfigData>
```

---

## Lock rules

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/unity-vcs-organization-settings

**Contents:**
- Lock rules#
- Organization lock rule#
- Repository lock rules#
- Exclude branches#
- Delete lock rules#

Locking (exclusive checkout) is useful for handling files that cannot be merged (3D assets, images, audio). You can configure lock rules so that UVCS knows which files to lock on checkout.

To access Lock rules, go to the Unity Dashboard, select DevOps > Settings > Lock Rules.

There are two types of lock rules:

This lock rule applies to all repositories that don’t have repository-specific rules. You can only create one rule per organization.

To set up an organization lock rule:

These lock rules are specific to a repository and overwrite the organization lock rules. You can create as many repository-specific rules per organization.

To set up a repository-specific lock rule:

When configuring lock rules, you can also define branches that are not affected by them.

Branch exclusion rules give you more control over how you set up automations, prototype branches or any configuration that fits with your workflow.

To delete a lock rule:

---

## CHANGELIST

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/changelist

**Contents:**
- CHANGELIST#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Groups pending changes in changelists.

cm changelist | clist [--symlink]

(Displays all changelists.)

cm changelist | clist create <clist_name> [<clist_desc>] [--persistent | --notpersistent] [--symlink]

(Creates a changelist.)

cm changelist | clist delete <clist_name> [--symlink]

(Deletes the selected changelist. If this changelist contains pending changes, then these will be moved to the default changelist.)

cm changelist | clist edit <clist_name> [<action_name> <action_value>] [--persistent | --notpersistent] [--symlink]

(Edits the selected changelist.)

cm changelist | clist <clist_name> (add | rm) <path_name>[ ...] [--symlink]

(Edits the selected changelist by adding ('add') or removing ('rm') the change(s) that match with the given path_name(s). Use a whitespace to separate path_names. Use double quotes (" ") to specify paths containing spaces. The status of the paths must be 'Added' or 'Checked-out'.)

The 'changelist' command handles both the workspace pending changelists and the changes contained in a changelist.

(Shows the current workspace changelists.)

cm changelist create config_changes "dotConf files" --persistent

(Creates a new changelist named 'config_changes' and description 'dotConf files' which will remain persistent in the current workspace once the pending changelist is either checked-in or reverted.)

cm changelist create --namefile="name.txt" --descriptionfile="desc.txt"

(Creates a new changelist which name and description are both taken from files.)

cm changelist edit config_changes rename config_files --notpersistent

(Edits the changelist named 'config_changes' and renames it to 'config_files'. Also, it turns the changelist into "not persistent".)

cm changelist edit config_changes --notpersistent

(Edits the changelist named 'config_changes' by turning it into "not persistent".)

cm changelist delete config_files

(Removes the pending changelist 'config_files' from the current workspace.)

cm changelist delete --namefile="name.txt"

(Removes the changelist identified by the content of 'name.txt' file from the current workspace.)

cm changelist config_files add foo.conf

(Adds the file 'foo.conf' to the 'config_files' changelist.)

cm changelist config_files rm foo.conf readme.txt

(Removes the files 'foo.conf' and 'readme.txt' from the 'config_files' changelist and moves the files to the system default changelist.)

cm changelist edit --namefile="name.txt" description --descriptionfile="desc.txt"

(Edits the changelist identified by the content of 'name.txt' file, changing its description to the text content of the 'desc.txt' file.)

cm changelist edit --namefile="name.txt" rename --newnamefile="newname.txt"

(Edits the changelist identified by the content of 'name.txt' file, renaming it to the text content of the 'newname.txt' file.)

**Examples:**

Example 1 (unknown):
```unknown
cm changelist | clist [--symlink]
```

Example 2 (unknown):
```unknown
cm changelist | clist create <clist_name> [<clist_desc>] [--persistent | --notpersistent] [--symlink]
```

Example 3 (unknown):
```unknown
cm changelist | clist delete <clist_name> [--symlink]
```

Example 4 (unknown):
```unknown
cm changelist | clist edit <clist_name> [<action_name> <action_value>] [--persistent | --notpersistent] [--symlink]
```

---

## About Debugging Symbols

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/DebuggingSymbols/AboutDebuggingSymbols

**Contents:**
- About Debugging Symbols#
  - Understanding missing system symbols#
  - Understanding missing application symbols#
  - What’s next?#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Symbols map program addresses to function names. They allow crash and exception reports to provide a native crash stack trace with human-readable function names, instead of numerical addresses. They can be contained within the executable itself, but are usually stored in a separate file to reduce executable size.

Crash and Exception Reporting works with two sets of symbols:

If your crash and exception reports contain missing symbol files, it can be harder to diagnose issues since they appear as numerical addresses. With the Crash and Exception Reporting service, you may upload symbol files to help identify issues in reports.

Symbol files have a universally unique identifier (UUID) or globally unique identifier (GUID) that must exactly match the ID of the executable. Crash and Exception Reporting generates the following errors if the service cannot load a symbol file with an ID that matches a library or module:

If this happens, the issue typically is that Cloud Diagnostics does not have the symbols for that version of the operating system. For iOS and other Apple platforms, it can be difficult to obtain the symbols for older versions of an operating system.

If you encounter this situation, you may check to see if you have similar crash reports for another version of the operating system. If you do, you might be able to resolve the issue by debugging in that version of the operating system.

Reports where the application symbols are missing contain a line in the stack trace:

<symbols missing for uuid: xxx...>

When building a project on which Crash and Exception Reporting is enabled, Unity generates a symbol file and uploads it to the Crash and Exception Reporting servers. If this process fails, a symbols missing message appears in the Unity Dashboard.

To troubleshoot failures in the symbol upload, check the symbol_upload.log file located in the same folder as the main Unity log. It should indicate which symbols were found and processed, along with any errors that occurred while processing and uploading those symbols.

If your Crash and Exception reports contain missing symbols, upload symbol files from the Dashboard. See Uploading symbol files.

---

## Install the UVCS plugin for Jenkins

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/jenkins-plugin

**Contents:**
- Install the UVCS plugin for Jenkins#

Install the Unity Version Control (UVCS) plugin for Jenkins.

This opens a dialog to tell you that the plugin installs after a system restart. To restart immediately, select the relevant checkbox.

---

## Delete accounts

**URL:** https://docs.unity.com/authentication/en/manual/account-deletion

**Contents:**
- Delete accounts#

To give your players more control over their personal data, you can provide a way to delete their own account by using the DeleteAccountAsync() API. This permanently deletes the player’s account. You should inform and prompt the player before calling this API.

Offering this option is a requirement for iOS applications as part of the App Store Review Guideline 5.1.1.

Note: DeleteAccountAsync() only deletes the player’s Unity Authentication account. Upon such a deletion request, you must delete all associated player data connected to the player’s Unity Authentication account and other UGS services you use.

**Examples:**

Example 1 (unknown):
```unknown
DeleteAccountAsync()
```

Example 2 (unknown):
```unknown
DeleteAccountAsync()
```

---

## Upgrade to IAP version 5

**URL:** https://docs.unity.com/ugs/en-us/manual/iap/manual/upgrade-to-iap-v5

**Contents:**
- Upgrade to IAP version 5#
- Overview of changes#
- Replace UnityPurchasing.Initialize()#
  - Code sample of new initialization process using StoreController#
- Replace IDetailedStoreListener and IStoreListener#
- Replace ConfigurationBuilder#
- Replace IStoreController#
- Replace purchase flow#
  - Unity IAP version 4 and earlier#
  - Unity IAP version 5 and later#

Use this guide to upgrade from Unity In-App Purchasing version 4 (or earlier) to version 5.

IAP version 5 (v5) is a major rework of the IAP package, and migration requires significant code changes.

As of IAP v5, you can initialize the Unity IAP package with greater flexibility. Connect to the store, fetch products, and handle purchases independently and asynchronously. This approach helps you identify and resolve issues that might block a successful initialization.

Note: In versions 4 and earlier, the Unity IAP package connects to the store, fetches products and fetched purchases synchronously at package initialization. The package reports a successful initialization only after completing all these steps. If any of these steps fail, initialization does not complete successfully.

Follow these steps to replace UnityPurchasing.Initialize()'s behaviour:

Note: By default, calling FetchPurchases invokes OnPurchasePending for any pending purchases which have not yet been handled in the session. You can disable this behaviour with StoreController.ProcessPendingOrdersOnPurchasesFetched(false).

The following is an example of the new initialization process:

IAP v5 no longer requires an implementation of IDetailedStoreListener or IStoreListener for handling purchases or initialization. Functionality previously handled by an implementation of IDetailedStoreListener should be replaced by attaching event handlers to StoreController, or the individual ProductService, PurchaseService and StoreService services.

For an example of adding event handlers to StoreController, refer to Code sample of new initialization process.

Note: Event handlers can be added or removed at any time, however certain event handlers are recommended before calling certain methods. Unity IAP displays a warning when you call a function before the recommended event handlers have been attached.

During migration, replace the IDetailedStoreListener functions' behaviours with the following:

Replace the following ConfigurationBuilder functions with the following behaviours:

Note: If you fetch a Store Extended Service on an unsupported platform (for example, fetching AppleStoreExtendedService in the Editor or on Android), the service will be null. Always check that the service isn't null before adding event handlers or changing settings.

Replace IStoreController with StoreController. StoreController exposes IAP functionality similar to IStoreListener, but can be fetched by calling UnityIAPServices.StoreController() at any time.

Methods from IStoreController can be replaced with the following from StoreController:

To initiate a purchase, call Purchase() or PurchaseProduct()on StoreController or PurchaseService. To confirm a pending purchase, call StoreController.ConfirmPurchase(PendingOrder) or PurchaseService.ConfirmPurchase(PendingOrder) with the PendingOrder you want to confirm. For more information about the purchase flow, refer to Purchases.

Purchase handling has the following callbacks:

Use your existing ProcessPurchase logic within both of these new callbacks.

RestoreTransactions has moved from Store Extensions to StoreController and PurchaseService.

Confirmed purchases are automatically restored when you call FetchPurchases() or through CheckEntitlement().

To check a user's entitlement to a product, IAP relies on events. You can check the entitlements for all your fetched products by calling FetchPurchases and handling the OnPurchasesFetched event. To check the entitlement for a single product, call CheckEntitlement and handle the OnCheckEntitlement event.

Call FetchProducts on either StoreController or ProductService with a list of additional products to trigger your OnPurchasesFetched event handler. Alternatively, you can call FetchProducts on a CatalogProvider instance. For an example of fetching products via ProductService, refer to Code sample of new initialization process. For an example of calling FetchProducts on CatalogProvider, refer to Define your products.

Receipt validation for Apple App Store receipts has been deprecated. Receipt validation is supported only for Google Play Store. To fetch receipts, use Order.Info.Receipt from Order instead of Product.Receipt.

Replace the following CodelessIAPStoreListener function with the following:

**Examples:**

Example 1 (unknown):
```unknown
CatalogProvider
```

Example 2 (unknown):
```unknown
IDetailedStoreListener
```

Example 3 (unknown):
```unknown
UnityPurchasing.Initialize()
```

Example 4 (unknown):
```unknown
UnityPurchasing.Initialize()
```

---

## Funnels tutorial

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/Funnels

**Contents:**
- Funnels tutorial#
- Create a new funnel#
- Manage saved funnels#
- Interpret funnel results#
- Export a Funnel#

A funnel is a sequence of steps a player goes through in-game during a time period (for example, the last 24 hours or the last 7 days). A funnel analysis is a method of understanding the steps required to reach an outcome and how many users get through each of those steps. Funnels help you better understand your player progression, identify opportunities to boost your KPIs, and uncover potential issues that prevent players from having an optimal experience.

You can ask questions like:

Use funnels by entering steps: game events that match certain criteria sent for that player. At each step you can see the number of players who meet those criteria compared to the previous step and how long it takes for players to move between the steps. Any event can be used for a step. For example, each step could represent a level in the game to see how many players reach each level during the last day. This shows how players drop off from the first level to the second, then the third and so on. The median and average time it takes your group of players to reach each step is recorded. You can see if your levels are too difficult if the percentage of players that reach each step within a day is too low compared to what you expect.

>Note: There's no limit to the number of steps you can have for each funnel. We recommend between eight and fifteen steps to optimize load times.

Saved funnels can be accessed from the list page. Once loaded, you can edit the funnel but will need to save for the changes to take effect.

From within the funnel you can Rename and edit the Funnel steps. Save your changes after editing.

As funnel steps are sequential, only players that show up in step two are those that were present in step one, and so on. Players who aren't present in step one can't join later steps. The following criteria are represented:

Each of the above will be available on the hover state on the chart and within the table.

When you’re looking at a particular funnel, click Export at the top to download the table as a CSV or the chart as a PNG.

**Examples:**

Example 1 (unknown):
```unknown
levelComplete
```

---

## Client configuration files

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/config-files/client-configuration

**Contents:**
- Client configuration files#

Refer to the list of configuration files that you can use to configure your client.

Find or create the following configuration files in the following specified locations:

Note: The locations are listed in order of lowest to highest precedence. For example, a rule in the client installation directory overrules a rule in the plastic4 directory.

**Examples:**

Example 1 (unknown):
```unknown
$HOME/.plastic
```

Example 2 (unknown):
```unknown
C:\Users\user\AppData\Local\plastic4
```

Example 3 (unknown):
```unknown
plastic-global-config
```

Example 4 (unknown):
```unknown
branchexplorer.cfg
```

---

## Apple privacy manifest

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/AppleAppPrivacySurvey

**Contents:**
- Apple privacy manifest#
- PrivacyInfo.xcprivacy#

To publish applications for iOS, iPadOS, tvOS, and visionOS platforms on the App Store, you must include a privacy manifest file in your application as per Apple’s privacy policy.

Note: For information on creating a privacy manifest file to include in your application, refer to Apple’s privacy manifest policy requirements.

The PrivacyInfo.xcprivacy manifest file outlines the required information, ensuring transparency in accordance with user privacy practices. This file lists the types of data that your Unity applications, third-party SDKs, packages, and plug-ins collect, and the reasons for using certain required reason API (Apple documentation) categories. Apple also requires that certain domains be declared as tracking (Apple documentation); these domains might be blocked unless a user provides consent.

Important: If your privacy manifest doesn’t declare the use of the required reason API by you or third-party SDKs, the App Store might reject your application. Read more about the required reason API in Apple’s documentation.

Note: Remote Config has a soft dependency on Unity Authentication. Refer to its manifest file for applicable data practices.

The privacy manifest for Remote Config is available from version 4.1.0.

The following code sample contains the PrivacyInfo.xcprivacy manifest for Remote Config. This file is also available in the SDK.

To identify the data that this SDK collects and the purpose for collecting it, refer to the following keys:

**Examples:**

Example 1 (unknown):
```unknown
NSPrivacyCollectedDataType
```

Example 2 (unknown):
```unknown
NSPrivacyCollectedDataTypePurposes
```

Example 3 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
    	<array>
            <dict>
                <key>NSPrivacyCollectedDataType</key>
                <string>NSPrivacyCollectedDataTypeCoarseLocation</string>
                <key>NSPrivacyCollectedDataTypeLinked</key>
                <true/>
                <key>NSPrivacyCollectedDataTypeTracking</key>
                <false/>
                <key>NSPrivacyCollectedDataTypePurposes</key>
                <array>
                    <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
                </array>
            </dict>
            <dict>
                <key>NSPrivacyCollectedDataType</key>
                <string>NSPrivacyCollectedDataTypeUserID</string>
                <key>NSPrivacyCollectedDataTypeLinked</key>
                <true/>
                <key>NSPrivacyCollectedDataTypeTracking</key>
                <false/>
                <key>NSPrivacyCollectedDataTypePurposes</key>
                <array>
                    <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
                </array>
            </dict>
            <dict>
                <key>NSPrivacyCollectedDataType</key>
                <string>NSPrivacyCollectedDataTypeDeviceID</string>
                <key>NSPrivacyCollectedDataTypeLinked</key>
                <true/>
                <key>NSPrivacyCollectedDataTypeTracking</key>
                <false/>
                <key>NSPrivacyCollectedDataTypePurposes</key>
                <array>
                    <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
                </array>
            </dict>
            <dict>
                <key>NSPrivacyCollectedDataType</key>
                <string>NSPrivacyCollectedDataTypeCrashData</string>
                <key>NSPrivacyCollectedDataTypeLinked</key>
                <false/>
                <key>NSPrivacyCollectedDataTypeTracking</key>
                <false/>
                <key>NSPrivacyCollectedDataTypePurposes</key>
                <array>
                    <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
                </array>
            </dict>
    	</array>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
		<dict>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>CA92.1</string>
			</array>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategoryUserDefaults</string>
		</dict>
	</array>
</dict>
</plist>
```

Example 4 (unknown):
```unknown
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>NSPrivacyTracking</key>
	<false/>
	<key>NSPrivacyTrackingDomains</key>
	<array/>
	<key>NSPrivacyCollectedDataTypes</key>
    	<array>
            <dict>
                <key>NSPrivacyCollectedDataType</key>
                <string>NSPrivacyCollectedDataTypeCoarseLocation</string>
                <key>NSPrivacyCollectedDataTypeLinked</key>
                <true/>
                <key>NSPrivacyCollectedDataTypeTracking</key>
                <false/>
                <key>NSPrivacyCollectedDataTypePurposes</key>
                <array>
                    <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
                </array>
            </dict>
            <dict>
                <key>NSPrivacyCollectedDataType</key>
                <string>NSPrivacyCollectedDataTypeUserID</string>
                <key>NSPrivacyCollectedDataTypeLinked</key>
                <true/>
                <key>NSPrivacyCollectedDataTypeTracking</key>
                <false/>
                <key>NSPrivacyCollectedDataTypePurposes</key>
                <array>
                    <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
                </array>
            </dict>
            <dict>
                <key>NSPrivacyCollectedDataType</key>
                <string>NSPrivacyCollectedDataTypeDeviceID</string>
                <key>NSPrivacyCollectedDataTypeLinked</key>
                <true/>
                <key>NSPrivacyCollectedDataTypeTracking</key>
                <false/>
                <key>NSPrivacyCollectedDataTypePurposes</key>
                <array>
                    <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
                </array>
            </dict>
            <dict>
                <key>NSPrivacyCollectedDataType</key>
                <string>NSPrivacyCollectedDataTypeCrashData</string>
                <key>NSPrivacyCollectedDataTypeLinked</key>
                <false/>
                <key>NSPrivacyCollectedDataTypeTracking</key>
                <false/>
                <key>NSPrivacyCollectedDataTypePurposes</key>
                <array>
                    <string>NSPrivacyCollectedDataTypePurposeAppFunctionality</string>
                </array>
            </dict>
    	</array>
	<key>NSPrivacyAccessedAPITypes</key>
	<array>
		<dict>
			<key>NSPrivacyAccessedAPITypeReasons</key>
			<array>
				<string>CA92.1</string>
			</array>
			<key>NSPrivacyAccessedAPIType</key>
			<string>NSPrivacyAccessedAPICategoryUserDefaults</string>
		</dict>
	</array>
</dict>
</plist>
```

---

## Session creation

**URL:** https://docs.unity.com/ugs/en-us/manual/mps-sdk/manual/create-session

**Contents:**
- Session creation#
- The CreateOrJoinSessionAsync method#
- Session options properties#
- Example: Creating a session with a client-hosted solution#
- Additional resources#

Configure session options and choose network connection types to add multiplayer support to your project.

Note: The Multiplayer Services SDK uses sessions to manage groups of players. Sessions relies internally on different combinations of Unity Gaming Services such as Relay, Distributed Authority, Lobby, Matchmaker and Multiplay Hosting, and thus contributes to the billing of those services.

To start a multiplayer game, the host must create a session that other players join to participate in the game. This page outlines what you must include in your script to create a session. Consider the following factors when you create a session:

Note: To access the API for the Multiplayer Services SDK, import the SDK's namespace in your script:

Use the CreateOrJoinSessionAsync method to do the following:

This approach ensures that only one session is created when multiple clients attempt to join the same session, often referred to as race conditions.

The session options determine various properties of your session, such as the maximum number of players, or whether the session is password protected.

Refer to Class SessionOptions for a full list of options.

The following example demonstrates how to create a session using a Unity client-hosted solution:

**Examples:**

Example 1 (unknown):
```unknown
using Unity.Services.Multiplayer;
```

Example 2 (unknown):
```unknown
using Unity.Services.Multiplayer;
```

Example 3 (unknown):
```unknown
CreateOrJoinSessionAsync
```

Example 4 (unknown):
```unknown
var session = await MultiplayerService.Instance.CreateOrJoinSessionAsync(sessionId, options)
```

---

## Get started

**URL:** https://docs.unity.com/ugs/manual/matchmaker/manual/unreal-engine-sdk/get-started

**Contents:**
- Get started#
  - What's included#
  - Understand the requirements#
- Download the Matchmaker SDK#
  - From the Unreal Engine Marketplace website#
  - From the Epic Games Launcher#
  - Configure the Matchmaker SDK#
    - Configure backfill#
- What's next ?#

Use the following instructions to learn how to install and configure the Unity Gaming Services SDK plugin. After you’ve installed and configured the Unity Gaming Services SDK for your project, you can use C++ or Blueprints for Unity Matchmaker.

The Unity Gaming Services SDK includes three of Unity’s services built into one plugin:

The Matchmaker SDK plug-in for Unreal Engine supports the Unreal Engine versions 4.27 to 5.3.

>Important: Currently, the Unity Matchmaker only supports matchmaking players into dedicated servers hosted using Unity Multiplay Hosting. Multiplay Hosting may incur costs. For pricing details, see Pricing.

>Important: Unity Matchmaker uses a protocol called Centrifuge to handle events on the server. This is contained in the plugin module MatchmakerServer. Centrifuge is not supported on non-PC platforms. Exclude the MatchmakerServer module from Client builds using Multiple Game Modules and TargetAllowList in the .uproject file.

Sign in to the Unreal Engine Marketplace.

Access the Unity Gaming Services SDK for Unreal Engine Marketplace page.

Select Open in Launcher.

Skip to Step 4 in From the Epic Games Launcher.

>Note: If you use a version of the engine built from sources then you can access your Marketplace folder by doing the following:

Unity Matchmaker relies on the Unity Authentication service, which is included in the Unity Gaming Services SDK.

Before you start calling the Matchmaker APIs and start allocating players using the Matchmaker, configure your Unity Matchmaker settings on the Unity Dashboard. Otherwise, all matchmaking requests fail. Unity Matchmaker requires a minimum of one queue with a default pool.

Backfill enables you to place players into an existing match that’s below the maximum player count. See backfill documentation to learn more.

Before using backfill, ensure you enable backfill on the Unity Dashboard for your queue.

Proceed with either integrations:

**Examples:**

Example 1 (unknown):
```unknown
MatchmakerServer
```

Example 2 (unknown):
```unknown
MatchmakerServer
```

Example 3 (unknown):
```unknown
TargetAllowList
```

Example 4 (unknown):
```unknown
C:\Program Files\Epic Games\UE_5.3\Engine\Plugins\Marketplace
```

---

## Google Play data safety

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-save/manual/privacy/google-play-data-safety

**Contents:**
- Google Play data safety#
- Data collection survey#
  - Data types#

Starting April 2022, Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Cloud Save. For your convenience, Cloud Save provides information on its data collection practices below.

Important: The data disclosures below are for the Cloud Save SDK only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please check the Google documentation.

*Since Cloud Save allows for saving of arbitrary data a developer might choose to save any type of data. We suggest to only use Cloud Save for in game progress and preferences.**Developers can delete the data through the cloud save API.

*Player ID is collected. The Player ID is a random string of numbers generated by the Authentication SDK, which is used to identify returning and new players on different devices and external providers.

*Possible (developers can record whatever data they desire).

*Player ID is collected.

---

## HELP

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/help

**Contents:**
- HELP#
- Description#
  - Usage#
- Help#

Gets help for a UVCS command.

Mind this command is partially overlapped with the --help option at each command.

**Examples:**

Example 1 (unknown):
```unknown
cm help <command>
```

---

## REVERT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/revert

**Contents:**
- REVERT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Reverts an item to a previous revision.

The item must be checked in.

cm revert C:\mywks\dir\file1.txt#23456

**Examples:**

Example 1 (unknown):
```unknown
cm revert <revspec>
```

Example 2 (unknown):
```unknown
cm revert dir#cs:0
```

Example 3 (unknown):
```unknown
cm revert C:\mywks\dir\file1.txt#23456
```

---

## Host migration

**URL:** https://docs.unity.com/ugs/en-us/manual/relay/manual/host-migration

**Contents:**
- Host migration#

Host migration is the act of transferring the Relay host role from one player to another.

Relay doesn't have any method to migrate the host role when a host player disconnects from the Relay server. If the host player disconnects from the Relay server, Relay ends the host player’s allocation and disconnects the remaining players.

However, you can add custom logic to your game to migrate the Relay host role to another player if the original host player disconnects. The logic might include a workflow similar to the following:

Note: Also see Lobby host migration.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/ccd/manual/data-privacy

---

## Privacy overview

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/privacy-overview

**Contents:**
- Privacy overview#
- Personal data collected about app users/game players#
- Developer-defined#
- Relationship under privacy laws#
- Legal basis for processing#
- Data subject requests#
- Access#
- Deletion#
- Dependencies#
- Data retention#

Unity Analytics, part of the Unity Gaming Services platform, provides an end-to-end data and analysis solution designed to support your entire studio. Analytics lets studios easily understand game performance and player behaviors.

Important: this documentation is intended to inform developers of their data privacy obligations when using Analytics. It is not intended to be used as legal guidance or as a replacement to reading our Privacy Policy. If you have questions about a term used, please see the Glossary below.

If you have further questions about the privacy of a product, please email DPO@unity3d.com with your question. For expediency, please list the product about which you are inquiring.

For practical information about how to fulfil your data privacy obligations when integrating Analytics into your game, please see the manage data privacy with the SDK page.

While this product allows for the collection of developer-defined data, we ask that you do not collect personal data through this mechanism. Our systems will not understand that it is personal data and so would not treat it as such in retention processes or data subject requests.

Under European Privacy Law, Unity is the Processor. You, the developer, are the Controller. In limited circumstances, we can become independent Controllers e.g., if Analytics is used alongside our Grow Services.

Under Californian Privacy Law, Unity is the Service Provider. You, the developer, are the Business. In limited circumstances, we can become independent Businesses e.g., if used alongside our Grow Services.

As we are a Processor, we do not determine the legal basis for processing. Instead, it is your responsibility as the Controller to determine such a legal basis.

In the limited circumstances in which we are an Independent Controller, you can find our legal basis for processing data collected through our Ads Service in our Privacy Policy. Please note: As an independent controller, you too should determine your own legal basis.

Two of the most common data subject requests based in law are the request for access to personal data and the request for deletion of personal data.

This service has no native functionality to support data access requests. You, the developer, are responsible for actioning them. You can action them by submitting the request here.

This service has native functionality to support data deletion requests. This is achieved using the RequestDataDeletion method of the SDK. Please see the manage data privacy page for more information.

Depending on how you enable it, this product may be on the Authentication product. By enabling this product, you will also be enabling the Authentication product and you should refer to Unity Authentication SDK for more information.

By default, personal data is retained for 13 months. If you wish to implement a shorter retention period, you can do so by contacting support.

If required to do so under applicable laws, you (the developer) must obtain Verified Parental Consent prior to submitting child-user data, as outlined in the Unity Terms of Service.

It is never appropriate to use Unity's privacy policy for your application. You will need to ensure that the personal data practices are reflected in your Privacy Policy, as required in the Unity Terms of Service.

If you need to present the user with Unity's privacy policy, use the privacy URL: https://unity.com/legal/game-player-and-app-user-privacy-policy.

This is available in the Analytics SDK in the property AnalyticsService.Instance.PrivacyUrl.

Unity DPA applies to the transfer of data for this product.

**Examples:**

Example 1 (unknown):
```unknown
RequestDataDeletion
```

Example 2 (unknown):
```unknown
AnalyticsService.Instance.PrivacyUrl
```

---

## Get started with Leaderboards

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/get-started

**Contents:**
- Get started with Leaderboards#
- Unity Dashboard#
- Unity SDK installation and setup#
  - Install Leaderboards SDK#
  - Install Authentication SDK#
  - Link your Unity project#
  - Initialize the SDKs and authenticate the player#
  - Next steps#
- Leaderboards in the UGS CLI#
  - Deploy a Leaderboards configuration#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

The first step in using Leaderboards is to learn how to implement the feature. This section describes how to set up Leaderboards for your project.

You can set up and manage Leaderboards in the Unity Dashboard:

When you launch Leaderboards for the first time, this adds Leaderboards to the Shortcuts section on the sidebar and opens the Leaderboards Overview.

You can use the Unity Dashboard to create and manage your leaderboards and view their entries.

The Leaderboards SDK requires Unity 2020.3.0 or newer.

You can install the package in the Unity Editor.

Navigate to Window > Package Manager and select Unity Registry in the Packages dropdown on the top left. You can either:

There is a Samples section where you can import example code to your project to assist you calling the Leaderboards SDK from your game.

After installation, the Leaderboards SDK is available in Unity scripts from the Unity.Services.Leaderboards namespace:

The Leaderboards package relies on the Authentication package. The Unity Authentication service creates an account to persist player scores where you can use anoynymous sign-in or platform-specific authentication.

The Authentication package is installed as a dependency when you install the Leaderboards package. For information on installing packages manually, refer to Install a package from a registry.

After installation, the Authentication SDK is available in Unity scripts from the Unity.Services.Authentication namespace:

Once installed, the Authentication package prompts you to link your Unity project to a Unity Gaming Services Project ID. Follow the instructions in the prompt on the screen to link your project.

Alternatively, follow the steps to Link your project in the Unity Editor.

You must initialize the Leaderboards SDK and its dependencies from inside a Unity script lifecycle callback before use. The following example uses the Awake callback. This is done by initializing all installed services via the Core SDK by calling await UnityServices.InitializeAsync();, available from the Unity.Services.Core namespace.

After the SDK initialization is complete, the player is authenticated. The following example uses anonymous authentication to create an anonymous account for the player to persist their scores. Other methods of authentication are available as outlined in the Unity Authentication documentation.

After completing the above steps the Leaderboards SDK is now ready to use from the Unity.Services.Leaderboards namespace. Review the features, Unity SDK tutorial, and the SDK sample to find out more about the Leaderboards feature set and how to use them.

The Unity Gaming Services (UGS) command line interface provides a scalable and automatable alternative to the Unity Dashboard and improves your team's workflows and productivity. The CLI is used to manage, test and deploy your Leaderboards configuration.

See the documentation on how to install and use the CLI.

To make your Leaderboards configurations accessible to the game client, you must deploy the configuration to the Leaderboards service.

Refer to write configuration to learn more about script deployment.

To get started with the UGS CLI, perform the following steps:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Configure a Service Account with the required roles for Leaderboards and environments management. Refer to Get Authenticated.

Run the following command:

ugs deploy <path-to-configuration-file>

Developers that do not use Unity can access APIs via web endpoints or REST APIs. REST APIs provide more flexibility and allow you to automate your workflows by using your favorite language and game development engine.

The Leaderboards service provides the following REST APIs:

This module allows users to author, modify, and deploy Leaderboard configuration assets directly from the Unity Editor.

Leaderboards Authoring is only supported on Unity 2021.3 and above.

The Deployment Window is a core feature of the Deployment package.

The purpose of the Deployment Window is to allow all services to have a single cohesive interface for Deployment needs.

The Deployment Window provides a uniform deployment interface for all services. It allows you to upload cloud assets for your respective cloud service.

For more information, refer to the com.unity.services.deployment package documentation.

Use the right click menu in the Project window to create a Leaderboard asset.

The Deployment Window automatically detects these files to be deployed at a later time.

For more information on how to create and modify Leaderboards Assets, refer to Leaderboards assets.

**Examples:**

Example 1 (unknown):
```unknown
Unity.Services.Leaderboards
```

Example 2 (unknown):
```unknown
using Unity.Services.Leaderboards;
```

Example 3 (unknown):
```unknown
using Unity.Services.Leaderboards;
```

Example 4 (unknown):
```unknown
Unity.Services.Authentication
```

---

## WORKSPACE CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/workspace-create

**Contents:**
- WORKSPACE CREATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Creates a new workspace.

cm workspace | wk [create | mk] <rep_spec> [create | mk] <wk_name> <wk_path> [<rep_spec>] [create | mk] <wk_name> <wk_path> [--selector[=<selector_file>]

(Creates a new workspace.)

cm workspace | wk [create | mk] <wk_name> <wk_path> --dynamic --tree=[<tree>]

(Creates a dynamic workspace. This feature is still experimental, and it's only available for Windows.)

cm workspace create mycode

(Creates a 'mycode' workspace pointing to the repository with the same name. The workspace directory will be created under the current directory.)

cm wk mk mycode@localhost:8084

cm wk mk mycode@myorganization@cloud

(Creates a 'mycode' workspace as before, but you can specify different repository server.)

cm workspace create myworkspace c:\workspace

cm wk mk myworkspace /home/john/plastic_view

(Creates 'myworkspace' workspace in Windows and in Linux respectively.)

cm wk mywktest c:\wks\wktest --selector=myselector.txt

(Creates 'mywktest' workspace using the selector in 'myselector.txt' file.)

cm wk mywkprj c:\wks\wkprj myrep@repserver:localhost:8084

(Creates 'mywkprj' workspace with the selected repository.)

cm wk mywkprj c:\dynwks\mywkprj --dynamic --tree=br:/main@myrep@localhost:8084

(Creates dynamic 'mywkprj' workspace with the 'myrep@localhost:8084' repository, pointing to 'br:/main' the first time it gets mounted.)

**Examples:**

Example 1 (unknown):
```unknown
cm workspace | wk [create | mk] <rep_spec> [create | mk] <wk_name> <wk_path> [<rep_spec>] [create | mk] <wk_name> <wk_path> [--selector[=<selector_file>]
```

Example 2 (unknown):
```unknown
cm workspace | wk [create | mk] <wk_name> <wk_path> --dynamic --tree=[<tree>]
```

Example 3 (unknown):
```unknown
cm workspace create mycode
```

Example 4 (unknown):
```unknown
cm wk mk mycode
```

---

## Purchases

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual/SDK-purchases

**Contents:**
- Purchases#
- MakeVirtualPurchaseAsync#
  - MakeVirtualPurchaseOptions#
  - MakeVirtualPurchaseResult#
- RedeemAppleAppStorePurchaseAsync#
  - RedeemAppleAppStorePurchaseArgs#
  - RedeemAppleAppStorePurchaseResult#
    - INVALID_VERIFICATION_FAILED#
  - EconomyAppleAppStorePurchaseFailedException#
- RedeemGooglePlayPurchaseAsync#

The methods in the Purchases namespace allow you to make purchases for the currently signed in user.

All the methods in this namespace can throw an EconomyException.

Makes a virtual purchase specified by ID.

This method optionally takes a MakeVirtualPurchaseOptions object. This can be used to specify the PlayersInventoryItems IDs of the items in the players inventory that should be used towards the cost(s) of the purchase. If these are not supplied, the items used towards the cost(s) are chosen automatically.

Returns a MakeVirtualPurchaseResult.

Alternative Example using PlayersInventoryItem IDs:

The options object for a MakeVirtualPurchaseAsync call. It has the following field:

This object is returned by a MakeVirtualPurchaseAsync call. It contains the following fields:

Costs: A Costs object representing the costs that were spent in this purchase. This in turn has two fields:

Rewards: A Rewards object representing the rewards given in exchange for this purchase. This also has two fields as above:

Redeems a real money purchase by submitting a receipt from the Apple App Store. This is validated and if valid, the rewards as defined in the configuration are applied to the player’s inventory and currency balances.

Takes a required RedeemAppleAppStorePurchaseArgs object. This is used to provide the purchase details.

The arguments object for a RedeemAppleAppStorePurchaseAsync call. It has the following fields:

This object is returned by a RedeemAppleAppStorePurchaseAsync call. It contains the following fields:

Verification: The receipt verification details from the validation service.

Status: Status of the receipt verification. This will be one of:

Store: Details from the receipt validation service. This has three fields:

Rewards: A Rewards object representing the rewards given in exchange for this purchase. This has the following fields:

If you get an INVALID_VERIFICATION_FAILED error with the store message The receipt could not be authenticated. and with error code 21003, it might be because your receipt contains a renewable subscription, which is not supported for validation by the Economy service.

RedeemAppleAppStorePurchaseAsync may throw an exception of type EconomyAppleAppStorePurchaseFailedException. This inherits from EconomyException and contains one additional field called Data.

The Data field is of type RedeemAppleAppStorePurchaseResult (see above).

This Data field is different from the Data field in the base Exception class.

Redeems a real money purchase by submitting a receipt from the Google Play Store. This is validated and if valid, the rewards as defined in the configuration are applied to the player’s inventory and currency balances.

Takes a required RedeemGooglePlayStorePurchaseArgs object. This is used to provide the purchase details.

The arguments object for a RedeemGooglePlayPurchaseAsync call. It has the following fields:

This object is returned by a RedeemGooglePlayPurchaseAsync call. It contains the following fields:

Verification: The receipt verification details from the validation service.

Status: Status of the receipt verification. This will be one of:

Store: Details from the receipt validation service. This has one field:

Rewards: A Rewards object representing the rewards given in exchange for this purchase. This has the following fields:

RedeemGooglePlayPurchaseAsync may throw an exception of type EconomyGooglePlayStorePurchaseFailedException. This inherits from EconomyException and contains one additional field called Data.

The Data field is of type RedeemGooglePlayPurchaseResult (see above).

This Data field is different from the Data field in the base Exception class.

This object represents a currency that was part of a purchase. It has these fields:

This object represents an inventory item that was part of a purchase. It has these fields:

**Examples:**

Example 1 (unknown):
```unknown
MakeVirtualPurchaseOptions
```

Example 2 (unknown):
```unknown
PlayersInventoryItems
```

Example 3 (unknown):
```unknown
MakeVirtualPurchaseResult
```

Example 4 (unknown):
```unknown
string purchaseID = "BUY_A_SWORD";
MakeVirtualPurchaseResult purchaseResult = await EconomyService.Instance.Purchases.MakeVirtualPurchaseAsync(purchaseID);
```

---

## Leaderboard archives and versions

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/concepts/archives

**Contents:**
- Leaderboard archives and versions#
- Archives#
  - Archive limits#
- Versions#

When resetting a leaderboard manually or using a scheduled reset, you can optionally create a read-only archive copy of the current leaderboard scores, which game clients can access by fetching scores for that archived version. Refer to the Leaderboards resets page for details on resets.

Important: When using leaderboard archives be mindful of your data retention policy and that each archived version leaderboards will count towards the number of leaderboards used per Monthly Active User.

Every leaderboard maintains a versionId to identify its current live version. It also maintains an array of versions for previous archived resets.

The versionId parameter in AddPlayerScore requests serves as a safeguard: it can be used to ensure that outdated game clients cannot inadvertently submit scores to a newer live leaderboard. You can only submit scores to the live leaderboard version.

**Examples:**

Example 1 (unknown):
```unknown
20250407151515238177311
```

Example 2 (unknown):
```unknown
AddPlayerScore
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/workflow/merge-branch

---

## Event Browser

**URL:** https://docs.unity.com/ugs/en-us/manual/analytics/manual/event-browser

**Contents:**
- Event Browser#

Use the Event Browser feature in Analytics to debug events coming in from your game. You can access a list of up to 100 of the latest events sent by your game over the last 48 hours.

You can toggle between valid events that are processed successfully and invalid events that are not. This might be due to setting up events in your game incorrectly, such as sending the wrong data type, wrong format, or invalid enumeration values.

Note: Event processing time varies. It can take up to 10 minutes for events to appear in the Event Browser.

You can filter by Event Name, User ID and Unity Player ID:

The list is currently view-only and cannot be exported. Contact support if you require a bulk raw data export.

The Event Browser shows the following information for both valid and invalid events:

To view the event payload in the flattened JSON format, select <> at the end of the row.

Note: Nested events (for example, transaction) are flattened (have their nesting removed) by splitting the event into multiple, separate events. These events have the same Main Event ID value, with the parent event having an "eventLevel": 0 in their JSON, and the child events having "eventLevel": 1. Only the parent event contributes towards user metrics.

The Event Browser shows the following information only for valid events:

The Event Browser shows the following information only for invalid events:

For a detailed breakdown of an invalid event, select the arrow at the end of the row. Notices inform you of errors and warnings. For example, if there is no format on a parameter such as a UUID, you receive an invalid notice.

**Examples:**

Example 1 (unknown):
```unknown
Main Event ID
```

Example 2 (unknown):
```unknown
"eventLevel": 0
```

Example 3 (unknown):
```unknown
"eventLevel": 1
```

---

## Google Play data safety section for Remote Config

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/GoogleDataSafety

**Contents:**
- Google Play data safety section for Remote Config#
- Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Remote Config. For your convenience, Remote Config provides information on its data collection practices below.

Important: The data disclosures below are for the Remote Config SDK only. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

* Remote Config accepts some basic device info data in the request, which we use to provide "stateless" segmentation (on-the-fly calculations to deliver content that meets certain criteria).

*** Remote Config does not store any of this data or share it with any other entity.

---

## Google Play data safety section for Vivox

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-core/manual/Core/google-data-safety

**Contents:**
- Google Play data safety section for Vivox#
- Data collection survey#
- Data types#

Starting April 2022, Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs. For your convenience, this topic provides information on Vivox data collection practices.

Important: The following data disclosures are only for the Vivox SDK. You are also responsible for providing any additional disclosures for your app, including other Unity SDKs and/or third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

* Voice data is not encrypted, but the signaling is. Voice data is encoded (not encrypted), and gets decoded by the SDK/client side. The purpose of this is for app functionality and analytics.

*Required for message function, but message function not required to be implemented

---

## Unreal Shooter Game sample app

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unreal/manual/Unreal/vivox-unreal-sample-app/sample-app-overview

**Contents:**
- Unreal Shooter Game sample app#

The Unreal Shooter Game sample app, which is available for Windows 7, 8, and 10 (64-bit), provides an example how to incorporate a fundamental subset of Vivox SDK features into an Unreal Engine project. It is often used by game developers for the following reasons:

To access the Unreal Shooter Game sample app, on the Vivox Developer Portal sidebar, select the Downloads link, select the Windows platform, and then download Unreal Shooter Game (Source) and Unreal Shooter Game (Prebuilt).

Note: Before you can inspect Unreal Shooter Game (Source) to understand how it operates, you must replace the default credentials in VivoxGameInstance.cpp and VivoxToken.cpp with your custom credentials from the VIVOX API INFO section for your application on the Vivox Developer Portal. See Update sample app environment and API values.

---

## Get started

**URL:** https://docs.unity.com/ugs/manual/matchmaker/manual/matchmaker-sdk-installation

**Contents:**
- Get started#
- Prerequisites#
- Configure your hosting#
- Install the Matchmaker SDK#
- Set up Matchmaker#
- Create a queue and a pool#
- Create a matchmaking ticket#
- Poll ticket status#
- Matchmaking Results#

Attention: The Digital Services Act (DSA) requires Unity to notify our customers’ end users if Unity takes an action that impacts those end users under the DSA. To comply with this requirement, if you use Unity Gaming Services (UGS) products that rely on the Unity Authentication Service, you must integrate the notification API.

For more information on DSA, refer to the Digital Services Act - compliance update.

To make your game compliant, refer to DSA notifications.

This guide walks you through the different steps required to install the Matchmaker SDK, enable Matchmaker, create the first matchmaking ticket and create a Multiplay Hosting allocation.

To get started with Matchmaker, you need to do the following:

Before enabling Matchmaker, either initialize Multiplay Hosting or a client-hosted solution provided by Unity. Refer to Get Started with Multiplay Hosting, Get Started with Relay, and the Distributed Authority Quickstart.

To install the latest Matchmaker package for Unity:

Note: For most users, the unified Multiplayer Services package replaces the Matchmaker standalone package, which is deprecated in Unity 6. Consider migrating to the unified package to facilitate a smooth transition. Visit the migration guide for a step-by-step transition process.

You can set up and manage Matchmaker through the Unity Dashboard:

When you launch Matchmaker for the first time, this adds Matchmaker to the Shortcuts section on the sidebar and opens the Overview page.

Define the rules used to define the matches created when sending ticket to that queue and pool. Select JSON and copy/paste the following block of code:

This creates matches of one team with a minimum of one player and a maximum of five players.

Matchmaker is now configured. You can check the Queue and Pool that were created by clicking on Queues in the menu under the Matchmaker section.

Now that the matchmaker is configured we can create and send a ticket to request a Multiplay Hosting allocation:

> Note: Player Ids must be different to be matched together.

https://services.docs.unity.com/matchmaker/v2/index.html#tag/Tickets/operation/createTicket

Once the ticket is created, the client polls to get the status of the ticket using the ticket ID returned when creating the ticket.

When the ticket is assigned to a match and a server is allocated, Matchmaker adds the server information to the ticket status response.

https://services.docs.unity.com/matchmaker/v2/index.html#tag/Tickets/operation/getTicketStatus

On the server side, when the server is allocated it is possible to fetch the Matchmaking Results about the match made using the Payload Allocation.

Matchmaking results give the server information about the different players that are supposed to be in the match, their data as well as their distribution in the different teams.

This code only works on the server allocated by Multiplay Hosting.

Note: Use the server.json file to get a server’s allocation UUID.

You will need to install the Multiplay Hosting SDK to access the matchmaking results

**Examples:**

Example 1 (unknown):
```unknown
com.unity.services.multiplayer
```

Example 2 (unknown):
```unknown
com.unity.services.matchmaker
```

Example 3 (unknown):
```unknown
{
  "Name": "Test",
  "MatchDefinition": {
    "Teams": [
      {
        "Name": "Main team",
        "TeamCount": {
          "Min": 1,
          "Max": 1
        },
        "PlayerCount": {
          "Min": 1,
          "Max": 5
        }
      }
    ],
    "MatchRules": []
  },
  "BackfillEnabled": false
}
```

Example 4 (unknown):
```unknown
{
  "Name": "Test",
  "MatchDefinition": {
    "Teams": [
      {
        "Name": "Main team",
        "TeamCount": {
          "Min": 1,
          "Max": 1
        },
        "PlayerCount": {
          "Min": 1,
          "Max": 5
        }
      }
    ],
    "MatchRules": []
  },
  "BackfillEnabled": false
}
```

---

## Server status

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/server-status

**Contents:**
- Server status#
  - Allocated#
  - Available#
  - Online#

A server status is an indication of the server’s current state. Servers can be in one of the following states:

When a server has an active allocation ID and is hosting a game session, it’s in an allocated state. Allocated servers might or might not have active players connected to the game session it's hosting.

A server is available when it’s offline and doesn't have an active allocation. When a server is available, it's in the available servers pool and ready for a matchmaker to use in an allocation.

Warning: Any number of available servers incurs costs, even without traffic. If you're in development or trying to limit costs in a low traffic environment, set the Minimum available scaling value to 0.

A server is online after it has received a start command, usually through an automated process or a manual command from user. Players can connect to an online server if they know its IP.

---

## Context analysis glossary

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/context-analysis/context-analysis-glossary

**Contents:**
- Context analysis glossary#
- Identity attack#
- Harassment#
- Inappropriate content#
- Unlawful conduct#

---

## DIFFMETRICS

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/diffmetrics

**Contents:**
- DIFFMETRICS#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Comparison methods (--comparisonmethod option)#
  - Examples#

Shows diff metrics between two revs.

cm diffmetrics | dm <revspec1> <revspec2> [--format=<str_format>] [--encoding=<name>] [--comparisonmethod=(ignoreeol | ignorewhitespaces | ignoreeolandwhitespaces | recognizeall)]

The metrics are: number of changed, added, and deleted lines.

Output format parameters (--format option): This command accepts a format string to show the output. The output parameters of this command are the following:

cm diffmetrics file.txt#cs:2 file.txt#br:/main/scm0211 --format="There are {0} changed, {1} added and {2} deleted lines."

(Retrieves diffmetrics results formatted.)

cm dm file.txt#cs:2 file.txt#cs:3 --encoding=utf-8 --comparisonmethod=ignorewhitespaces

**Examples:**

Example 1 (unknown):
```unknown
cm diffmetrics | dm <revspec1> <revspec2> [--format=<str_format>] [--encoding=<name>] [--comparisonmethod=(ignoreeol | ignorewhitespaces | ignoreeolandwhitespaces | recognizeall)]
```

Example 2 (unknown):
```unknown
cm diffmetrics file.txt#cs:2 file.txt#br:/main/scm0211 --format="There are {0} changed, {1} added and {2} deleted lines."
```

Example 3 (unknown):
```unknown
cm dm file.txt#cs:2 file.txt#cs:3 --encoding=utf-8 --comparisonmethod=ignorewhitespaces
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/update-lobby-data

---

## Google Play Data Safety Section

**URL:** https://docs.unity.com/ugs/en-us/manual/friends/manual/google-play-data-safety

**Contents:**
- Google Play Data Safety Section#
- Data collection survey#
  - Data types#

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs such as Friends. For your convenience, Friends provides information on its data collection practices in the following sections.

Important: The data disclosures below are for this service only. You are also responsible for providing any additional disclosures for your app, including other third-party SDKs used in your app.

For more information on Google's data safety disclosure policies, including terminology definitions, please see the Google documentation.

---

## Set up User Reporting

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-diagnostics/manual/UserReporting/SettingupUserReporting

**Contents:**
- Set up User Reporting#
- Set up notifications for new reports#
- Test reports and notifications#

Important: Cloud Diagnostics is deprecated, and will be phased out in future versions of Unity. For more robust reports and device information, including information on Application Not Responding (ANR) errors for Android, use the diagnostics experience available in Unity 6.2 and later. For information about migrating from Cloud Diagnostics, refer to Migrate to Diagnostics in the Unity Dashboard.

Integrate the User Reporting SDK with your app to set up user reports. Once integrated, you can use the built-in user report prefab, or create your own custom user reports without the prefab.

Note: Before you integrate User reports with your project, make sure you set up your project for Unity Services. Your project must be in the Editor to the Dashboard with a project ID. See Setting up your project for Unity Services.

To add the built-in example User Reporting Prefab to your project:

User Reporting supports new report notifications via Integrations so you can connect your development workflow to non-Unity tools. Receive a notification via third-party integrations such as email, Slack, Discord, Trello, and more.

To set up notifications:

The sample scene is an effective tool for confirming whether or not your User Reporting has been set up correctly. In this example, we’ll optionally include a test of the email notification integration for new reports.

To set up email notifications (optional):

To test that reports are received:

---

## Configure file compression

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/configure-compression

**Contents:**
- Configure file compression#
- Compression methods#
- compression.conf file configuration#
  - Compression rules#

Use compression to reduce the size of files in your Unity Version Control (UVCS) system, save storage space, and speed up data transfer.

You can use the compression.conf file on the UVCS client to select the compression type.

Find the compression.conf file in the following locations:

Note: If you have a compression.conf file in both locations, UVCS combines the rules. If the same rule is specified with two different values, the first one to appear in the file takes precedence.

You can select the type of compression that UVCS uses to store a new revision of a file in your database. The following operations create new changesets, which may contain new revisions that the compression rules affect:

The compression.conf file supports the following compression options:

If the compression.conf file doesn't exist then the compression type of any file is .zip.

Each line of the compression.conf file defines a compression type followed by a whitespace and a rule to match the file path. For example:

This example compression.conf file ensures that UVCS compresses all .txt files as .zip files but doesn't compress any .jpeg files.

You can specify different types of rules, and the following is the order of application:

If a file path matches with a path rule, that rule defines the compression type. If not, UVCS tries to match the file with a file name rule.

For example, if you have the following compression.conf file under the wkstest workspace and you perform a checkin on the main-test.png, user1-test.png and test-result.png files, UVCS checks in all the .png files but the /test01/main-test.png file with the .zip compression method:

**Examples:**

Example 1 (unknown):
```unknown
compression.conf
```

Example 2 (unknown):
```unknown
compression.conf
```

Example 3 (unknown):
```unknown
$HOME/.plastic4
```

Example 4 (unknown):
```unknown
C:\Users\user\AppData\Local\plastic4
```

---

## UNDOCHECKOUT

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/undocheckout

**Contents:**
- UNDOCHECKOUT#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Requirements#
  - Reading input from stdin#
  - Examples#

Undoes the checkout of an item.

cm undocheckout | unco <item_path>[ ...] [-a | --all] [--symlink] [--silent] [--keepchanges | -k] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]

If an item is checked out and you do not want to checkin it, you can undo the checkout using this command. Both files and folders can be unchecked out. The item will be updated to the state it had before checking it out.

The 'undocheckout' command can read paths from stdin. To do this, pass a single dash "-". Example:

cm undocheckout checkin -

Paths will be read until an empty line is entered. This allows you to use pipe to specify for which files to undo the checkout. Example:

dir /S /B *.c | cm undocheckout --all -

(In Windows, undoes the checkout of all .c files in the workspace.)

(Undoes checkouts in the current directory.)

cm undocheckout file1.txt file2.txt

cm unco c:\workspace\file.txt

(Undoes checkouts of the selected files.)

(Undoes checkouts or local modifications of 'file1.txt')

cm unco link --symlink

(Applies the undocheckout operation to the symlink file and not to the target.)

cm status --short --changelist=pending_to_review | cm undocheckout -

(Undoes client changelist. The command above will list the paths in the changelist named 'pending_to_review' and the path list will be redirected to the input of the undocheckout command).

cm unco . --machinereadable

(Undoes checkouts in the current directory, and prints the result in a simplified, easier-to-parse format.)

cm unco . --machinereadable --startlineseparator=">" --endlineseparator="<" --fieldseparator=","

(Undoes checkouts in the current directory, and prints the result in a simplified, easier to parse format, starting and ending the lines, and separating the fields, with the specified strings.)

**Examples:**

Example 1 (unknown):
```unknown
cm undocheckout | unco <item_path>[ ...] [-a | --all] [--symlink] [--silent] [--keepchanges | -k] [--machinereadable [--startlineseparator=<sep>] [--endlineseparator=<sep>] [--fieldseparator=<sep>]]
```

Example 2 (unknown):
```unknown
cm undocheckout checkin -
```

Example 3 (unknown):
```unknown
dir /S /B *.c | cm undocheckout --all -
```

Example 4 (unknown):
```unknown
cm undocheckout .
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/push-notifications/manual/License

---

## Pricing examples

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/pricing-examples

**Contents:**
- Pricing examples#
- Prototyping#
- Scale testing#
- Additional resources#

The following examples serve to illustrate some Multiplay Hosting pricing scenarios.

Assume you are prototyping your multiplayer game. You test various builds and build configurations per week according to the following schedule:

You have two online machines, with two CPU cores and 8 GiB of RAM, running in two locations, for each test.

You would incur the following usage:

Approximately 100 GiB of storage is reserved in a month.

You would incur the following usage:

Additionally, approximately 30 GiB of egress traffic is incurred.

You would incur the following usage:

Your $800 credit automatically applies to your bill for the month, with $780.54 remaining toward your following months' invoices.

The $800 sign-up credit is designed to enable moderate-scale testing for at least a month.

Assume you are testing an alpha release of your multiplayer game. Based on your scaling settings and build configurations, you have the equivalent of six online machines, with two CPU and 8 GiB of RAM, running in the month, in three locations.

You would incur the following usage:

Approximately 300 GiB of storage is reserved in the month.

You would incur the following usage:

Additionally, approximately 1500 GiB of egress traffic is incurred.

You would incur the following usage:

Your $800 credit automatically applies to your bill for the month, with $53.44 remaining toward your following months' invoices.

---

## Use case sample: Announce a level up to all players in joined lobbies

**URL:** https://docs.unity.com/ugs/en-us/manual/cloud-code/manual/triggers/tutorials/use-cases/announce-level-up

**Contents:**
- Use case sample: Announce a level up to all players in joined lobbies#
- Prerequisites#
  - Authenticate using a Service Account#
  - Configure the UGS CLI#
- Examine the key-saved event#
- Set up Cloud Code#
- Configure a trigger#
- Set up Lobby#
- Add players to a lobby#
- Validate the result#

This use case sample demonstrates how to use Triggers to announce a player’s level up to all other players in any lobbies the player is in. The sample uses the key-saved event that the Cloud Save service emits. The sample notifies players who are in the same Lobby as the player who leveled about the level up through a push message.

The trigger uses a filter to evaluate the event payload so that the Cloud Code module only triggers when the player levels up and a player entity emits the Cloud Save event.

WARNING: Ensure you are using at least version 1.7.1 of the UGS CLI to follow this sample, as this includes the required features for Triggers. Otherwise, the configurations will not deploy with filters.

Note: You can only use push messages with Cloud Code modules.

You must first create a service account with required access roles.

Before you can call the Triggers service, you must authenticate using a Service Account.

Add Product roles and create a key:

For more information, refer to Authentication.

Follow the steps below to get started with the UGS CLI:

Configure your Project ID and Environment as such:ugs config set project-id <your-project-id>ugs config set environment-name <your-environment-name>

Use the Service account that you created to authenticate. Refer to Get Authenticated.

The Cloud Save service emits a key-saved event when a Cloud Save key is saved. The event payload looks like this:

The event passes the event payload to Cloud Code as parameters.

Refer to Cloud Save: Key Saved for more information.

Define a module endpoint that sends a push message to all players in the lobby when a player levels up.

Create a AnnounceLevelUp module function with contents as below:

Refer to Deploying Hello World to learn how to deploy a module.

Note: If you are deploying the module using the UGS CLI, don't forget to add additional Service Account role of Cloud Code Editor.

To connect your Cloud Code resource to the Cloud Save key-saved event, create a trigger. The trigger executes the Cloud Code module when the event is fired, for example, every time a player saves a key.

WARNING: To follow this sample, you need to use 1.7.1 or above of the UGS CLI, so that you have the required features for Triggers. Otherwise, the configurations don't deploy with filters.

The filter in the trigger configuration evaluates the event payload to only trigger the Cloud Code module when the player levels up and the Cloud Save event is emitted by a player entity.

You should get a response similar to the following:

The sample trigger executes your Cloud Code module function when a player saves a value to the LEVEL key.

To follow the sample, you need to create a Lobby. You can use a helper Cloud Code script from the Unity Dashboard. to achieve this:

Note down the lobby ID.

You can run the following Cloud Code script to add players to the lobby you created from the Unity Dashboard. Make sure to select the Generate icon to regenerate the Player ID token on every test run to add a new player.

Note down one of the player ID of the player you added to the lobby. You can use this later to validate the result by updating their Cloud Save data.

The script takes in lobbyId as parameter.

Note: When you add players to the lobby, remember the maximum number of players allowed in the lobby. Leave a spare slot so you can add the player that you are authenticated as in the Unity project to test the sample later.

To validate the result, you can set up a Unity project that subscribes to push messages and use the Cloud Code script for adding players you created earlier to make the authenticated player join a lobby.

To subscribe to push messages, you need to install the Cloud Code SDK and link your Unity Gaming Services project to the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

In Unity Editor, select Edit > Project Settings > Services.

Link your project.If your project doesn't have a Unity project ID:

If you have an existing Unity project ID:

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script with the UnityEditor.CloudProjectSettings.projectId property.

To install the latest Cloud Code package for Unity Editor:

Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

You can subscribe to messages with Cloud Code SDK versions 2.4.0+.

To subscribe to player-level messages, set up a Monobehaviour script. Refer to Send push messages for more information.

You can use the sample code below for your MonoBehaviour script:

The first time you run the Monobehaviour script, it logs a player ID. Note this value down.

You can use the Cloud Code script for adding players you created earlier to make the authenticated player join a lobby. Pass in the lobby ID you created earlier as the lobbyId parameter and player ID you noted down when running the Unity project as the playerId parameter.

You can update the Cloud Save key to trigger the Cloud Code module by running the script below.

It takes in a string parameter playerId and a number parameter level.

Note: If you have a custom trigger using a filter with the event's value, ensure you specify the level parameter as a number. With no specific type parameter defined, the parameter is passed as a string. If your filter evaluates the value as a number, and you pass in a string, the trigger won't work.

Use the player ID of one of the players you added to the lobby earlier. This ensures that the player authenticated in the Unity project receives the message, as they are in the same lobby.

Ensure that the Unity project is running, the authenticated player in your Unity project is in a lobby, and update the LEVEL key in Cloud Save.

You should encounter a push message sent when your player score is beaten in the Unity Editor:

**Examples:**

Example 1 (unknown):
```unknown
key_id:secret_key
```

Example 2 (unknown):
```unknown
ugs config set project-id <your-project-id>
```

Example 3 (unknown):
```unknown
ugs config set environment-name <your-environment-name>
```

Example 4 (unknown):
```unknown
{
  "id": "7LpyhpsIvEczGkDI1r8J6gHhHezL",
  "idType": "player",
  "key": "LEVEL",
  "value": 1,
  "valueIncluded": true,
  "writeLock": "7b8920a57912509f6b5cbb183eb7fcb0",
  "accessClass": "default",
  "modifiedDate": "2021-03-04T09:00:00Z"
}
```

---

## Multiplay Hosting SDK for Unreal Engine

**URL:** https://docs.unity.com/ugs/manual/game-server-hosting/manual/sdk/unreal-engine-sdk/overview

**Contents:**
- Multiplay Hosting SDK for Unreal Engine#

The Multiplay Hosting SDK for Unreal Engine includes all the functionality necessary to leverage Multiplay scaling and game server services in your game.

For more information about using Unity Gaming Services products with Unreal Engine, refer to Multiplay Hosting SDK for the Unreal Engine, which contains Multiplay Hosting, Matchmaker and Authentication in one convenient package.

Refer to Get started (UGS for the Unreal Engine) to download and install the SDK.

Note: Refer to Multiplay Hosting SDK for Unity if you’re using the Unity Engine to develop your game.

Important: The Multiplay Hosting SDK for Unreal Engine is incompatible because it's now included in the UGS SDK. If you're already using the Multiplay Hosting SDK for Unreal Engine, delete it to resolve the migration. No code change is required.

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/economy/manual

---

## PARTIAL REMOVE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/partial-remove

**Contents:**
- PARTIAL REMOVE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
    - Requirements#
  - Examples#
    - (Removes 'src'. If 'src' is a directory, this is the same that#

Deletes a file or directory from version control.

cm partial remove | rm <item_path>[ ...] [--nodisk]

Items are deleted from disk. Removed items are removed from the parent directory in the source code control.

cm partial remove src

cm partial remove -R src.)

cm partial remove c:\workspace\pic01.png --nodisk

(Removes 'pic01.png' from version control, but keeps it on disk.)

**Examples:**

Example 1 (unknown):
```unknown
cm partial remove | rm <item_path>[ ...] [--nodisk]
```

Example 2 (unknown):
```unknown
cm partial remove src
```

Example 3 (unknown):
```unknown
cm partial remove -R src.)
```

Example 4 (unknown):
```unknown
cm partial remove c:\workspace\pic01.png --nodisk
```

---

## Game Overrides and Settings

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/game-overrides-and-settings

**Contents:**
- Game Overrides and Settings#
- Adding new Settings#
- Adding new Game Overrides#
  - Name#
  - Targeting Strategy#
  - Condition#
    - JEXL support#
  - Rollout Percentage#
  - Content type#
  - Start date and time#

Unity Remote Config uses Game Overrides to target specific user groups and deliver different settings for each group. Game Overrides are linked to Settings, which you map to variables in your game code to override their default values when the audience criteria for a Game Override is met.

Plan Remote Config settings early, when you design your game or before a new deployment. Unity recommends including inert Remote Config settings with your initial deployment, which you can later apply once you understand how your audience uses your game, and how it performs on different devices.

In the Unity Editor, select Window > Remote Config to begin working with Settings.

Use the Remote Config window to configure your Remote Config Settings. You can configure Game Overrides in the Unity Dashboard which you can access with the View in Dashboard button. Game Overrides dictate conditions or player segments to surface Settings. By default, you start with one config: Settings Config. This config contains the default Settings that all users receive unless an active Game Override with higher priority applies.

Important: Each environment has a unique Game Overrides set. Before configuring Game Overrides for your game, make sure you select the correct Remote Config environment in the Remote Config window.

A Setting is a key/value pair. Map the key name to a variable in your game code, so you can dynamically change its value without changing your code.

The default Settings Config config contains every Setting you create for a given environment. To create a new Setting, highlight the Settings Config config, then select the Add Setting button at the bottom of the right panel.

Note: You must create Settings in the Editor, so the game code can consume them. However, once you’ve created Settings in the game binary, you can also update them using the Remote Config REST APIs or the Unity Dashboard. See Interfaces for more information.

Each Setting consists of a Key, Type, and Value:

To create a new Remote Config Game Override, select View in Dashboard > View Overrides > Create Override. Each Game Override has five parameters, which are detailed below:

The Name is the name for your Game Override. For example, you might name a difficulty curve for Game Override level_1_enemies, or a seasonal event halloween_event.

The Targeting Strategy defines the kind of audience for your Game Override. It can be Stateful, where you pick audiences such as 'All Spenders' or 'Existing Players' etc, or Stateless where you can define target audience based on the Condition

The Condition is a JEXL expression (see JEXL support section below) of contextual data attributes used to define the audience to apply to a Game Override. You can use multiple criteria to define this segment. Remote Config currently supports three attribute categories:

The user category contains custom developer-defined attributes that describe the user (for example, subscriber status, name, age), which you must pass to RemoteConfigService.Instance.FetchConfigs<T, T2>(T userAttributes, T2 appAttributes).

Note: When using SetCustomUserId, the Id you pass in is automatically attached to your user attributes as customUserId.

The app category contains custom developer-defined attributes that describe the application (for example, connectivity status, app version, current level), which you must pass to RemoteConfigService.Instance.FetchConfigs<T, T2>(T userAttributes, T2 appAttributes).

The unity category contains predefined attributes, detailed in the table below:

Note: The unity attributes listed are subject to change. For a complete updated list, please view the REST API documentation.

For example, if you want to define a Game Override that targets users with a score greater than 10, you can define a score property from the app context using dot notation:

You can also reference multiple attributes within the same Game Override:

To define a Game Override that matches all conditions and always applies, simply enter true.

Remote Config supports the Java Expression Language (JEXL) spec, with some exceptions:

Note: You cannot nest attributes (for example, app.level1.score). Using an invalid JEXL string, or leaving the Condition field blank results in an error.

The Rollout Percentage dictates the percentage of your user base that adheres to this Game Override. For values less than 100, Unity randomly assigns the Game Override to that percent of your players on a user ID basis. While experiences might differ from player to player, each individual player has a consistent experience across play sessions. This parameter is particularly useful when combined with analytics to parse results.

Depending on services, you use, there is many types of content which might be chosen for a particular Game Override, Config Overrides being utilized from Remote Config, or some other content like Currency or Inventor Item utilized by Economy Services.

You can optionally specify a start date and time, which dictates when the Game Override takes effect. Timestamps are represented as strings in the ISO 8601 UTC format (YYYY-MM-DDThh:mm:ssZ). If you don't specify a value, the Game Override immediately takes effect upon activation.

You can optionally specify an end date and time, which dictates when the Game Override ceases to be active. Timestamps are represented as strings in the ISO 8601 UTC format (YYYY-MM-DDThh:mm:ssZ). If you don't specify a value, the Game Override remains in effect until you deactivate it.

To apply a Setting to a Game Override, navigate to the desired Game Override and edit the Content block to view a list of all the available Settings.

Use the button at the top of the Game Override page to enable or disable it.

For editing of Settings Keys and Values in the Remote Config Window in the Editor, make sure you save and Push your changes.

Until you do so, your configurations are only stored locally. Make sure you push your changes to save them before switching Remote Config environments.

Select the trashcan next to the Setting to delete it. Note that you should not delete a Setting if an active Game Override is currently using it.

You can assign each Game Override a weighted priority value Low, Medium or High. If you want to numerically assign priority values that functionality is available via the Advanced Editor between 1 (highest priority) and 1000 (lowest priority). To do so, Select the Edit Schedule -> Scheduling field in the Game Override, select Use Advanced Editor and enter an integer value.

To edit a Game Override and save your changes:

Note: When you pull remote changes to your local configuration, the settings retrieved from the service overwrite and delete your local settings.

If you're using settings of type JSON, the Remote Config window displays the JSON Editor dialog. This lets you format and validate the JSON value. To open this window, select Edit for the JSON setting:

If you enter a valid but unformatted JSON value, the validation indicator is green. Use the Format button to reformat the JSON object.

If the json value is invalid, the validation indicator is red and you cannot submit the JSON object.

The Select json object field lets you load a JSON file (if available from your /Assets folder). To choose a file, select the button to the right of the field.

You don't need to deploy a new version of your application to propagate changes to your configuration. Client devices request a refresh of your Remote Config settings whenever players initiate a new session of your application. Remote Config defines a new session when the user launches the application, or returns to the application after it has been in the background for at least 30 minutes.

If the client has no internet connection and cannot communicate with the Remote Config service, the application uses the last settings it received and cached.

Note: Requesting settings from the Remote Config service is an asynchronous process that might not complete before your initial Scene finishes loading, or in some edge cases might not complete at all. Therefore, always initialize your game variables with reasonable defaults.

Once you’ve configured your Game Overrides and Settings, integrate Remote Config with your game code.

**Examples:**

Example 1 (unknown):
```unknown
enemyHealth
```

Example 2 (unknown):
```unknown
eventPackPrice
```

Example 3 (unknown):
```unknown
enableBetaFeature
```

Example 4 (unknown):
```unknown
‘jack-o-lantern’
```

---

## 

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/branch-delete

---

## RCR - Caching Mechanism

**URL:** https://docs.unity.com/ugs/en-us/manual/remote-config/manual/caching-mechanism

**Contents:**
- RCR - Caching Mechanism#
- Cache file location#
- Caching Scenarios#

Remote Config Runtime uses caching mechanism, which works as follows:

The location of the cache file is in Application.persistentDataPath/{YourApp}/RemoteConfigCache.json, which differs by platform, as depicted in persistentDataPath docs

E.g for mac, the cache file can be found under: /Users/YourName/Library/Application Support/DefaultCompany/{YourApp}/RemoteConfigCache.json

Contents of the example cache file:

Within caching mechanism, we maintain two values, requestOrigin and status which can be utilized to understand caching scenarios.

They can be accessed from configResponse variable, e.g this is how we utilize requestOrigin within the callback:

Possible values for requestOrigin are: {0:Default, 1:Cached, 2:Remote}

Possible values for status are: {0:None, 1:Failed, 2:Success, 3:Pending}

Based on those values, we recognize the following caching scenarios:

Those scenarios should fit the table below:

**Examples:**

Example 1 (unknown):
```unknown
Application.persistentDataPath/{YourApp}/RemoteConfigCache.json
```

Example 2 (unknown):
```unknown
{
    "settings": {
        "requestOrigin": 2,
        "status": 2,
        "body": {
            "configs": {
                "settings": {
                    "rotateY": 30.0,
                    "rotSpeed": 44.0,
                    "swordName": "Singing Sword",
                    "rotateZ": 4.0,
                    "jsonCubeCustom": {
                        "rotateX": 20,
                        "color": {
                            "r": 0.2,
                            "g": 0.2,
                            "b": 0.3,
                            "a": 1
                        }
                    },
                    "swordPrice": 5,
                    "testdateString": "2021-10-21T10:00:00.0000001-07:00",
                    "rotateX": 777.0
                }
            },
            "metadata": {
                "assignmentId": "355faf1d-9ce0-4528-9267-95ffe07ed891",
                "environmentId": "11daa94d-0ffa-41e2-8579-f4acbbdb3987",
                "bundle": "657abf6ee46c9dc227581a7adba48bca89dfb620"
            }
        },
        "headers": {
            "Date": "Mon, 15 Nov 2021 17:44:08 GMT",
            "Content-Type": "application/json;charset=utf-8",
            "Access-Control-Allow-Origin": "\*",
            "Content-Length": "429",
            "Server": "Jetty(9.4.z-SNAPSHOT)",
            "Via": "1.1 google",
            "Alt-Svc": "clear",
            "Connection": "keep-alive"
        }
    }
}
```

Example 3 (unknown):
```unknown
{
    "settings": {
        "requestOrigin": 2,
        "status": 2,
        "body": {
            "configs": {
                "settings": {
                    "rotateY": 30.0,
                    "rotSpeed": 44.0,
                    "swordName": "Singing Sword",
                    "rotateZ": 4.0,
                    "jsonCubeCustom": {
                        "rotateX": 20,
                        "color": {
                            "r": 0.2,
                            "g": 0.2,
                            "b": 0.3,
                            "a": 1
                        }
                    },
                    "swordPrice": 5,
                    "testdateString": "2021-10-21T10:00:00.0000001-07:00",
                    "rotateX": 777.0
                }
            },
            "metadata": {
                "assignmentId": "355faf1d-9ce0-4528-9267-95ffe07ed891",
                "environmentId": "11daa94d-0ffa-41e2-8579-f4acbbdb3987",
                "bundle": "657abf6ee46c9dc227581a7adba48bca89dfb620"
            }
        },
        "headers": {
            "Date": "Mon, 15 Nov 2021 17:44:08 GMT",
            "Content-Type": "application/json;charset=utf-8",
            "Access-Control-Allow-Origin": "\*",
            "Content-Length": "429",
            "Server": "Jetty(9.4.z-SNAPSHOT)",
            "Via": "1.1 google",
            "Alt-Svc": "clear",
            "Connection": "keep-alive"
        }
    }
}
```

Example 4 (unknown):
```unknown
requestOrigin
```

---

## 

**URL:** https://docs.unity.com/ugs-overview/en/manual/getting-started

---

## Access Control

**URL:** https://docs.unity.com/ugs/en-us/manual/overview/manual/access-control

**Contents:**
- Access Control#
- How Access Control works#
- How to use Access Control#
  - Example policies#
  - Error responses#
- Policy selection in Access Control#
- Resource URNs and Query Parameter Handling#
  - Rules for Query Parameter Handling in Resource URNs#
  - Backward Compatibility#
- Best practices#

Access Control for Unity Gaming Services (UGS) allows you to defend your game state and logic in UGS from cheaters and exploiters. Access Control (also known as API Authorization) is important as it lets you control who can access, modify, or delete game data and resources in order to protect the game from unauthorized access.

API authorization for UGS is the process of determining what actions a user is allowed to perform once they have been authenticated. Authentication verifies that a user is who they claim to be. Together, authentication and authorization provide a secure way to control access to APIs and access to resources. UGS provides an Authentication solution that works with API authorization described in this documentation.

Without authentication, anyone can access the API and potentially perform unauthorized actions. For example, if an API allows users to view sensitive information or make changes to data, and there is no authentication in place, anyone can access that information or make changes without permission.

Authentication establishes the identity of the user, and authorization controls what actions they are allowed to perform. Authentication provides the necessary foundation for authorization to work. It’s like a key that unlocks the door of the API, but the authorization decides if the user is allowed to enter, and what they can do once they are in.

Access Control in UGS is configured using resource policies. UGS services enforce rules for who can access those services and what actions they are allowed to perform.

When a user attempts to access a UGS service, the service checks the user's identity against the configured policies and either denies or allows an API request.

A resource policy is a collection of statements. The statements are defined in terms of the user’s identity (the Principal attribute), what actions (the Action attribute) are restricted or allowed (the Effect attribute), and the resource the policy applies to (the Resource attribute). A policy also contains a Sid attribute (Statement Identifier), a user-defined descriptive name for the given policy which can only contain alphanumeric characters and hyphens.

The resources in the policies are defined as Uniform Resource Names (URNs), which typically end in API paths that make up the component parts of the URN.

Resource policies are configured on a per-project or per-player basis. A project policy is evaluated for all Principals that call UGS services for that project. A player policy is only evaluated for an individual player within the scope of a project and environment.

Here is an example of a valid URN in the Economy service:

It uses a glob pattern to match a set of resources that share a common pattern. The following table describes the different components of this URN.

Because URN matching uses glob patterns, the above URN can also be defined as the following.

urn:ugs:economy:/**/currencies/gold

When no Access Control policies are created, Access Control defaults to allowing all authenticated API calls from authenticated players. That could be described using the following resource policy.

The following example shows how to create a valid policy to allow authenticated players to read, but not change (write), the gold currency in Economy via an API call.

Alternatively, to completely deny access to authenticated players to all APIs within Economy:

Use the REST API or the UGS CLI to create resource policies for UGS. These policies only need to be created once and are evaluated and enforced for each API call to UGS within the context of the authenticated caller.

Do not allow Players to execute any Cloud Code scripts:

This resource policy denies access to all actions on cloud code scripts in the project that a Player is authenticated for. Cloud Code only provides an execute API as a POST request to that API, which falls under the Write Action in the above policy statement.

Below is another example of what a resource policy for Cloud Save could be:

This resource policy denies write access to all the cloud save data for any authenticated player for the project, including all nested paths and subfolders under items for a user or group with a Player identity. This effectively prevents Players from directly writing data to Cloud Save. Combining this policy with the previous policy for Cloud Code, means a developer could write data to Cloud Save via Cloud Code and implement any additional game logic within Cloud Code.

Below are the different components that make up a policy and what they do.

When a player attempts to access a resource for which they don't have appropriate permissions, an error response is returned with a status code of 403 Forbidden. The exact format of the error response depends on the type of access control policy in place.

If a player is restricted from accessing a resource based on a project-based policy, the error response includes the following fields:

If a player is restricted from accessing a resource based on a player-based policy, the error response includes the following fields:

If the player is temporarily banned, the error response also includes an expiresAt field which indicates when the ban expires:

If the player is permanently banned, the error response doesn't include an expiresAt field. You should handle these error responses appropriately in your application code to ensure a smooth user experience.

When Access Control policies are evaluated, only the most specific rule wins and its effect is applied.

Below are three example policies.

If a request is made to */currencies/silver, the second rule, allow /currencies/*, is applied because it is more specific than the first rule.

If a request is made to */currencies/gold, the third rule, deny */currencies/gold, is applied because it is the most specific rule that matches the request.

If there are multiple policies that list the exact same Resource, then the Deny Effect always takes precedence.

Resource URNs support query parameter-specific matching for flexible policy definitions. The rules governing how query parameters are evaluated depend on the structure of resource URNs in policies.

Access Control policies evaluate resource URNs as follows:

1.URNs with Query Parameters

If the defined policy URN includes specific query parameters (?), such as:

The policy matches requests that contain the exact path and query parameters specified in the URN. This enables precise control over requests based on the path and query parameter values.

2.URNs with a Wildcard(*)

If the defined policy URN ends with a *, such as:

The policy matches requests with the specified path (up to the wildcard) and any query parameters attached to the request.

3. URNs Without Query Parameters or Wildcard (*)

If the defined policy URN does not contain a ? or end with a *, such as:

Query parameters from the request are stripped during evaluation. This ensures that the policy applies strictly to the path, preventing misuse of query parameters to bypass authorization policies.

Resource URN matching rules are designed to maintain backward compatibility with existing policies. Policies created before this update that do not define query parameters (or use wildcards * at the end) will continue to evaluate requests based only on the path, excluding query parameters.

This avoids unintended bypasses or behaviors while enabling query parameter matching for newly defined or updated policies.

Start with a default policy of denying all access and explicitly grant access to specific APIs or resources.

Grant only the minimum permissions required for an API or resource.

Create policies for specific API methods and resources, rather than for all APIs and resources.

The URNs for the services are listed below. Note that Friends are Player Name use the same URN prefix, so you may need to add the routes you want to block into the resource field.

Regularly review and update API policies to ensure they reflect the current state of the game and to remove unnecessary permissions.

The Access Control APIs are accessible via web endpoints, or REST APIs. REST APIs provide flexibility to automate your workflows using your favorite language and game development engine.

Refer to the Access Control REST API documentation for more information. Refer to the Service Account Authentication documentation for more information on how to authenticate your API calls.

The following example shows how to set a resource policy using the REST APIs with the cURL tool.

To apply your configuration, you must deploy the configuration to the Access Control service.

To deploy Access Control configurations in the Unity Editor you must first install the required packages and link your Unity Gaming Services project to the Unity Editor.

Link your Unity Gaming Services project with the Unity Editor. You can find your UGS project ID in the Unity Dashboard.

In the Unity Editor, select Edit > Project Settings > Services.

If your project doesn't have a Unity project ID:

If you have an existing Unity project ID:

Your Unity Project ID appears, and the project is now linked to Unity services. You can also access your project ID in a Unity Editor script using UnityEditor.CloudProjectSettings.projectId.

To create Access Control configurations within the Editor, you must install the following packages:

Check Unity - Manual: Package Manager window to familiarize yourself with the Unity Package Manager interface.

To install these packages and add them to your list of available packages:

Follow these steps to create an Access Control configuration:

The new configuration is now visible in the Project window, and in the Deployment window, accessible by selecting Window > Deployment.

There are two methods to edit an existing Access Control configuration:

Use the UGS Access Control CLI for simpler management and automation of your Access Control configuration.

To configure the UGS CLI:

Run the following command:

ugs deploy <path-to-access-control-file>

**Examples:**

Example 1 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/*/currencies/gold
```

Example 2 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/*/currencies/gold
```

Example 3 (unknown):
```unknown
urn:ugs:economy:/v2/project/
```

Example 4 (unknown):
```unknown
urn:ugs:economy:/v2/project/*/player/
```

---

## Get scores for other players from a leaderboard version

**URL:** https://docs.unity.com/ugs/en-us/manual/leaderboards/manual/tutorials/unity-sdk/get-score-other-player-version

**Contents:**
- Get scores for other players from a leaderboard version#

Get the scores for other players from a leaderboard version with the GetVersionScoresByPlayerIdsAsync method:

Metadata is not retrieved by default.

To get the score with any associated metadata, use the IncludeMetadata option on the GetVersionScoresByPlayerIdsOptions configuration object:

For details on how to get available leaderboard version IDs, visit Get available leaderboard version.

For methods that retrieve scores: if your player has not submitted a score and the leaderboard is bucketed, the player is not assigned a bucket. A failed score retrieval returns an error that has its Reason field set to ScoreSubmissionRequired.

**Examples:**

Example 1 (unknown):
```unknown
GetVersionScoresByPlayerIdsAsync
```

Example 2 (unknown):
```unknown
public async void GetVersionScoresByPlayerIds(string leaderboardId, string versionId)
{
    var playerIds = new List<string>{ "abc123", "abc456" };
    var scoresResponse = await LeaderboardsService.Instance
        .GetVersionScoresByPlayerIdsAsync(
            leaderboardId,
            versionId,
            playerIds
        );
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 3 (unknown):
```unknown
public async void GetVersionScoresByPlayerIds(string leaderboardId, string versionId)
{
    var playerIds = new List<string>{ "abc123", "abc456" };
    var scoresResponse = await LeaderboardsService.Instance
        .GetVersionScoresByPlayerIdsAsync(
            leaderboardId,
            versionId,
            playerIds
        );
    Debug.Log(JsonConvert.SerializeObject(scoresResponse));
}
```

Example 4 (unknown):
```unknown
IncludeMetadata
```

---

## Plugin for Bamboo

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/bamboo-plugin

**Contents:**
- Plugin for Bamboo#
- How to install the UVCS plugin for Bamboo#
- Plastic SCM configuration and Bamboo service account#
  - Option A#
  - Option B#
- Plan branch filtering#

The Bamboo plugin internally uses the UVCS command line client. So, the user running the Bamboo service must have a valid Plastic SCM client configuration. There are two options:

Change the user account:

If you don't want to change the user running the Bamboo service, an alternative configuration is:

Branches can be filtered in two ways:

Specifying an attribute name and value pair as follows: attribute_name=attribute_value. For example: status=validated which means that only the branches with an attribute named status with the value validated will be sent to Bamboo to create a plan branch.

Specifying a complex query valid for cm find branch command (which is the underlying plastic command executed to retrieve the candidate branches). It is not mandatory to specify a plastic attribute in this mode. Two examples below:

**Examples:**

Example 1 (unknown):
```unknown
<UVCS install directory>/client/plugins/bambooplugin/<bamboo-plugin.jar>
```

Example 2 (unknown):
```unknown
<Bamboo server installation directory>/atlassian-bamboo/WEB-INF/lib
```

Example 3 (unknown):
```unknown
plastic --configure
```

Example 4 (unknown):
```unknown
clconfigureclient
```

---

## Heartbeat a lobby

**URL:** https://docs.unity.com/ugs/en-us/manual/lobby/manual/heartbeat-a-lobby

**Contents:**
- Heartbeat a lobby#

Important: The Multiplayer Services SDK automatically keeps the session alive. If you're using sessions, you don't have to send a heartbeat ping.

Lobbies are marked as inactive if they haven’t been updated or sent a heartbeat request by the host within a given duration. The default active lifespan of a lobby is 30 seconds. You can configure the active lifespan for lobbies in your project.

Note: Updates only count if they make a change to the lobby properties; this does not include changes to the host's player data, and doesn't include no-op updates.

The main purpose of hiding inactive lobbies is to prevent players from continually finding/joining abandoned lobbies. Inactive public lobbies don't appear in query results nor are they joinable through ‘Quick Join’, and both public and private inactive lobbies are eventually automatically deleted. Inactive lobbies can be reactivated by being updated or sent a heartbeat request by the host.

Note: Inactive lobbies are automatically excluded from queries using a filter on the LastUpdated field. If you include a LastUpdated filter it overrides the default filter and can include inactive lobbies in query results. The Get Lobby API is not affected by inactive status.

After 1 hour of inactivity, a lobby is considered expired. An expired lobby may be deleted at any time. Upon deletion, a lobby is no longer available in queries or any APIs. This duration isn't configurable. You may reactivate an expired lobby by updating it or sending a heartbeat.

The following code sample shows how to integrate a co-routine with lobby creation to periodically heartbeat a new lobby:

While hosts should periodically heartbeat their lobbies when in use, hosts should also be mindful of these lobbies and delete them afterward. One way to do this is to loop over created lobbies during shutdown.

The following code sample shows how to use a MonoBehaviour’s OnApplicationQuit() function to delete created lobbies:

**Examples:**

Example 1 (unknown):
```unknown
LastUpdated
```

Example 2 (unknown):
```unknown
LastUpdated
```

Example 3 (unknown):
```unknown
async Task<Lobby> CreateLobbyWithHeartbeatAsync()
{
    string lobbyName = "test lobby";
    int maxPlayers = 4;
    CreateLobbyOptions options = new CreateLobbyOptions();

    // Lobby parameters code goes here...
    // See 'Creating a Lobby' for example parameters
    var lobby = await LobbyService.Instance.CreateLobbyAsync(lobbyName, maxPlayers, options);

    // Heartbeat the lobby every 15 seconds.
    StartCoroutine(HeartbeatLobbyCoroutine(lobby.Id, 15));
    return lobby;
}

IEnumerator HeartbeatLobbyCoroutine(string lobbyId, float waitTimeSeconds)
{
    var delay = new WaitForSecondsRealtime(waitTimeSeconds);

    while (true)
    {
        LobbyService.Instance.SendHeartbeatPingAsync(lobbyId);
        yield return delay;
    }
}
```

Example 4 (unknown):
```unknown
async Task<Lobby> CreateLobbyWithHeartbeatAsync()
{
    string lobbyName = "test lobby";
    int maxPlayers = 4;
    CreateLobbyOptions options = new CreateLobbyOptions();

    // Lobby parameters code goes here...
    // See 'Creating a Lobby' for example parameters
    var lobby = await LobbyService.Instance.CreateLobbyAsync(lobbyName, maxPlayers, options);

    // Heartbeat the lobby every 15 seconds.
    StartCoroutine(HeartbeatLobbyCoroutine(lobby.Id, 15));
    return lobby;
}

IEnumerator HeartbeatLobbyCoroutine(string lobbyId, float waitTimeSeconds)
{
    var delay = new WaitForSecondsRealtime(waitTimeSeconds);

    while (true)
    {
        LobbyService.Instance.SendHeartbeatPingAsync(lobbyId);
        yield return delay;
    }
}
```

---

## User roles

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/user-roles

**Contents:**
- User roles#
- Safety Moderator#
- Safety Admin#
- Related pages#

To access the Moderation Platform, users must have one of two roles: Safety Moderator or Safety Admin. Each role comes with distinct permissions:

To assign a role to a user:

By default, Organization members with the base role Owner or Manager have all the safety roles.

Safety Moderator is a role that is assigned to a user within a project to gain access to the Moderation Platform.

The Moderation Platform assists moderation teams with online experiences by providing additional context, through Safe Text, to user communications. Safe Text will highlight text messages that are identified as inappropriate. The analysis generates a report for the moderation team to aid in decision-making and help the moderation team prioritize and quickly identify whether the incident violated any policies.

Once connected to Safe Text, and sessions are processed, moderators can use the Moderation Platform to analyze session results.

Safety Moderators can:

The Moderator platform allows administrators, users with the Safety Admin role, to configure certain features used by moderation teams to identify problematic content.

These features are configurable to help optimize processes relative to the needs of respective game communities and moderation teams.

Review the Settings section for more information on how to configure the Moderation service.

---

## Use a proxy server

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/configure/use-proxy-server

**Contents:**
- Use a proxy server#
  - Windows operations#
- Configure the proxy server#
- Configure the clients#
- Cache data from UVCS cloud#
  - Configure the disk cache limit#

You can use a proxy server with Unity Version Control (UVCS) to help you balance traffic between two machines. For more information, refer to Proxy servers.

The UVCS proxy server is bundled as a sub command of the UVCS server executable file.

To start the proxy, run plasticd proxy.

The following operations are available with the plasticd proxy sub command:

To configure your proxy server, you can edit the configuration file.

You can find the plasticcached.network.conf file in the \PlasticSCM5\server\config_samples directory:

UVCS clients need to configure the proxy server:

To cache data from the cloud, install a Proxy (and your client too if you use encrypted data in the Cloud) and start to cache data.

You can limit the size of the on-disk cache.

To configure the disk cache limit, edit the MaxCacheSizeInGb setting in the plasticcached.conf file. For example, the following value ensures that the proxy cache size doesn’t exceed 20.5 GB.

A value of 0 disables the limit.

Note: For more information on proxy storage and how the UVCS monitors storage with the log file, refer to proxy storage.

**Examples:**

Example 1 (unknown):
```unknown
plasticd proxy
```

Example 2 (unknown):
```unknown
plasticd proxy
```

Example 3 (unknown):
```unknown
plasticd proxy --installservice
```

Example 4 (unknown):
```unknown
plasticd proxy --start
```

---

## Facebook

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-facebook

**Contents:**
- Facebook#
- Set up a Facebook account sign-in#
- Sign in a returning player or create new player#
- Update a player from anonymous to a Facebook account#
- Implement a Facebook sign-in authentication#
- Unlink Facebook account#
- Handle Facebook Limited Login on iOS devices#

Minimum SDK version: 2.0.0

This article guides you through the following scenarios in setting up authentication for players in your game with a Facebook account:

To provide a Facebook sign-in option for the players in your game, create an app in the Facebook Developer Portal and install Facebook's Unity SDK to sign in the user and get the access token.

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

Set up and install the Facebook SDK following Facebook’s getting started documentation.

Add Facebook as an Id Provider for Unity Authentication:

Implement the Facebook login using this sample code.

Unity Authentication supports Limited Login. This is the default on iOS unless your app is compliant with Apple's App Tracking Transparency (ATT) privacy protection framework, and the player has consented. If you are building for iOS devices, please take note of the section below on handling Limited Login.

The Facebook SDK doesn't work with Unity 2021.1 in play mode, as tracked in this Github issue. As a workaround, build a new Facebook.Unity.dll using this pull request.

We currently support the ‘Consumer’ and ‘Business’ app types.

You can use the SignInWithFacebookAsync method to either:

If no Unity Authentication player in your project is associated with the credentials, SignInWithFacebookAsync creates a new player. If a Unity Authentication player in your project is associated with the credentials, SignInWithFacebookAsync signs into that player's account. This function doesn't consider the cached player, and SignInWithFacebookAsync replaces the cached player.

After you’ve set up anonymous authentication, if the player wants to upgrade from being anonymous to creating a Facebook account and sign in using Facebook, the game should prompt the player to trigger the Facebook login and get the access token from Facebook. Then, call the LinkWithFacebookAsync API to link the player to the Facebook Access token.

If a cached player exists on the SDK, you can link the cached player to the Facebook Account.

For more information about cached players, please read the Sign In a Cached Player section.

When the player triggers the Facebook login by signing in or by creating a new player profile, and you have received the Facebook access token, call the following API to authenticate the player.

When the player triggers the Facebook login to login or create a new player, and you have received the Facebook access token, call the following API to sign-in the player: SignInWithFacebookAsync(string accessToken).

Use the UnlinkFacebookAsync API so your players can unlink their Facebook account. Once unlinked, if their account isn’t linked to any additional identity, it transitions to an anonymous account.

iOS 14 and later requires publishers to obtain permission to track the user's device across applications. This device setting is called App Tracking Transparency, or ATT. Please see Apple's documentation for more details. Without explicit consent, the Facebook SDK will default to the Facebook Limited Login flow. This provides a slightly different token, but it can still be used by Unity Authentication to associate a player.

To help with this integration, Unity provides an optional iOS support package which supports requesting consent and querying the consent status. It can be found in the Unity editor Package Manager as com.unity.ads.ios-support. For more details please refer to the package documentation and the App Tracking Transparency compliance page from the Unity Ads documentation.

On login if consent has been granted, then the global AccessToken instance should be used as normal for the call to Unity Autentication. But if the player has not explicitly consented, then you will need to use the AuthenticationToken from the callback result instead. Both AccessToken and AuthenticationToken may appear to be available at all times, but if the wrong one is used then the Unity Authentication service will not be able to verify the token and will return an error.

The following snippet is equivalent to the login examples above, except that it uses the iOS support package to request consent from the player, and uses the ATT status to select the appropriate token for signing in with Unity Authentication.

**Examples:**

Example 1 (javascript):
```javascript
using System.Collections.Generic;
using UnityEngine;

// Other needed dependencies
using Facebook.Unity;

public class FacebookExampleScript : MonoBehaviour
{
    public string Token;
    public string Error;

    // Awake function from Unity's MonoBehaviour
    void Awake()
    {
        if (!FB.IsInitialized)
        {
            // Initialize the Facebook SDK
            FB.Init(InitCallback, OnHideUnity);
        }
        else
        {
            // Already initialized, signal an app activation App Event
            FB.ActivateApp();
        }
    }

    void InitCallback()
    {
        if (FB.IsInitialized)
        {
            // Signal an app activation App Event
            FB.ActivateApp();
            // Continue with Facebook SDK
        }
        else
        {
            Debug.Log("Failed to Initialize the Facebook SDK");
        }
    }

    void OnHideUnity(bool isGameShown)
    {
        if (!isGameShown)
        {
            // Pause the game - we will need to hide
            Time.timeScale = 0;
        }
        else
        {
            // Resume the game - we're getting focus again
            Time.timeScale = 1;
        }
    }

    public void Login()
    {
        // Define the permissions
        var perms = new List<string>() { "public_profile", "email" };

        FB.LogInWithReadPermissions(perms, result =>
        {
            if (FB.IsLoggedIn)
            {
                Token = AccessToken.CurrentAccessToken.TokenString;
                Debug.Log($"Facebook Login token: {Token}");
            }
            else
            {
                Error = "User cancelled login";
                Debug.Log("[Facebook Login] User cancelled login");
            }
        });
    }
}
```

Example 2 (javascript):
```javascript
using System.Collections.Generic;
using UnityEngine;

// Other needed dependencies
using Facebook.Unity;

public class FacebookExampleScript : MonoBehaviour
{
    public string Token;
    public string Error;

    // Awake function from Unity's MonoBehaviour
    void Awake()
    {
        if (!FB.IsInitialized)
        {
            // Initialize the Facebook SDK
            FB.Init(InitCallback, OnHideUnity);
        }
        else
        {
            // Already initialized, signal an app activation App Event
            FB.ActivateApp();
        }
    }

    void InitCallback()
    {
        if (FB.IsInitialized)
        {
            // Signal an app activation App Event
            FB.ActivateApp();
            // Continue with Facebook SDK
        }
        else
        {
            Debug.Log("Failed to Initialize the Facebook SDK");
        }
    }

    void OnHideUnity(bool isGameShown)
    {
        if (!isGameShown)
        {
            // Pause the game - we will need to hide
            Time.timeScale = 0;
        }
        else
        {
            // Resume the game - we're getting focus again
            Time.timeScale = 1;
        }
    }

    public void Login()
    {
        // Define the permissions
        var perms = new List<string>() { "public_profile", "email" };

        FB.LogInWithReadPermissions(perms, result =>
        {
            if (FB.IsLoggedIn)
            {
                Token = AccessToken.CurrentAccessToken.TokenString;
                Debug.Log($"Facebook Login token: {Token}");
            }
            else
            {
                Error = "User cancelled login";
                Debug.Log("[Facebook Login] User cancelled login");
            }
        });
    }
}
```

Example 3 (unknown):
```unknown
SignInWithFacebookAsync
```

Example 4 (unknown):
```unknown
SignInWithFacebookAsync
```

---

## Install Wwise

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/vcs-plugins/wwise-plugin

**Contents:**
- Install Wwise#
- Install the plugin#
- Configure the plugin#
- Operations#

Open the Download page and click the big Download button. You'll need to sign in before you can actually download the tool. You need an account anyway to open Wwise.

The installer will open the Audiokinetic launcher, which will help you install whatever version of Wwise you need.

In the left menu, you can open the Wwise section to manage installations of Wwise on your computer. Under "Install new version", you can use the dropdown list to select any desired version. Note that only latest versions of each branch are listed by default. In case you need an intermediate version, you can select All instead of Latest in the first dropdown.

Once you find the right version of Wwise, you can proceed with the installation by clicking "Install..." at the bottom.

As part of the installation process, you can select a series of packages and development platforms to be included in the installation.

Once installed, you could launch Wwise by clicking the "Launch Wwise (64-bit)" button next to the version that you want.

But watch out! You need to install the plugin first.

The Unity Version Control installer includes a set of plugins for Wwise under the installation folder, typically C:\Program Files\PlasticSCM5\client\plugins\wwise, based on the version of Wwise you want to use.

In order to install the plugin, you just need to copy the DLL file matching your Wwise version under the corresponding Wwise installation folder, normally C:\Program Files (x86)\Audiokinetic\Wwise x.y.z\Authoring\x64\Release\bin\SourceControl

Once you copy the DLL, you can launch Wwise and it will detect Plastic SCM as an available VCS.

After loading a project, either a new or existing one, you need to configure Wwise to use Plastic SCM as version control.

First, you need to ensure that the Wwise project is contained within a Plastic workspace (at the moment, workspaces cannot be created directly from Wwise).

Then, go to Project > Project Settings or press Shift + K to open the Project Settings dialog.

Change the "Plug-in" dropdown selector under "Source Control" to "Plastic SCM".

The "Config..." button will become enabled, so click it to display the following version control settings:

Path to cm - Full path to your CLI executable. Note that the Unity Version Control installer configures the alias cm for you automatically, which should be enough. However, you can use this field to reference a different path to your preferred cm.exe.

Project root path - Full path to your project directory. This might not be the same as the workspace root.

Test connection - Helping button to test the connection to your Unity Version Control workspace.

Path to mergetool - You can optionally define the mergetool path to launch diffs from inside Wwise.

You can perform VCS operations from the Project Explorer inside Wwise by right-clicking items and expanding the Source Control actions.

If you want to have a general overview of your project and update/checkin items globally, you can open the File Manager.

You can do that by selecting menu item Project > File Manager or by pressing Shift + F1.

In the File Manager window, you can either right-click items to perform VCS actions (multiple selection is allowed) or click the "Checkin" or "Update" actions. Those will checkin/update all applicable items in the workspace.

**Examples:**

Example 1 (unknown):
```unknown
C:\Program Files\PlasticSCM5\client\plugins\wwise
```

Example 2 (unknown):
```unknown
C:\Program Files (x86)\Audiokinetic\Wwise x.y.z\Authoring\x64\Release\bin\SourceControl
```

---

## Undo or revert changes

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/gluon/undo-revert

**Contents:**
- Undo or revert changes#

Use Gluon to undo changes and deletions, or revert to a previous revision.

---

## Safety Moderator

**URL:** https://docs.unity.com/ugs/en-us/manual/moderation/manual/safety-moderator/use-sv-as-a-moderator

**Contents:**
- Safety Moderator#

Safety Moderator is a role that is assigned to a user within a project to gain access to the Moderation Platform.

The Moderation Platform assists moderation teams with online experiences by providing additional context, through Safe Text, to user communications. Safe Text will highlight text messages that are identified as inappropriate. The analysis generates a report for the moderation team to aid in decision-making and help the moderation team prioritize and quickly identify whether the incident violated any policies.

Safety Moderators can:

---

## Hot copy back up and restore

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/backups/hot-copy

**Contents:**
- Hot copy back up and restore#
  - Backup#
  - Restore#

Perform the hot backup and restore operations for your Unity Version Control (UVCS) server. Both of these operations require you to enter read-only mode.

Note: You can also create a hot copy with rdiff.

**Examples:**

Example 1 (unknown):
```unknown
cm admin readonly enter
```

Example 2 (unknown):
```unknown
cm admin readonly leave
```

Example 3 (unknown):
```unknown
cm admin readonly enter
```

Example 4 (unknown):
```unknown
cm admin readonly leave
```

---

## Server Query Protocol

**URL:** https://docs.unity.com/ugs/en-us/manual/game-server-hosting/manual/concepts/sqp

**Contents:**
- Server Query Protocol#
- Requirements#
- Reference implementation#
- Data types#
- Request types#
- Packet types#
- Headers#
  - Challenge numbers#
- Challenge packets#
  - Request format#

The Server Query Protocol (SQP) allows clients to retrieve information about a running game server using UDP/IP packets.

A client initiates queries by sending a ChallengeRequest to the server. In response, the server sends a ChallengeResponse that includes a ChallengeId. After the client receives the ChallengeResponse, it can continue to query the server for information.

The following sections describe the technical specifications of SQP, including data types, request types, and packet formats.

Game server state information that SQP supports includes:

Note: SQP works with the Multiplay Hosting game server monitoring process to make sure reports by the game server match the information in Multiplay Hosting’s database.

Before implementing SQP as the game server query protocol, you must populate the ServerInfoData object with all the game server information on the game client end. This ensures the game server reports the correct information.

Refer to go-svrquery for an example implementation of SQP. go-svrquery is a Golang client or talking to game servers using various query protocols, including SQP.

All server queries consist of five basic types of data packed together into a data stream. The following table describes each of these types. All types are big-endian.

A client can make five types of requests to a server. The following table specifies the response a client should expect from the server for each request type.

The following table has the distinct types of SQP packets.

All SQP packets, whether they're a request or a response, contain a header with the following data.

SQP uses a challenge number (which is a random 32-bit integer) to ensure the client making query requests is the same client that received the challenge number.

When a client first sends a request to a server, the server randomly selects the challenge number and includes it in the packet header. The client must then include the same challenge number in the header of all following requests.

Clients can use challenge packets to retrieve a usable challenge number for a following request.

Note: Challenge packets only have a header. There is no payload.

The following code snippet has an example of a ChallengeRequest packet:

The following code snippet has an example of a ChallengeResponse packet:

Clients can send query packets to retrieve information about a server. Multiplay Hosting only requires game servers to respond to queries with ServerInfo chunks. You can use the other request types but they're not necessary for Multiplay Hosting.

There are four different types of chunks that clients can request with a query packet. However, this documentation only includes the ServerInfo chunk type since it's the only one Multiplay Hosting supports.

The byte value of each chunk type indicates the response chunk that the requesting client expects. When a server receives a query packet, it inspects the RequestedChunks field in the request and performs a bitwise AND operation using the byte value of the chunk type. The server knows a chunk type has been requested if the result of this operation is greater than zero.

For example, the server responds with a ServerInfo chunk if RequestedChunks&1 > 0. Refer to note below.

Note: Although there are four types of chunk types available in the SQP protocol, Multiplay Hosting only supports the ServerInfo chunk type.

Note: RequestedChunks can request more than one chunk at the same time, so your implementation must be able to perform the correct bitwise checks on the RequestedChunks value.

The request format is the same for all query requests.

Note: Multiplay Hosting only requires a server to respond to ServerInfo requests. Therefore, all other request types are omitted.

The following code snippet has an example of a QueryRequest packet:

All chunk types share a standard response format for the first four fields (Version, CurrentPacket, LastPacket, and PacketLength). Information after the PacketLength field of a packet varies depending on the request type.

The following table has the part of the response that's the same for all chunk types.

The following code snippet has an example of a QueryResponse packet:

**Examples:**

Example 1 (unknown):
```unknown
ChallengeRequest
```

Example 2 (unknown):
```unknown
ChallengeResponse
```

Example 3 (unknown):
```unknown
ChallengeId
```

Example 4 (unknown):
```unknown
ChallengeResponse
```

---

## Unity Version Control On-Prem

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-on-prem/overview

**Contents:**
- Unity Version Control On-Prem#
- Seat management#
- Additional resources#

Unity offers a Unity Version Control (UVCS) On-Prem license if you want to use your own on-premises server instead of the Unity Cloud.

Note: If you want a cloud based version control system, refer to Unity Version Control.

If you need further assistance with your purchase or your company has a procurement process in place, please contact the Sales team for additional support.

The following topics explain how to configure and manage your UVCS On-Prem server and clients as an administrator. For documentation on how to use UVCS in general, refer to the additional resources.

You can purchase and manage On-Prem seats through the Version Control > Seats > On-Prem page of the Unity Dashboard.

To manage DevOps seats, refer to the Unity DevOps Seat Management documentation.

The following sections of the Unity Version Control documentation are relevant to On-Prem users:

---

## Context analysis

**URL:** https://docs.unity.com/ugs/en-us/manual/safe-text/manual/concepts/context-analysis

**Contents:**
- Context analysis#

Context analysis is a feature that receives automated AI based analysis on text-based messages for additional textual context. Context analysis detects specific toxicity types by analyzing the conversation to help provide a complete picture of text interactions.

Once Context analysis is in a project, text messages are analyzed for inappropriate content and highlighted within player reports and incidents. These text detections happen in real-time. When detected, they're added to the Moderation queue.

---

## Client side variables

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/triggers/concepts/client-variables

**Contents:**
- Client side variables#
- client.conf variables#
- UVCS predefined variables#
  - Example trigger#

You can use relative or user-defined paths to customize client-side triggers. You can build the script execution paths in the following ways:

These approaches allow you to define client-side triggers across platforms.

You can define custom variables in the client.conf file in your home directory. To use the custom variable when you create a client-side trigger, you need to add a new section with the TriggerVariables in the client.conf file. The example below defines a variable called TRIGGERS_PATH with the c:\triggers value:

You can use this variable to assign a path when you create a client-side trigger. You can give the path a name that you can use later with your triggers. Refer to the following example:

cm trigger create before-clientcheckin "client code checker" "@TRIGGERS_PATH\addformat.bat"

There are several predefined values that you can use to compose the script field value when you create a client-side trigger:

Create a trigger that executes a script in the global configuration directory of the server you're using:

Note: You can use either the \ or the / separator with these variables in Windows and Linux. For example, if you enter "@PLASTIC_BIN_PATH/triggers/checkdirectories.pl" in a Windows platform, the client-side trigger can identify the separator and interpret it as: "@PLASTIC_BIN_PATH\triggers\checkdirectories.pl".

Note: Use @ to refer to these variables.

**Examples:**

Example 1 (unknown):
```unknown
client.conf
```

Example 2 (unknown):
```unknown
client.conf
```

Example 3 (unknown):
```unknown
client.conf
```

Example 4 (unknown):
```unknown
TriggerVariables
```

---

## Google

**URL:** https://docs.unity.com/ugs/en-us/manual/authentication/manual/platform-signin-google

**Contents:**
- Google#
- Set up a Google sign-in#
- Sign in a returning player or create new player#
- Update a player from anonymous to a Google account#
- Unlink Google account#

Deprecated: The approach documented below relies on the Google Sign-In API and games v1 SDK. Google has deprecated them for new titles as of Feburary 2025. Please see the notice in Google's documentation for more details.

Unity will be evaluating how best to support Sign in with Google going forward. In the mean time we recommend using Google Play Games for a frictionless Android login experience, or Unity Player Accounts which supports a web-based Sign in with Google flow on all platforms.

This article guides you through the following scenarios in setting up authentication for players in your game with a Google account:

Attention: The following concerns products or services (each a “Third Party Product”) that are not developed, owned, or operated by Unity. This information might not be up-to-date or complete, and is provided to you for your information and convenience only. Your access and use of any Third Party Product is governed solely by the terms and conditions of such Third Party Product. Unity makes no express or implied representations or warranties regarding such Third Party Products, and will not be responsible or liable, directly or indirectly, for any actual or alleged damage or loss arising from your use thereof (including damage or loss arising from any content, advertising, products or other materials on or available from the provider of any Third Party Products).

To provide a Google sign-in option for the players in your game, create your app in the Google Play Console and install Google Play Games plugin for Unity v10.14 to sign in the player and get the access token. This requires an Open Authentication (ID) access token to identify the player to other services such as Firebase or Google.

For plugin versions running v10.14 and later, refer to Google Play Games.

Note: The code example below assumes you already have the player's Google ID Token.

Note: Google sign-in is supported by Google Play Games plugin for Unity v10.14 and below which uses Play Games Services v1 SDK.

Note: You must set a Web App client ID in the plugin setup dialog to use the Authentication SDK.

Use the SignInWithGoogleAsync method to either:

After you’ve set up anonymous authentication, if the player wants to upgrade from being anonymous to creating a Google account and sign in, your game should prompt the player to trigger the Google sign-in and get the ID token from Google. Then, call the LinkWithGoogleAsync API to link the player to the Google ID token.

If a cached player exists on the SDK, you can link the cached player to the Google Account.

For more information about cached players, refer to Sign In a Cached Player.

Use the UnlinkGoogleAsync API so your players can unlink their Google account. Once unlinked, if their account isn’t linked to any additional identity, it transitions to an anonymous account.

**Examples:**

Example 1 (unknown):
```unknown
{
    ((PlayGamesLocalUser)Social.localUser).GetIdToken()
}
```

Example 2 (unknown):
```unknown
{
    ((PlayGamesLocalUser)Social.localUser).GetIdToken()
}
```

Example 3 (unknown):
```unknown
void InitializePlayGamesLogin()
{
    var config = new PlayGamesClientConfiguration.Builder()
        // Requests an ID token be generated.
        // This OAuth token can be used to
        // identify the player to other services such as Firebase.
        .RequestIdToken()
        .Build();

    PlayGamesPlatform.InitializeInstance(config);
    PlayGamesPlatform.DebugLogEnabled = true;
    PlayGamesPlatform.Activate();
}

void LoginGoogle()
{
    Social.localUser.Authenticate(OnGoogleLogin);
}

void OnGoogleLogin(bool success)
{
    if (success)
    {
        // Call Unity Authentication SDK to sign in or link with Google.
        Debug.Log("Login with Google done. IdToken: " + ((PlayGamesLocalUser)Social.localUser).GetIdToken());
    }
    else
    {
        Debug.Log("Unsuccessful login");
    }
}
```

Example 4 (unknown):
```unknown
void InitializePlayGamesLogin()
{
    var config = new PlayGamesClientConfiguration.Builder()
        // Requests an ID token be generated.
        // This OAuth token can be used to
        // identify the player to other services such as Firebase.
        .RequestIdToken()
        .Build();

    PlayGamesPlatform.InitializeInstance(config);
    PlayGamesPlatform.DebugLogEnabled = true;
    PlayGamesPlatform.Activate();
}

void LoginGoogle()
{
    Social.localUser.Authenticate(OnGoogleLogin);
}

void OnGoogleLogin(bool success)
{
    if (success)
    {
        // Call Unity Authentication SDK to sign in or link with Google.
        Debug.Log("Login with Google done. IdToken: " + ((PlayGamesLocalUser)Social.localUser).GetIdToken());
    }
    else
    {
        Debug.Log("Unsuccessful login");
    }
}
```

---

## TRIGGER CREATE

**URL:** https://docs.unity.com/ugs/en-us/manual/devops/manual/uvcs-cli/trigger-create

**Contents:**
- TRIGGER CREATE#
- Description#
  - Usage#
  - Options#
- Help#
  - Remarks#
  - Examples#

Creates a new trigger on a server.

cm trigger | tr create | mk <subtype-type> <new_name> <script_path> [--position=<new_position>] [--filter=<str_filter>] [--server=<repserverspec>]

Web triggers: A web trigger is created by typing "webtrigger <target-uri>" as the trigger command. In this case, the trigger will execute a POST query against the specified URI -where the request body contains a JSON dictionary with the trigger environment variables- and a fixed INPUT key pointing to an array of strings.

cm trigger create after-setselector "BackupMgr" "/path/to/script" --position=4

cm tr mk before-mklabel new "/path/to/script" --server=myserver:8084

cm tr mk after-mklabel Log "/path/to/script" --filter="rep:myRep,LB*"

(This trigger will be executed only if the label name starts with 'LB' and it is being created in a repository called 'myRep'.)

cm tr mk after-checkin NotifyTeam "webtrigger http://myserver.org/api"

**Examples:**

Example 1 (unknown):
```unknown
cm trigger | tr create | mk <subtype-type> <new_name> <script_path> [--position=<new_position>] [--filter=<str_filter>] [--server=<repserverspec>]
```

Example 2 (unknown):
```unknown
cm trigger create after-setselector "BackupMgr" "/path/to/script" --position=4
```

Example 3 (unknown):
```unknown
cm tr mk before-mklabel new "/path/to/script" --server=myserver:8084
```

Example 4 (unknown):
```unknown
cm tr mk after-mklabel Log "/path/to/script" --filter="rep:myRep,LB*"
```

---

## Daily rewards

**URL:** https://docs.unity.com/ugs/en-us/solutions/manual/DailyRewards

**Contents:**
- Daily rewards#
- Prerequisites#
- Overview#
  - Initialization#
  - Functionality#
- Setup#
  - Requirements#
  - Unity Cloud services configuration#
    - Using the Deployment package#
    - Using the Unity Dashboard#

Daily reward calendars are prevalent engagement features that can boost retention in games of all genres. Showing players an escalating series of rewards in advance incentivizes them to keep signing in to claim better and better prizes. This sample demonstrates how to present a calendar of rewards that increase in value over time, which encourages players to return each day to claim them. This implementation permits skipping days, but the player always claims rewards sequentially. If they miss a day, the same reward is available the next day. The player must claim a given day's reward to unlock the subsequent day's reward.

To use this sample use case, you must download and install the UGS Use Cases project in your Unity project.

This sample demonstrates how to initialize Unity Services, retrieve and update current values from the Economy service, call Cloud Code to retrieve the updated status, and then claim each day's reward.

Note: Unity recommends implementing daily rewards by setting the start epoch time with Remote Config so all players experience the event starting on the first day of the month. However, to facilitate testing, this implementation saves the event start value to Cloud Save, so the event "month" starts when you first open the scene. Each "day" is also compressed into 30 seconds, which allows you to quickly test claiming an entire month's rewards.

To see this use case in action, open the samples menu and navigate to Daily Rewards. To open this scene directly and interact with the use case:

The DailyRewardsSceneManager.cs script performs the following initialization tasks in its Start function:

When you dismiss the event prompt, the scene begins tracking the passage of time to determine whether you claim a reward within the eligible window for a given day. For testing purposes, each "day" lasts about 30 seconds. Each calendar node has a Claim button that is only active when two conditions are met:

When you click an active Claim button, you receive the reward for that day. The following occurs:

If the client remains idle (you do not claim the reward within a day's timeframe), the Days Left UI indicator decreases, which indicates that you missed a day. If you miss a day, you can still claim the previous day's reward.

In this sample, the month is 31 days. If you claim rewards for at least 28 days in that month, you are eligible for a bonus reward each additional day until the event ends (up to 3 times, if every day is collected on time). When the event ends (31 days expire), you can dismiss the daily rewards window and click the Daily Rewards button in the bottom-right corner to begin a new event.

To replicate this use case, you'll need the following Unity packages in your project:

To use these services in your game, activate each service for your Organization and project in the Unity Dashboard.

To replicate this sample scene's setup in your own Unity project, configure the following items:

To configure these items you can use the Deployment package, or manually enter them using the Unity Dashboard. The recommended best practice is to use the Deployment package as it greatly accelerates this process.

To deploy configurations using the Deployment package:

This deploys all the necessary items.

You can use the Unity Dashboard to manually configure your services by project and environment. Refer to the following sections to configure this sample.

Publish the following scripts in the Unity Dashboard:

Note: The Cloud Code scripts included in the Cloud Code folder are local copies because you cannot view the sample project's dashboard. Changes to these scripts do not affect the behavior of this sample because they are not automatically uploaded to the Cloud Code service.

Configure the following resources in the Unity Dashboard:

This sample also uses Addressable Assets to implement the sprite icons for all Economy currencies. As the developer, you can add the Addressables address of the icon for each currency directly in the Economy dashboard, and then retrieve it at runtime without needing to change your code. This is helpful if for example, you want to swap in holiday-themed sprites by changing the address in your dashboard instead of updating your app. To do this for each currency:

This configuration allows the service to determine each currency's Addressable address and initialize all icons with the proper sprites. Later, when the application needs the icons (for example, when showing the currencies granted for claiming a daily reward), it uses that currency's ID as a dictionary key to quickly find the associated sprite.

This functionality occurs in the sample's EconomyManager.cs script, in the InitializeCurrencySprites method that is called at startup to initialize the dictionary with all currency icons, and the GetSpriteForCurrencyId method that looks up currency IDs (such as COIN) to find the associated sprite.

**Examples:**

Example 1 (unknown):
```unknown
DailyRewardsSample.unity
```

Example 2 (unknown):
```unknown
DailyRewardsSceneManager.cs
```

Example 3 (unknown):
```unknown
DailyRewardsSceneManager.cs
```

Example 4 (unknown):
```unknown
OnClaimButtonPressed
```

---

## Privacy and consent for the Vivox SDK

**URL:** https://docs.unity.com/ugs/en-us/manual/vivox-unity/manual/Unity/privacy/privacy-and-consent

**Contents:**
- Privacy and consent for the Vivox SDK#
- Privacy overview#
- Apple privacy survey#
- Google Play data safety#

The following privacy guides apply to each Vivox SDK.

iOS publishers must define what data their apps collect, including the data collected by integrated third-party SDKs.

Android developers publishing on the Google Play store must define what data their apps collect, including the data collected by integrated third-party SDKs.

---
